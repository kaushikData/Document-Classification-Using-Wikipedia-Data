{"id": "36175304", "url": "https://en.wikipedia.org/wiki?curid=36175304", "title": "Actuarial Society of South Africa HIV/AIDS models", "text": "Actuarial Society of South Africa HIV/AIDS models\n\nThe Actuarial Society of South Africa HIV/AIDS models, also known as ASSA AIDS models, are a series of mathematical models developed to assist the actuarial profession and the Actuarial Society of South Africa in assessing and addressing the impact of the HIV and AIDS epidemic in South Africa. The models have been developed by the AIDS Committee of the Society and the Center for Actuarial Research (CARe) at the University of Cape Town in Cape Town, South Africa.\n\nIn 1996 the first and earliest version of ASSA AIDS model ASSA500 was developed by the AIDS Committee of the society, While the ASSA2008 model is the most recent version of ASSA AIDS and demographic model which was released in March 2011. The models have assisted insurers and those insured to have fair and balanced insurance policies in a country ravaged by AIDS.\n\nA joint task team of the South African National Department of Health and the Treasury used the ASSA model to estimate the impact of extending the life of AIDS patients.\n\nASSA is one of only two models used in South Africa; both are capable of making projections on the progression of the epidemic through an interaction of many factors. Four population risk groups are included, along with assumptions about sexual behaviour, rates of infection, conception rates, the median duration to mortality of those with HIV/AIDS, and the rates of transmission between mother and child. The impact of drug treatments at birth and while nursing, enhanced STD treatment, and risk avoidance is projected by a lower rate scenario The model makes provisions for migration of the population, separate modeling of racial groups, and separate modeling of provincial populations.\n\nA study by the South African National Department of Health and the Treasury used the ASSA model to project a positive result for the increased implementation of antiretroviral drugs (ARV) in the country, although their cost is a problem.\n\n\n"}
{"id": "193911", "url": "https://en.wikipedia.org/wiki?curid=193911", "title": "Albert Wohlstetter", "text": "Albert Wohlstetter\n\nAlbert James Wohlstetter (December 19, 1913 – January 10, 1997) was an influential and controversial nuclear strategist during the Cold War. He and his wife Roberta Wohlstetter, an accomplished historian and intelligence expert, received the Presidential Medal of Freedom from Ronald Reagan on November 7, 1985.\n\nAlbert Wohlstetter's paternal grandparents were cosmopolitan Jews who immigrated to the United States from the Austro-Hungarian Empire in the latter half of the nineteenth century. Albert's father, Philip, was born in the United States about twenty years later.\n\nAlbert was born on 19 December 1913, the fourth and youngest child of Philip Wohlstetter and Nellie (née Friedman). Albert's older siblings were William (1902–1967), Helene (1906–1974) and Charles (1910–1995). Albert's brother Charles was an accomplished businessman who would help Albert get his start as a young man. Charles also employed Helene at one of his companies, ConTel, where she was killed in a shooting by a disgruntled employee in 1974.\n\nThe Wohlstetters lived in the Washington Heights neighborhood of Manhattan. Philip Wohlstetter had attended City College of New York was an attorney and the Chief Legal Council to the Metropolitan Opera Company. In 1912, he founded one of the early phonograph companies, the Rex Talking Machine Corporation. Luminaries of the performance world were regular guests in the Wohlstetter home. The Rex company was taken over and its Wilmington, Delaware factory converted to war production during the First World War. Philip died of a heart attack in 1918 when Albert was four years old.\n\nWohlstetter started at City College of New York in 1931 through a scholarship in modern dance, earning a B.A. in 1934.\n\nWohlstetter started at Columbia Law School on a fellowship in 1934. It was in a class there that he met Roberta Morgan. Wohlstetter was bored by the law and left the program after only one year. But he stayed at Columbia to pursue a Ph.D. in mathematical logic and the philosophy of science. He studies under Abraham Wald where he was a peer of Jacob Wolfowitz. After a thesis titled \"Language and Empiricism\" earned him an M.A. in June 1937, several fellowships allowed him to work on is dissertation. He had a fellowship with the Social Science Research Council on a project to incorporate modern mathematical methods into economics and business cycle research. From 1941–1942 he was a research associate at the National Bureau of Economic Research.\n\nIn August 1942 the Wohlstetters vacationed with Dwight Macdonald, one of the editors of \"Partisan Review\", and his wife, Nancy in Nantucket.\n\nHe left Columbia's graduate program when the Second World War started to work for the U.S. government on war planning and never completed his doctorate.\n\nDuring the Second World War, Wohlstetter worked on problems of war production. He was first hired by the Planning Committee of the War Production Board. It is unclear how he ended up there. In an interview, Wohlstetter says that while on the Carnegie associateship with NBER, Simon Kuznets was hired by Robert R. Nathan and it was Kuznets who hired Wohlstetter. Albert's brother Charles recounts that it was Arthur F. Burns who gave Albert the job.\n\nLater he worked at Atlas Aircraft Products Company.\n\nAfter the war, Wohlstetter worked briefly in business in New York. He moved back to Washington, D.C. to serve as the Director of Programs for the National Housing Agency (USHA) in 1946 and 1947, the only time in his career he was a federal employee. At the USHA Wohlstetter worked with Paul Weidlinger, an engineer who had worked during the war for an aircraft company owned by Albert's brother, Charles, designing modular buildings such as airplane hangers that could be assembled quickly. At the USHA Wohlstetter and Weidlinger worked on applying such principles to domestic residential buildings.\n\nDuring the 1937–1938 school year, Roberta had worked as a teaching assistant at the University of Southern California, during which time she became enamored with the California lifestyle. At her urging, and with his brother Charles helping to secure a job for Albert, the Wohlstetters moved to Santa Monica in 1947. Albert went to work for the General Panel Corporation to \"tool up\" their industrial plant. General Panel Corporation was a company founded by Walter Gropius and Konrad Wachsmann, two important figures in the Bauhaus movement.\n\nWhile on a walk, Albert and Roberta ran into Abe Girschick, Olaf Helmer and Chen McKinsey on the street in Santa Monica. Albert knew the three from his days as a student and in government service. The three mathematicians \"... were overjoyed to see us. Mathematical logic was a very, very small world. There were only a little over a dozen mathematical logicians before the war in the United States ...\" Girschick, Helmer and McKinsey were working at the recently formed RAND Corporation. With their help, Hans Speier, the head of the RAND social science division, hired Roberta, initially to write book abstracts for circulation to the RAND staff. When General Panel Corporation finally went out of business in 1951, Albert wanted to return to academia in the east, but Roberta was intent on remaining in California. She set up a meeting between Albert and Charles J. Hitch, the head of the RAND economics department. The two hit it off and Wohlstetter was brought on as a consultant to the Mathematics Department.\n\nWohlstetter remained a consultant with RAND for the first few years. It was not until June or July 1953, a few months after he began briefing \"Selection and Use of Strategic Air Bases\" to the Air Force that Hitch finally insisted that his consultant status was \"absurd\" and that he join the permanent staff.\n\nAt RAND, he researched how to posture and operate U.S. strategic nuclear forces to deter plausible forms of Soviet nuclear-armed aggression in way that was credible, cost-effective and controllable.\n\nWohlstetter's 1958 'The Delicate Balance of Terror' was highly influential in shaping the thinking of the Washington foreign policy establishment, particularly in its emphasis on the looming threat of Soviet attack.\n\nThe relationship between Bernard Brodie and Wohlstetter grew increasingly acrimonious and personal. In 1963, Brodie accused Wohlstetter of a security violation and financial malfeasance. Wohlstetter had shared a draft RAND paper by Constantin Melnik with Henry Rowen, then one of the Whiz Kids working as the Deputy Assistant Secretary of Defense for International Security Affairs at McNamara's Pentagon. Brodie also claimed that Wohlstetter was extravagant in wining and dining clients and colleagues using RAND funds. Wohlstetter defended himself by pointing out that the Melnik paper was only a \"D\" designated document, RAND's lowest level classification, and as a former RAND employee who had collaborated extensively with Wohlstetter on some of his most important studies, Rowen was authorized to receive the paper. Nevertheless, RAND Director Frank Collbohm demanded that Wohlstetter submit his resignation. When Wohlstetter refused, Collbohm fired him, but agreed to let Wohlstetter stay on at RAND long enough to find another job.\n\nAt the suggestion of Hans Morgenthau and with his help, Wohlstetter secured a position as a professor of political science at the University of Chicago.\n\nIn the 1960s and 1970s, he expanded the scope of his research to include alliance policy and nuclear nonproliferation, ballistic missile defense, innovation in military technology, peacetime military competitions, and military potential and economics of civil nuclear energy.\n\nIn the 1980s, Wohlstetter frequently criticized proponents of mutual assured destruction who supported targeting of nuclear weapons on civilians and cities instead over enemy combatants and military forces.\n\nWohlstetter and his wife, Roberta Wohlstetter, also counseled both Democratic and Republican administrations, including advisers to President John F. Kennedy during the Cuban missile crisis in 1962. They received the Presidential Medal of Freedom from Ronald Reagan on November 7, 1985.\n\nDuring his long career, Wohlstetter also taught at UCLA and the University of California, Berkeley, in the early 1960s. From 1964 to 1980, he taught in the political science department of the University of Chicago, and chaired the dissertation committees of Paul Wolfowitz and Zalmay Khalilzad. He is often credited with influencing a number of prominent members of the neoconservative movement, including Richard Perle (who, as a teenager, dated Wohlstetter's daughter Joan). He is the uncle of John Wohlstetter, author of \"Sleepwalking with the Bomb\" and \"The Long War Ahead and The Short War Upon Us\".\n\nOn 16 December 1996, his 83rd birthday, Wohlstetter was not feeling well. He and Roberta thought he was just ill or having an asthma attack. Over the telephone from New York their daughter Joan reviewed the symptoms for a heart attack and told Roberta to call an ambulance. Albert made a fuss, not wanting to go to the emergency room. At the hospital he was diagnosed as having had a serious heart attack and was discharged home with around-the-clock nursing care. In the living room he set up a makeshift chair that allowed him to partially recline so he could continue to work. A month later, on 10 January 1997, Wohlstetter died at his Laurel Canyon home.\n\nA memorial was held at the office of the RAND Corporation and a month later Senator Jon Kyl and special guest Richard Perle conducted a brief remembrance in the Senate chamber. Albert Wohlstetter is buried at Westwood Village Memorial Park Cemetery in Los Angeles. Roberta Wolstetter died on 6 January 2007.\n\nHe was twice awarded the Department of Defense Medal for Distinguished Public Service, first by Robert McNamara in February 1965 and again by Donald Rumsfeld in November 1976. He is the first recipient not employed by the Department of Defense and the first person awarded it twice.\n\nOn 7 November 1985 President Reagan awarded Albert Wohlstetter, along with his wife Roberta Wohlstetter and Paul Nitze, the Presidential Medal of Freedom.\n\nThe \"Albert J. and Roberta Wohlstetter Papers\" are available at the Hoover Institution Archives at Stanford University.\n\nWohlstetter served as an inspiration for Stanley Kubrick's film, \"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\". In 1962, Kubrick was looking for his next project after \"Lolita\" and started reading intensively on nuclear issues. One of Kubrick's early ideas was to make a realistic thriller, titled after Wohlstetter's \"Delicate Balance of Terror\". But Kubrick could not conceive of a realistic scenario for an accidental nuclear war, so turned instead to the idea of making a comedy. While the character of Dr. Stragelove is a composite of numerous people associated with RAND (Dr. Strangelove confesses to the president having commissioned a study by \"the Bland Corporation\" of the possibility of a doomsday device) in the movie that was made, he is mostly based on Herman Kahn, John von Neumann, Wernher von Braun and Edward Teller.\n\nFor a more complete list of the works of Albert Wohlstetter, see the Albert Wohlstetter Bibliography at the Nonproliferation Policy Education Center's AlbertWohlstetter.com website.\n\n\n\n\n\n\n"}
{"id": "2829647", "url": "https://en.wikipedia.org/wiki?curid=2829647", "title": "Algorithmic information theory", "text": "Algorithmic information theory\n\nAlgorithmic information theory is a subfield of information theory and computer science that concerns itself with the relationship between computation and information. According to Gregory Chaitin, it is \"the result of putting Shannon's information theory and Turing's computability theory into a cocktail shaker and shaking vigorously.\"\n\nAlgorithmic information theory principally studies complexity measures on strings (or other data structures). Because most mathematical objects can be described in terms of strings, or as the limit of a sequence of strings, it can be used to study a wide variety of mathematical objects, including integers.\n\nThe theory was founded by Ray Solomonoff, who published the basic ideas on which the field is based as part of his invention of algorithmic probability—a way to overcome serious problems associated with the application of Bayes' rules in statistics. He first described his results at a Conference at Caltech in 1960, and in a report, February 1960, \"A Preliminary Report on a General Theory of Inductive Inference.\"\n\nAlgorithmic information theory was later developed independently by Andrey Kolmogorov, in 1965 and Gregory Chaitin, around 1966. There are several variants of Kolmogorov complexity or algorithmic information; the most widely used one is based on self-delimiting programs and is mainly due to Leonid Levin (1974).\n\nPer Martin-Löf also contributed significantly to the information theory of infinite sequences. An axiomatic approach to algorithmic information theory based on the Blum axioms (Blum 1967) was introduced by Mark Burgin in a paper presented for publication by Andrey Kolmogorov (Burgin 1982). The axiomatic approach encompasses other formulations.\n\nAlgorithmic information theory principally studies complexity measures on strings (or other data structures). Because most mathematical objects can be described in terms of strings, or as the limit of a sequence of strings, it can be used to study a wide variety of mathematical objects, including integers.\n\nInformally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string. A self-contained representation is essentially a program—in some fixed but otherwise irrelevant universal programming language—that, when run, outputs the original string.\n\nFrom this point of view, a 3000-page encyclopedia actually contains less information than 3000 pages of completely random letters, despite the fact that the encyclopedia is much more useful. This is because to reconstruct the entire sequence of random letters, one must know, more or less, what every single letter is. On the other hand, if every vowel were removed from the encyclopedia, someone with reasonable knowledge of the English language could reconstruct it, just as one could likely reconstruct the sentence \"Ths sntnc hs lw nfrmtn cntnt\" from the context and consonants present.\n\nUnlike classical information theory, algorithmic information theory gives formal, rigorous definitions of a random string and a random infinite sequence that do not depend on physical or philosophical intuitions about nondeterminism or likelihood. (The set of random strings depends on the choice of the universal Turing machine used to define Kolmogorov complexity, but any choice\ngives identical asymptotic results because the Kolmogorov complexity of a string is invariant up to an additive constant depending only on the choice of universal Turing machine. For this reason the set of random infinite sequences is independent of the choice of universal machine.)\n\nSome of the results of algorithmic information theory, such as Chaitin's incompleteness theorem, appear to challenge common mathematical and philosophical intuitions. Most notable among these is the construction of Chaitin's constant Ω, a real number which expresses the probability that a self-delimiting universal Turing machine will halt when its input is supplied by flips of a fair coin (sometimes thought of as the probability that a random computer program will eventually halt). Although Ω is easily defined, in any consistent axiomatizable theory one can only compute finitely many digits of Ω, so it is in some sense \"unknowable\", providing an absolute limit on knowledge that is reminiscent of Gödel's Incompleteness Theorem. Although the digits of Ω cannot be determined, many properties of Ω are known; for example, it is an algorithmically random sequence and thus its binary digits are evenly distributed (in fact it is normal).\n\nAlgorithmic information theory was founded by Ray Solomonoff, who published the basic ideas on which the field is based as part of his invention of algorithmic probability—a way to overcome serious problems associated with the application of Bayes' rules in statistics. He first described his results at a Conference at Caltech in 1960, and in a report, February 1960, \"A Preliminary Report on a General Theory of Inductive Inference.\" Algorithmic information theory was later developed independently by Andrey Kolmogorov, in 1965 and Gregory Chaitin, around 1966.\n\nThere are several variants of Kolmogorov complexity or algorithmic information; the most widely used one is based on self-delimiting programs and is mainly due to Leonid Levin (1974). Per Martin-Löf also contributed significantly to the information theory of infinite sequences. An axiomatic approach to algorithmic information theory based on the Blum axioms (Blum 1967) was introduced by Mark Burgin in a paper presented for publication by Andrey Kolmogorov (Burgin 1982). The axiomatic approach encompasses other approaches in the algorithmic information theory. It is possible to treat different measures of algorithmic information as particular cases of axiomatically defined measures of algorithmic information. Instead of proving similar theorems, such as the basic invariance theorem, for each particular measure, it is possible to easily deduce all such results from one corresponding theorem proved in the axiomatic setting. This is a general advantage of the axiomatic approach in mathematics. The axiomatic approach to algorithmic information theory was further developed in the book (Burgin 2005) and applied to software metrics (Burgin and Debnath, 2003; Debnath and Burgin, 2003).\n\nA binary string is said to be random if the Kolmogorov complexity of the string is at least the length of the string. A simple counting argument shows that some strings of any given length are random, and almost all strings are very close to being random. Since Kolmogorov complexity depends on a fixed choice of universal Turing machine (informally, a fixed \"description language\" in which the \"descriptions\" are given), the collection of random strings does depend on the choice of fixed universal machine. Nevertheless, the collection of random strings, as a whole, has similar properties regardless of the fixed machine, so one can (and often does) talk about the properties of random strings as a group without having to first specify a universal machine.\nAn infinite binary sequence is said to be random if, for some constant \"c\", for all \"n\", the Kolmogorov complexity of the initial segment of length \"n\" of the sequence is at least \"n\" − \"c\". It can be shown that almost every sequence (from the point of view of the standard measure—\"fair coin\" or Lebesgue measure—on the space of infinite binary sequences) is random. Also, since it can be shown that the Kolmogorov complexity relative to two different universal machines differs by at most a constant, the collection of random infinite sequences does not depend on the choice of universal machine (in contrast to finite strings). This definition of randomness is usually called \"Martin-Löf\" randomness, after Per Martin-Löf, to distinguish it from other similar notions of randomness. It is also sometimes called \"1-randomness\" to distinguish it from other stronger notions of randomness (2-randomness, 3-randomness, etc.). In addition to Martin-Löf randomness concepts, there are also recursive randomness, Schnorr randomness, and Kurtz randomness etc. Yongge Wang showed that all of these randomness concepts are different.\n\nAlgorithmic information theory (AIT) is the information theory of individual objects, using computer science, and concerns itself with the relationship between computation, information, and randomness.\n\nThe information content or complexity of an object can be measured by the length of its shortest description. For instance the string\n\ncodice_1\n\nhas the short description \"32 repetitions of '01'\", while\n\ncodice_2\n\npresumably has no simple description other than writing down the string itself.\n\nMore formally, the Algorithmic Complexity (AC) of a string x is defined as the length of the shortest program that computes or outputs x, where the program is run on some fixed reference universal computer.\n\nA closely related notion is the probability that a universal computer outputs some string x when fed with a program chosen at random. This Algorithmic \"Solomonoff\" Probability (AP) is key in addressing the old philosophical problem of induction in a formal way.\n\nThe major drawback of AC and AP are their incomputability. Time-bounded \"Levin\" complexity penalizes a slow program by adding the logarithm of its running time to its length. This leads to computable variants of AC and AP, and Universal \"Levin\" Search (US) solves all inversion problems in optimal time (apart from some unrealistically large multiplicative constant).\n\nAC and AP also allow a formal and rigorous definition of randomness of individual strings to not depend on physical or philosophical intuitions about non-determinism or likelihood. Roughly, a string is Algorithmic \"Martin-Löf\" Random (AR) if it is incompressible in the sense that its algorithmic complexity is equal to its length.\n\nAC, AP, and AR are the core sub-disciplines of AIT, but AIT spawns into many other areas. It serves as the foundation of the Minimum Description Length (MDL) principle, can simplify proofs in computational complexity theory, has been used to define a universal similarity metric between objects, solves the Maxwell daemon problem, and many others.\n\n\n"}
{"id": "25431925", "url": "https://en.wikipedia.org/wiki?curid=25431925", "title": "Alternating tree automata", "text": "Alternating tree automata\n\nIn automata theory, an alternating tree automaton (ATA) is an extension of nondeterministic tree automaton as same as alternating finite automaton extends nondeterministic finite automaton (NFA).\n\nThe emptiness problem (deciding whether the language of an input ATA is empty) and the universality problem for ATAs are EXPTIME-complete. The membership problem (testing whether an input tree is accepted by an input AFA) is in PTIME.\n"}
{"id": "243369", "url": "https://en.wikipedia.org/wiki?curid=243369", "title": "Archytas", "text": "Archytas\n\nArchytas (; ; 428–347 BC) was an Ancient Greek philosopher, mathematician, astronomer, statesman, and strategist. He was a scientist of the Pythagorean school and famous for being the reputed founder of mathematical mechanics, as well as a good friend of Plato.\n\nArchytas was born in Tarentum, Magna Graecia and was the son of Mnesagoras or Histiaeus. For a while, he was taught by Philolaus, and was a teacher of mathematics to Eudoxus of Cnidus. Archytas and Eudoxus' student was Menaechmus. As a Pythagorean, Archytas believed that only arithmetic, not geometry, could provide a basis for satisfactory proofs.\n\nArchytas is believed to be the founder of mathematical mechanics. As only described in the writings of Aulus Gellius five centuries after him, he was reputed to have designed and built the first artificial, self-propelled flying device, a bird-shaped model propelled by a jet of what was probably steam, said to have actually flown some 200 meters. This machine, which its inventor called \"The pigeon\", may have been suspended on a wire or pivot for its flight. Archytas also wrote some lost works, as he was included by Vitruvius in the list of the twelve authors of works of mechanics. Thomas Winter has suggested that the pseudo-Aristotelian \"Mechanical Problems\" is an important mechanical work by Archytas, not lost after all, but misattributed.\n\nArchytas named the harmonic mean, important much later in projective geometry and number theory, though he did not invent it. According to Eutocius, Archytas solved the problem of doubling the cube in his manner (though he believed \"that only arithmetic, not geometry\", could provide a basis for satisfactory proofs) with a geometric construction. Hippocrates of Chios before, reduced this problem to finding mean proportionals. Archytas' theory of proportions is treated in book VIII of Euclid's \"Elements\", where is the construction for two proportional means, equivalent to the extraction of the cube root. According to Diogenes Laertius, this demonstration, which uses lines generated by moving figures to construct the two proportionals between magnitudes, was the first in which geometry was studied with concepts of mechanics. The Archytas curve, which he used in his solution of the doubling the cube problem, is named after him.\n\nPolitically and militarily, Archytas appears to have been the dominant figure in Tarentum in his generation, somewhat comparable to Pericles in Athens a half-century earlier. The Tarentines elected him \"strategos\", 'general', seven years in a row – a step that required them to violate their own rule against successive appointments. He was allegedly undefeated as a general, in Tarentine campaigns against their southern Italian neighbors. The \"Seventh Letter\" of Plato asserts that Archytas attempted to rescue Plato during his difficulties with Dionysius II of Syracuse. In his public career, Archytas had a reputation for virtue as well as efficacy. Some scholars have argued that Archytas may have served as one model for Plato's philosopher king, and that he influenced Plato's political philosophy as expressed in \"The Republic\" and other works (i.e., how does a society obtain good rulers like Archytas, instead of bad ones like Dionysius II?).\n\nArchytas may have drowned in a shipwreck in the shore of Mattinata, where his body lay unburied on the shore until a sailor humanely cast a handful of sand on it. Otherwise, he would have had to wander on this side of the Styx for a hundred years, such the virtue of a little dust, \"munera pulveris\", as Horace calls it in Ode 1.28 on which this information on his death is based. The poem, however, is difficult to interpret and it is not certain that the shipwrecked and Archytas are in fact the same person.\n\nThe crater Archytas on the Moon is named in his honour.\n\nThe Archytas curve is created by placing a semicircle (with a diameter of d) on the diameter of one of the two circles of a cylinder (which also has a diameter of d) such that the plane of the semicircle is at right angles to the plane of the circle and then rotating the semicircle about one of its ends in the plane of the cylinder's diameter. This rotation will cut out a portion of the cylinder forming the Archytas curve.\n\nAnother way of thinking of this construction is that the Archytas curve is basically the result of cutting out a torus formed by rotating a hemisphere of diameter d out of a cylinder also of diameter d. A cone can go through the same procedures also producing the Archytas curve. Archytas used his curve to determine the construction of a cube with a volume of one third of that of a given cube.\n\n\n"}
{"id": "50882022", "url": "https://en.wikipedia.org/wiki?curid=50882022", "title": "Arithmetic Fuchsian group", "text": "Arithmetic Fuchsian group\n\nArithmetic Fuchsian groups are a special class of Fuchsian groups constructed using orders in quaternion algebras. They are particular instances of arithmetic groups. The prototypical example of an arithmetic Fuchsian group is the modular group formula_1. They, and the hyperbolic surface associated to their action on the hyperbolic plane often exhibit particularly regular behaviour among Fuchsian groups and hyperbolic surfaces.\n\nA quaternion algebra over a field formula_2 is a four-dimensional central simple formula_2-algebra. A quaternion algebra has a basis formula_4 where formula_5 and formula_6.\n\nA quaternion algebra is said to be split over formula_2 if it is isomorphic as an formula_2-algebra to the algebra of matrices formula_9.\n\nIf formula_10 is an embedding of formula_2 into a field formula_12 we shall denote by formula_13 the algebra obtained by extending scalars from formula_2 to formula_12 where we view formula_2 as a subfield of formula_17 via formula_10.\n\nA subgroup of formula_19 is said to be \"derived from a quaternion algebra\" if it can be obtained through the following construction. Let formula_2 be a totally real number field and formula_21 a quaternion algebra over formula_2 satisfying the following conditions. First there is a unique embedding formula_23 such that formula_24 is split over formula_25 ; we denote by formula_26 such an isomorphism. We also ask that for all other embeddings formula_27 the algebra formula_28 is not split (this is equivalent to it being isomorphic to the Hamilton quaternions). Next we need an order formula_29 in formula_21. Let formula_31 be the group of elements in formula_29 of reduced norm 1 and let formula_33 be its image in formula_34 via formula_26. Then the image of formula_33 is a subgroup of formula_37 (since the reduced norm of a matrix algebra is just the determinant) and we can consider the Fuchsian group which is its image in formula_19.\n\nThe main fact about these groups is that they are discrete subgroups and they have finite covolume for the Haar measure on formula_39 Moreover, the construction above yields a cocompact subgroup if and only if the algebra formula_21 is not split over formula_2. The discreteness is a rather immediate consequence of the fact that formula_21 is only split at one real embedding. The finiteness of covolume is harder to prove.\n\nAn \"arithmetic Fuchsian group\" is any subgroup of formula_19 which is commensurable to a group derived from a quaternion algebra. It follows immediately from this definition that arithmetic Fuchsian groups are discrete and of finite covolume (this means that they are mattices in formula_19).\n\nThe simplest example of an arithmetic Fuchsian group is the modular formula_45 which is obtained by the construction above with formula_46 and formula_47 By taking Eichler orders in formula_21 we obtain subgroups formula_49 for formula_50 of finite index in formula_51 which can be explicitly written as follows:\n\nOf course the arithmeticity of such subgroups follows from the fact that they are finite-index in the arithmetic group formula_53 ; they belong to a more general class of finite-index subgroups, congruence subgroups.\n\nAny order in a quaternion algebra over formula_54 which is not split over formula_54 but splits over formula_25 yields a cocompact arithmetic Fuchsian group. There is a plentiful supply of such algebras.\n\nMore generally, all orders in quaternion algebras (satisfying the above conditions) which are not formula_57 yield cocompact subgroups. A further example of particular interest is obtained by taking formula_21 to be the Hurwitz quaternions.\n\nA natural question is to identify those among arithmetic Fuchsian groups which are not strictly contained in a larger discrete subgroup. These are called \"maximal\" Kleinian groups and it is possible to give a complete classification in a given arithmetic commensurability class. Note that a theorem of Margulis implies that a lattice in formula_59 is arithmetic if and only if it is commensurable to infinitely many maximal Kleinian groups.\n\nA \"principal congruence subgroup\" of formula_60 is a subgroup of the form :\n\nfor some formula_62 These are finite-index normal subgroups and the quotient formula_63 is isomorphic to the finite group formula_64 A \"congruence subgroup\" of formula_33 is by definition a subgroup which contains a principal cingruence subgroup (these are the groups which are defined by taking the matrices in formula_33 which satisfy certain congruences modulo an integer, hence the name).\n\nNotably, not all finite-index subgroups of formula_67 are congruence subgroups. A nice way to see this is to observe that formula_67 has subgroups which surject onto the alternating group formula_69 for arbitrary formula_70 and since for large formula_71 the group formula_69 is not a subgroup of formula_73 for any formula_74 these subgroups cannot be congruence subgroups. In fact one can also see that there are many more non-congruence than congruence subgroups in formula_67.\n\nThe notion of a congruence subgroup generalizes to cocompact arithmetic Fuchsian groups and the results above also hold in this general setting.\n\nThere is an isomorphism between formula_19 and the connected component of the orthogonal group formula_77 given by the action of the former by conjugation on the space of matrices of trace zero, on which the determinant induces the structure of a real quadratic space of signature (2,1). Arithmetic Fuchsian groups can be constructed directly in the latter group by taking the integral points in the orthogonal group associated to quadratic forms defined over number fields (and satisfying certain conditions).\n\nIn this correspondence the modular group is associated up to commensurability to the group formula_78\n\nThe construction above can be adapted to obtain subgroups in formula_59: instead of asking for formula_2 to be totally real and formula_21 to be split at exactly one real embedding one asks for formula_2 to have exactly one complex embedding up to complex conjugacy, at which formula_21 is automatically split, and that formula_21 is not split at any embedding formula_85. The subgroups of formula_59 commensurable to those obtained by this construction are called \"arithmetic Kleinian groups\". As in the Fuchsian case arithmetic Kleinian groups are discrete subgroups of finite covolume.\n\nThe invariant trace field of a Fuchsian group (or, through the monodromy image of the fundamental group, of an hyperbolic surface) is the field generated by the traces of the squares of its elements. In the case of an arithmetic surface whose fundamental group is commensurable with a Fuchsian group derived from a quaternion algebra over a number field formula_2 the invariant trace field equals formula_2.\n\nOne can in fact characterise arithmetic manifolds through the traces of the elements of their fundamental group, a result known as Takeuchi's criterion. A Fuchsian group is an arithmetic group if and only if the following three conditions are realised:\n\nThe Lie group formula_19 is the group of positive isometries of the hyperbolic plane formula_96. Thus, if formula_97 is a discrete subgroup of formula_19 then formula_33 acts properly discontinuously on formula_96. If moreover formula_33 is torsion-free then the action is free and the quotient space formula_102 is a surface (a 2-manifold) with an hyperbolic metric (a Riemannian metric of constant sectional curvature −1). If formula_33 is an arithmetic Fuchsian group such a surface formula_104 is called an \"arithmetic hyperbolic surface\" (not to be confused with the arithmetic surfaces from arithmetic geometry; however when the context is clear the \"hyperbolic\" specifier may be omitted). Since arithmetic Fuchsian groups are of finite covolume, arithmetic hyperbolic surfaces always have finite Riemannian volume (i.e. the integral over formula_104 of the volume form is finite).\n\nIt is possible to give a formula for the volume of distinguished arithmetic surfaces from the arithmetic data with which it was constructed. Let formula_29 be a maximal order in the quaternion algebra formula_21 of discriminant formula_108 over the field formula_2, let formula_110 be its degree, formula_111 its discriminant and formula_112 its Dedekind zeta function. Let formula_113 be the arithmetic group obtained from formula_29 by the procedure above and formula_104 the orbifold formula_116. Its volume is computed by the formula\n\nthe product is taken over prime ideals of formula_118 dividing formula_119 and we recall the formula_120 is the norm function on ideals, i.e. formula_121 is the cardinality of the finite ring formula_122). The reader can check that if formula_123 the output of this formula recovers the well-known result that the hyperbolic volume of the modular surface equals formula_124.\n\nCoupled with the description of maximal subgroups and finiteness results for number fields this formula allows to prove the following statement:\n\nNote that in dimensions four and more Wang's finiteness theorem (a consequence of local rigidity) asserts that this statement remains true by replacing \"arithmetic\" by \"finite volume\". An asymptotic equivalent for the number if arithmetic manifolds of a certain volume was given by Belolipetsky—Gelander—Lubotzky—Mozes.\n\nThe hyperbolic orbifold of minimal volume can be obtained as the surface associated to a particular order, the Hurwitz quaternion order, and it is compact of volume formula_127.\n\nA closed geodesic on a Riemannian manifold is a closed curve that is also geodesic. One can give an effective description of the set of such curves in an arithmetic surface or three—manifold: they correspond to certain units in certain quadratic extensions of the base field (the description is lengthy and shall not be given in full here). For example, the length of primitive closed geodesics in the modular surface corresponds to the absolute value of units of norm one in real quadratic fields. This description was used by Sarnak to establish a conjecture of Gauss on the mean order of class groups of real quadratic fields.\n\nArithmetic surfaces can be used to construct families of surfaces of genus formula_128 for any formula_128 which satisfy the (optimal, up to a constant) systolic inequality\n\nIf formula_104 is an hyperbolic surface then there is a distinguished operator formula_132 on smooth functions on formula_104. In the case where formula_104 is compact it extends to an unbounded, essentially self-adjoint operator on the Hilbert space formula_135 of square-integrable functions on formula_104. The spectral theorem in Riemannian geometry states that there exists an orthonormal basis formula_137 of eigenfunctions for formula_132. The associated eigenvalues formula_139 are unbounded and their asymptotic behaviour is ruled by Weyl's law.\n\nIn the case where formula_140 is arithmetic these eigenfunctions are a special type of automorphic forms for formula_33 called Maass forms. The eigenvalues of formula_132 are of interest for number theorists, as well as the distribution and nodal sets of the formula_143.\n\nThe case where formula_104 is of finte volume is more complicated but a similar theory can be established via the notion of cusp form.\n\nThe \"spectral gap\" of the surface formula_104 is by definition the gap between the smallest eigenvalue formula_146 and the second smallest eigenvalue formula_147; thus its value equals formula_148 and we shall denote it by formula_149 In general it can be made arbitrarily small(ref Randol) (however it has a positive lower bound for a surface with fixed volume). The Selberg conjecture is the following statement providing a conjectural uniform lower bound in the arithmetic case:\n\nNote that the statement is only valid for a subclass of arithmetic surfaces and can be seen to be false for general subgroups of finite index in lattices derived from quaternion algebras. Selberg's original statement was made only for congruence covers of the modular surface and it has been verified for some small groups. Selberg himself has proven the lower bound formula_155 a result known as \"Selberg's 1/16 theorem\". The best known result in full generality is due to Luo—Rudnick—Sarnak.\n\nThe uniformity of the spectral gap has implications for the construction of expander graphs as Schreier graphs of formula_156\n\nSelberg's trace formula shows that for an hyperbolic surface of finite volume it is equivalent to know the length spectrum (the collection of lengths of all closed geodesics on formula_104, with multiplicities) and the spectrum of formula_132. However the precise relation is not explicit.\n\nAnother relation between spectrum and geometry is given by Cheeger's inequality, which in the case of a surface formula_104 states roughly that a positive lower bound on the spectral gap of formula_104 translates into a positive lower bound for the total length of a collection of smooth closed curves separating formula_104 into two connected components.\n\nThe quantum ergodicity theorem of Shnirelman, Colin de Verdière and Zelditch states that on average, eigenfunctions equidistribute on formula_104. The unique quantum ergodicity conjecture of Rudnick and Sarnak asks whether the stronger statement that individual eigenfunctions equidistribure is true. Formally, the statement is as follows.\n\nThis conjecture has been proven by E. Lindenstrauss in the case where formula_104 is compact and the formula_164 are additionally eigenfunctions for the Hecke operators on formula_104. In the case of congruence covers of the modular some additional difficulties occur, which were dealt with by K. Soundararajan.\n\nThe fact that for arithmetic surfaces the arithmetic data determines the spectrum of the Laplace operator formula_132 was pointed out by M. F. Vignéras and used by her to construct examples of isospectral compact hyperbolic surfaces. The precise statement is as follows:\n\nVignéras then constructed explicit instances for formula_179 satisfying the conditions above and such that in addition formula_180 is not conjugated by an element of formula_21 to formula_182 The resulting isospectral hyperbolic surfaces are then not isometric.\n"}
{"id": "634543", "url": "https://en.wikipedia.org/wiki?curid=634543", "title": "Bendixson–Dulac theorem", "text": "Bendixson–Dulac theorem\n\nIn mathematics, the Bendixson–Dulac theorem on dynamical systems states that if there exists a formula_1 function formula_2 (called the Dulac function) such that the expression\n\nhas the same sign (formula_4) almost everywhere in a simply connected region of the plane, then the plane autonomous system\n\nhas no nonconstant periodic solutions lying entirely within the region. \"Almost everywhere\" means everywhere except possibly in a set of measure 0, such as a point or line.\n\nThe theorem was first established by Swedish mathematician Ivar Bendixson in 1901 and further refined by French mathematician Henri Dulac in 1933 using Green's theorem.\n\nWithout loss of generality, let there exist a function formula_2 such that\n\nin simply connected region formula_9. Let formula_10 be a closed trajectory of the plane autonomous system in formula_9. Let formula_12 be the interior of formula_10. Then by Green's theorem,\n\nBut on formula_10, formula_16 and formula_17, so the integral evaluates to 0. This is a contradiction, so there can be no such closed trajectory formula_10.\n\nHenri Dulac is a French mathematician (1870, 1955) from Fayence\n"}
{"id": "3206099", "url": "https://en.wikipedia.org/wiki?curid=3206099", "title": "Biological half-life", "text": "Biological half-life\n\nThe biological half-life of a biological substance is the time it takes for half to be removed by biological processes when the rate of removal is roughly exponential. It is often denoted by the abbreviation formula_1. Examples include metabolites, drugs, and signalling molecules. Typically, this refers to the body's cleansing through the function of kidneys and liver in addition to excretion functions to eliminate a substance from the body. In a medical context, half-life may also describe the time it takes for the blood plasma concentration of a substance to halve (\"plasma half-life\") its steady-state. The relationship between the biological and plasma half-lives of a substance can be complex depending on the substance in question, due to factors including accumulation in tissues (protein binding), active metabolites, and receptor interactions.\n\nThe biological half-life of water in a human is about 7 to 14 days. It can be altered by behavior. Drinking large amounts of alcohol will reduce the biological half-life of water in the body. This has been used to decontaminate humans who are internally contaminated with tritiated water (tritium). The basis of this decontamination method (used at Harwell) is to increase the rate at which the water in the body is replaced with new water.\n\nThe removal of ethanol (drinking alcohol) through oxidation by alcohol dehydrogenase in the liver from the human body is limited. Hence the removal of a large concentration of alcohol from blood may follow zero-order kinetics. Also the rate-limiting steps for one substance may be in common with other substances. For instance, the blood alcohol concentration can be used to modify the biochemistry of methanol and ethylene glycol. In this way the oxidation of methanol to the toxic formaldehyde and formic acid in the human body can be prevented by giving an appropriate amount of ethanol to a person who has ingested methanol. Note that methanol is very toxic and causes blindness and death. A person who has ingested ethylene glycol can be treated in the same way. Half life is also relative to the subjective metabolic rate of the individual in question.\n\nThe biological half-life of caesium in humans is between one and four months. This can be shortened by feeding the person prussian blue. The prussian blue in the digestive system acts as a solid ion exchanger which absorbs the caesium while releasing potassium ions.\n\nFor some substances, it is important to think of the human or animal body as being made up of several parts, each with their own affinity for the substance, and each part with a different biological half-life (physiologically-based pharmacokinetic modelling). Attempts to remove a substance from the whole organism may have the effect of increasing the burden present in one part of the organism. For instance, if a person who is contaminated with lead is given EDTA in a chelation therapy, then while the rate at which lead is lost from the body will be increased, the lead within the body tends to relocate into the brain where it can do the most harm.\n\nSome substances may have different half-lives in different parts of the body. For example, oxytocin has a half-life of typically about three minutes in the blood when given intravenously. Peripherally administered (e.g. intravenous) peptides like oxytocin cross the blood-brain-barrier very poorly, although very small amounts (< 1%) do appear to enter the central nervous system in humans when given via this route. In contrast to peripheral administration, when administered intranasally via a nasal spray, oxytocin reliably crosses the blood–brain barrier and exhibits psychoactive effects in humans. In addition, also unlike the case of peripheral administration, intranasal oxytocin has a central duration of at least 2.25 hours and as long as 4 hours. In likely relation to this fact, endogenous oxytocin concentrations in the brain have been found to be as much as 1000-fold higher than peripheral levels.\n\nHalf-times apply to processes where the elimination rate is exponential. If formula_2 is the concentration of a substance at time formula_3, its time dependence is given by\nwhere \"k\" is the reaction rate constant. Such a decay rate arises from a first-order reaction where the rate of elimination is proportional to the amount of the substance:\n\nThe half-life for this process is\n\nHalf-life is determined by clearance (CL) and volume of distribution (V) and the relationship is described by the following equation:\n\nIn clinical practice, this means that it takes 4 to 5 times the half-life for a drug's serum concentration to reach steady state after regular dosing is started, stopped, or the dose changed. So, for example, digoxin has a half-life (or t) of 24–36 h; this means that a change in the dose will take the best part of a week to take full effect. For this reason, drugs with a long half-life (e.g., amiodarone, elimination t of about 58 days) are usually started with a loading dose to achieve their desired clinical effect more quickly.\n\nMany drugs follow a biphasic elimination curve — first a steep slope then a shallow slope:\nThe longer half-life is called the \"terminal half-life\" and the half-life of the largest component is called the \"dominant half-life.\" For a more detailed description see Pharmacokinetics--Multi-compartmental_models.\n\n"}
{"id": "4850775", "url": "https://en.wikipedia.org/wiki?curid=4850775", "title": "Centre (geometry)", "text": "Centre (geometry)\n\nIn geometry, a centre (or center) (from Greek \"κέντρον\") of an object is a point in some sense in the middle of the object. According to the specific definition of centre taken into consideration, an object might have no centre. If geometry is regarded as the study of isometry groups then a centre is a fixed point of all the isometries which move the object onto itself.\n\nThe centre of a circle is the point equidistant from the points on the edge. Similarly the centre of a sphere is the point equidistant from the points on the surface, and the centre of a line segment is the midpoint of the two ends.\n\nFor objects with several symmetries, the centre of symmetry is the point left unchanged by the symmetric actions. So the centre of a square, rectangle, rhombus or parallelogram is where the diagonals intersect, this being (amongst other properties) the fixed point of rotational symmetries. Similarly the centre of an ellipse or a hyperbola is where the axes intersect.\n\nSeveral special points of a triangle are often described as triangle centres:\n\n\nFor an equilateral triangle, these are the same point, which lies at the intersection of the three axes of symmetry of the triangle, one third of the distance from its base to its apex.\n\nA strict definition of a triangle centre is a point whose trilinear coordinates are \"f\"(\"a\",\"b\",\"c\") : \"f\"(\"b\",\"c\",\"a\") : \"f\"(\"c\",\"a\",\"b\") where \"f\" is a function of the lengths of the three sides of the triangle, \"a\", \"b\", \"c\" such that:\n\n\nThis strict definition excludes pairs of bicentric points such as the Brocard points (which are interchanged by a mirror-image reflection). The Encyclopedia of Triangle Centers lists over 9,000 different triangle centres.\n\nA tangential polygon has each of its sides tangent to a particular circle, called the incircle or inscribed circle. The centre of the incircle, called the incentre, can be considered a centre of the polygon.\n\nA cyclic polygon has each of its vertices on a particular circle, called the circumcircle or circumscribed circle. The centre of the circumcircle, called the circumcentre, can be considered a centre of the polygon.\n\nIf a polygon is both tangential and cyclic, it is called bicentric. (All triangles are bicentric, for example.) The incentre and circumcentre of a bicentric polygon are not in general the same point.\n\nThe centre of a general polygon can be defined in several different ways. The \"vertex centroid\" comes from considering the polygon as being empty but having equal masses at its vertices. The \"side centroid\" comes from considering the sides to have constant mass per unit length. The usual centre, called just the centroid (centre of area) comes from considering the surface of the polygon as having constant density. These three points are in general not all the same point.\n\n"}
{"id": "2318488", "url": "https://en.wikipedia.org/wiki?curid=2318488", "title": "Classification of electromagnetic fields", "text": "Classification of electromagnetic fields\n\nIn differential geometry and theoretical physics, the classification of electromagnetic fields is a pointwise classification of bivectors at each point of a Lorentzian manifold. It is used in the study of solutions of Maxwell's equations and has applications in Einstein's theory of relativity.\n\nThe electromagnetic field at a point \"p\" (i.e. an event) of a Lorentzian spacetime is represented by a real bivector defined over the tangent space at \"p\".\n\nThe tangent space at \"p\" is isometric as a real inner product space to E. That is, it has the same notion of vector magnitude and angle as Minkowski spacetime. To simplify the notation, we will assume the spacetime \"is\" Minkowski spacetime. This tends to blur the distinction between the tangent space at \"p\" and the underlying manifold; fortunately, nothing is lost by this specialization, for reasons we discuss as the end of the article.\n\nThe classification theorem for electromagnetic fields characterizes the bivector \"F\" in relation to the Lorentzian metric by defining and examining the so-called \"principal null directions\". Let us explain this.\n\nThe bivector \"F\" yields a skew-symmetric linear operator defined by lowering one index with the metric. It acts on the tangent space at \"p\" by . We will use the symbol \"F\" to denote either the bivector or the operator, according to context.\n\nWe mention a dichotomy drawn from exterior algebra. A bivector that can be written as , where \"v\", \"w\" are linearly independent, is called \"simple\". Any nonzero bivector over a 4-dimensional vector space either is simple, or can be written as , where \"v\", \"w\", \"x\", and \"y\" are linearly independent; the two cases are mutually exclusive. Stated like this, the dichotomy makes no reference to the metric \"η\", only to exterior algebra. But it is easily seen that the associated skew-symmetric linear operator \"F\" has rank 2 in the former case and rank 4 in the latter case.\n\nTo state the classification theorem, we consider the \"eigenvalue problem\" for \"F\", that is, the problem of finding eigenvalues \"λ\" and eigenvectors \"r\" which satisfy the eigenvalue equation\nThe skew-symmetry of \"F\" implies that:\n\n\nA 1-dimensional subspace generated by a null eigenvector is called a \"principal null direction\" of the bivector.\n\nThe classification theorem characterizes the possible principal null directions of a bivector. It states that one of the following must hold for any nonzero bivector:\nFurthermore, for any non-null bivector, the two eigenvalues associated with the two distinct principal null directions have the same magnitude but opposite sign, , so we have three subclasses of non-null bivectors:\nwhere the rank refers to the rank of the linear operator \"F\".\n\nThe algebraic classification of bivectors given above has an important application in relativistic physics: the electromagnetic field is represented by a skew-symmetric second rank tensor field (the electromagnetic field tensor) so we immediately obtain an algebraic classification of electromagnetic fields.\n\nIn a cartesian chart on Minkowski spacetime, the electromagnetic field tensor has components\nwhere formula_3 and formula_4 denote respectively the components of the electric and magnetic fields, as measured by an inertial observer (at rest in our coordinates). As usual in relativistic physics, we will find it convenient to work with geometrised units in which formula_5. In the \"Index gymnastics\" formalism of special relativity, the Minkowski metric formula_6 is used to raise and lower indices.\n\nThe fundamental invariants of the electromagnetic field are:\n\nA null electromagnetic field is characterised by formula_9. In this case, the invariants reveal that the electric and magnetic fields are perpendicular and that they are of the same magnitude (in geometrised units). An example of a null field is a plane electromagnetic wave in Minkowski space.\n\nA non-null field is characterised by formula_10. If formula_11, there exists an inertial reference frame for which either the electric or magnetic field vanishes. (These correspond respectively to \"magnetostatic\" and \"electrostatic\" fields.) If formula_12, there exists an inertial frame in which electric and magnetic fields are proportional.\n\nSo far we have discussed only Minkowski spacetime. According to the (strong) equivalence principle, if we simply replace \"inertial frame\" above with a frame field, everything works out exactly the same way on curved manifolds.\n\n\n"}
{"id": "32291149", "url": "https://en.wikipedia.org/wiki?curid=32291149", "title": "Comeasuring", "text": "Comeasuring\n\nLet \"A\" be an algebra. A comeasuring of \"A\" is a pair (\"B\", \"β\") where:\n"}
{"id": "750326", "url": "https://en.wikipedia.org/wiki?curid=750326", "title": "Compact group", "text": "Compact group\n\nIn mathematics, a compact (topological) group is a topological group whose topology is compact. Compact groups are a natural generalization of finite groups with the discrete topology and have properties that carry over in significant fashion. Compact groups have a well-understood theory, in relation to group actions and representation theory.\n\nIn the following we will assume all groups are Hausdorff spaces.\n\nLie groups form a very nice class of topological groups, and the compact Lie groups have a particularly well-developed theory. Basic examples of compact Lie groups include\nThe classification theorem of compact Lie groups states that up to finite extensions and finite covers this exhausts the list of examples (which already includes some redundancies). This classification is described in more detail in the next subsection.\n\nGiven any compact Lie group \"G\" one can take its identity component \"G\", which is connected. The quotient group \"G\"/\"G\" is the group of components π(\"G\") which must be finite since \"G\" is compact. We therefore have a finite extension\nMeanwhile, for connected compact Lie groups, we have the following result:\nThus, the classification of connected compact Lie groups can in principle be reduced to knowledge of the simply connected compact Lie groups together with information about their centers. (For information about the center, see the section below on fundamental group and center.)\n\nFinally, every compact, connected, simply-connected Lie group \"K\" is a product of compact, connected, simply-connected simple Lie groups \"K\" each of which is isomorphic to exactly one of the following:\nor one of the five exceptional groups G, F, E, E, and E. The restrictions on \"n\" are to avoid special isomorphisms among the various families for small values of \"n\". For each of these groups, the center is known explicitly. The classification is through the associated root system (for a fixed maximal torus), which in turn are classified by their Dynkin diagrams.\n\nThe classification of compact, simply connected Lie groups is the same as the classification of complex semisimple Lie algebras. Indeed, if \"K\" is a simply connected compact Lie group, then the complexification of the Lie algebra of \"K\" is semisimple. Conversely, every complex semisimple Lie algebra has a compact real form isomorphic to the Lie algebra of a compact, simply connected Lie group.\n\nA key idea in the study of a connected compact Lie group \"K\" is the concept of a \"maximal torus\", that is a subgroup \"T\" of \"K\" that is isomorphic to several copies of formula_5 and that is not contained in any larger subgroup of this type. A basic example is the case formula_6, in which case we may take formula_7 to be the group of diagonal elements in formula_8. A basic result is the \"torus theorem\" which states that every element of formula_8 belongs to a maximal torus and that all maximal tori are conjugate.\n\nThe maximal torus in a compact group plays a role analogous to that of the Cartan subalgebra in a complex semisimple Lie algebra. In particular, once a maximal torus formula_10 has been chosen, one can define a root system and a Weyl group similar to what one has for semisimple Lie algebras. These structures then play an essential role both in the classification of connected compact groups (described above) and in the representation theory of a fixed such group (described below).\n\nThe root systems associated to the simple compact groups appearing in the classification of simply connected compact groups are as follows:\n\nIt is important to know whether a connected compact Lie group is simply connected, and if not, to determine its fundamental group. For compact Lie groups, there are two basic approaches to computing the fundamental group. The first approach applies to the classical compact groups formula_11, formula_20, formula_21, and formula_15 and proceeds by induction on formula_23. The second approach uses the root system and applies to all connected compact Lie groups.\n\nIt is also important to know the center of a connected compact Lie group. The center of a classical group formula_24 can easily be computed \"by hand,\" and in most cases consists simply of whatever multiples of the identity are in formula_24. (The group SO(2) is an exception—the center is the whole group, even though most elements are not multiples of the identity.) Thus, for example, the center of formula_11 consists of \"n\"th roots of unity times the identity, a cyclic group of order formula_23.\n\nIn general, the center can be expressed in terms of the root lattice and the kernel of the exponential map for the maximal torus. The general method shows, for example, that the simply connected compact group corresponding to the exceptional root system formula_28 has trivial center. Thus, the compact formula_28 group is one of very few simple compact groups that are simultaneously simply connected and center free. (The others are formula_30 and formula_31.)\n\nAmongst groups that are not Lie groups, and so do not carry the structure of a manifold, examples are the additive group \"Z\" of p-adic integers, and constructions from it. In fact any profinite group is a compact group. This means that Galois groups are compact groups, a basic fact for the theory of algebraic extensions in the case of infinite degree.\n\nPontryagin duality provides a large supply of examples of compact commutative groups. These are in duality with abelian discrete groups.\n\nCompact groups all carry a Haar measure, which will be invariant by both left and right translation (the modulus function must be a continuous homomorphism to positive reals (ℝ, ×), and so 1). In other words, these groups are unimodular. Haar measure is easily normalized to be a probability measure, analogous to dθ/2π on the circle.\n\nSuch a Haar measure is in many cases easy to compute; for example for orthogonal groups it was known to Adolf Hurwitz, and in the Lie group cases can always be given by an invariant differential form. In the profinite case there are many subgroups of finite index, and Haar measure of a coset will be the reciprocal of the index. Therefore, integrals are often computable quite directly, a fact applied constantly in number theory.\n\nThe representation theory of compact groups (not necessarily Lie groups and not necessarily connected) was founded by the Peter–Weyl theorem. Hermann Weyl went on to give the detailed character theory of the compact connected Lie groups, based on maximal torus theory. The resulting Weyl character formula was one of the influential results of twentieth century mathematics. The combination of the Peter–Weyl theorem and the Weyl character formula led Weyl to a complete classification of the representations of a connected compact Lie group; this theory is described in the next section.\n\nA combination of Weyl's work and Cartan's theorem gives a survey of the whole representation theory of compact groups \"G\" . That is, by the Peter–Weyl theorem the irreducible unitary representations ρ of \"G\" are into a unitary group (of finite dimension) and the image will be a closed subgroup of the unitary group by compactness. Cartan's theorem states that Im(ρ) must itself be a Lie subgroup in the unitary group. If \"G\" is not itself a Lie group, there must be a kernel to ρ. Further one can form an inverse system, for the kernel of ρ smaller and smaller, of finite-dimensional unitary representations, which identifies \"G\" as an inverse limit of compact Lie groups. Here the fact that in the limit a faithful representation of \"G\" is found is another consequence of the Peter–Weyl theorem,\n\nThe unknown part of the representation theory of compact groups is thereby, roughly speaking, thrown back onto the complex representations of finite groups. This theory is rather rich in detail, but is qualitatively well understood.\n\nCertain simple examples of the representation theory of compact Lie groups can be worked out by hand, such as the representations of the , the special unitary group SU(2), and the special unitary group SU(3). We focus here on the general theory. See also the parallel theory of representations of a semisimple Lie algebra.\n\nThroughout this section, we fix a connected compact Lie group \"K\" and a maximal torus \"T\" in \"K\".\nSince \"T\" is commutative, Schur's lemma tells us that each irreducible representation formula_32 of \"T\" is one-dimensional:\nSince, also, \"T\" is compact, formula_32 must actually map into formula_35.\n\nTo describe these representations concretely, we let formula_36 be the Lie algebra of \"T\" and we write points formula_37 as\nIn such coordinates, formula_32 will have the form\nfor some linear functional formula_41 on formula_36. \n\nNow, since the exponential map formula_43 is not injective, not every such linear functional formula_41 gives rise to a well-defined map of \"T\" into formula_5. Rather, let formula_46 denote the kernel of the exponential map:\nwhere formula_48 is the identity element of \"T\". (We scale the exponential map here by a factor of formula_49 in order to avoid such factors elsewhere.) \nThen for formula_41 to give a well-defined map formula_32, formula_41 must satisfy\nwhere formula_54 is the set of integers. A linear functional formula_41 satisfying this condition is called an analytically integral element. This integrality condition is related to, but not identical to, the notion of integral element in the setting of semisimple Lie algebras.\n\nSuppose, for example, \"T\" is just the group of formula_5 of complex numbers formula_57 of absolute value 1. The Lie algebra is the set of pure imaginary numbers, formula_58 and the kernel of the (scaled) exponential map is the set of numbers of the form formula_59 where formula_23 is an integer. A linear functional formula_41 takes integer values on all such numbers if and only if it is of the form formula_62 for some integer formula_63. The irreducible representations of \"T\" in this case are one-dimensional and of the form\n\nWe now let formula_65 denote a finite-dimensional irreducible representation of \"K\" (over formula_66). We then consider the restriction of formula_65 to \"T\". This restriction not irreducible unless formula_65 is one-dimensional. Nevertheless, the restriction decomposes as a direct sum of irreducible representations of \"T\". (Note that a given irreducible representation of \"T\" may occur more than once.) Now, each irreducible representation of \"T\" is described by a linear functional formula_41 as in the preceding subsection. If a given formula_41 occurs at least once in the decomposition of the restriction of formula_65 to \"T\", we call formula_41 a weight of formula_65. The strategy of the representation theory of \"K\" is to classify the irreducible representations in terms of their weights.\n\nWe now briefly describe the structures needed to formulate the theorem; more details can be found in the article on weights in representation theory. We need the notion of a root system for \"K\" (relative to a given maximal torus \"T\"). The construction of this root system formula_74 is very similar to the construction for complex semisimple Lie algebras. Specifically, the weights are the nonzero weights for the adjoint action of \"T\" on the complexified Lie algebra of \"K\". The root system \"R\" has all the usual properties of a root system, except that the elements of \"R\" may not span formula_36. We then choose a base formula_76 for \"R\" and we say that an integral element formula_41 is dominant if formula_78 for all formula_79. Finally, we say that one weight is higher than another if their difference can be expressed as a linear combination of elements of formula_76 with non-negative coefficients.\n\nThe irreducible finite-dimensional representations of \"K\" are then classified by a theorem of the highest weight, which is closely related to the analogous theorem classifying representations of a semisimple Lie algebra. The result says that: \n\nThe theorem of the highest weight for representations of \"K\" is then almost the same as for semisimple Lie algebras, with one notable exception: The concept of an integral element is different. The weights formula_41 of a representation formula_65 are analytically integral in the sense described in the previous subsection. Every analytically integral element is integral in the Lie algebra sense, but not the other way around. (This phenomenon reflects that, in general, not every representation of the Lie algebra formula_83 comes from a representation of the group \"K\".) On the other hand, if \"K\" is simply connected, the set of possible highest weights in the group sense is the same as the set of possible highest weights in the Lie algebra sense.\n\nIf formula_84 is representation of \"K\", we define the character of formula_85 to be the function formula_86 given by\nThis function is easily seen to be a class function, i.e., formula_88 for all formula_89 and formula_90 in \"K\". Thus, formula_91 is determined by its restriction to \"T\".\n\nThe study of characters is an important part of the representation theory of compact groups. One crucial result, which is a corollary of the Peter–Weyl theorem, is that the characters form an orthonormal basis for the set of square-integrable class functions in \"K\". A second key result is the Weyl character formula, which gives an explicit formula for the character—or, rather, the restriction of the character to \"T\"—in terms of the highest weight of the representation. \n\nIn the closely related representation theory of semisimple Lie algebras, the Weyl character formula is an additional result established \"after\" the representations have been classified. In Weyl's analysis of the compact group case, however, the Weyl character formula is actually a crucial part of the classification itself. Specifically, in Weyl's analysis of the representations of \"K\", the hardest part of the theorem—showing that every dominant, analytically integral element is actually the highest weight of some representation—is proved in totally different way from the usual Lie algebra construction using Verma modules. In Weyl's approach, the construction is based on the Peter–Weyl theorem and an analytic proof of the Weyl character formula. Ultimately, the irreducible representations of \"K\" are realized inside the space of continuous functions on \"K\".\n\nWe now consider the case of the compact group SU(2). The representations are often considered from the Lie algebra point of view, but we here look at them from the group point of view. We take the maximal torus to be the set of matrices of the form\nAccording to the example discussed above in the section on representations of \"T\", the analytically integral elements are labeled by integers, so that the dominant, analytically integral elements are non-negative integers formula_93. The general theory then tells us that for each formula_93, there is a unique irreducible representation of SU(2) with highest weight formula_93. \n\nMuch information about the representation corresponding to a given formula_93 is encoded in its character. Now, the Weyl character formula says, in this case, that the character is given by\nWe can also write the character as sum of exponentials as follows:\n\nFrom this last expression and the standard formula for the character in terms of the weights of the representation, we can read off that the weights of the representation are \neach with multiplicity one. (The weights are the integers appearing in the exponents of the exponentials and the multiplicities are the coefficients of the exponentials.) Since there are formula_100 weights, each with multiplicity 1, the dimension of the representation is formula_100. Thus, we recover much of the information about the representations that is usually obtained from the Lie algebra computation.\n\nWe now outline the proof of the theorem of the highest weight, following the original argument of Hermann Weyl. We continue to let formula_8 be a connected compact Lie group and formula_7 a fixed maximal torus in formula_8. We focus on the most difficult part of the theorem, showing that every dominant, analytically integral element is the highest weight of some (finite-dimensional) irreducible representation.\n\nThe tools for the proof are the following:\n\nWith these tools in hand, we proceed with the proof. The first major step in the argument is to prove the Weyl character formula. The formula states that if formula_85 is an irreducible representation with highest weight formula_41, then the character formula_91 of formula_85 satisfies:\nfor all formula_111 in the Lie algebra of formula_7. Here formula_32 is half the sum of the positive roots. (The notation uses the convention of \"real weights\"; this convention requires an explicit factor of formula_114 in the exponent.) Weyl's proof of the character formula is analytic in nature and hinges on the fact that the formula_115 norm of the character is 1. Specifically, if there were any additional terms in the numerator, the Weyl integral formula would force the norm of the character to be greater than 1.\n\nNext, we let formula_116 denote the function on the right-hand side of the character formula. We show that \"even if formula_41 is not known to be the highest weight of a representation\", formula_116 is a well-defined, Weyl-invariant function on formula_7, which therefore extends to a class function on formula_8. Then using the Weyl integral formula, one can show that as formula_41 ranges over the set of dominant, analytically integral elements, the functions formula_116 form an orthonormal family of class functions. We emphasize that do not currently know that every such formula_41 is the highest weight of a representation; nevertheless, the expressions on the right-hand side of the character formula gives a well-defined set of functions formula_116, and these functions are orthonormal.\n\nNow comes the conclusion. The set of all formula_116—with formula_41 ranging over the dominant, analytically integral elements—forms an orthonormal set in the space of square integrable class functions. But by the Weyl character formula, the characters of the irreducible representations form a subset of the formula_116's. And by the Peter–Weyl theorem, the characters of the irreducible representations form an orthonormal basis for the space of square integrable class functions. If there were some formula_41 that is not the highest weight of a representation, then the corresponding formula_116 would not the character of a representation. Thus, the characters would be a \"proper\" subset of the set of formula_116's. But then we have an impossible situation: an orthonormal \"basis\" (the set of characters of the irreducible representations) would be contained in a strictly larger orthonormal set (the set of formula_116's). Thus, every formula_41 must actually be the highest weight of a representation.\n\nThe topic of recovering a compact group from its representation theory is the subject of the Tannaka–Krein duality, now often recast in term of tannakian category theory.\n\nThe influence of the compact group theory on non-compact groups was formulated by Weyl in his unitarian trick. Inside a general semisimple Lie group there is a maximal compact subgroup, and the representation theory of such groups, developed largely by Harish-Chandra, uses intensively the restriction of a representation to such a subgroup, and also the model of Weyl's character theory.\n\n\n"}
{"id": "5205878", "url": "https://en.wikipedia.org/wiki?curid=5205878", "title": "Computational mechanics", "text": "Computational mechanics\n\nComputational mechanics is the discipline concerned with the use of computational methods to study phenomena governed by the principles of mechanics. Before the emergence of computational science (also called scientific computing) as a \"third way\" besides theoretical and experimental sciences, computational mechanics was widely considered to be a sub-discipline of applied mechanics. It is now considered to be a sub-discipline within computational science.\n\nComputational mechanics (CM) is interdisciplinary. Its three pillars are mechanics, mathematics, and computer science.\n\nComputational fluid dynamics, computational thermodynamics, computational electromagnetics, computational solid mechanics are some of the many specializations within CM.\n\nThe areas of mathematics most related to computational mechanics are partial differential equations, linear algebra and numerical analysis. The most popular numerical methods used are the finite element, finite difference, and boundary element methods in order of dominance. In solid mechanics finite element methods are far more prevalent than finite difference methods, whereas in fluid mechanics, thermodynamics, and electromagnetism, finite difference methods are almost equally applicable. The boundary element technique is in general less popular, but has a niche in certain areas including acoustics engineering, for example.\n\nWith regard to computing, computer programming, algorithms, and parallel computing play a major role in CM. The most widely used programming language in the scientific community, including computational mechanics, is Fortran. Recently, C++ has increased in popularity. The scientific computing community has been slow in adopting C++ as the lingua franca. Because of its very natural way of expressing mathematical computations, and its built-in visualization capacities, the proprietary language/environment MATLAB is also widely used, especially for rapid application development and model verification.\n\nScientists within the field of computational mechanics follow a list of tasks to analyze their target mechanical process:\n\n\nSome examples where computational mechanics have been put to practical use are vehicle crash simulation, petroleum reservoir modeling, biomechanics, glass manufacturing, and semiconductor modeling. \n\nComplex systems that would be very difficult or impossible to treat using analytical methods have been successfully simulated using the tools provided by computational mechanics.\n\n\n"}
{"id": "17637383", "url": "https://en.wikipedia.org/wiki?curid=17637383", "title": "Discrete Morse theory", "text": "Discrete Morse theory\n\nDiscrete Morse theory is a combinatorial adaptation of Morse theory developed by Robin Forman. The theory has various practical applications in diverse fields of applied mathematics and computer science, such as configuration spaces, homology computation, denoising, mesh compression, and topological data analysis .\n\nLet formula_1 be a CW complex. Define the \"incidence function\" formula_2 in the following way: given two cells formula_3 and formula_4 in formula_1, let formula_6 be the degree of the attaching map from the boundary of formula_3 to formula_4. The boundary operator formula_9 on formula_1 is defined by\n\nIt is a defining property of boundary operators that formula_12. In more axiomatic definitions one can find the requirement that formula_13\n\nwhich is a corollary of the above definition of the boundary operator and the requirement that formula_12.\n\nA real-valued function formula_16 is a \"discrete Morse function\" if it satisfies the following two properties:\n\n\nIt can be shown that the cardinalities in the two conditions cannot both be one simultaneously for a fixed cell formula_3, provided that formula_1 is a \"regular\" CW complex. In this case, each cell formula_17 can be paired with at most one exceptional cell formula_18: either a boundary cell with larger formula_29 value, or a co-boundary cell with smaller formula_29 value. The cells which have no pairs, i.e., whose function values are strictly higher than their boundary cells and strictly lower than their co-boundary cells are called \"critical\" cells. Thus, a discrete Morse function partitions the CW complex into three distinct cell collections: formula_31, where:\n\n\nBy construction, there is a bijection of sets between formula_35-dimensional cells in formula_33 and the formula_37-dimensional cells in formula_34, which can be denoted by formula_39 for each natural number formula_35. It is an additional technical requirement that for each formula_41, the degree of the attaching map from the boundary of formula_42 to its paired cell formula_43 is a unit in the underlying ring of formula_1. For instance, over the integers formula_45, the only allowed values are formula_46. This technical requirement is guaranteed, for instance, when one assumes that formula_1 is a regular CW complex over formula_45.\n\nThe fundamental result of discrete Morse theory establishes that the CW complex formula_1 is isomorphic on the level of homology to a new complex formula_32 consisting of only the critical cells. The paired cells in formula_33 and formula_34 describe \"gradient paths\" between adjacent critical cells which can be used to obtain the boundary operator on formula_32. Some details of this construction are provided in the next section.\n\nA \"gradient path\" is a sequence of paired cells\n\nsatisfying formula_55 and formula_56. The \"index\" of this gradient path is defined to be the integer\n\nThe division here makes sense because the incidence between paired cells must be formula_46. Note that by construction, the values of the discrete Morse function formula_29 must decrease across formula_60. The path formula_60 is said to \"connect\" two critical cells formula_62 if formula_63. This relationship may be expressed as formula_64. The \"multiplicity\" of this connection is defined to be the integer formula_65. Finally, the Morse boundary operator on the critical cells formula_32 is defined by\n\nwhere the sum is taken over all gradient path connections from formula_68 to formula_69.\n\nMany of the familiar results from continuous Morse theory apply in the discrete setting.\n\nLet formula_32 be a Morse complex associated to the CW complex formula_1. The number formula_72 of formula_73-cells in formula_32 is called the formula_75 \"Morse number\". Let formula_76 denote the formula_75 Betti number of formula_1. Then, for any formula_79, the following inequalities hold\n\nMoreover, the Euler characteristic formula_82 of formula_1 satisfies\n\nLet formula_1 be a regular CW complex with boundary operator formula_9 and a discrete Morse function formula_16. Let formula_32 be the associated Morse complex with Morse boundary operator formula_89. Then, there is an isomorphism of homology groups\n\nand similarly for the homotopy groups.\n\n\n"}
{"id": "14662815", "url": "https://en.wikipedia.org/wiki?curid=14662815", "title": "Double-negation translation", "text": "Double-negation translation\n\nIn proof theory, a discipline within mathematical logic, double-negation translation, sometimes called negative translation, is a general approach for embedding classical logic into intuitionistic logic, typically by translating formulas to formulas which are classically equivalent but intuitionistically inequivalent. Particular instances of double-negation translation include Glivenko's translation for propositional logic, and the Gödel–Gentzen translation and Kuroda's translation for first-order logic.\n\nThe easiest double-negation translation to describe comes from Glivenko's theorem, proved by Valery Glivenko in 1929. It maps each classical formula φ to its double negation ¬¬φ.\n\nGlivenko's theorem states:\n\nGlivenko's theorem implies the more general statement:\n\nIn particular, a set of propositional formulas is intuitionistically consistent if and only if it is classically satisfiable.\n\nThe \"Gödel–Gentzen translation\" (named after Kurt Gödel and Gerhard Gentzen) associates with each formula φ in a first-order language another formula φ, which is defined inductively:\n\n\nThis translation has the property that φ is classically equivalent to φ. The fundamental soundness theorem (Avigad and Feferman 1998, p. 342; Buss 1998 p. 66) states:\n\nHere \"T\" consists of the double-negation translations of the formulas in \"T\".\n\nA sentence φ may not imply its negative translation φ in intuitionistic first-order logic. Troelstra and Van Dalen (1988, Ch. 2, Sec. 3) give a description (due to Leivant) of formulas that do imply their Gödel–Gentzen translation.\n\nThere are several alternative definitions of the negative translation. They are all provably equivalent in intuitionistic logic, but may be easier to apply in particular contexts.\n\nOne possibility is to change the clauses for disjunction and existential quantifier to\nThen the translation can be succinctly described as: prefix ¬¬ to every atomic formula, disjunction, and existential quantifier.\n\nAnother possibility (known as Kuroda's translation) is to construct φ from φ by putting ¬¬ before the whole formula and after every universal quantifier. Notice that this reduces to the simple ¬¬φ translation if φ is propositional.\n\nIt is also possible to define φ by prefixing ¬¬ before every subformula of φ, as done by Kolmogorov. Such a translation is the logical counterpart to the call-by-name continuation-passing style translation of functional programming languages along the lines of the Curry–Howard correspondence between proofs and programs.\n\nThe double-negation translation was used by Gödel (1933) to study the relationship between classical and intuitionistic theories of the natural numbers (\"arithmetic\"). He obtains the following result:\n\nThis result shows that if Heyting arithmetic is consistent then so is Peano arithmetic. This is because a contradictory formula is interpreted as , which is still contradictory. Moreover, the proof of the relationship is entirely constructive, giving a way to transform a proof of in Peano arithmetic into a proof of in Heyting arithmetic. (By combining the double-negation translation with the Friedman translation, it is in fact possible to prove that Peano arithmetic is Π-conservative over Heyting arithmetic.)\n\nThe propositional mapping of φ to ¬¬φ does not extend to a sound translation of first-order logic, because is not a theorem of intuitionistic predicate logic. This explains why φ has to be defined in a more complicated way in the first-order case.\n\n\n\n"}
{"id": "42249910", "url": "https://en.wikipedia.org/wiki?curid=42249910", "title": "Embodied design", "text": "Embodied design\n\nEmbodied design grows from the idea of embodied cognition: that the actions of the body can play a role in the development of thought and ideas. Embodied design brings mathematics to life; studying the effects of the body on the mind, researchers learn how to design objects and activities for learning. Embodiment is an aspect of pattern recognition in all fields of human endeavor.\n\nEmbodied design has an increasing role in mathematics education. Designers can use embodied cognition as a tool to study human behavior and create user-centered designs. Embodied design examines the meaning of abstractions, analyzing student reasoning and connecting mathematics to other subjects; for example, students can look at proportional relationships in a work of art.\n\nLearning strategies based on embodied design rely on motion and visualization; physical activity is helpful in learning a mathematical concept. When students are physically and mentally involved in learning, they retain content better. Recent theoretical advances such as Embodied Cognitive Load Theory have been suggested to harvest the potential advantages of embodied interaction modes for learning without filling up cognitive resources. Embodied design frequently includes trial-and-error learning.\n\nEmbodied cognition is a tool designers can use to study \"human behavior normally unobservable in order to create human-centric designs\". For teachers, embodied design is planning experiences for students with lesson plans, curricula, activities and lessons.\n\nOne aspect of embodied design is the use of manipulatives in learning. Manipulatives allow students to explore mathematical concepts by working with physical objects, linking their discoveries to abstractions. Although manipulatives are primarily used to illustrate modern elementary mathematics, educators use objects to represent abstract topics taught in high school, college and beyond. A function of embodied design is to expand the use of manipulatives to foster the understanding of undergraduate abstract mathematics.\n\nOne disadvantage of manipulatives is that students struggle to connect the physical activity to mathematical symbols and notation. Although manipulatives allow students to develop a deeper understanding of a concept, they need support to transfer that knowledge to algebraic representations.\n\nAlthough an influential theory in the field of instructional design, cognitive load theory, recommends designs involving lower levels of interactivity in order to save up cognitive resources for learning, the benefits of embodied interactions are evident. As a result, a synthesis, embodied cognitive load theory, has been proposed to aid in embodied design. In this model, embodied interactions are conducive to learning if the cognitive costs (such as motor coordination) are outweighed by their benefits (such as multimodal processing).\n\nAnother application of embodied design in mathematics education is its effect on problem solving and the development of critical-thinking skills. Throughout the problem-solving process students use objects to develop understanding, conveying understanding and meaning through gestures. Problem solvers use gestures to connect their thoughts to the manipulatives with which they are familiar, and changing a manipulative's shape affects how a student connects with it and uses it to solve a problem. In a study by van Gog, Post, ten Napel and Deijkers, students performed better when they used simpler objects (such as colored discs) than when they used more-complicated objects (such as animal figures). Although problems can be as simple as what to wear or eat, their solutions are still a cognitive process.\n\nWith embodied design, mathematics is not only about correct answers but the process of finding them. Students are asked to communicate the process (\"road map\") they took to arrive at an answer. Typical problem-solving questions, such as \"What needs do you have? What is the problem you are posed with? How did you collect information? How did you come to your conclusion? How could you have optimized your steps to reach that conclusion?\" can be answered with manipulatives. One aim of problem solving in embodied design is to inspire students' creativity and curiosity, allowing personal connections to problems.\n\nIf students are given a problem which involves tactile manipulation, the learning process may be more meaningful. For example, students can learn to solve a Rubik's Cube puzzle by using a series of algorithms and steps. The process involves orientation, following directions and spatial cognition.\n\nOne approach to embodied design in mathematics is the use of creative tasks, such as arts and crafts. When a student has mathematics in mind while creating a unique piece, they are engaged in mental and physical learning. The concept of area can be taught with an arts-and-crafts activity, where students find leaves and trace them on paper; they are then asked to determine the number of beans (or peas) required to cover the entire leaf area. The class can then be asked which student had the largest (or smallest) leaf, and the areas can be compared.\n\nWith game consoles such as the Wii and PlayStation Move, students can understand how moving a gaming wand can change the effects on the screen. Researchers who developing programs in mathematics use embodied design and gaming principles to help students create and manipulate mathematical models. At the Embodied Design Research Laboratory, researchers created a game in which fifth-graders learn ratios by holding tennis balls in the air. When the tennis balls are held at a 1:2 ratio, the screen turns green.\n\nAnother embodied-design area related to programming is digital manipulatives. Some students feel weak in mathematics because it is not connected to the physical world, and digital manipulatives are being created to strengthen the connection between mathematics and the physical world.\n\nWhen students use a touchscreen with their fingers, they use gestures to create (or use) virtual objects in the program. Computers can model environments where the students imagine their bodies to be, and the mind behaves as it would on a playground. Cell phones, pads and computers provide mathematically-enhanced models everywhere, exploring everyday experiences and the curriculum in more-abstract ways.\n"}
{"id": "663489", "url": "https://en.wikipedia.org/wiki?curid=663489", "title": "Endre Szemerédi", "text": "Endre Szemerédi\n\nEndre Szemerédi (; born August 21, 1940) is a Hungarian-American mathematician and computer scientist, working in the field of combinatorics and theoretical computer science. He has been the State of New Jersey Professor of computer science at Rutgers University since 1986. He also holds a professor emeritus status at the Alfréd Rényi Institute of Mathematics of the Hungarian Academy of Sciences.\n\nSzemerédi has won prizes in mathematics and science, including the Abel Prize in 2012. He has made a number of discoveries in combinatorics and computer science, including Szemerédi's theorem, the Szemerédi regularity lemma, the Erdős–Szemerédi theorem, the Hajnal–Szemerédi theorem and the Szemerédi–Trotter theorem.\n\nSzemerédi was born in Budapest. Since his parents wished him to become a doctor, Szemerédi enrolled at a college of medicine, but he dropped out after six months (in an interview he explained it: \"I was not sure I could do work bearing such responsibility.\"). He studied in Eötvös Loránd University in Budapest and received his PhD from Moscow State University. His adviser was Israel Gelfand. This stemmed from a misspelling, as Szemerédi originally wanted to study with Alexander Gelfond.\n\nSzemerédi has been the State of New Jersey Professor of computer science at Rutgers University since 1986. He has held visiting positions at Stanford University (1974), McGill University (1980), the University of South Carolina (1981–1983) and the University of Chicago (1985–1986).\n\nEndre Szemerédi has published over 200 scientific articles in the fields of discrete mathematics, theoretical computer science, arithmetic combinatorics and discrete geometry. He is best known for his proof from 1975 of an old conjecture of Paul Erdős and Pál Turán: if a sequence of natural numbers has positive upper density then it contains arbitrarily long arithmetic progressions. This is now known as Szemerédi's theorem. One of the lemmas introduced in his proof is now known as the Szemerédi regularity lemma, which has become an important lemma in combinatorics, being used for instance in property testing for graphs and in the theory of graph limits.\n\nHe is also known for the Szemerédi–Trotter theorem in incidence geometry and the Hajnal–Szemerédi theorem in graph theory. Miklós Ajtai and Szemerédi proved the corners theorem, an important step toward higher-dimensional generalizations of the Szemerédi theorem. With Ajtai and János Komlós he proved the \"ct\"/log \"t\" upper bound for the Ramsey number \"R\"(3,\"t\"), and constructed a sorting network of optimal depth. With Ajtai, Václav Chvátal, and Monroe M. Newborn, Szemerédi proved the famous Crossing Lemma, that a graph with \"n\" vertices and \"m\" edges, where has at least crossings. With Paul Erdős, he proved the Erdős–Szemerédi theorem on the number of sums and products in a finite set. With Wolfgang Paul, Nick Pippenger, and William Trotter, he established a separation between nondeterministic linear time and deterministic linear time, in the spirit of the infamous P versus NP problem.\n\nSzemerédi has won numerous awards and honors for his contribution to mathematics and computer science. A few of them are listed here:\n\nSzemerédi is a corresponding member (1982), and member (1987) of the Hungarian Academy of Sciences and a member (2010) of the National Academy of Sciences. He is also a member of the Institute for Advanced Study in Princeton, New Jersey and a permanent research fellow at the Alfréd Rényi Institute of Mathematics in Budapest. He was the Fairchild Distinguished Scholar at the California Institute of Technology in 1987–88.\nHe is an honorary doctor of Charles University in Prague.\nHe was the lecturer in the Forty-Seventh Annual DeLong Lecture Series at the University of Colorado. He is also a recipient of the Aisenstadt Chair at CRM, University of Montreal. In 2008 he was the Eisenbud Professor at the Mathematical Sciences Research Institute in Berkeley, California.\n\nIn 2012, Szemerédi was awarded the Abel Prize “for his fundamental contributions to discrete mathematics and theoretical computer science, and in recognition of the profound and lasting impact of these contributions on additive number theory and ergodic theory” The Abel Prize citation also credited Szemerédi with bringing combinatorics to the centre-stage of mathematics and noted his place in the tradition of Hungarian mathematicians such as George Pólya who emphasized a problem-solving approach to mathematics. Szemerédi reacted to the announcement by saying that \"It is not my own personal achievement, but recognition for this field of mathematics and Hungarian mathematicians,\" that gave him the most pleasure.\n\nOn August 2–7, 2010, the Alfréd Rényi Institute of Mathematics and the János Bolyai Mathematical Society organized a conference in honor of the 70th birthday of Endre Szemerédi.\n\nPrior to the conference a volume of the Bolyai Society Mathematical Studies Series, \"An Irregular Mind\", a collection of papers edited by Imre Bárány and József Solymosi, was published to celebrate Szemerédi's achievements on the occasion of his 70th birthday. Another conference devoted to celebrating Szemerédi's work is\nthe Third Abel Conference: A Mathematical Celebration of Endre Szemerédi.\n\nSzemerédi is married and has five children.\n\n"}
{"id": "30445494", "url": "https://en.wikipedia.org/wiki?curid=30445494", "title": "Euler calculus", "text": "Euler calculus\n\nEuler calculus is a methodology from applied algebraic topology and integral geometry that integrates constructible functions and more recently definable functions by integrating with respect to the Euler characteristic as a finitely-additive measure. In the presence of a metric, it can be extended to continuous integrands via the Gauss–Bonnet theorem. It was introduced independently by Pierre Schapira and Oleg Viro in 1988, and is useful for enumeration problems in computational geometry and sensor networks.\n\nEuler calculus begins from the observation that the Euler characteristic with compact supports obeys one of the main properties of a measure:\nformula_1. As a result, for a suitably restricted class of functions, it is possible to define an integral with respect to this measure. One begins by selecting an o-minimal structure of \"definable\" sets in the topology, for instance, semialgebraic or subanalytic sets. The class of constructible functions consists of those functions formula_2 such that formula_3 is definable for all formula_4. A definition of the Euler integral follows: \nformula_5\nDue to the properties of the o-minimal structure, the integral may also be computed by decomposing formula_6 as a sum of indicator functions defined on a disjoint union of cells formula_7 (giving formula_8 a cell structure). If formula_9, then\nformula_10\n\n\n\n"}
{"id": "24864800", "url": "https://en.wikipedia.org/wiki?curid=24864800", "title": "Fedosov manifold", "text": "Fedosov manifold\n\nIn mathematics, a Fedosov manifold is a symplectic manifold with a compatible torsion-free connection, that is, a triple (\"M\", ω, ∇), where (\"M\", ω) is a symplectic manifold (i.e., ω is a symplectic form, a non-degenerate closed exterior 2-form, on a \"C\"-manifold \"M\"), and ∇ is a symplectic torsion-free connection on \"M\". (A connection ∇ is called compatible or symplectic if \"X\" ⋅ ω(\"Y,Z\") = ω(∇\"Y\",\"Z\") + ω(\"Y\",∇\"Z\") for all vector fields \"X,Y,Z\" ∈ Γ(T\"M\"). In other words, the symplectic form is parallel with respect to the connection, i.e., its covariant derivative vanishes.) Note that every symplectic manifold admits a symplectic torsion-free connection. Cover the manifold with Darboux charts and on each chart define a connection ∇ with Christoffel symbol formula_1. Then choose a partition of unity (subordinate to the cover) and glue the local connections together to a global connection which still preserves the symplectic form. The famous result of Boris Vasilievich Fedosov gives a canonical deformation quantization of a Fedosov manifold.\n\nFor example, formula_2 with the standard symplectic form formula_3 has the symplectic connection given by the exterior derivative formula_4. Hence, formula_5 is a Fedosov manifold.\n\n"}
{"id": "43540545", "url": "https://en.wikipedia.org/wiki?curid=43540545", "title": "Frequency selective surface", "text": "Frequency selective surface\n\nA frequency-selective surface (FSS) is any thin, repetitive surface (such as the screen on a microwave oven) designed to reflect, transmit or absorb electromagnetic fields based on the frequency of the field. In this sense, an FSS is a type of optical filter or metal-mesh optical filters in which the filtering is accomplished by virtue of the regular, periodic (usually metallic, but sometimes dielectric) pattern on the surface of the FSS. Though not explicitly mentioned in the name, FSS's also have properties which vary with incidence angle and polarization as well - these are unavoidable consequences of the way in which FSS's are constructed. Frequency-selective surfaces have been most commonly used in the radio frequency region of the electromagnetic spectrum and find use in applications as diverse as the aforementioned microwave oven, antenna radomes and modern metamaterials. Sometimes frequency selective surfaces are referred to simply as periodic surfaces and are a 2-dimensional analog of the new periodic volumes known as photonic crystals.\n\nMany factors are involved in understanding the operation and application of frequency selective surfaces. These include analysis techniques, operating principles, design principles, manufacturing techniques and methods for integrating these structures into space, ground and airborne platforms.\n\nHistorically, the first approach to solving for fields reflected and transmitted by FSS was the spectral domain method (SDM), and it is still a valuable tool even today [Scott(1989)]. The spectral domain method is known at Ohio State University as the periodic method of moments (PMM). The SDM starts out with an assumed Floquet/Fourier series solution for all fields, currents and potentials whereas the PMM starts out with a single scatterer, then adds in all of the scatterers in the infinite plane (in the \"spatial\" domain), then uses a transformation to yield the spectral domain representation of the fields. Both approaches are effectively the same approach, in the sense that they both assume an infinite planar structure which gives rise to a discrete Fourier series representation for the fields.\n\nThe spectral domain method has one very important advantage over other – strictly numerical - solutions to Maxwell's equations for FSS. And that is that it yields a matrix equation of very small dimensionality, so it is amenable to solution on virtually any type of computer. The dimension of the matrix is determined by the number of current basis functions on each individual scatterer and can be as small as 1×1 for a dipole at or below resonance. The matrix elements however take longer to compute than with volumetric approaches such as FEM. Volumetric approaches require that a volume surrounding the unit cell be gridded accurately, and can require many thousands of elements for an accurate solution, though the matrices are usually sparse.\n\nThe spectral domain method is based on Floquet's principle, which implies that when an infinite, planar, periodic structure is illuminated by an infinite plane wave, then every unit cell in the periodic plane must contain exactly the same currents and fields, except for a phase shift, corresponding to the incident field phase. This principle allows all currents, fields and potentials to be written in terms of a modified Fourier series, which consists of an ordinary Fourier series multiplied by the incident field phase. If the periodic plane occupies the \"x\"-\"y\" plane, then the Fourier series is a 2-dimensional Fourier series in \"x\", \"y\".\n\nAs in Fourier optics, the Floquet–Fourier series expansion of fields and currents \"in the plane of the FSS\" leads immediately to the discrete plane wave spectrum representation of the fields on either side of the FSS.\n\nPerfectly electrically conducting (PEC) periodic surfaces are not only the most common but also the easiest to understand mathematically, as they admit only electric current sources J. This section presents the spectral domain method for analyzing a free-standing (no substrate) PEC FSS. The electric field E is related to the vector magnetic potential A via the well-known relation (Harrington [2001], Scott [1989], Scott [1997]):\n\nand the vector magnetic potential is in turn related to the source currents via (Harrington [2001], Scott [1997]):\n\nwhere\n\nFrequency-selective surfaces are frequently stratified in the direction normal to the plane of the surface. That is, all dielectrics are stratified and all metallic conductors are considered stratified as well, and they will be regarded as perfectly planar. As a result, we are excluding metallic vias (wires perpendicular to the plane of the FSS) which could potentially connect currents from different strata of the FSS structure. With this type of a stratified structure in mind, we can then use a plane wave expansion for the fields in and around the FSS, since plane waves are the eigenfunction solution to the vector wave equations in \"source-free media\".\n\nTo solve equations (1.1) and (1.2) for a free-standing, doubly periodic surface, we consider an infinite 2D periodic surface occupying the entire x-y plane, and assume a discrete plane wave expansion for all currents, fields and potentials (Tsao [1982], Scott [1989], Fourier optics):\n\nwhere for mathematical simplicity, we assume a rectangular lattice in which α only depends on \"m\" and β only depends on \"n\". In the equations above,\n\nand,\n\nwhere \"l\", \"l\" are the dimensions of the unit cell in the \"x\",\"y\" directions respectively, λ is the free space wavelength and θ, φ are the directions of an assumed incident plane wave, with the FSS regarded as lying in the \"x\"-\"y\" plane. In (2.2c), the root is taken which has a positive real part and non-positive (\"i\".\"e\"., either negative or zero) imaginary part).\n\nSubstituting equations (2.1) into (1.1) and (1.2) yields the spectral domain Greens function relating the radiated electric field to its source currents (Scott [1989]), where we now consider only those components of the field vectors lying in the plane of the FSS, the x-y plane:\n\nwhere,\n\nOne notices the branch point singularity in the equation above (the inverse square root singularity), which is no problem thanks to the discrete spectrum, as long as the wavelength never equals the cell spacing. With this, the electric field boundary condition on the surface of PEC material within a unit cell becomes (Scott [1989]):\n\nwhere again, we are restricting our attention to the x,y components of currents and fields, which lie in the plane of the scatterer.\n\nEquation (3.3) is not strictly correct, since only the tangential components of electric field are actually zero on the surface of the PEC scatterers. This inexactness will be resolved presently when (3.3) is tested with the current basis functions, defined as residing on the surface of the scatterer.\n\nIn this type of problem, the incident field is considered a plane wave expressed as\n\nin the x-y plane.\n\nAs is usual in the method of moments, we assume an expansion for the source currents over some known set of basis functions with unknown weighting coefficients \"J\" (Scott [1989]):\n\nSubstituting (4.1) into (3.3) and then testing the resulting equation with the \"i\"-th current basis function (i.e., dotting from the left and integrating over the domain of the \"i\"-th current basis function, thereby completing the quadratic form) produces the \"i\"-th row of the matrix equation as (Scott [1989]):\n\nThis is the \"i\"-th row of the electric field integral equation (EFIE) for a free-standing metallic FSS. Equation (4.2) may be readily modified for analyzing FSS with surrounding dielectric sheets (substrates and/or superstrates), and even complex multi-layer FSS structures (Scott [1989]). All of these matrix equations are very simple to implement and require only that the 2D Fourier transform (FT) of the basis functions be computed, preferably in closed form. There is a striking similarity between eqn. (4.2) above, and the Bloch wave - MoM method eqn. (4.2) for computing ω–β diagrams for triply-periodic electromagnetic media such as photonic crystals (Scott [1998], Scott [2002], available on researchgate.net). Given this similarity, eqn. (4.2) and its numerous variants in dielectric-layered FSS structures (Scott [1989]) could also be used (with the RHS set to zero) to find surface waves in complex FSS structures.\n\nThe RWG (Rao–Wilton–Glisson) basis functions (Rao, Wilton and Glisson [1982]) are a very versatile choice for many purposes and have a transform that is readily computed using area coordinates.\n\nEquations (4.2) and (3.1) have been used to solve for the electric current J and then the scattered fields E to compute reflection and transmission from various types of FSS (Scott[1989]). The reflected field is due to the currents on the FSS (the field radiated by the FSS) and the transmitted field is equal to the radiated field plus the incident field, and differs from the reflected field only for the \"m\" = 0, \"n\" = 0 order (the zero order).\n\nFor wavelengths greater than the FSS lattice dimensions, only one – out of the infinitude of Floquet modes – actually propagates. All of the others are (exponentially decaying in the z-direction, normal to the plane of the FSS, since the quantity under the root in (2.2c) is negative. And for FSS spacings greater than roughly a tenth of a wavelength or so, these evanescent wave fields have negligible effect on FSS stack performance. So, for practical purposes, in the frequency bands for which we'll be likely to use the FSS, a single propagating wave will be sufficient to capture the significant properties of a multi-layer FSS stack. This single propagating wave can be modeled in terms of an equivalent transmission line.\n\nThe FSS sheet may be represented in terms of lumped RLC networks placed in parallel across the transmission line. The shunt admittance FSS model is exact only for an infinitesimally thin FSS, for which the tangential electric field is continuous across the FSS; for finite thickness FSS, a tee or pi network can be used as a better approximation.\n\nBoth free space and transmission lines admit TEM traveling wave solutions, and even the TE/TM plane waves in free space can be modeled using equivalent transmission line models. The main thing is that both free space and transmission lines admit traveling wave solutions with a z-dependence of the form:\n\nOne can construct equivalent transmission lines as follows:\n\nFor TEM waves,\n\nFor TE waves,\n\nFor TM waves,\n\nwhere θ is the angle off-normal that the incident wave makes with respect to the FSS. Z for free space is 377 Ohms.\n\nCircuit elements placed in parallel across an equivalent transmission line have some factors in common with thin FSS. The continuity of tangential electric field condition for thin FSS mirrors the voltage continuity condition on either side of the shunt circuit elements. The magnetic field jump condition for the FSS mirrors the Kirchhoff current division law for the equivalent circuit. For sufficiently thick FSS sheets, a more general pi or tee model will likely be required for good approximation to the real FSS.\n\nFor all but the most tightly packed dipole arrays (the brickwork-like \"gangbuster\" low-pass filters), a first order understanding of FSS operation can be achieved by simply considering the scattering properties of a single periodic element in free space. A dipole or patch in free space will strongly reflect energy for wavelengths comparable in size to the object itself, for example when the dipole is 1/2 wavelength in length. For frequencies below this first resonance (and for frequencies between the first and second resonance), the object will reflect little energy. So, this resonance phenomenon observed with dipoles and patches leads naturally to the notion of modeling them as a resonant circuit connected in parallel across a transmission line - in this case the element is a series connection of a capacitor and inductor, which produces a reflective short circuit at resonance. This type of structure would be known as a band-reject or band-stop filter. Bandpass filters may be constructed using apertures in conducting planes, which are modeled as a shunt element consisting of a parallel connection of an inductor and a capacitor.\n\nOne-dimensional line gratings can be modeled as shunt inductors (for polarization parallel to the lines) or shunt capacitors (for polarization perpendicular to the lines). Tightly packed \"gangbuster\" dipole arrays are lowpass structures that can be modeled using shunt capacitors.\n\nThe exact circuit topology and element values of an equivalent circuit for a FSS sheet have to be determined using first-principles codes. A bandpass mesh-type FSS sheet is a parallel connection of L,C and bandstop patch-type FSS sheet is a series connection of L,C and in both cases, the L,C values are determined from the center frequency and bandwidth of the filter.\n\nThe equivalent transmission line circuit models for FSS came into being from the observation that FSS yield reflection and transmission properties that are very similar to the reflection and transmission properties of inductors and capacitors placed in parallel across a transmission line.\n\nThe two fundamental types of FSS are shown in Fig. 2.4.1-1 to the right - the bandpass mesh-type FSS and the bandstop patch-type FSS (Metal-mesh optical filters). The equivalent circuit for a patch-type bandstop FSS is shown in Fig. 2.4.1-2. The impedance of the series connection of the inductor and the capacitor is (Desoer, Kuh [1984]):\n\nor,\n\nand this series connection of an inductor and capacitor produces a zero impedance (short circuit) condition when\n\nAt the short circuit condition, all incident energy is reflected, and so this is the equivalent circuit of a resonant patch bandstop filter.\n\nThe magnitude of the reflection coefficient is:\n\nwhere Z is the characteristic impedance of the transmission line.\n\nThe frequencies for the upper and lower 3 dB points are given as the solution to the equation:\n\nwhere,\n\nSo, if the center frequency and the width of the resonance are determined from first principles codes, the L,C of the equivalent circuit may be readily obtained by fitting the reflection response of the equivalent resonant circuit to the reflection response of the actual FSS, and in this way, the circuit parameters L,C are readily extracted. Once that is done, then we can use the equivalent circuit model for multi-layer FSS design. Any nearby dielectrics should be included in the equivalent circuit.\n\nFor small values of ω, the impedance of the inductor, jωL, is smaller than the impedance of the capacitor, 1/jωC, therefore the capacitor dominates the shunt impedance and so the patch-type bandstop FSS is capacitive below resonance. We'll use this fact in section 2.3.1 to design a lowpass FSS filter using equivalent circuits.\n\nThe equivalent circuit for a mesh-type bandpass FSS is shown in Fg. 2.4.2-1. The admittance of the parallel connection of inductor and capacitor is (Desoer, Kuh [1984]):\n\nand this admittance is zero (open-circuit condition) when\n\nWhen the parallel combination of inductor and capacitor produces an open circuit, all energy is transmitted.\n\nIn the same way, the magnitude of the transmission coefficient of the bandpass filter is:\n\nBelow resonance, the admittance of the inductor, 1/jωL is greater than the admittance of the capacitor jωC, therefore the mesh-type bandpass FSS is inductive below resonance.\n\nFig. 2.4.3-1 shows the comparison in reflection between a single-layer crossed dipole FSS and its fitted equivalent circuit. The equivalent circuit is a series connection of a capacitor and inductor placed in parallel across the transmission line, as in Fig. 2.4.1-2. This resonator produces a short circuit condition at resonance. The fit is very good below the resonance though not nearly as good above.\n\nThe real FSS has a reflection null at 18.7 GHz (the frequency at which the wavelength equals the unit cell dimension of .630\"), which is not accounted for in the equivalent circuit model. The null is known as a Wood's anomaly and is caused by the inverse square root singularity in the spectral domain Green's function (3.1) going to infinity. Physically, this represents a uniform plane wave propagating in the plane of the FSS. In the spatial domain, the coherent summation of all of the spatial domain Green's function's becomes infinite, so that any finite current produces an infinite field on the surface of the FSS. As a result, all currents must be zero under this condition.\n\nThis example illustrates the usefulness and shortcomings of the simple equivalent circuit model. The equivalent circuit only includes features related to the individual scattering element, not features related to the periodic array, such as interactions between the scatterers.\n\nIf a mesh type FSS is created from a patch type FSS in such a way that the metal portions or the former are replaced by aperture portions of the latter, then the two FSS are said to be duals of one another. Duality only strictly applies when no dielectric substrates are present, therefore it is only approximately satisfied in practice, though even when dielectric substrates are present, duality can be useful in FSS design. As a side note, Pathological FSS patterns such as a checkerboard FSS may be treated as the limit of the patch and mesh as the patch (and aperture) size approaches the unit cell size, with electrical connections of the mesh retained in the limit. For dual FSS, the reflection coefficient of the patch will be equal to the transmission coefficient of the mesh.\n\nCircuit duality\n\nThe dual circuit of the bandstop filter can be obtained simply equating the reflection coefficient of the bandstop FSS to the transmission coefficient of the bandpass FSS to obtain (if we use L, C for the bandstop patch FSS and L, C for the bandpass mesh FSS):\n\nThis produces a bandpass circuit (with parameters L, C) which is the dual of the bandstop circuit (with parameters L, C).\n\nOnce the transmission line equivalent circuit has been determined, multi-layer FSS design becomes much simpler and more intuitive - like ordinary filter analysis and design. Now while it is certainly possible to design multi-layer FSS structures using first principles codes and generalized scattering matrices (GSM), it is far easier, quicker and more intuitive to use equivalent circuit models for FSS design, since it is possible to leverage decades' worth of research performed on electrical filter analysis and design and bring it to bear on FSS structures. And, FSS filters are even easier to design than waveguide filters since the incidence angle does not vary with frequency.\n\nAs an example of how to use FSS equivalent circuits for quick and efficient design of a practical filter, we can sketch out the process that would be followed in designing a 5-stage Butterworth filter (Hunter [2001], Matthaei [1964]) using a stack of 5 frequency selective surfaces, with 4 air spacers in between the FSS sheets.\n\nThe lowpass prototype L,C ladder network is shown in Fig. 3.1.1-1 (Hunter [2001]). The cutoff frequency will be scaled to 7 GHz and the filter will be matched to 377 Ohms (the impedance of free space) on the input and output sides. The idea we'll follow is that the shunt capacitors will eventually be replaced by sub-resonant (capacitive) patch-type FSS sheets and the series inductors will be replaced by air spacers between the 5 FSS layers. Short transmission lines are approximately equivalent to series inductors.\n\nThe transmission magnitude and phase response of the scaled Butterworth L,C filter is shown in Fig. 3.1.2-1. Transmission magnitude is flat in the passband (below the 7 GHz cutoff frequency) and has a monotonically decreasing skirt on the high frequency side of the passband. The phase through the filter is linear throughout the 7 GHz passband, making this filter an ideal choice for a linear phase filter application, for example in the design of an ultra-wideband filter that approximates a true time delay transmission line. This is the baseline lumped L,C filter that will be the starting point for our 5-layer FSS Butterworth filter design.\n\nNow we begin the process of transforming the prototype Butterworth lumped L,C filter into an equivalent FSS Butterworth filter. Two modifications of the baseline lumped L,C filter will be necessary, in order to obtain the corresponding FSS filter. First, the series inductors will be replaced by their equivalent transmission line sections, and then the shunt capacitors will be replaced by capacitive frequency selective surfaces.\n\nAt this point in the development, the series inductors in the prototype L,C ladder network will now be replaced by sub-half-wavelength air spacers (which we will model as transmission lines) between the FSS layers. The thickness of the air spacers may be determined as shown in Fig. 3.1.3-1, in which we compare the ABCD matrix of a series inductor with the ABCD matrix of a short transmission line (Ramo [1994]), in order to obtain the proper length of transmission line between the shunt capacitors (sub-resonant FSS layers) to produce a Butterworth filter response. It is well known that a series inductor represents an approximate lumped circuit model of a short transmission line, and we'll exploit this equivalence to determine the required thickness of the air spacers.\n\nWith the thickness of the air spacers between sheets now determined, the equivalent circuit now takes on the form shown in Fig. 3.1.4-1:\n\nNow the only thing left to do is to find the lowpass FSS that yields the shunt capacitance values called out in Fig. 2.3.1-4. This is usually done through trial and error. Fitting a shunt capacitor to a real FSS is done by repeated running of a first principles code to match the reflection response of the shunt capacitor with the reflection from a capacitive FSS. Patch-type FSS below resonance will produce a capacitive shunt admittance equivalent circuit, with closer packing of elements in the FSS sheet yielding higher shunt capacitance values in the equivalent circuit.\n\nFSS can seemingly take on a nearly infinite number of forms, depending on the application. And now FSS are being used in the development of certain classes of meta-materials.\n\nFSS are typically resonance region structures (wavelength comparable to element size and spacing). FSS can be classified either by their form or by their function. Morphologically, Munk (Munk [200]) classified FSS elements into 2 broad categories: those that are \"wire-like\" (one-dimensional) and those that are \"patch-like\" (two-dimensional) in appearance. His lifelong preference was for the one-dimensional wire-like FSS structures, and they do seem to have advantages for many applications. Frequency selective surfaces, as any type of filter, may also be classified according to their function, and these usually fall into 3 categories: low-pass, high-pass and bandpass, in addition to band-stop filters. FSS may be made to be absorptive as well, and absorption is usually over some frequency band.\n\nA number of FSS scatterer configurations are now known, ranging from early types such as resonant dipoles, disks and squares to crossed dipoles, Jerusalem crosses, four-legged loaded slots and tripoles,\n\nThe FSS reflection and transmission properties are determined by both the individual scatterer and the lattice.\n\nTypically FSSs are fabricated by chemically etching a copper-clad dielectric sheet, which may consist of Teflon (ε=2.1), Kapton, (ε=3.1), fiberglass (ε-4.5) or various forms of duroid (ε=6.0, 10.2). The sheet may range in thickness from a few thousandths of an inch to as much as 20–40 thousand.\n\nApplications of FSS range from the mundane (microwave ovens) to the forefront of contemporary technology involving active and reconfigurable structures such as smart skins.\n\n\n"}
{"id": "1077450", "url": "https://en.wikipedia.org/wiki?curid=1077450", "title": "G. N. Watson", "text": "G. N. Watson\n\nGeorge Neville Watson (31 January 1886 – 2 February 1965) was an English mathematician, who applied complex analysis to the theory of special functions. His collaboration on the 1915 second edition of E. T. Whittaker's \"A Course of Modern Analysis\" (1902) produced the classic \"Whittaker and Watson\" text. In 1918 he proved a significant result known as Watson's lemma, that has many applications in the theory on the asymptotic behaviour of exponential integrals.\n\nHe was educated at St Paul's School, as a pupil of F. S. Macaulay, and Trinity College, Cambridge. There he encountered Whittaker, though their overlap was only two years. He became Professor at the University of Birmingham in 1918, where he remained until 1951.\n\nHe was awarded an honorary MSc Pure Science in 1919 by Birmingham University.\n\nHis \"Treatise on the theory of Bessel functions\" (1922) also became a classic, in particular in regard to the asymptotic expansions of Bessel functions.\n\nHe subsequently spent many years on Ramanujan's formulae in the area of modular equations, mock theta functions and q-series, and for some time looked after Ramanujan's lost notebook.\n\nRamanujan discovered many more modular equations than all of his mathematical predecessors combined. Watson provided proofs for most of Ramanujan's modular equations. Bruce C. Berndt completed the project begun by Watson and Wilson. Much of Berndt's book \"Ramanujan's Notebooks, Part 3\" (1998) is based upon the prior work of Watson.\n\nWatson's interests included solvable cases of the quintic equation. He introduced Watson's quintuple product identity.\n\nWatson was elected in 1919 to the Royal Society, and in 1946, he received the Sylvester Medal from the Society. He was president of the London Mathematical Society from 1933 to 1935.\n\nHe is sometimes confused with the mathematician G. L. Watson, who worked on quadratic forms, and G. Watson, a statistician.\n"}
{"id": "28408157", "url": "https://en.wikipedia.org/wiki?curid=28408157", "title": "Galactic quadrant", "text": "Galactic quadrant\n\nA galactic quadrant, or quadrant of the Galaxy, is one of four circular sectors in the division of the Milky Way Galaxy.\n\nIn actual astronomical practice, the delineation of the galactic quadrants is based upon the galactic coordinate system, which places the Sun as the pole of the mapping system. The Sun is used instead of the Galactic Center for practical reasons since all astronomical observations (by humans) to date have been based on Earth or within the solar system.\n\nQuadrants are described using ordinals—for example, \"1st galactic quadrant\" \"second galactic quadrant,\" or \"third quadrant of the Galaxy.\" Viewing from the north galactic pole with 0 degrees (°) as the ray that runs starting from the Sun and through the galactic center, the quadrants are as follows (where is galactic longitude):\n\nDue to the orientation of the Earth with respect to the rest of the Galaxy, the 2nd galactic quadrant is primarily only visible from the northern hemisphere while the 4th galactic quadrant is mostly only visible from the southern hemisphere. Thus, it is usually more practical for amateur stargazers to use the celestial quadrants. Nonetheless, cooperating or international astronomical organizations are not so bound by the Earth's horizon.\n\nBased on a view from Earth, one may look towards major constellations for a rough sense of where the borders of the quadrants are: (Note: by drawing a line through the following, one can also approximate the galactic equator.)\n\nA long tradition of dividing the visible skies into four precedes the modern definitions of four galactic quadrants. Ancient Mesopotamian formulae spoke of \"the four corners of the universe\" and of \"the heaven's four corners\",\nand the Biblical Book of Jeremiah echoes this phraseology: \"And upon Elam will I bring the four winds from the four quarters of heaven\" (Jeremiah, 49:36). Astrology too uses quadrant systems to divide up its stars of interest. And the astronomy of the location of constellations sees each of the Northern and Southern celestial hemispheres divided into four quadrants.\n\n\"Galactic quadrants\" within \"Star Trek\" are based around a meridian that runs from the center of the Galaxy through Earth's solar system, which is not unlike the system used by astronomers. However, rather than have the perpendicular axis run through the Sun, as is done in astronomy, the \"Star Trek\" version runs the axis through the galactic center. In that sense, the \"Star Trek\" quadrant system is less geocentric as a cartographical system than the standard. Also, rather than use ordinals, \"Star Trek\" designates them by the Greek letters Alpha, Beta, Gamma, and Delta.\n\nThe Canadian Galactic Plane Survey (CGPS) created a radio map of the Galaxy based on \"Star Trek\"s quadrants, joking that \"the CGPS is primarily concerned with Cardassia, while the SGPS (Southern Galactic Plane Survey) focuses on Romulans.\"\n\n\n"}
{"id": "589626", "url": "https://en.wikipedia.org/wiki?curid=589626", "title": "George Darwin", "text": "George Darwin\n\nSir George Howard Darwin, KCB, FRS, FRSE (9 July 1845 – 7 December 1912) was an English barrister and astronomer, the second son and fifth child of Charles Darwin and Emma Darwin.\n\nGeorge H. Darwin was born at Down House, Kent, the fifth child of geneticist Charles Darwin and Emma Darwin.\n\nFrom the age of 11 he studied under Charles Pritchard at Clapham Grammar School, and entered St John's College, Cambridge, in 1863, though he soon moved to Trinity College, where his tutor was Edward John Routh. He graduated as second wrangler in 1868, when he was also placed second for the Smith's Prize and was appointed to a college fellowship. He earned his M.A. in 1871. He was admitted to the bar in 1872, but returned to science. \nGeorge Darwin conducted studies into the prevalence and health outcomes of contemporary first-cousin marriages in Great Britain. His father Charles had become concerned after the death of three of his children, including his favorite daughter, Annie, from tuberculosis in 1851, that his and Emma’s union may have been a mistake from a biological perspective. He was reassured by George's results.\n\nIn 1879, he was elected a Fellow of the Royal Society and won their Royal Medal in 1884 and their Copley Medal in 1911. He delivered their Bakerian Lecture in 1891 on the subject of \"tidal prediction\".\n\nIn 1883 Darwin became Plumian Professor of Astronomy and Experimental Philosophy at the University of Cambridge. He studied tidal forces involving the Sun, Moon, and Earth, and formulated the fission theory of Moon formation.\n\nDarwin was a Fellow of the Royal Astronomical Society (RAS) and won the Gold Medal of the RAS in 1892. From 1899–1901 he served as President of the RAS. The RAS founded a prize lectureship in 1984 and named it the George Darwin Lectureship in Darwin's honour.\n\nHe was an invited speaker in the International Congress of Mathematicians 1908, Rome on the topic of \"\"Mechanics, Physical Mathematics, Astronomy\".\" As President of the Cambridge Philosophical Society, he also gave the Introductory Address to the Congress in 1912 on the character of pure and applied mathematics.\n\nHe received the degree of \"Doctor mathematicae (honoris causa)\" from the Royal Frederick University on 6 September 1902, when they celebrated the centennial of the birth of mathematician Niels Henrik Abel.\n\nDarwin married Martha (Maud) du Puy, the daughter of Charles du Puy of Philadelphia, in 1884;\nhis wife was a member of the Ladies Dining Society in Cambridge, with 11 other members.\n\nShe died on 6 February 1947. They had three sons and two daughters:\n\n\nGeorge and Maud Darwin bought Newnham Grange, Cambridge in 1885. The Darwins extensively remodelled the house. Since 1962 the Grange has been part of Darwin College, Cambridge.\n\nHe is buried in Trumpington Extension Cemetery in Cambridge with his son Leonard and his daughter Gwen (Raverat), his wife Lady Maud Darwin was cremated at Cambridge Crematorium; his brothers Sir Francis Darwin and Sir Horace Darwin and their respective wives are interred in the Parish of the Ascension Burial Ground.\n\n\n\n"}
{"id": "57338111", "url": "https://en.wikipedia.org/wiki?curid=57338111", "title": "Golomb graph", "text": "Golomb graph\n\nIn graph theory, the Golomb graph is a polyhedral graph with 10 vertices and 18 edges. It is named after Solomon W. Golomb, who constructed it (with a non-planar embedding) as a unit distance graph that requires four colors in any graph coloring. Thus, like the simpler Moser spindle, it provides a lower bound for the Hadwiger–Nelson problem: coloring the points of the Euclidean plane so that each unit line segment has differently-colored endpoints requires at least four colors.\n\nThe method of construction of the Golomb graph as a unit distance graph, by drawing an outer regular polygon connected to an inner twisted polygon or star polygon, has also been used for unit distance representations of the Petersen graph and of generalized Petersen graphs. As with the Moser spindle, the coordinates of the unit-distance embedding of the Golomb graph can be represented in the quadratic field formula_1.\n\nThe fractional chromatic number of the Golomb graph is 10/3. The fact that this number is at least this large follows from the fact that the graph has 10 vertices, at most three of which can be in any independent set. The fact that the number is at most this large follows from the fact that one can find 10 three-vertex independent sets, such that each vertex is in exactly three of these sets.\nThis fractional chromatic number is less than the number 7/2 for the Moser spindle and less than the fractional chromatic number of the unit distance graph of the plane, which is bounded between 3.6190 and 4.3599.\n"}
{"id": "54133307", "url": "https://en.wikipedia.org/wiki?curid=54133307", "title": "Hadamard test (quantum computation)", "text": "Hadamard test (quantum computation)\n\nIn quantum computation the Hadamard test is a method used to create a random variable whose expected value is the expected real part of the observed value of a state with respect to some unitary operator.\n\nLet formula_1 be a state which can be efficiently generated, and let formula_2 be a unitary gate. The Hadamard test produces a random variable whose image is in formula_3 and whose expected value is exactly formula_4. A variant of the test produces a random variable whose expected value is formula_5.\n\nTo perform the Hadamard test we first calculate the state formula_6. We then apply the unitary operator on formula_1 conditioned on the first qubit to obtain the state formula_8. We then apply the Hadamard gate to the first qubit, yielding formula_9. \n\nMeasuring the first qubit, the result is formula_10 with probability formula_11, in which case we output formula_12. The result is formula_13 with probability formula_14, in which case we output formula_15. The expected value of the output will then be the difference between the two probabilities, which is formula_16\n\nTo obtain a random variable whose expectation is formula_5 follow the exact same procedure but start with formula_18.\n\nThe Hadamard test has many applications in quantum algorithms such as the Aharonov-Jones-Landau algorithm.\n"}
{"id": "1657860", "url": "https://en.wikipedia.org/wiki?curid=1657860", "title": "Hadwiger conjecture (graph theory)", "text": "Hadwiger conjecture (graph theory)\n\nIn graph theory, the Hadwiger conjecture (or Hadwiger's conjecture) states that, if all proper colorings of an undirected graph \"G\" use \"k\" or more colors, then one can find \"k\" disjoint connected subgraphs of \"G\" such that each subgraph is connected by an edge to each other subgraph. Contracting the edges within each of these subgraphs so that each subgraph collapses to a single vertex produces a complete graph \"K\" on \"k\" vertices as a minor of \"G\".\n\nThis conjecture, a far-reaching generalization of the four-color problem, was made by Hugo Hadwiger in 1943 and is still unsolved. call it “one of the deepest unsolved problems in graph theory.”\n\nAn equivalent form of the Hadwiger conjecture (the contrapositive of the form stated above) is that, if there is no sequence of edge contractions (each merging the two endpoints of some edge into a single supervertex) that brings a graph \"G\" to the complete graph \"K\", then \"G\" must have a vertex coloring with \"k\" − 1 colors.\n\nNote that, in a minimal \"k\"-coloring of any graph \"G\", contracting each color class of the coloring to a single vertex will produce a complete graph \"K\". However, this contraction process does not produce a minor of \"G\" because there is (by definition) no edge between any two vertices in the same color class, thus the contraction is not an edge contraction (which is required for minors). Hadwiger's conjecture states that there exists a different way of properly edge contracting sets of vertices to single vertices, producing a complete graph \"K\", in such a way that all the contracted sets are connected.\n\nIf \"F\" denotes the family of graphs having the property that all minors of graphs in \"F\" can be (\"k\" − 1)-colored, then it follows from the Robertson–Seymour theorem that \"F\" can be characterized by a finite set of forbidden minors. Hadwiger's conjecture is that this set consists of a single forbidden minor, \"K\".\n\nThe Hadwiger number \"h\"(\"G\") of a graph \"G\" is the size \"k\" of the largest complete graph \"K\" that is a minor of \"G\" (or equivalently can be obtained by contracting edges of \"G\"). It is also known as the contraction clique number of \"G\". The Hadwiger conjecture can be stated in the simple algebraic form \"χ\"(\"G\") ≤ \"h\"(\"G\") where \"χ\"(\"G\") denotes the chromatic number of \"G\".\n\nThe case where \"k\" = 2 is trivial: a graph requires more than one color if and only if it has an edge, and that edge is itself a \"K\" minor. The case \"k\" = 3 is also easy: the graphs requiring three colors are the non-bipartite graphs, and every non-bipartite graph has an odd cycle, which can be contracted to a 3-cycle, that is, a \"K\" minor.\n\nIn the same paper in which he introduced the conjecture, Hadwiger proved its truth for \"k\" ≤ 4. The graphs with no \"K\" minor are the series-parallel graphs and their subgraphs. Each graph of this type has a vertex with at most two incident edges; one can 3-color any such graph by removing one such vertex, coloring the remaining graph recursively, and then adding back and coloring the removed vertex. Because the removed vertex has at most two edges, one of the three colors will always be available to color it when the vertex is added back.\n\nThe truth of the conjecture for \"k\" = 5 implies the four color theorem: for, if the conjecture is true, every graph requiring five or more colors would have a \"K\" minor and would (by Wagner's theorem) be nonplanar.\nKlaus Wagner proved in 1937 that the case \"k\" = 5 is actually equivalent to the four color theorem and therefore we now know it to be true. As Wagner showed, every graph that has no \"K\" minor can be decomposed via clique-sums into pieces that are either planar or an 8-vertex Möbius ladder, and each of these pieces can be 4-colored independently of each other, so the 4-colorability of a \"K\"-minor-free graph follows from the 4-colorability of each of the planar pieces.\n\nFor \"k\" = 7, some partial results are known: every 7-chromatic graph must contain either a \"K\" minor or both a \"K\" minor and a \"K\" minor.\n\nEvery graph \"G\" has a vertex with at most O(\"h\"(\"G\") ) incident edges, from which it follows that a greedy coloring algorithm that removes this low-degree vertex, colors the remaining graph, and then adds back the removed vertex and colors it, will color the given graph with O(\"h\"(\"G\") ) colors.\n\nGyörgy Hajós conjectured that Hadwiger's conjecture could be strengthened to subdivisions rather than minors: that is, that every graph with chromatic number \"k\" contains a subdivision of a complete graph \"K\". Hajós' conjecture is true for \"k\" ≤ 4, but found counterexamples to this strengthened conjecture for \"k\" ≥ 7; the cases \"k\" = 5 and \"k\" = 6 remain open. observed that Hajós' conjecture fails badly for random graphs: for any ε > 0, in the limit as the number of vertices, \"n\", goes to infinity, the probability approaches one that a random \"n\"-vertex graph has chromatic number ≥ (1/2 − ε)\"n\" / log \"n\", and that its largest clique subdivision has at most \"cn\" vertices for some constant \"c\". In this context it is worth noting that the probability also approaches one that a random \"n\"-vertex graph has Hadwiger number greater than or equal to its chromatic number, so the Hadwiger conjecture holds for random graphs with high probability; more precisely, the Hadwiger number is with high probability a constant times \"n\"/.\n\nGerards and Seymour conjectured that every graph \"G\" with chromatic number \"k\" has a complete graph \"K\" as an \"odd minor\". Such a structure can be represented as a family of \"k\" vertex-disjoint subtrees of \"G\", each of which is two-colored, such that each pair of subtrees is connected by a monochromatic edge. Although graphs with no odd \"K\" minor are not necessarily sparse, a similar upper bound holds for them as it does for the standard Hadwiger conjecture: a graph with no odd \"K\" minor has chromatic number \"χ\"(\"G\") = O(k ).\n\nBy imposing extra conditions on \"G\", it may be possible to prove the existence of larger minors than \"K\". One example is the snark theorem, that every cubic graph requiring four colors in any edge coloring has the Petersen graph as a minor, conjectured by W. T. Tutte and announced to be proved in 2001 by Robertson, Sanders, Seymour, and Thomas.\n\n"}
{"id": "149215", "url": "https://en.wikipedia.org/wiki?curid=149215", "title": "Hilbert's Nullstellensatz", "text": "Hilbert's Nullstellensatz\n\nHilbert's Nullstellensatz (German for \"theorem of zeros,\" or more literally, \"zero-locus-theorem\"—see \"Satz\") is a theorem that establishes a fundamental relationship between geometry and algebra. This relationship is the basis of algebraic geometry, a branch of mathematics. It relates algebraic sets to ideals in polynomial rings over algebraically closed fields. This relationship was discovered by David Hilbert who proved the Nullstellensatz and several other important related theorems named after him (like Hilbert's basis theorem).\n\nLet \"k\" be a field (such as the rational numbers) and \"K\" be an algebraically closed field extension (such as the complex numbers), consider the polynomial ring \"k\"[\"X\",\"X\"..., \"X\"] and let \"I\" be an ideal in this ring. The algebraic set V(\"I\") defined by this ideal consists of all \"n\"-tuples x = (\"x\"...,\"x\") in \"K\" such that \"f\"(x) = 0 for all \"f\" in \"I\". Hilbert's Nullstellensatz states that if \"p\" is some polynomial in \"k\"[\"X\",\"X\"..., \"X\"] that vanishes on the algebraic set V(\"I\"), i.e. \"p\"(x) = 0 for all x in \"V\"(\"I\"), then there exists a natural number \"r\" such that \"p\" is in \"I\".\n\nAn immediate corollary is the \"weak Nullstellensatz\": The ideal \"I\" in \"k\"[\"X\",\"X\"..., \"X\"] contains 1 if and only if the polynomials in \"I\" do not have any common zeros in \"K\". It may also be formulated as follows:\nif \"I\" is a proper ideal in \"k\"[\"X\",\"X\"..., \"X\"], then V(\"I\") cannot be empty, i.e. there exists a common zero for all the polynomials in the ideal in every algebraically closed extension of \"k\". This is the reason for the name of the theorem, which can be proved easily from the 'weak' form using the Rabinowitsch trick. The assumption of considering common zeros in an algebraically closed field is essential here; for example, the elements of the proper ideal (\"X\" + 1) in R[\"X\"] do not have a common zero in R.\nWith the notation common in algebraic geometry, the Nullstellensatz can also be formulated as\nfor every ideal \"J\". Here, formula_2 denotes the radical of \"J\" and I(\"U\") is the ideal of all polynomials that vanish on the set \"U\".\n\nIn this way, we obtain an order-reversing bijective correspondence between the algebraic sets in \"K\" and the radical ideals of \"K\"[\"X\",\"X\"..., \"X\"]. In fact, more generally, one has a Galois connection between subsets of the space and subsets of the algebra, where \"Zariski closure\" and \"radical of the ideal generated\" are the closure operators.\n\nAs a particular example, consider a point formula_3. Then formula_4. More generally,\nConversely, every maximal ideal of the polynomial ring formula_6 (note that formula_7 is algebraically closed) is of the form formula_8 for some formula_9.\n\nAs another example, an algebraic subset \"W\" in \"K\" is irreducible (in the Zariski topology) if and only if formula_10 is a prime ideal.\n\nThere are many known proofs of the theorem. One proof uses Zariski's lemma, which asserts that, if a field is finitely generated as an associative algebra over a field \"k\", then it is a finite field extension of \"k\" (that is, it is also finitely generated as a vector space). Here is a sketch of this proof.\n\nLet formula_11 (\"k\" algebraically closed field), \"I\" an ideal of \"A\" and \"V\" the common zeros of \"I\" in formula_12. Clearly, formula_13. Let formula_14. Then formula_15 for some prime ideal formula_16 in \"A\". Let formula_17 and formula_18 a maximal ideal in formula_19. By Zariski's lemma, formula_20 is a finite extension of \"k\"; thus, is \"k\" since \"k\" is algebraically closed. Let formula_21 be the images of formula_22 under the natural map formula_23. It follows that formula_24 and formula_25.\n\nThe Nullstellensatz will also follow trivially once one systematically developed the theory of a Jacobson ring, a ring in which a radical ideal is an intersection of maximal ideals. Let formula_19 be a Jacobson ring. If formula_27 is a finitely generated \"R\"-algebra, then formula_27 is a Jacobson ring. Further, if formula_29 is a maximal ideal, then formula_30 is a maximal ideal of R, and formula_31 is a finite extension field of formula_20.\n\nAnother generalization states that a faithfully flat morphism of schemes formula_33 locally of finite type with \"X\" quasi-compact has a \"quasi-section\", i.e. there exists formula_34 affine and faithfully flat and quasi-finite over \"X\" together with an \"X\"-morphism formula_35\n\nIn all of its variants, Hilbert's Nullstellensatz asserts that some polynomial belongs or not to an ideal generated, say, by ; we have in the strong version, in the weak form. This means the existence or the non-existence of polynomials such that . The usual proofs of the Nullstellensatz are not constructive, non-effective, in the sense that they do not give any way to compute the .\n\nIt is thus a rather natural question to ask if there is an effective way to compute the (and the exponent in the strong form) or to prove that they do not exist. To solve this problem, it suffices to provide an upper bound on the total degree of the : such a bound reduces the problem to a finite system of linear equations that may be solved by usual linear algebra techniques. Any such upper bound is called an effective Nullstellensatz.\n\nA related problem is the ideal membership problem, which consists in testing if a polynomial belongs to an ideal. For this problem also, a solution is provided by an upper bound on the degree of the . A general solution of the ideal membership problem provides an effective Nullstellensatz, at least for the weak form.\n\nIn 1925, Grete Hermann gave an upper bound for ideal membership problem that is doubly exponential in the number of variables. In 1982 Mayr and Meyer gave an example where the have a degree that is at least double exponential, showing that every general upper bound for the ideal membership problem is doubly exponential in the number of variables. \n\nSince most mathematicians at the time assumed the effective Nullstellensatz was at least as hard as ideal membership, few mathematicians sought a bound better than double-exponential. In 1987, however, W. Dale Brownawell gave an upper bound for the effective Nullstellensatz that is simply exponential in the number of variables. Brownawell's proof relied on analytic techniques valid only in characteristic 0, but, one year later, János Kollár gave a purely algebraic proof, valid in any characteristic, of a slightly better bound.\n\nIn the case of the weak Nullstellensatz, Kollár's bound is the following:\n\nIf is the maximum of the degrees of the , this bound may be simplified to \n\nKollár's result has been improved by several authors. , the best improvement, due to M. Sombra is\n\nHis bound improves Kollár's as soon as at least two of the degrees that are involved are lower than 3.\n\nWe can formulate a certain correspondence between homogeneous ideals of polynomials and algebraic subsets of a projective space, called the projective Nullstellensatz, that is analogous to the affine one. To do that, we introduce some notations. Let formula_39 The homogeneous ideal formula_40 is called the \"maximal homogeneous ideal\" (see also irrelevant ideal). As in the affine case, we let: for a subset formula_41 and a homogeneous ideal \"I\" of \"R\",\nBy formula_43 we mean: for every homogeneous coordinates formula_44 of a point of \"S\" we have formula_45. This implies that the homogeneous components of \"f\" are also zero on \"S\" and thus that formula_46 is a homogeneous ideal. Equivalently, formula_46 is the homogeneous ideal generated by homogeneous polynomials \"f\" that vanish on \"S\". Now, for any homogeneous ideal formula_48, by the usual Nullstellensatz, we have:\nand so, like in the affine case, we have:\n\nThe Nullstellensatz also holds for the germs of holomorphic functions at a point of complex \"n\"-space formula_54. Precisely, for each open subset formula_55, let formula_56 denote the ring of holomorphic functions on \"U\"; then formula_57 is a \"sheaf\" on formula_54. The stalk formula_59 at, say, the origin can be shown to be a Noetherian local ring that is a unique factorization domain.\n\nIf formula_60 is a germ represented by a holomorphic function formula_61, then let\nwhere two subsets \"X\", \"Y\" of formula_54 are considered equivalent if formula_65 for some neighborhood \"U\" of 0. Note formula_62 is independent of a choice of the representative formula_67. For each ideal formula_68, let formula_69 denote formula_70 for some generators formula_71 of \"I\". It is well-defined; i.e., is independent of a choice of the generators.\n\nFor each subset formula_72, let formula_73. It is easy to see that formula_74 is an ideal of formula_59 and that formula_76 if formula_77 in the sense discussed above.\n\nThe analytic Nullstellensatz then states: for each ideal formula_68,\nwhere the left-hand side is the radical of \"I\".\n\n\n"}
{"id": "17510593", "url": "https://en.wikipedia.org/wiki?curid=17510593", "title": "Hyperstability", "text": "Hyperstability\n\nIn stability theory, hyperstability is a property of a system that requires the state vector to remain bounded if the inputs are restricted to belonging to a subset of the set of all possible inputs. \n\nDefinition: A system is hyperstable if there are two constants formula_1 such that any state trajectory of the system satisfies the inequality:\n\n"}
{"id": "8487086", "url": "https://en.wikipedia.org/wiki?curid=8487086", "title": "Infinitely near point", "text": "Infinitely near point\n\nIn algebraic geometry, an infinitely near point of an algebraic surface \"S\" is a point on a surface obtained from \"S\" by repeatedly blowing up points. Infinitely near points of algebraic surfaces were introduced by .\n\nThere are some other meanings of \"infinitely near point\". Infinitely near points can also be defined for higher-dimensional varieties: there are several inequivalent ways to do this, depending on what one is allowed to blow up. Weil gave a definition of infinitely near points of smooth varieties, though these are not the same as infinitely near points in algebraic geometry.\nIn the line of hyperreal numbers, an extension of the real number line, two points are called infinitely near if their difference is infinitesimal.\n\nWhen blowing up is applied to a point \"P\" on a surface \"S\", the new surface \"S\"* contains a whole curve \"C\" where \"P\" used to be. The points of \"C\" have the geometric interpretation as the tangent directions at \"P\" to \"S\". They can be called infinitely near to \"P\" as way of visualizing them on \"S\", rather than \"S\"*. More generally this construction can be iterated by blowing up a point on the new curve \"C\", and so on.\n\nAn infinitely near point (of order \"n\") \"P\" on a surface \"S\" is given by a sequence of points \"P\", \"P\"...,\"P\" on surfaces \"S\", \"S\"...,\"S\" such that \"S\" is given by blowing up \"S\" at the point \"P\" and \"P\" is a point of the surface \"S\" with image \"P\".\n\nIn particular the points of the surface \"S\" are the infinitely near points on \"S\" of order 0.\n\nInfinitely near points correspond to 1-dimensional valuations of the function field of \"S\" with 0-dimensional center, and in particular correspond to some of the points of the Zariski–Riemann surface. (The 1-dimensional valuations with 1-dimensional center correspond to irreducible curves of \"S\".) It is also possible to iterate the construction infinitely often, producing an infinite sequence \"P\", \"P\"... of infinitely near points. These infinite sequences correspond to the 0-dimensional valuations of the function field of the surface, which correspond to the \"0-dimensional\" points of the Zariski–Riemann surface.\n\nIf \"C\" and \"D\" are distinct irreducible curves on a smooth surface \"S\" intersecting at a point \"p\", then the multiplicity of their intersection at \"p\" is given by \nwhere \"m\"(\"C\") is the multiplicity of \"C\" at \"x\". In general this is larger than \"m\"(\"C\")\"m\"(\"D\") if \"C\" and \"D\" have a common tangent line at \"x\" so that they also intersect at infinitely near points of order greater than 0, for example if \"C\" is the line \"y\" = 0 and \"D\" is the parabola \"y\" = \"x\" and \"p\" = (0,0).\n\nThe genus of \"C\" is given by \nwhere \"N\" is the normalization of \"C\" and \"m\" is the multiplicity of the infinitely near point \"x\" on \"C\".\n\n"}
{"id": "654139", "url": "https://en.wikipedia.org/wiki?curid=654139", "title": "Ken Batcher", "text": "Ken Batcher\n\nKen Batcher, full name Kenneth Edward Batcher is an emeritus professor of Computer Science at Kent State University. He also worked as a computer architect at Goodyear Aerospace in Akron, Ohio for 28 years. \n\nHe was born in December 1935 in Queens, New York City. His father, Ralph R. Batcher, was the Chief Engineer of The A. H. Grebe Radio Company until its bankruptcy in 1932. \nBatcher graduated from Iowa State University with B.E. degree in 1957. In 1964, Batcher received his Ph.D. in electrical engineering from the University of Illinois. He graduated from Brooklyn Technical High School.\n\nAmong the designs he worked on at Goodyear were the:\n\n\nHe published several technical papers and owns 14 patents of his own. \"He discovered two parallel sorting algorithms: the odd-even mergesort and the bitonic mergesort\". He is also a discoverer of scrambling data method in a random access memory which allows accesses along multiple dimensions. These memories were used in the STARAN and the MPP parallel processors.\n\nIn 1980 he received an \"Arnstein Award\" presented by Goodyear Aerospace Corporation for technical achievement.\n\nIn 1990, Batcher was awarded the ACM/IEEE Eckert-Mauchly Award for his pioneering work on parallel computers. He holds 14 patents.\n\nIn 2007, Batcher was awarded the IEEE Seymour Cray Computer Engineering Award; \"For fundamental theoretical and practical contributions to massively parallel computation, including parallel sorting algorithms, interconnection networks, and pioneering designs of the STARAN and MPP computers.\"\n\nHe is credited with discovering two important parallel sorting algorithms: the odd-even mergesort and the bitonic mergesort.\n\nBatcher is known for his half-serious, half-humorous definition that \"A supercomputer is a device for turning compute-bound problems into I/O-bound problems.\"\n\nAs author or co-author in \"Journal articles\"<br>\n\n\nThe patent number is followed by the title and the year issued.\n\n\n\n\n\n"}
{"id": "1109958", "url": "https://en.wikipedia.org/wiki?curid=1109958", "title": "Loop-erased random walk", "text": "Loop-erased random walk\n\nIn mathematics, loop-erased random walk is a model for a random simple path with important applications in combinatorics and, in physics, quantum field theory. It is intimately connected to the uniform spanning tree, a model for a random tree. See also \"random walk\" for more general treatment of this topic.\n\nAssume \"G\" is some graph and formula_1 is some path of length \"n\" on \"G\". In other words, formula_2 are vertices of \"G\" such that formula_3 and formula_4 are connected by an edge. Then the loop erasure of formula_1 is a new simple path created by erasing all the loops of formula_1 in chronological order. Formally, we define indices formula_7 inductively using\n\nwhere \"max\" here means up to the length of the path formula_1. The induction stops when for some formula_7 we have formula_12. Assume this happens at \"J\" i.e. formula_13 is the last formula_7. Then the loop erasure of formula_1, denoted by formula_16 is a simple path of length \"J\" defined by\n\nNow let \"G\" be some graph, let \"v\" be a vertex of \"G\", and let \"R\" be a random walk on \"G\" starting from \"v\". Let \"T\" be some stopping time for \"R\". Then the loop-erased random walk until time \"T\" is LE(\"R\"([1,\"T\"])). In other words, take \"R\" from its beginning until \"T\" — that's a (random) path — erase all the loops in chronological order as above — you get a random simple path.\n\nThe stopping time \"T\" may be fixed, i.e. one may perform \"n\" steps and then loop-erase. However, it is usually more natural to take \"T\" to be the hitting time in some set. For example, let \"G\" be the graph Z and let \"R\" be a random walk starting from the point (0,0). Let \"T\" be the time when \"R\" first hits the circle of radius 100 (we mean here of course a \"discretized\" circle). LE(\"R\") is called the loop-erased random walk starting at (0,0) and stopped at the circle.\n\nA spanning tree chosen randomly from among all possible spanning trees with equal probability is called a uniform spanning tree. To create such a tree Wilson’s algorithm uses loop-erased random walks. The algorithm proceeds by initializing the tree maze with a random starting cell. New cells are then subsequently added to the maze, initiating a random walk. The random walk progresses uninterrupted until it eventually links with the prevailing maze. However, if the random walk traverses through itself, the resulting loop is erased before the random walk proceeds. The initial random walks are unexpected to link with the small existing maze. As the maze develops, the random walks tend to have a higher probability to collide with the maze and may cause the algorithm to accelerate dramatically.\n\nFor instance, Let \"G\" again be a graph. A spanning tree of \"G\" is a subgraph of \"G\" containing all vertices and some of the edges, which is a tree, i.e. connected and with no cycles. The uniform spanning tree (UST for short) is a \"random\" spanning tree chosen among all the possible spanning trees of \"G\" with equal probability.\n\nLet now \"v\" and \"w\" be two vertices in \"G\". Any spanning tree contains precisely one simple path between \"v\" and \"w\". Taking this path in the \"uniform\" spanning tree gives a random simple path. It turns out that the distribution of this path is identical to the distribution of the loop-erased random walk starting at \"v\" and stopped at \"w\".\n\nAn immediate corollary is that loop-erased random walk is symmetric in its start and end points. More precisely, the distribution of the loop-erased random walk starting at \"v\" and stopped at \"w\" is identical to the distribution of the reversal of loop-erased random walk starting at \"w\" and stopped at \"v\". This is not a trivial fact. Loop-erasing a path and the reverse path do not give the same result. It is only the \"distributions\" that are identical.\n\nA-priori sampling a UST seems difficult. Even a relatively modest graph (say a 100x100 grid) has far too many spanning trees to prepare a complete list. Therefore, a different approach is needed. There are a number of algorithms for sampling a UST, but we will concentrate on Wilson's algorithm.\n\nTake any two vertices and perform loop-erased random walk from one to the other. Now take a third vertex (not on the constructed path) and perform loop-erased random walk until hitting the already constructed path. This gives a tree with either two or three leaves. Choose a fourth vertex and do loop-erased random walk until hitting this tree. Continue until the tree spans all the vertices. It turns out that \"no matter which method you use to choose the starting vertices\" you always end up with the same distribution on the spanning trees, namely the uniform one.\n\nAnother representation of loop-erased random walk stems from solutions of the discrete Laplace equation. Let \"G\" again be a graph and let \"v\" and \"w\" be two vertices in \"G\". Construct a random path from \"v\" to \"w\" inductively using the following procedure. Assume we have already defined formula_18. Let \"f\" be a function from \"G\" to R satisfying\n\nWhere a function \"f\" on a graph is discretely harmonic at a point \"x\" if \"f\"(\"x\") equals the average of \"f\" on the neighbors of \"x\".\n\nWith \"f\" defined choose formula_22 using \"f\" at the neighbors of formula_23 as weights. In other words, if formula_24 are these neighbors, choose formula_25 with probability\n\nContinuing this process, recalculating \"f\" at each step, with result in a random simple path from \"v\" to \"w\"; the distribution of this path is identical to that of a loop-erased random walk from \"v\" to \"w\".\n\nAn alternative view is that the distribution of a loop-erased random walk conditioned to start in some path β is identical to the loop-erasure of a random walk conditioned not to hit β. This property is often referred to as the Markov property of loop-erased random walk (though the relation to the usual Markov property is somewhat vague).\n\nIt is important to notice that while the proof of the equivalence is quite easy, models which involve dynamically changing harmonic functions or measures are typically extremely difficult to analyze. Practically nothing is known about the p-Laplacian walk or diffusion-limited aggregation. Another somewhat related model is the harmonic explorer.\n\nFinally there is another link that should be mentioned: Kirchhoff's theorem relates the number of spanning trees of a graph \"G\" to the eigenvalues of the discrete Laplacian. See spanning tree for details.\n\nLet \"d\" be the dimension, which we will assume to be at least 2. Examine Z i.e. all the points formula_27 with integer formula_28. This is an infinite graph with degree 2\"d\" when you connect each point to its nearest neighbors. From now on we will consider loop-erased random walk on this graph or its subgraphs.\n\nThe easiest case to analyze is dimension 5 and above. In this case it turns out that there the intersections are only local. A calculation shows that if one takes a random walk of length \"n\", its loop-erasure has length of the same order of magnitude, i.e. \"n\". Scaling accordingly, it turns out that loop-erased random walk converges (in an appropriate sense) to Brownian motion as \"n\" goes to infinity. Dimension 4 is more complicated, but the general picture is still true. It turns out that the loop-erasure of a random walk of length \"n\" has approximately formula_29 vertices, but again, after scaling (that takes into account the logarithmic factor) the loop-erased walk converges to Brownian motion.\n\nIn two dimensions, arguments from conformal field theory and simulation results led to a number of exciting conjectures. Assume \"D\" is some simply connected domain in the plane and \"x\" is a point in \"D\". Take the graph \"G\" to be\n\nthat is, a grid of side length ε restricted to \"D\". Let \"v\" be the vertex of \"G\" closest to \"x\". Examine now a loop-erased random walk starting from \"v\" and stopped when hitting the \"boundary\" of \"G\", i.e. the vertices of \"G\" which correspond to the boundary of \"D\". Then the conjectures are\n\n\nThe first attack at these conjectures came from the direction of domino tilings. Taking a spanning tree of \"G\" and adding to it its planar dual one gets a domino tiling of a special derived graph (call it \"H\"). Each vertex of \"H\" corresponds to a vertex, edge or face of \"G\", and the edges of \"H\" show which vertex lies on which edge and which edge on which face. It turns out that taking a uniform spanning tree of \"G\" leads to a uniformly distributed random domino tiling of \"H\". The number of domino tilings of a graph can be calculated using the determinant of special matrices, which allow to connect it to the discrete Green function which is approximately conformally invariant. These arguments allowed to show that certain measurables of loop-erased random walk are (in the limit) conformally invariant, and that the expected number of vertices in a loop-erased random walk stopped at a circle of radius \"r\" is of the order of formula_33.\n\nIn 2002 these conjectures were resolved (positively) using Stochastic Löwner Evolution. Very roughly, it is a stochastic conformally invariant ordinary differential equation which allows to catch the Markov property of loop-erased random walk (and many other probabilistic processes).\n\nThe scaling limit exists and is invariant under rotations and dilations. If formula_34 denotes the expected number of vertices in the loop-erased random walk until it gets to a distance of \"r\", then\n\nwhere ε, \"c\" and \"C\" are some positive numbers (the numbers can, in principle, be calculated from the proofs, but the author did not do it). This suggests that the scaling limit should have Hausdorff dimension between formula_36 and 5/3 almost surely. Numerical experiments show that it should be formula_37.\n\n"}
{"id": "1246955", "url": "https://en.wikipedia.org/wiki?curid=1246955", "title": "Mandelbrot Competition", "text": "Mandelbrot Competition\n\nNamed in honor of Benoit Mandelbrot, the Mandelbrot Competition is a mathematics competition founded by Sam Vandervelde, Richard Rusczyk and Sandor Lehoczky that allows high school students to compete individually and in four-person teams.\n\nThe Mandelbrot is a \"correspondence competition,\" meaning that the competition is sent to a school's coach and students compete at their own school on a predetermined date. Individual results and team answers are then sent back to the contest coordinators. The most notable aspects of the Mandelbrot competition are the difficulty of the problems (much like the American Mathematics Competition and harder American Invitational Mathematics Examination problems) and the proof-based team round. Many past medalists at the International Mathematics Olympiad first tried their skills on the Mandelbrot Competition.\n\nThe Mandelbrot Competition was started by Sam Vandervelde, Richard Rusczyk and Sandor Lehoczky while they were undergraduates in the early 1990s. Vandervelde still runs the competition. Rusczyk now manages Art of Problem Solving Inc. and Lehoczky enjoys a successful career on Wall Street.\n\nThe individual competition consists of seven questions of varying value, worth a total of 14 points, that students have 40 minutes to answer. The team competition is a proof-based competition, where many questions are asked about a particular situation, and a team of four students is given 60 minutes to answer.\n\nThe Mandelbrot Competition has two divisions, currently referred to as \"National\" and \"Regional.\" Questions at the National level are more difficult than those at the Regional level, but generally have overlap or concern similar topics. For example, in the individual competition, the National competition will remove some of the easier Regional questions, and add some harder questions. In the team competition, the topic will be the same but the National level will give fewer hints.\n\nThe top four high schools in the 2003–2004 National division were Academy for the Advancement of Science and Technology, NJ; Thomas Jefferson High School for Science and Technology, VA; Stuyvesant High School, NY; and the Illinois Math and Science Academy.\n\n"}
{"id": "6409655", "url": "https://en.wikipedia.org/wiki?curid=6409655", "title": "Maryam Mirzakhani", "text": "Maryam Mirzakhani\n\nMaryam Mirzakhani (, ; 12 May 1977 – 14 July 2017) was an Iranian mathematician and a professor of mathematics at Stanford University. Her research topics included Teichmüller theory, hyperbolic geometry, ergodic theory, and symplectic geometry.\n\nOn 13 August 2014, Mirzakhani was honored with the Fields Medal, the most prestigious award in mathematics. Thus, she became both the first woman and the first Iranian to be honored with the award. The award committee cited her work in \"the dynamics and geometry of Riemann surfaces and their moduli spaces\".\n\nOn 14 July 2017, Mirzakhani died of breast cancer at the age of 40.\n\nMirzakhani was born on 12 May 1977 in Tehran, Iran. Her father Ahmad is an electrical engineer. She attended Tehran Farzanegan School there, part of the National Organization for Development of Exceptional Talents (NODET). In 1994, Mirzakhani achieved the gold medal level in the International Mathematical Olympiad, the first female Iranian student to do so. In the 1995 International Mathematical Olympiad, she became the first Iranian student to achieve a perfect score and to win two gold medals.\n\nShe obtained a BSc in mathematics in 1999 from the Sharif University of Technology. She then went to the United States for graduate work, earning a Ph.D. in 2004 from Harvard University, where she worked under the supervision of the Fields Medalist Curtis T. McMullen. At Harvard she is said to have been \"distinguished by ... determination and relentless questioning\", despite not being a native English-speaker. She used to take her class notes in Persian.\n\nMirzakhani was a 2004 research fellow of the Clay Mathematics Institute and a professor at Princeton University. In 2009, she became a professor at Stanford University.\n\nMirzakhani made several contributions to the theory of moduli spaces of Riemann surfaces. Mirzakhani’s early work solved the problem of counting simple closed geodesics on hyperbolic Riemann surfaces by finding a relationship to volume calculations on moduli space. Geodesics are the natural generalization of the idea of a \"straight line\" to \"curved spaces\". Slightly more formally, a curve is a geodesic if no slight deformation can make it shorter. Closed geodesics are geodesics which are also closed curves—that is, they are curves that close up into loops. A closed geodesic is simple if it does not cross itself.\n\nA previous result, known as the “prime number theorem for geodesics”, established that the number of closed geodesics of length less than L grows exponentially with L—it is asymptotic to formula_1. However, the analogous counting problem for simple closed geodesics remained open, despite being “the key object to unlocking the structure and geometry of the whole surface,” according to University of Chicago topologist Benson Farb. Mirzakhani’s 2004 PhD thesis solved this problem, showing that the number of simple closed geodesics of length less than L is polynomial in L. Explicitly, it is asymptotic to formula_2, where g is the genus (roughly, the number of “holes”) and c is a constant depending on the hyperbolic structure. This result can be seen as a generalization of the theorem of the three geodesics for spherical surfaces.\n\nMirzakhani solved this counting problem by relating it to the problem of computing volumes in moduli space—a space whose points correspond to different complex structures on a surface genus g. In her thesis, Mirzakhani found a volume formula for the moduli space of bordered Riemann surfaces of genus g with n geodesic boundary components. From this formula followed the counting for simple closed geodesics mentioned above, as well as a number of other results. This led her to obtain a new proof for the formula discovered by Edward Witten and Maxim Kontsevich on the intersection numbers of tautological classes on moduli space.\n\nHer subsequent work focused on Teichmüller dynamics of moduli space. In particular, she was able to prove the long-standing conjecture that William Thurston's earthquake flow on Teichmüller space is ergodic. One can construct a simple earthquake map by cutting a surface along a finite number of disjoint simple closed geodesics, sliding the edges of each of these cut past each other by some amount, and closing the surface back up. One can imagine the surface being cut by strike-slip faults. An earthquake is a sort of limit of simple earthquakes, where one has an infinite number of geodesics, and instead of attaching a positive real number to each geodesic one puts a measure on them.\n\nIn 2014, with Alex Eskin and with input from Amir Mohammadi, Mirzakhani proved that complex geodesics and their closures in moduli space are surprisingly regular, rather than irregular or fractal. The closures of complex geodesics are algebraic objects defined in terms of polynomials and therefore they have certain rigidity properties, which is analogous to a celebrated result that Marina Ratner arrived at during the 1990s. The International Mathematical Union said in its press release that \"It is astounding to find that the rigidity in homogeneous spaces has an echo in the inhomogeneous world of moduli space.\"\n\nMirzakhani was awarded the Fields Medal in 2014 for \"her outstanding contributions to the dynamics and geometry of Riemann surfaces and their moduli spaces\". The award was made in Seoul at the International Congress of Mathematicians on 13 August. At the time of the award, Jordan Ellenberg explained her research to a popular audience:\n\nIn 2014, President Hassan Rouhani of Iran congratulated her for winning the topmost world mathematics prize.\n\nMirzakhani has an Erdős number of 3.\n\nIn 2008, Mirzakhani married Jan Vondrák, a Czech theoretical computer scientist and applied mathematician who currently is an associate professor at Stanford University. They have a daughter named Anahita. Mirzakhani lived in Palo Alto, California.\n\nMirzakhani described herself as a \"slow\" mathematician, saying that \"you have to spend some energy and effort to see the beauty of math.\" To solve problems, Mirzakhani would draw doodles on sheets of paper and write mathematical formulas around the drawings. Her daughter described her mother's work as \"painting\".\n\nShe declared:\nMirzakhani was diagnosed with breast cancer in 2013. In 2016, the cancer spread to her bones and liver, and she died on 14 July 2017 at the age of 40 at Stanford Hospital in Stanford, California.\n\nIranian president Hassan Rouhani and other officials published condolence messages and praised Mirzakhani's scientific achievements. Rouhani said in his message that \"the unprecedented brilliance of this creative scientist and modest human being, who made Iran's name resonate in the world's scientific forums, was a turning point in showing the great will of Iranian women and young people on the path towards reaching the peaks of glory and in various international arenas.\" Sharif University of Technology, the place where Mirzakhani studied, announced that its faculty of mathematics will be renamed to \"Mirzakhani\".\n\nUpon her death, several Iranian newspapers, along with Iranian President Hassan Rouhani, broke taboo and published photographs of Mirzakhani with her hair uncovered, a gesture that was widely noted in the press and on social media. Mirzakhani's death has also renewed debates within Iran regarding matrilineal citizenship for children of mixed-nationality parentage; Fars News Agency reported that, on the heels of Mirzakhani's death, 60 Iranian MPs urged the speeding up of an amendment to a law that would allow children of Iranian mothers married to foreigners to be given Iranian nationality, in order to make it easier for Mirzakhani's daughter to visit Iran.\n\nNumerous obituaries and tributes were published in the days following Maryam Mirzakhani's death.\n\nOn February 2, 2018, Satellogic, a high-resolution Earth observation imaging and analytics company, launched a ÑuSat type micro-satellite named in honor of Maryam Mirzakhani.\n\n\n\n"}
{"id": "3510908", "url": "https://en.wikipedia.org/wiki?curid=3510908", "title": "Minkowski functional", "text": "Minkowski functional\n\nIn mathematics, in the field of functional analysis, a Minkowski functional is a function that recovers a notion of distance on a linear space.\n\nLet \"K\" be a symmetric (i.e. if it contains \"x\" it also contains -\"x\") convex body in a linear space \"V\". We define a function \"p\" on \"V\" as\n\nThis is the Minkowski functional of \"K\". Usually it is assumed that \"K\" is such that the set of formula_2 is never empty, but sometimes the set is allowed to be empty and then \"p(x)\" is defined as infinity.\n\nConsider a normed vector space formula_3, with the norm ||·||. Let formula_4 be the unit ball in formula_3. Define a function formula_6 by \n\nOne can see that formula_8, i.e. formula_9 is just the norm on formula_3. The function \"p\" is a special case of a Minkowski functional.\n\nLet \"X\" be a vector space without topology with underlying scalar field formula_11. Take formula_12, the algebraic dual of formula_3, i.e. formula_14 is a linear functional on formula_3. Fix formula_16. Let the set formula_4 be given by\n\nAgain we define\n\nThen\n\nThe function \"p\"(\"x\") is another instance of a Minkowski functional. It has the following properties:\n\n\nTherefore, formula_9 is a seminorm on formula_3, with an induced topology. This is characteristic of Minkowski functionals defined via \"nice\" sets. There is a one-to-one correspondence between seminorms and the Minkowski functional given by such sets. What is meant precisely by \"nice\" is discussed in the section below.\n\nNotice that, in contrast to a stronger requirement for a norm, formula_25 need not imply formula_26. In the above example, one can take a nonzero formula_27 from the kernel of formula_28. Consequently, the resulting topology need not be Hausdorff.\n\nThe above examples suggest that, given a (complex or real) vector space \"X\" and a subset \"K\", one can define a corresponding Minkowski functional\n\nby\n\nwhich is often called the gauge of formula_4.\n\nIt is implicitly assumed in this definition that 0 ∈ \"K\" and the set {\"r\" > 0: \"x\" ∈ \"r K\"} is nonempty for every x. In order for \"p\" to have the properties of a seminorm, additional restrictions must be imposed on \"K\". These conditions are listed below.\n\n\nA set \"K\" with these properties is said to be absolutely convex.\n\nA simple geometric argument that shows convexity of \"K\" implies subadditivity is as follows. Suppose for the moment that \"p\"(\"x\") = \"p\"(\"y\") = \"r\". Then for all \"ε\" > 0, we have \"x\", \"y\" ∈ (\"r + ε\") \"K\" = \" K' \". The assumption that \"K\" is convex means \" K' \" is also. Therefore, ½ \"x\" + ½ \"y\" is in \" K' \". By definition of the Minkowski functional \"p\", one has\n\nBut the left hand side is ½ \"p\"(\"x\" + \"y\"), i.e. the above becomes\n\nThis is the desired inequality. The general case \"p\"(\"x\") > \"p\"(\"y\") is obtained after the obvious modification.\n\nNote Convexity of \"K\", together with the initial assumption that the set {\"r\" > 0: \"x\" ∈ \"r K\"} is nonempty, implies that \"K\" is absorbing.\n\nNotice that \"K\" being balanced implies that\n\nTherefore\n\n"}
{"id": "35197301", "url": "https://en.wikipedia.org/wiki?curid=35197301", "title": "Modular unit", "text": "Modular unit\n\nIn mathematics, modular units are certain units of rings of integers of fields of modular functions, introduced by . They are functions whose zeroes and poles are confined to the cusps (images of infinity).\n\n\n"}
{"id": "357416", "url": "https://en.wikipedia.org/wiki?curid=357416", "title": "Monomial", "text": "Monomial\n\nIn mathematics, a monomial is, roughly speaking, a polynomial which has only one term. Two definitions of a monomial may be encountered:\n\nIn the context of Laurent polynomials and Laurent series, the exponents of a monomial may be negative, and in the context of Puiseux series, the exponents may be rational numbers.\n\nSince the word \"monomial\", as well as the word \"polynomial\", comes from the late Latin word \"binomium\" (binomial), by changing the prefix \"bi\" (two in Latin), a monomial should theoretically be called a \"mononomial\". \"Monomial\" is a syncope by haplology of \"mononomial\".\n\nWith either definition, the set of monomials is a subset of all polynomials that is closed under multiplication.\n\nBoth uses of this notion can be found, and in many cases the distinction is simply ignored, see for instance examples for the first and second meaning. In informal discussions the distinction is seldom important, and tendency is towards the broader second meaning. When studying the structure of polynomials however, one often definitely needs a notion with the first meaning. This is for instance the case when considering a monomial basis of a polynomial ring, or a monomial ordering of that basis. An argument in favor of the first meaning is also that no obvious other notion is available to designate these values (the term power product is in use, in particular when \"monomial\" is used with the first meaning, but it does not make the absence of constants clear either), while the notion term of a polynomial unambiguously coincides with the second meaning of monomial. \n\n\"The remainder of this article assumes the first meaning of \"monomial\".\"\n\nThe most obvious fact about monomials (first meaning) is that any polynomial is a linear combination of them, so they form a basis of the vector space of all polynomials, called the \"monomial basis\" - a fact of constant implicit use in mathematics.\n\nThe number of monomials of degree \"d\" in \"n\" variables is the number of multicombinations of \"d\" elements chosen among the \"n\" variables (a variable can be chosen more than once, but order does not matter), which is given by the multiset coefficient formula_7. This expression can also be given in the form of a binomial coefficient, as a polynomial expression in \"d\", or using a rising factorial power of :\nThe latter forms are particularly useful when one fixes the number of variables and lets the degree vary. From these expressions one sees that for fixed \"n\", the number of monomials of degree \"d\" is a polynomial expression in \"d\" of degree formula_9 with leading coefficient formula_10.\n\nFor example, the number of monomials in three variables (formula_11) of degree \"d\" is formula_12; these numbers form the sequence 1, 3, 6, 10, 15, ... of triangular numbers.\n\nThe Hilbert series is a compact way to express the number of monomials of a given degree: the number of monomials of degree in variables is the coefficient of degree of the formal power series expansion of\n\nThe number of monomials of degree at most in variables is formula_14 This follows from the one-to-one correspondence between the monomials of degree in variables and the monomials of degree at most in variables, which consists in substituting by 1 the extra variable.\n\nNotation for monomials is constantly required in fields like partial differential equations. If the variables being used form an indexed family like formula_15, formula_16, formula_17, ..., then \"multi-index notation\" is helpful: if we write \n\nwe can define \n\nand save a great deal of space.\n\nThe degree of a monomial is defined as the sum of all the exponents of the variables, including the implicit exponents of 1 for the variables which appear without exponent; e.g., in the example of the previous section, the degree is formula_20. The degree of formula_21 is 1+1+2=4. The degree of a nonzero constant is 0. For example, the degree of -7 is 0. \n\nThe degree of a monomial is sometimes called order, mainly in the context of series. It is also called total degree when it is needed to distinguish it from the degree in one of the variables.\n\nMonomial degree is fundamental to the theory of univariate and multivariate polynomials. Explicitly, it is used to define the degree of a polynomial and the notion of homogeneous polynomial, as well as for graded monomial orderings used in formulating and computing Gröbner bases. Implicitly, it is used in grouping the terms of a Taylor series in several variables.\n\nIn algebraic geometry the varieties defined by monomial equations formula_22 for some set of α have special properties of homogeneity. This can be phrased in the language of algebraic groups, in terms of the existence of a group action of an algebraic torus (equivalently by a multiplicative group of diagonal matrices). This area is studied under the name of \"torus embeddings\".\n\n"}
{"id": "40764984", "url": "https://en.wikipedia.org/wiki?curid=40764984", "title": "Notre Dame Journal of Formal Logic", "text": "Notre Dame Journal of Formal Logic\n\nThe Notre Dame Journal of Formal Logic is a quarterly peer-reviewed scientific journal covering the foundations of mathematics and related fields of mathematical logic, as well as philosophy of mathematics. It was established in 1960 and is published by Duke University Press on behalf of the University of Notre Dame. The editors-in-chief are Michael Detlefsen and Peter Cholak (University of Notre Dame).\n\nThe journal is abstracted and indexed in:\n\nAccording to the \"Journal Citation Reports\", the journal has a 2012 impact factor of 0.431.\n\n"}
{"id": "8756788", "url": "https://en.wikipedia.org/wiki?curid=8756788", "title": "One-pass algorithm", "text": "One-pass algorithm\n\nIn computing, a one-pass algorithm is a streaming algorithm which reads its input exactly once, in order, without unbounded buffering. A one-pass algorithm generally requires O(n) (see 'big O' notation) time and less than O(n) storage (typically O(1)), where n is the size of the input.\n\nBasically one-pass algorithm operates as follows:\n(1) the object descriptions are processed serially;\n(2) the first object becomes the cluster representative of the first cluster;\n(3) each subsequent object is matched against all cluster representatives existing at\nits processing time;\n(4) a given object is assigned to one cluster (or more if overlap is allowed) according\nto some condition on the matching function;\n(5) when an object is assigned to a cluster the representative for that cluster is\nrecomputed;\n(6) if an object fails a certain test it becomes the cluster representative of a new\ncluster (7) nothing happened\nGiven any list as an input:\n\nGiven a list of numbers:\n\nGiven a list of symbols from an alphabet of \"k\" symbols, given in advance.\n\nGiven any list as an input:\n\nGiven a list of numbers:\n"}
{"id": "212980", "url": "https://en.wikipedia.org/wiki?curid=212980", "title": "Order of operations", "text": "Order of operations\n\nIn mathematics and computer programming, the order of operations (or operator precedence) is a collection of rules that reflect conventions about which procedures to perform first in order to evaluate a given mathematical expression.\n\nFor example, in mathematics and most computer languages, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation. Thus, the expression is interpreted to have the value , not . With the introduction of exponents in the 16th and 17th centuries, they were given precedence over both addition and multiplication and could be placed only as a superscript to the right of their base. Thus and .\n\nThese conventions exist to eliminate ambiguity while allowing notation to be as brief as possible. Where it is desired to override the precedence conventions, or even simply to emphasize them, parentheses ( ) (sometimes replaced by brackets [ ] or braces { } for readability) can indicate an alternate order or reinforce the default order to avoid confusion. For example, forces addition to precede multiplication, and forces addition to precede exponentiation.\n\nThe order of operations used throughout mathematics, science, technology and many computer programming languages is expressed here:\n\nThis means that if a mathematical expression is preceded by one binary operator and followed by another, the operator higher on the list should be applied first.\n\nThe commutative and associative laws of addition and multiplication allow adding terms in any order, and multiplying factors in any order—but mixed operations must obey the standard order of operations.\n\nIn some contexts, it is helpful to replace a division by multiplication by the reciprocal (multiplicative inverse) and a subtraction by addition of the opposite (additive inverse). For example, in computer algebra, this allows manipulating fewer binary operations and makes it easier to use commutativity and associativity when simplifying large expressions – for more details, see . Thus ; in other words, the quotient of 3 and 4 equals the product of 3 and ¼. Also ; in other words the difference of 3 and 4 equals the sum of 3 and −4. Thus, can be thought of as the sum of , and the three summands may be added in any order, in all cases giving 5 as the result. \n\nThe root symbol √ requires a symbol of grouping around the radicand. The usual symbol of grouping is a bar (called vinculum) over the radicand. Other functions use parentheses around the input to avoid ambiguity. The parentheses are sometimes omitted if the input is a monomial. Thus, , but , because is not a monomial. Some calculators and programming languages require parentheses around function inputs, some do not.\n\nSymbols of grouping can be used to override the usual order of operations. Grouped symbols can be treated as a single expression. Symbols of grouping can be removed using the associative and distributive laws, also they can be removed if the expression inside the symbol of grouping is sufficiently simplified so no ambiguity results from their removal.\n\nA horizontal fractional line also acts as a symbol of grouping:\n\nFor ease in reading, other grouping symbols, such as curly braces { } or square brackets [ ], are often used along with parentheses ( ). For example:\n\nThere are differing conventions concerning the unary operator − (usually read \"minus\"). In written or printed mathematics, the expression −3 is interpreted to mean ,\n\nSome applications and programming languages, notably Microsoft Excel (and other spreadsheet applications) and the programming language bc, unary operators have a higher priority than binary operators, that is, the unary minus has higher precedence than exponentiation, so in those languages −3 will be interpreted as . This does not apply to the binary minus operator −; for example while the formulas codice_1 and codice_2 return 4 in Microsoft Excel, the formula codice_3 returns −4. In cases where there is the possibility that the notation might be misinterpreted, a binary minus operation can be enforced by explicitly specifying a leading 0 (as in codice_4 instead of just codice_5), or parentheses can be used to clarify the intended meaning.\n\nSimilarly, there can be ambiguity in the use of the slash symbol / in expressions such as 1/2\"x\". If one rewrites this expression as and then interprets the division symbol as indicating multiplication by the reciprocal, this becomes:\n\nWith this interpretation is equal to . However, in some of the academic literature, multiplication denoted by juxtaposition (also known as implied multiplication) is interpreted as having higher precedence than division, so that equals , not .\n\nFor example, the manuscript submission instructions for the \"Physical Review\" journals state that multiplication is of higher precedence than division with a slash, and this is also the convention observed in prominent physics textbooks such as the \"Course of Theoretical Physics\" by Landau and Lifshitz and the \"Feynman Lectures on Physics\".\n\nMnemonics are often used to help students remember the rules, involving the first letters of words representing various operations. Different mnemonics are in use in different countries.\n\nThese mnemonics may be misleading when written this way. For example, misinterpreting any of the above rules to mean \"addition first, subtraction afterward\" would incorrectly evaluate the expression\n\nThe correct value is 9 (and not 5, as if the addition would be carried out first and the result used with the subtraction afterwards).\n\nIf exponentiation is indicated by stacked symbols, the usual rule is to work from the top down, because exponentiation is right-associative in mathematics thus:\nwhich typically is not equal to (\"a\").\n\nHowever, some computer systems may resolve the ambiguous expression differently. For example, Microsoft Excel evaluates codice_6 as (\"a\"), which is opposite of normally accepted convention of top-down order of execution for exponentiation. Thus codice_7 is evaluated to 4,096 instead of 262,144.\n\nAnother difference in Microsoft Excel is codice_8 which is evaluated as codice_9 instead of codice_10. For compatibility, the same behavior is observed on LibreOffice. The computational programming language MATLAB is another example of a computer system resolving the stacked exponentiation in the non-standard way.\n\nA similar ambiguity exists in the case of serial division, for example, the expression can either be interpreted as \nor as\n\nThe left-to-right operation convention would resolve the ambiguity in favor of the last expression. Further, the mathematical habit of combining factors and representing division as multiplication by a reciprocal both greatly reduce the frequency of ambiguous division. However, when two long expressions are combined by division, the correct order of operations can be lost in the notation.\n\nDifferent calculators follow different orders of operations. Many simple calculators without a stack implement chain input working left to right without any priority given to different operators, for example typing\nwhile more sophisticated calculators will use a more standard priority, for example typing\n\nThe \"Microsoft Calculator\" program uses the former in its standard view and the latter in its scientific and programmer views.\n\nChain input expects two operands and an operator. When the next operator is pressed, the expression is immediately evaluated and the answer becomes the left hand of the next operator. Advanced calculators allow entry of the whole expression, grouped as necessary, and evaluates only when the user uses the equals sign.\n\nCalculators may associate exponents to the left or to the right depending on the model or the evaluation mode. For example, the expression codice_6 is interpreted as \"a\" on the TI-92 and the TI-30XS MultiView in \"Mathprint mode\", whereas it is interpreted as (\"a\") on the TI-30XII and the TI-30XS MultiView in \"Classic mode\".\n\nAn expression like codice_14 is interpreted as 1/(2\"x\") by TI-82, but as (1/2)\"x\" by TI-83 and every other TI calculator released since 1996, as well as by all Hewlett-Packard calculators with algebraic notation. While the first interpretation may be expected by some users, only the latter is in agreement with the standard rule that multiplication and division are of equal precedence, so 1/2\"x\" is read one divided by two and the answer multiplied by \"x\".\n\nWhen the user is unsure how a calculator will interpret an expression, it is a good idea to use parentheses so there is no ambiguity.\n\nCalculators that utilize reverse Polish notation (RPN), also known as postfix notation, use a stack to enter formulas without the need for parentheses.\n\nSome programming languages use precedence levels that conform to the order commonly used in mathematics, though others, such as APL, Smalltalk or Occam, have no operator precedence rules (in APL, evaluation is strictly right to left; in Smalltalk and Occam, it is strictly left to right).\n\nIn addition, because many operators are not associative, the order within any single level is usually defined by grouping left to right so that codice_15 is interpreted as rather than ; such operators are perhaps misleadingly referred to as \"left associative\". Exceptions exist; for example, languages with operators corresponding to the cons operation on lists usually make them group right to left (\"right associative\"), e.g. in Haskell, codice_16.\n\nThe logical bitwise operators in C (and all programming languages that borrow precedence rules from C, for example, C++, Perl and PHP) have a precedence level that the creator of the C language considered unsatisfactory. However, many programmers have become accustomed to this order. The relative precedence levels of operators found in many C-style languages are as follows:\n\nExamples:\n\nSource-to-source compilers that compile to multiple languages need to explicitly deal with the issue of different order of operations across languages. Haxe for example standardizes the order and enforces it by inserting brackets where it is appropriate.\n\nThe accuracy of software developer knowledge about binary operator precedence has been found to closely follow their frequency of occurrence in source code.\n\n"}
{"id": "1470549", "url": "https://en.wikipedia.org/wiki?curid=1470549", "title": "Pierre Cartier (mathematician)", "text": "Pierre Cartier (mathematician)\n\nPierre Emile Cartier (born 10 June 1932) is a French mathematician. An associate of the Bourbaki group and at one time a colleague of Alexander Grothendieck, his interests have ranged over algebraic geometry, representation theory, mathematical physics, and category theory.\n\nHe studied at the École Normale Supérieure in Paris under Henri Cartan and André Weil. Since his 1958 thesis on algebraic geometry he has worked in a number of fields. He is known for the introduction of the Cartier operator in algebraic geometry in characteristic \"p\", and for work on duality of abelian varieties and on formal groups. He is the eponym of Cartier divisors and Cartier duality.\n\nFrom 1961 to 1971 he was a Professor at the University of Strasbourg. In 1970 he was an Invited Speaker at the International Congress of Mathematicians in Nice. He was awarded the Prize Ampère of the French Academy of Sciences in 1979. In 2012 he became a fellow of the American Mathematical Society.\n\n\n"}
{"id": "454936", "url": "https://en.wikipedia.org/wiki?curid=454936", "title": "Positive element", "text": "Positive element\n\nIn mathematics, especially functional analysis, a self-adjoint (or Hermitian) element formula_1 of a C*-algebra formula_2 is called positive if its spectrum formula_3 consists of non-negative real numbers. Moreover, an element formula_1 of a C*-algebra formula_2 is positive if and only if there is some formula_6 in formula_2 such that formula_8. A positive element is self-adjoint and thus normal.\n\nIf formula_9 is a bounded linear operator on a complex Hilbert space formula_10, then this notion coincides with the condition that formula_11 is non-negative for every vector formula_12 in formula_10. Note that formula_11 is real for every formula_12 in formula_10 if and only if formula_9 is self-adjoint. Hence, a positive operator on a Hilbert space is always self-adjoint (and a self-adjoint \"everywhere defined\" operator on a Hilbert space is always bounded because of the Hellinger-Toeplitz theorem).\n\nThe set of positive elements of a C*-algebra forms a convex cone.\n\nA bounded linear operator formula_18 on an inner product space formula_19 is said to be \"positive\" (or \"positive semidefinite\") if formula_20 for some bounded operator formula_21 on formula_19, and is said to be \"positive definite\" if formula_21 is also non-singular. \n(I) The following conditions for a bounded operator formula_18 on formula_19 to be positive semidefinite are equivalent:\n\n(II) The following conditions for a bounded operator formula_18 on formula_19 to be positive definite are equivalent:\n\n(III) A complex matrix formula_43 represents a positive (semi)definite operator if and only if formula_1 is Hermitian (or self-adjoint) and formula_45, formula_46 and formula_47 are (strictly) positive real numbers. \n\nLet the Banach spaces formula_48 and formula_49 be ordered vector spaces and let formula_50 be a linear operator.\nThe operator formula_9 is called \"positive\" if formula_52 for all formula_53 in formula_48. For a positive operator formula_9 we write formula_56.\n\nA positive operator maps the positive cone of formula_48 onto a subset of the positive cone of formula_49. If formula_49 is the field of formula_48 then formula_9 is called a positive linear functional.\n\nMany important operators are positive. For example:\n\nThe Laplace operator is an example of an unbounded positive linear operator. Hence, by the Hellinger-Toeplitz theorem it cannot be everywhere defined.\n\n\nBy introducing the convention\nfor self-adjoint elements in a C*-algebra formula_2, one obtains a partial order on the set of self-adjoint elements in formula_2. Note that according to this convention, we have formula_74 if and only if formula_1 is positive, which is convenient.\n\nThis partial order is analogous to the natural order on the real numbers, but only to some extent. For example, it respects multiplication by positive reals and addition of self-adjoint elements, but formula_76 need not hold for positive elements formula_77 with formula_78 and formula_79.\n"}
{"id": "1265440", "url": "https://en.wikipedia.org/wiki?curid=1265440", "title": "Prime Obsession", "text": "Prime Obsession\n\nPrime Obsession: Bernhard Riemann and the Greatest Unsolved Problem in Mathematics (2003) is a historical book on mathematics by John Derbyshire, detailing the history of the Riemann hypothesis, named for Bernhard Riemann, and some of its applications. \nThe book is written such that even-numbered chapters present historical elements related to the development of the conjecture, and odd-numbered chapters deal with the mathematical and technical aspects. Despite the title, the book provides biographical information on many iconic mathematicians including Euler, Gauss, and Lagrange. \n\nIn chapter 1, \"Card Trick\", Derbyshire introduces the idea of an infinite series and the ideas of convergence and divergence of these series. He imagines that there is a deck of cards stacked neatly together, and that one pulls off the top card so that it overhangs from the deck. Explaining that it can overhang only as far as the center of gravity allows, the card is pulled so that exactly half of it is overhanging. Then, without moving the top card, he slides the second card so that it is overhanging too at equilibrium. As he does this more and more, the fractional amount of overhanging cards as they accumulate becomes less and less. He explores various types of series such as the harmonic series.\n\nIn chapter 2, Bernhard Riemann is introduced and a brief historical account of Eastern Europe in the 18th Century is discussed.\n\nIn chapter 3, the Prime Number Theorem (PNT) is introduced. The function which mathematicians use to describe the number of primes in \"N\" numbers, π(\"N\"), is shown to behave in a logarithmic manner, as so:\nwhere \"log\" is the natural logarithm. In chapter 5, the Riemann Zeta Function is introduced:\n\nIn chapter 4, Derbyshire gives a short biographical history of Carl Friedrich Gauss and Leonard Euler, setting up their involvement in the Prime Number Theorem.\n\nIn chapter 7, the sieve of Eratosthenes is shown to be able to be simulated using the Zeta function. With this, the following statement which becomes the pillar stone of the book is asserted:\n\nFollowing the derivation of this finding, the book delves into how this is manipulated to expose the PNT's nature.\n\nThe book was awarded the Mathematical Association of America's inaugural Euler Book Prize in 2007.\n\n"}
{"id": "40342115", "url": "https://en.wikipedia.org/wiki?curid=40342115", "title": "Rhonda Hughes", "text": "Rhonda Hughes\n\nRhonda Jo Hughes (born Rhonda Weisberg September 28, 1947) is an American mathematician, the Helen Herrmann Professor Emeritus of Mathematics at Bryn Mawr College.\n\nHughes grew up on the South Side of Chicago. She attended Gage Park High School, where she was a cheerleader and valedictorian of her class. She studied engineering at the University of Illinois at Urbana–Champaign for one and a half years, then left school and worked for six months before resuming her education at the University of Illinois at Chicago on an Illinois State Scholarship studying mathematics. There, she came under the mentorship of Yoram Sagher, who encouraged her to pursue graduate studies in mathematics. She earned a Ph.D. from the same university in 1975, under the supervision of Shmuel Kantorovitz, with a dissertation entitled \"Semi-Groups of Unbounded Linear Operators in Banach Space\".\n\nShe began her teaching career at Tufts University then spent a year as a fellow at the Bunting Institute of Radcliffe College. She moved to Bryn Mawr College in 1980, where she served as department chair for six years.\nShe is the Helen Herrmann professor emeritus of mathematics at Bryn Mawr, and retired in 2011.\n\nShe was president of the Association for Women in Mathematics (AWM) 1987-1988. She has served on the Commission on Physical Science, Mathematics, and Applications of the United States National Research Council.\n\nShe and Sylvia Bozeman organized the Spelman-Bryn Mawr Summer Mathematics Program for female undergraduate students from 1992-1994. In 1998, they founded the EDGE Program (Enhancing Diversity in Graduate Education), a transition program for women entering graduate programs in the mathematical sciences.\nThe program is now in its twentieth year.\n\nHer most recent research involves ill-posed problems.\n\nHughes received a Distinguished Teaching Award from the Mathematical Association of America in 1997. In 2004 she received the AAAS Mentor Award for Lifetime Achievement, in 2010 the Gweneth Humphreys Award for Mentorship of Undergraduate Women in Mathematics of the Association for Women in Mathematics, and in 2013 she received the Elizabeth Bingham Award of the Philadelphia Chapter of the Association for Women in Science.\n\nIn 2017, she was selected as a fellow of the Association for Women in Mathematics in the inaugural class.\n\nShe has two children, Sarah Hughes, a historian, and Jeremy Hughes, an artist.\n\n"}
{"id": "50624130", "url": "https://en.wikipedia.org/wiki?curid=50624130", "title": "Robert William Genese", "text": "Robert William Genese\n\nRobert William Genese (1848, Dublin – 1928) was an Irish mathematician whose career was spent in Wales.\n\nGenese was born on Westland Row a street on the south side of Dublin on 8 May 1848. From St John's College of the University of Cambridge, Genese received in 1871 his bachelor's degree (with rank eighth Wrangler in the Tripos) and in 1874 his master's degree.\n\nFollowing an unsuccessful application for the Chair of Mathematics at Aberystwyth in 1872, he taught at the Training College in Carmarthen. He finally secured the professorship at Aberystwyth in 1879, and held it until 1919. Along the way his title became Professor of Mathematics and Astronomy.\nGenese introduced into the United Kingdom the ideas of Hermann Grassmann (advancing the use of vector analysis). In his 1941 book \"The calculus of extensions\", Henry Forder published numerous examples in vector analysis taken from Genese's posthumous notes. (Genese's notes were left to the Mathematical Association and then given in 1929 to Forder by E. H. Neville.)\n\nGenese was an Invited Speaker of the ICM in 1904 in Heidelberg with talk \"On some useful theorems in the continued multiplication of a regressive product in real four-point space\" and in 1908 in Rome with talk \"The method of reciprocal polars applied to forces in space\".\n\n\n"}
{"id": "31983045", "url": "https://en.wikipedia.org/wiki?curid=31983045", "title": "Ronald Gould (mathematician)", "text": "Ronald Gould (mathematician)\n\nRonald J. Gould (born April 15, 1950) is an American mathematician specializing in combinatorics and graph theory. He is most noted for his work in the area of Hamiltonian graph theory. His book \"Mathematics in Games, Sports, and Gambling: – The Games People Play\" () won the American Library Association award for Outstanding Academic Titles, 2010.\n\nGould received his Ph.D. in 1979 from Western Michigan University, under the supervision of Gary Chartrand. He is a Goodrich C. White professor in the Emory University Department of Mathematics and Computer Science.\n\n"}
{"id": "325637", "url": "https://en.wikipedia.org/wiki?curid=325637", "title": "Successor function", "text": "Successor function\n\nIn mathematics, the successor function or successor operation is a primitive recursive function \"S\" such that \"S\"(\"n\") = \"n\"+1 for each natural number \"n\".\nFor example, \"S\"(1) = 2 and \"S\"(2) = 3. Successor operations are also known as zeration in the context of a zeroth hyperoperation: H(\"a\", \"b\") = 1 + \"b\".\n\nThe successor function is used in the Peano axioms which define the natural numbers. As such, it is not defined by addition, but rather is used to define all natural numbers beyond 0, as well as addition. For example, 1 is defined to be \"S\"(0), and addition on natural numbers is defined recursively by:\n\nThis yields e.g. 5 + 2 = 5 + \"S\"(1) = \"S\"(5) + 1 = 6 + 1 = 6 + \"S\"(0) = \"S\"(6) + 0 = 7 + 0 = 7\n\nSeveral ways have been proposed to construct the natural numbers using set theory, see set-theoretic definition of natural numbers. A common approach is to define the number 0 to be the empty set {}, and the successor \"S\"(\"x\") to be \"x\" ∪ { \"x\" }. The axiom of infinity then guarantees the existence of a set ℕ that contains 0 and is closed with respect to \"S\"; members of ℕ are called natural numbers.\n\nThe successor function is the level-0 foundation of the infinite hierarchy of hyperoperations (used to build addition, multiplication, exponentiation, tetration, etc.).\n\nIt is also one of the primitive functions used in the characterization of computability by recursive functions.\n\n"}
{"id": "21466609", "url": "https://en.wikipedia.org/wiki?curid=21466609", "title": "Symposium on Foundations of Computer Science", "text": "Symposium on Foundations of Computer Science\n\nThe IEEE Annual Symposium on Foundations of Computer Science (FOCS) is an academic conference in the field of theoretical computer science. FOCS is sponsored by the IEEE Computer Society.\n\nAs writes, FOCS and its annual Association for Computing Machinery counterpart STOC (the Symposium on Theory of Computing) are considered the two top conferences in theoretical computer science, considered broadly: they “are forums for some of the best work throughout theory of computing that promote breadth among theory of computing researchers and help to keep the community together.” includes regular attendance at FOCS and STOC as one of several defining characteristics of theoretical computer scientists.\n\nThe Knuth Prize for outstanding contributions to theoretical computer science is presented alternately at FOCS and STOC. Works of the highest quality presented at the conference are awarded the Best Paper Award. In addition, the Machtey Award is presented to the best student-authored paper in FOCS.\n\nIn 1960–1965, FOCS was known as the Symposium on Switching Circuit Theory and Logical Design, and in 1966–1974 it was known as the Symposium on Switching and Automata Theory. The current name has been used since 1975. Since 1973, the cover page of the conference proceedings has featured an artwork entitled \"synapse\", by Alvy Ray Smith, who has also been the author of three papers in the conference.\n\nFOCS is almost exclusively held in North America, and in particular in the United States, with few exceptions.\n\n\n\n"}
{"id": "214124", "url": "https://en.wikipedia.org/wiki?curid=214124", "title": "Umbral calculus", "text": "Umbral calculus\n\nIn mathematics before the 1970s, the term umbral calculus referred to the surprising similarity between seemingly unrelated polynomial equations and certain shadowy techniques used to 'prove' them. These techniques were introduced by and are sometimes called Blissard's symbolic method. They are often attributed to Édouard Lucas (or James Joseph Sylvester), who used the technique extensively.\n\nIn the 1930s and 1940s, Eric Temple Bell attempted to set the umbral calculus on a rigorous footing.\n\nIn the 1970s, Steven Roman, Gian-Carlo Rota, and others developed the umbral calculus by means of linear functionals on spaces of polynomials. Currently, \"umbral calculus\" refers to the study of Sheffer sequences, including polynomial sequences of binomial type and Appell sequences, but may encompass systematic correspondence techniques of the calculus of finite differences.\n\nThe method is a notational procedure used for deriving identities involving indexed sequences of numbers by \"pretending that the indices are exponents\". Construed literally, it is absurd, and yet it is successful: identities derived via the umbral calculus can also be properly derived by more complicated methods that can be taken literally without logical difficulty.\n\nAn example involves the Bernoulli polynomials. Consider, for example, the ordinary binomial expansion (which contains a binomial coefficient):\n\nand the remarkably similar-looking relation on the Bernoulli polynomials:\n\nCompare also the ordinary derivative\n\nto a very similar-looking relation on the Bernoulli polynomials: \n\nThese similarities allow one to construct \"umbral\" proofs, which, on the surface, cannot be correct, but seem to work anyway. Thus, for example, by pretending that the subscript \"n\" − \"k\" is an exponent:\n\nand then differentiating, one gets the desired result:\n\nIn the above, the variable \"b\" is an \"umbra\" (Latin for \"shadow\").\n\nSee also Faulhaber's formula.\n\nSimilar relationships were also observed in the theory of finite differences. The umbral version of the Taylor series is given by a similar expression involving the \"k\"-th forward differences formula_7 of a polynomial function \"f\",\n\nwhere\n\nis the Pochhammer symbol used here for the falling sequential product. A similar relationship holds for the backward differences and rising factorial.\n\nThis series is also known as the \"Newton series\" or Newton's forward difference expansion.\nThe analogy to Taylor's expansion is utilized in the calculus of finite differences.\n\nIn the 1930s and 1940s, Eric Temple Bell tried unsuccessfully to make this kind of argument logically rigorous. The combinatorialist John Riordan in his book \"Combinatorial Identities\" published in the 1960s, used techniques of this sort extensively.\n\nAnother combinatorialist, Gian-Carlo Rota, pointed out that the mystery vanishes if one considers the linear functional \"L\" on polynomials in \"z\" defined by\n\nThen, using the definition of the Bernoulli polynomials and the definition and linearity of \"L\", one can write\n\nThis enables one to replace occurrences of formula_12 by formula_13, that is, move the \"n\" from a subscript to a superscript (the key operation of umbral calculus).\nFor instance, we can now prove that\nby expanding the right-hand side as\nRota later stated that much confusion resulted from the failure to distinguish between three equivalence relations that occur frequently in this topic, all of which were denoted by \"=\". \n\nIn a paper published in 1964, Rota used umbral methods to establish the recursion formula satisfied by the Bell numbers, which enumerate partitions of finite sets.\n\nIn the paper of Roman and Rota cited below, the umbral calculus is characterized as the study of the umbral algebra, defined as the algebra of linear functionals on the vector space of polynomials in a variable \"x\", with a product \"L\"\"L\" of linear functionals defined by\n\nWhen polynomial sequences replace sequences of numbers as images of \"y\" under the linear mapping \"L\", then the umbral method is seen to be an essential component of Rota's general theory of special polynomials, and that theory is the umbral calculus by some more modern definitions of the term. A small sample of that theory can be found in the article on polynomial sequences of binomial type. Another is the article titled Sheffer sequence.\n\nRota later applied umbral calculus extensively in his paper with Shen to study the various combinatorial properties of the cumulants.\n\n\n\n"}
{"id": "19571465", "url": "https://en.wikipedia.org/wiki?curid=19571465", "title": "Weakly symmetric space", "text": "Weakly symmetric space\n\nIn mathematics, a weakly symmetric space is a notion introduced by the Norwegian mathematician Atle Selberg in the 1950s as a generalisation of symmetric space, due to Élie Cartan. Geometrically the spaces are defined as complete Riemannian manifolds such that any two points can be exchanged by an isometry, the symmetric case being when the isometry is required to have period two. The classification of weakly symmetric spaces relies on that of periodic automorphisms of complex semisimple Lie algebras. They provide examples of Gelfand pairs, although the corresponding theory of spherical functions in harmonic analysis, known for symmetric spaces, has not yet been developed.\n\n"}
{"id": "1655876", "url": "https://en.wikipedia.org/wiki?curid=1655876", "title": "Wheel graph", "text": "Wheel graph\n\nIn the mathematical discipline of graph theory, a wheel graph is a graph formed by connecting a single universal vertex to all vertices of a cycle. A wheel graph with \"n\" vertices can also be defined as the 1-skeleton of an (\"n\"-1)-gonal pyramid. Some authors write \"W\" to denote a wheel graph with \"n\" vertices (n ≥ 4); other authors instead use \"W\" to denote a wheel graph with \"n\"+1 vertices (n ≥ 3), which is formed by connecting a single vertex to all vertices of a cycle of length \"n\". In the rest of this article we use the former notation. \n\nGiven a vertex set of {1,2,3,…,v}, the edge set of the wheel graph can be represented in set-builder notation by .\n\nWheel graphs are planar graphs, and as such have a unique planar embedding. More specifically, every wheel graph is a Halin graph. They are self-dual: the planar dual of any wheel graph is an isomorphic graph. Every maximal planar graph, other than \"K\" = \"W\", contains as a subgraph either \"W\" or \"W\".\n\nThere is always a Hamiltonian cycle in the wheel graph and there are formula_1 cycles in \"W\" .\n\nFor odd values of \"n\", \"W\" is a perfect graph with chromatic number 3: the vertices of the cycle can be given two colors, and the center vertex given a third color. For even \"n\", \"W\" has chromatic number 4, and (when \"n\" ≥ 6) is not perfect. \"W\" is the only wheel graph that is a unit distance graph in the Euclidean plane. \n\nThe chromatic polynomial of the wheel graph \"W\" is :\nformula_2\n\nIn matroid theory, two particularly important special classes of matroids are the \"wheel matroids\" and the \"whirl matroids\", both derived from wheel graphs. The \"k\"-wheel matroid is the graphic matroid of a wheel \"W\", while the \"k\"-whirl matroid is derived from the \"k\"-wheel by considering the outer cycle of the wheel, as well as all of its spanning trees, to be independent.\n\nThe wheel \"W\" supplied a counterexample to a conjecture of Paul Erdős on Ramsey theory: he had conjectured that the complete graph has the smallest Ramsey number among all graphs with the same chromatic number, but Faudree and McKay (1993) showed \"W\" has Ramsey number 17 while the complete graph with the same chromatic number, \"K\", has Ramsey number 18. That is, for every 17-vertex graph \"G\", either \"G\" or its complement contains \"W\" as a subgraph, while neither the 17-vertex Paley graph nor its complement contains a copy of \"K\".\n"}
