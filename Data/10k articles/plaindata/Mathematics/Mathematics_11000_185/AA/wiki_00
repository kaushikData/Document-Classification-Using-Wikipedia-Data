{"id": "20295062", "url": "https://en.wikipedia.org/wiki?curid=20295062", "title": "Ahlswede–Daykin inequality", "text": "Ahlswede–Daykin inequality\n\nA fundamental tool in statistical mechanics and probabilistic combinatorics (especially random graphs and the probabilistic method), the Ahlswede–Daykin inequality , also known as the four functions theorem (or inequality), \nis a correlation-type inequality for four functions on a finite distributive lattice.\n\nIt states that if formula_1 are nonnegative functions on a finite distributive lattice such that\n\nfor all \"x\", \"y\" in the lattice, then \n\nfor all subsets \"X\", \"Y\" of the lattice, where\n\nand\n\nThe Ahlswede–Daykin inequality can be used to provide a short proof of both the Holley inequality and the FKG inequality. It also implies the Fishburn–Shepp inequality.\n\nFor a proof, see the original article or .\n\nThe \"four functions theorem\" was independently generalized to 2\"k\" functions in and .\n\n"}
{"id": "35048260", "url": "https://en.wikipedia.org/wiki?curid=35048260", "title": "Bott cannibalistic class", "text": "Bott cannibalistic class\n\nIn mathematics, the Bott cannibalistic class, introduced by , is an element formula_1 of the representation ring of a compact Lie group that describes the action of the Adams operation formula_2 on the Thom class formula_3 of a complex representation formula_4. The term \"cannibalistic\" for these classes was introduced by .\n\n"}
{"id": "9410951", "url": "https://en.wikipedia.org/wiki?curid=9410951", "title": "Cayley plane", "text": "Cayley plane\n\nIn mathematics, the Cayley plane (or octonionic projective plane) P(O) is a projective plane over the octonions. It was discovered in 1933 by Ruth Moufang, and is named after Arthur Cayley (for his 1845 paper describing the octonions).\n\nMore precisely, there are two objects called Cayley planes, namely the real and the complex Cayley plane.\nThe real Cayley plane is the symmetric space F/Spin(9), where F is a compact form of an exceptional Lie group and Spin(9) is the spin group of nine-dimensional Euclidean space (realized in F). It admits a cell decomposition into three cells, of dimensions 0, 8 and 16.\n\nThe complex Cayley plane is a homogeneous space under a noncompact (adjoint type) form of the group E by a parabolic subgroup \"P\". It is the closed orbit in the projectivization of the minimal representation of E. The complex Cayley plane consists of two F-orbits: the closed orbit is a quotient of F by a parabolic subgroup, the open orbit is the real Cayley plane.\n\nIn the Cayley plane, lines and points may be defined in a natural way so that it becomes a 2-dimensional projective space, that is, a projective plane. It is a non-Desarguesian plane, where Desargues' theorem does not hold.\n\n\n"}
{"id": "402048", "url": "https://en.wikipedia.org/wiki?curid=402048", "title": "Closed system", "text": "Closed system\n\nA closed system is a physical system that does not allow certain types of transfers (such as transfer of mass and energy transfer) in or out of the system. The specification of what types of transfers are excluded varies in the closed systems of physics, chemistry or engineering.\n\nIn nonrelativistic classical mechanics, a closed system is a physical system that doesn't exchange any matter with its surroundings, and isn't subject to any net force whose source is external to the system. A closed system in classical mechanics would be considered an isolated system in thermodynamics. Closed systems are often used to limit the factors that can affect the results of specific problem or experiment.\n\nIn thermodynamics, a closed system can exchange energy (as heat or work) but not matter, with its surroundings.\nAn isolated system cannot exchange any heat, work, or matter with the surroundings, while an open system can exchange energy and matter. (This scheme of definition of terms is not uniformly used, though it is convenient for some purposes. In particular, some writers use 'closed system' where 'isolated system' is used here.)\n\nFor a simple system, with only one type of particle (atom or molecule), a closed system amounts to a constant number of particles. However, for systems which are undergoing a chemical reaction, there may be all sorts of molecules being generated and destroyed by the reaction process. In this case, the fact that the system is closed is expressed by stating that the total number of each elemental atom is conserved, no matter what kind of molecule it may be a part of. Mathematically:\n\nformula_1\n\nwhere formula_2 is the number of j-type molecules, formula_3 is the number of atoms of element \"i\" in molecule \"j\" and \"b\" is the total number of atoms of element \"i\" in the system, which remains constant, since the system is closed. There will be one such equation for each different element in the system.\n\nIn thermodynamics, a closed system is important for solving complicated thermodynamic problems. It allows the elimination of some external factors that could alter the results of the experiment or problem thus simplifying it. A closed system can also be used in situations where thermodynamic equilibrium is required to simplify the situation.\n\nThis equation, called Schrödinger's equation, describes the behavior of an isolated or closed quantum system, that is, by definition, a system which does not interchange information (i.e. energy and/or matter) with another system. So if an isolated system is in some pure state |ψ(t) ∈ H at time t, where H denotes the Hilbert space of the system, the time evolution of this state (between two consecutive measurements).\n\nformula_4\n\nwhere is the imaginary unit, is the Planck constant divided by , the symbol indicates a partial derivative with respect to time , (the Greek letter psi) is the wave function of the quantum system, and is the Hamiltonian operator (which characterizes the total energy of any given wave function and takes different forms depending on the situation).\n\nIn chemistry, a closed system is where no reactants or products can escape, only heat can be exchanged freely (e.g. an ice cooler). A closed system can be used when conducting chemical experiments where temperature is not a factor (i.e. reaching thermal equilibrium).\n\nIn an engineering context, a closed system is a bound system, i.e. defined, in which every input is known and every resultant is known (or can be known) within a specific time.\n\n"}
{"id": "38656223", "url": "https://en.wikipedia.org/wiki?curid=38656223", "title": "Contou-Carrère symbol", "text": "Contou-Carrère symbol\n\nIn mathematics, the Contou-Carrère symbol 〈\"a\",\"b\"〉 is a Steinberg symbol defined on pairs of invertible elements of the ring of Laurent power series over an Artinian ring \"k\", taking values in the group of units of \"k\". It was introduced by .\n\nIf \"k\" is an Artinian local ring, then any invertible formal Laurent series \"a\" with coefficients in \"k\" can be written uniquely as\nwhere \"w\"(\"a\") is an integer, the elements \"a\" are in \"k\", and are in \"m\" if \"i\" is negative, and is a unit if \"i\" = 0.\n\nThe Contou-Carrère symbol 〈\"a\",\"b\"〉 of \"a\" and \"b\" is defined to be\n"}
{"id": "40898831", "url": "https://en.wikipedia.org/wiki?curid=40898831", "title": "De arte supputandi", "text": "De arte supputandi\n\nDe arte supputandi libri quattuor was the first printed work on arithmetic published in England. Published in 1522, it was written by Cuthbert Tunstall, Bishop of London, and based on Luca Pacioli's \"Summa de arithmetica, geometria, proportioni et proportionalità\". It is dedicated to Sir Thomas More.\n"}
{"id": "6642843", "url": "https://en.wikipedia.org/wiki?curid=6642843", "title": "Dennis DeTurck", "text": "Dennis DeTurck\n\nDennis M. DeTurck (born July 15, 1954) is an American mathematician known for his work in partial differential equations and Riemannian geometry, in particular contributions to the theory of the Ricci flow and the prescribed Ricci curvature problem. He first used the DeTurck trick to give an alternative proof of the short time existence of the Ricci flow, which has found other uses since then.\n\nHe received a B.S. (1976) from Drexel University. He received an M.A. (1978) and Ph.D. (1980) in mathematics from the University of Pennsylvania. His Ph.D. supervisor was Jerry Kazdan.\n\nHe is currently Robert A. Fox Leadership Professor and Professor of Mathematics at the University of Pennsylvania, where he has been the Dean of the College of Arts and Sciences since 2005 and Faculty Director of Riepe College House. In 2002 DeTurck won the Haimo Award from the Mathematical Association of America for his teaching. Despite being recognized for excellence in teaching, he has been criticized for his belief that fractions are \"as obsolete as Roman numerals\" and suggesting that they not be taught to younger students.\n\nIn January 2012 he shared the Chauvenet Prize with three mathematical collaborators. In 2012 he became a fellow of the American Mathematical Society.\n\nHe is also well known within the Penn community for the famous cookie nights he hosts in his house.\n\n\n"}
{"id": "831350", "url": "https://en.wikipedia.org/wiki?curid=831350", "title": "Distance matrix", "text": "Distance matrix\n\nIn mathematics, computer science and especially graph theory, a distance matrix is a square matrix (two-dimensional array) containing the distances, taken pairwise, between the elements of a set. Depending upon the application involved, the \"distance\" being used to define this matrix may or may not be a metric. If there are elements, this matrix will have size . In graph-theoretic applications the elements are more often referred to as points, nodes or vertices.\n\nWhen distance is defined as a metric, as for example in the Euclidean distance matrix, the distance matrix satisfies properties directly related to the defining properties of a metric. That is, if with is a distance matrix for a metric distance, then\n\nAnother common example of a distance matrix arises in coding theory when in a block code the elements are strings of fixed length over an alphabet and the distance between them is given by the Hamming distance metric. The smallest non-zero entry in the distance matrix measures the error correcting and error detecting capability of the code.\n\nIn a network, a directed graph with weights assigned to the arcs, the distance between two nodes of the network can be defined as the minimum of the sums of the weights on the shortest paths joining the two nodes. This distance function, while well defined, is not a metric. There need be no restrictions on the weights other than the need to be able to combine and compare them, so negative weights are used in some applications. Since paths are directed, symmetry can not be guaranteed, and if cycles exist the distance matrix may not be hollow.\n\nAn algebraic formulation of the above can be obtained by using the min-plus algebra. Matrix multiplication in this system is defined as follows: Given two formula_1 matrices formula_2 and formula_3, their distance product formula_4 is defined as an formula_1 matrix such that formula_6. Note that the off-diagonal elements that are not connected directly will need to be set to infinity or a suitable large value for the min-plus operations to work correctly. A zero in these locations will be incorrectly interpreted as an edge with no distance, cost, etc.\n\nIf formula_7 is an formula_1 matrix containing the edge weights of a graph, then formula_9 (using this distance product) gives the distances between vertices using paths of length at most formula_10 edges, and formula_11 is the distance matrix of the graph.\n\nAn arbitrary graph on vertices can be modeled as a weighted complete graph on vertices by assigning a weight of one to each edge of the complete graph that corresponds to an edge of and zero to all other edges. for this complete graph is the adjacency matrix of . The distance matrix of can be computed from as above, however, calculated by the usual matrix multiplication only encodes the number of paths between any two vertices of length at most . \nA distance matrix is necessary for hierarchical clustering.\n\nDistance matrices are used in phylogenetic analysis.\n\nIn bioinformatics, distance matrices are used to represent protein structures in a coordinate-independent manner, as well as the pairwise distances between two sequences in sequence space. They are used in structural and sequential alignment, and for the determination of protein structures from NMR or X-ray crystallography.\n\nSometimes it is more convenient to express data as a similarity matrix.\n\nIt is used to define the distance correlation.\n\nFor example, suppose these data are to be analyzed, where pixel Euclidean distance is the distance metric.\n\nThe distance matrix would be:\n\nThese data can then be viewed in graphic form as a heat map. In this image, black denotes a distance of 0 and white is maximal distance.\n\n"}
{"id": "58786399", "url": "https://en.wikipedia.org/wiki?curid=58786399", "title": "Distance set", "text": "Distance set\n\nIn geometry, the distance set of a collection of points is the set of distances between distinct pairs of points. Thus, it can be seen as the generalization of a difference set, the set of distances (and their negations) in collections of numbers.\n\nSeveral problems and results in geometry concern distance sets, usually based on the principle that a large collection of points must have a large distance set (for varying definitions of \"large\"):\n\n\nDistance sets have also been used as a shape descriptor in computer vision.\n"}
{"id": "45482173", "url": "https://en.wikipedia.org/wiki?curid=45482173", "title": "Double vector bundle", "text": "Double vector bundle\n\nIn mathematics, a double vector bundle is the combination of two compatible vector bundle structures, which contains in particular the double tangent formula_1 of a vector bundle formula_2 and the double tangent bundle formula_3.\n\nA double vector bundle consists of formula_4, where \n\nA double vector bundle morphism formula_11 consists of maps formula_12, formula_13, formula_14 and formula_15 such that formula_16 is a bundle morphism from formula_17 to formula_18, formula_19 is a bundle morphism from formula_20 to formula_21, formula_22 is a bundle morphism from formula_23 to formula_24 and formula_25 is a bundle morphism from formula_26 to formula_27.\n\nThe \"'flip\" of the double vector bundle formula_4 is the double vector bundle formula_29.\n\nIf formula_30 is a vector bundle over a differentiable manifold formula_31 then formula_32 is a double vector bundle when considering its secondary vector bundle structure.\n\nIf formula_31 is a differentiable manifold, then its double tangent bundle formula_34 is a double vector bundle.\n"}
{"id": "26564121", "url": "https://en.wikipedia.org/wiki?curid=26564121", "title": "Eells–Kuiper manifold", "text": "Eells–Kuiper manifold\n\nIn mathematics, an Eells–Kuiper manifold is a compactification of formula_1 by an formula_2 - sphere, where \"n\" = 2, 4, 8, or 16. It is named after James Eells and Nicolaas Kuiper.\n\nIf \"n\" = 2, the Eells–Kuiper manifold is diffeomorphic to the real projective plane formula_3. For formula_4 it is simply-connected and has the integral cohomology structure of the complex projective plane formula_5 (formula_6), of the quaternionic projective plane formula_7 (formula_8) or of the Cayley projective plane (\"n\" = 16).\n\nThese manifolds are important in both Morse theory and foliation theory:\n\nTheorem: \"Let formula_9 be a connected closed manifold (not necessarily orientable) of dimension formula_10. Suppose formula_9 admits a Morse function formula_12 of class formula_13 with exactly three singular points. Then formula_9 is a Eells–Kuiper manifold.\"\n\nTheorem: \"Let formula_15 be a compact connected manifold and formula_16 a Morse foliation on formula_9. Suppose the number of centers formula_18 of the foliation formula_16 is more than the number of saddles formula_20. Then there are two possibilities:\"\n\n\n"}
{"id": "40033814", "url": "https://en.wikipedia.org/wiki?curid=40033814", "title": "Effaceable functor", "text": "Effaceable functor\n\nIn mathematics, an effaceable functor is an additive functor \"F\" between abelian categories \"C\" and \"D\" for which, for each object \"A\" in \"C\", there exists a monomorphism formula_1, for some \"M\", such that formula_2. Similarly, a coeffaceable functor is one for which, for each \"A\", there is an epimorphism into \"A\" that is killed by \"F\". The notions were introduced in Grothendieck's Tohoku paper.\n\nA theorem of Grothendieck says that every effaceble δ-functor (i.e., effaceable in each degree) is universal.\n\n"}
{"id": "44749903", "url": "https://en.wikipedia.org/wiki?curid=44749903", "title": "Elizabeth S. Allman", "text": "Elizabeth S. Allman\n\nElizabeth Spencer Allman (born 1965) is an American mathematician. She is a professor of mathematics in the Department of Mathematics and Statistics at the University of Alaska Fairbanks.\n\nAllman earned her Ph.D. in 1995 from the University of California, Los Angeles under the supervision of Murray M. Schacher. In 2012, Allman became a Fellow of the American Mathematical Society.\n\nWith her Fairbanks colleague John A. Rhodes, she is the author of the book \"Mathematical Models in Biology: An Introduction\" (Cambridge University Press, 2004).\n"}
{"id": "38420593", "url": "https://en.wikipedia.org/wiki?curid=38420593", "title": "F* (programming language)", "text": "F* (programming language)\n\nF* (pronounced \"F star\") is a functional programming language inspired by ML and aimed at program verification. Its type system includes dependent types, monadic effects, and refinement types. This allows expressing precise specifications for programs, including functional correctness and security properties. The F* type-checker aims to prove that programs meet their specifications using a combination of SMT solving and manual proofs.\nPrograms written in F* can be translated to OCaml, F#, and C for execution. Previous versions of F* could also be translated to JavaScript.\n\nThe latest version of F* is written entirely in a common subset of F* and F#, and bootstraps in OCaml and F#. It is open source (under the Apache 2.0 License) and is under active development on GitHub.\n\n\n"}
{"id": "794492", "url": "https://en.wikipedia.org/wiki?curid=794492", "title": "Fitting lemma", "text": "Fitting lemma\n\nThe Fitting lemma, named after the mathematician Hans Fitting, is a basic statement in abstract algebra. Suppose \"M\" is a module over some ring. If \"M\" is indecomposable and has finite length, then every endomorphism of \"M\" is either bijective or nilpotent.\n\nAs an immediate consequence, we see that the endomorphism ring of every finite-length indecomposable module is local.\n\nA version of Fitting's lemma is often used in the representation theory of groups. This is in fact a special case of the version above, since every \"K\"-linear representation of a group \"G\" can be viewed as a module over the group algebra \"KG\".\n\nTo prove Fitting's lemma, we take an endomorphism \"f\" of \"M\" and consider the following two sequences of submodules:\n\n\nBecause \"M\" has finite length, the first sequence cannot be \"strictly\" decreasing forever, so there exists some \"n\" with im(\"f\") = im(\"f\"). Likewise (as \"M\" has finite length) the second sequence cannot be \"strictly\" increasing forever, so there exists some \"m\" with ker(\"f\") = ker(\"f\"). It is easily seen that im(\"f\") = im(\"f\") yields im(\"f\") = im(\"f\") = im(\"f\") = …, and that ker(\"f\") = ker(\"f\") yields ker(\"f\") = ker(\"f\") = ker(\"f\") = …. Putting \"k\" = max(\"m\",\"n\"), it now follows that im(\"f\") = im(\"f\") and ker(\"f\") = ker(\"f\"). Hence, formula_1 (because every formula_2 satisfies formula_3 for some formula_4 but also formula_5, so that formula_6, therefore formula_7 and thus formula_8) and formula_9 (since for every formula_10, there exists some formula_4 such that formula_12 (since formula_13), and thus formula_14, so that formula_15 and thus formula_16). Consequently, \"M\" is the direct sum of im(\"f\") and ker(\"f\"). Because \"M\" is indecomposable, one of those two summands must be equal to \"M\", and the other must be equal to {0}. Depending on which of the two summands is zero, we find that \"f\" is bijective or nilpotent.\n"}
{"id": "678194", "url": "https://en.wikipedia.org/wiki?curid=678194", "title": "Generalized taxicab number", "text": "Generalized taxicab number\n\nIn mathematics, the generalized taxicab number \"Taxicab\"(\"k\", \"j\", \"n\") is the smallest number which can be expressed as the sum of \"j\" \"k\"th positive powers in \"n\" different ways. For \"k\" = 3 and \"j\" = 2, they coincide with taxicab numbers.\n\nEuler showed that\n\nHowever, \"Taxicab\"(5, 2, \"n\") is not known for any \"n\" ≥ 2; no positive integer is known which can be written as the sum of two fifth powers in more than one way.\n\n\n\n"}
{"id": "29949637", "url": "https://en.wikipedia.org/wiki?curid=29949637", "title": "Gilman–Griess theorem", "text": "Gilman–Griess theorem\n\nIn finite group theory, a mathematical discipline, the Gilman–Griess theorem, proved by , classifies the finite simple groups of characteristic 2 type with \"e\"(\"G\") ≥ 4 that have a \"standard component\", which covers one of the three cases of the trichotomy theorem.\n"}
{"id": "663041", "url": "https://en.wikipedia.org/wiki?curid=663041", "title": "Greatest and least elements", "text": "Greatest and least elements\n\nIn mathematics, especially in order theory, the greatest element of a subset \"S\" of a partially ordered set (poset) is an element of \"S\" that is greater than every other element of \"S\". The term least element is defined dually, that is, it is an element of \"S\" that is smaller than every other element of \"S\".\n\nFormally, given a partially ordered set (\"P\", ≤), an element \"g\" of a subset \"S\" of \"P\" is the greatest element of \"S\" if\n\nHence, the greatest element of \"S\" is an upper bound of \"S\" that is contained within this subset. It is necessarily unique. By using ≥ instead of ≤ in the above definition, one defines the least element of \"S\".\n\nLike upper bounds, greatest elements may fail to exist. Even if a set has some upper bounds, it need not have a greatest element, as shown by the example of the negative real numbers. This example also demonstrates that the existence of a least upper bound (the number 0 in this case) does not imply the existence of a greatest element either. Similar conclusions hold for least elements. A finite chain always has a greatest and a least element.\n\nA greatest element of a partially ordered subset must not be confused with \"maximal elements\" of the set, which are elements that are not smaller than any other elements. A set can have several maximal elements without having a greatest element. However, if it has a greatest element, it can't have any other maximal element.\n\nIn a totally ordered set both terms coincide; it is also called maximum; in the case of function values it is also called the absolute maximum, to avoid confusion with a local maximum. The dual terms are minimum and absolute minimum. Together they are called the absolute extrema.\n\nThe least and greatest element of the whole partially ordered set plays a special role and is also called bottom and top, or zero (0) and unit (1), or ⊥ and ⊤, respectively. If both exists, the poset is called a bounded poset. The notation of 0 and 1 is used preferably when the poset is even a complemented lattice, and when no confusion is likely, i.e. when one is not talking about partial orders of numbers that already contain elements 0 and 1 different from bottom and top. The existence of least and greatest elements is a special completeness property of a partial order.\n\nFurther introductory information is found in the article on order theory.\n\n\n"}
{"id": "18543082", "url": "https://en.wikipedia.org/wiki?curid=18543082", "title": "Hermite number", "text": "Hermite number\n\nIn mathematics, Hermite numbers are values of Hermite polynomials at zero argument. Typically they are defined for physicists' Hermite polynomials.\n\nThe numbers \"H\" = \"H\"(0), where \"H\"(\"x\") is a Hermite polynomial of order \"n\", may be called Hermite numbers. \n\nThe first Hermite numbers are:\n\nAre obtained from recursion relations of Hermitian polynomials for \"x\" = 0:\n\nSince \"H\" = 1 and \"H\" = 0 one can construct a closed formula for \"H\":\n\nwhere (\"n\" - 1)!! = 1 × 3 × ... × (\"n\" - 1).\n\nFrom the generating function of Hermitian polynomials it follows that \n\nReference gives a formal power series:\n\nwhere formally the \"n\"-th power of \"H\", \"H\", is the \"n\"-th Hermite number, \"H\". (See Umbral calculus.)\n"}
{"id": "47433672", "url": "https://en.wikipedia.org/wiki?curid=47433672", "title": "Hubert Bray", "text": "Hubert Bray\n\nHubert Lewis Bray is a mathematician and differential geometer. He is known for having proved the Riemannian Penrose inequality. He works as professor of mathematics and physics at Duke University.\n\nHe earned his B.A. and B.S. degrees in Mathematics and Physics, respectively, in 1992 from Rice University and obtained his Ph.D. in 1997 from Stanford University, under the mentorship of Richard Melvin Schoen.\n\nHe was an invited speaker at the 2002 International Congress of Mathematicians in Beijing (in the section of differential geometry).\n\nHe is one of the inaugural fellows of the American Mathematical Society.\n"}
{"id": "8837457", "url": "https://en.wikipedia.org/wiki?curid=8837457", "title": "Imperative logic", "text": "Imperative logic\n\nImperative logic is the field of logic concerned with arguments containing sentences in the imperative mood. In contrast to sentences in the declarative mood, imperatives are neither true nor false. This leads to a number of logical dilemmas, puzzles, and paradoxes. Unlike classical logic, there is almost no consensus on any aspect of imperative logic.\n\nOne of a logic's principal concerns is logical validity. It seems that arguments with imperatives can be valid. Consider:\n\nHowever, an argument is valid if the conclusion follows from the premises. This means the premises give us reason to believe the conclusion, or, alternatively, the truth of the premises determines truth of the conclusion. Since imperatives are neither true nor false and since they are not proper objects of belief, none of the standard accounts of logical validity apply to arguments containing imperatives.\n\nHere is the dilemma. Either arguments containing imperatives can be valid or not. On the one hand, if such arguments can be valid, we need a new or expanded account of logical validity and the concomitant details. Providing such an account has proved challenging. On the other hand, if such arguments cannot be valid (either because such arguments are all invalid or because validity is not a notion that applies to imperatives), then our logical intuitions regarding the above argument (and others similar to it) are mistaken. Since either answer seems problematic, this has come to be known as Jørgensen's dilemma, named after Jørgen Jørgensen ().\n\nWhile this problem was first noted in a footnote by Frege, it received a more developed formulation by Jørgensen.\n\nAlf Ross observed that there is a potential problem for any account of imperative inference. Classical logic validates the following inference:\n\nThis inference is called disjunction introduction. However, a similar inference does not seem to be valid for imperatives. Consider:\n\nRoss' paradox highlights the challenge faced by anyone who wants to modify or add to the standard account of validity. The challenge is what we mean by a valid imperative inference. For valid declarative inference, the premises give you a reason to believe the conclusion. One might think that for imperative inference, the premises give you a reason to do as the conclusion says. While Ross's paradox seems to suggest otherwise, its severity has been subject of much debate.\n\nThe following is an example of a pure imperative inference:\n\nIn this case, all the sentences making up the argument are imperatives. Not all imperative inferences are of this kind. Consider again:\n\nNotice that this argument is composed of both imperatives and declaratives and has an imperative conclusion.\n\nMixed inferences are of special interest to logicians. For instance, Henri Poincaré held that no imperative conclusion can be validly drawn from a set of premises which does not contain at least one imperative. While R.M. Hare held that no declarative conclusion can be validly drawn from a set of premises which cannot validly be drawn from the declaratives among them alone. There is no consensus among logicians about the truth or falsity of these (or similar) claims and mixed imperative and declarative inference remains vexed.\n\nAside from intrinsic interest, imperative logic has other applications. The use of imperatives in moral theory should make imperative inference an important subject for ethics and metaethics. Also, many major computer programming languages are imperative programming languages.\n\n\n\n"}
{"id": "18334553", "url": "https://en.wikipedia.org/wiki?curid=18334553", "title": "Inequalities in information theory", "text": "Inequalities in information theory\n\nInequalities are very important in the study of information theory. There are a number of different contexts in which these inequalities appear.\n\nConsider a finite collection of finitely (or at most countably) supported random variables on the same probability space. For a collection of \"n\" random variables, there are 2 − 1 such non-empty subsets for which entropies can be defined. For example, when \"n\" = 2, we may consider the entropies formula_1 formula_2 and formula_3 and express the following inequalities (which together characterize the range of the marginal and joint entropies of two random variables):\nIn fact, these can all be expressed as special cases of a single inequality involving the conditional mutual information, namely\n\nwhere formula_10, formula_11, and formula_12 each denote the joint distribution of some arbitrary (possibly empty) subset of our collection of random variables. Inequalities that can be derived from this are known as Shannon-type inequalities.\n\nFix some amount formula_13of jointly-distributed random variables formula_14each with at most countable support. Following the notation of Yeung , denote formula_15as the collection of all real vectors formula_16which satisfy all the above inequalities when each vector is thought of as a function of a sets of random variables formula_17.\n\nNow define formula_18 to be the set of all \"constructible\" points in formula_19 where a point is said to be constructible if and only if there is a joint, discrete distribution of \"n\" random variables such that each coordinate of that point, indexed by a non-empty subset of {1, 2, ..., \"n\"}, is equal to the joint entropy of the corresponding subset of the \"n\" random variables. The closure of formula_18 is denoted formula_21 In general\n\nThe last two sets above are, in fact, convex cones.\n\nSoftware has been developed to automate the task of proving such inequalities \nGiven an inequality, such software is able to determine whether the given inequality contains the cone formula_23 in which case the inequality can be verified, since formula_24\n\nOther, less trivial inequalities have been discovered among the entropies and joint entropies of four or more random variables, which cannot be derived from Shannon's basic inequalities. These are known as non-Shannon-type inequalities. In 1997 and 1998, Zhang and Yeung reported two non-Shannon-type inequalities. The latter implies that \n\nwhere the inclusions are proper for formula_26 This result means that the collection of inequalities in the previous section are not enough to fully characterize the behavior of joint-Shannon entropy.\n\nFurther non-Shannon-type inequalities were reported in. Dougherty et al. found a number of non-Shannon-type inequalities by computer search. Matus proved the existence of infinitely many linear non-Shannon-type inequalities.\n\nA great many important inequalities in information theory are actually lower bounds for the Kullback–Leibler divergence. Even the Shannon-type inequalities can be considered part of this category, since the bivariate mutual information can be expressed as the Kullback–Leibler divergence of the joint distribution with respect to the product of the marginals, and thus these inequalities can be seen as a special case of Gibbs' inequality.\n\nOn the other hand, it seems to be much more difficult to derive useful upper bounds for the Kullback–Leibler divergence. This is because the Kullback–Leibler divergence \"D\"(\"P\"||\"Q\") depends very sensitively on events that are very rare in the reference distribution \"Q\". \"D\"(\"P\"||\"Q\") increases without bound as an event of finite non-zero probability in the distribution \"P\" becomes exceedingly rare in the reference distribution \"Q\", and in fact \"D\"(\"P\"||\"Q\") is not even defined if an event of non-zero probability in \"P\" has zero probability in \"Q\". (Hence the requirement that \"P\" be absolutely continuous with respect to \"Q\".)\n\nThis fundamental inequality states that the Kullback–Leibler divergence is non-negative.\n\nAnother inequality concerning the Kullback–Leibler divergence is known as Kullback's inequality. If \"P\" and \"Q\" are probability distributions on the real line with \"P\" absolutely continuous with respect to \"Q,\" and whose first moments exist, then\nwhere formula_28 is the large deviations rate function, i.e. the convex conjugate of the cumulant-generating function, of \"Q\", and formula_29 is the first moment of \"P\".\n\nThe Cramér–Rao bound is a corollary of this result.\n\nPinsker's inequality relates Kullback–Leibler divergence and total variation distance. It states that if \"P\", \"Q\" are two probability distributions, then\n\nwhere\n\nis the Kullback–Leibler divergence in nats and\n\nis the total variation distance.\n\nIn 1957, Hirschman showed that for a (reasonably well-behaved) function formula_33 such that formula_34 and its Fourier transform formula_35 the sum of the differential entropies of formula_36 and formula_37 is non-negative, i.e.\nHirschman conjectured, and it was later proved, that a sharper bound of formula_39 which is attained in the case of a Gaussian distribution, could replace the right-hand side of this inequality. This is especially significant since it implies, and is stronger than, Weyl's formulation of Heisenberg's uncertainty principle.\n\nGiven discrete random variables formula_40, formula_41, and formula_42, such that formula_40 takes values only in the interval [−1, 1] and formula_42 is determined by formula_41 (such that formula_46), we have\n\nrelating the conditional expectation to the conditional mutual information. This is a simple consequence of Pinsker's inequality. (Note: the correction factor log 2 inside the radical arises because we are measuring the conditional mutual information in bits rather than nats.)\n\n\n"}
{"id": "986353", "url": "https://en.wikipedia.org/wiki?curid=986353", "title": "Information leakage", "text": "Information leakage\n\nInformation leakage happens whenever a system that is designed to be closed to an eavesdropper reveals some information to unauthorized parties nonetheless. For example, when designing an encrypted instant messaging network, a network engineer without the capacity to crack encryption codes could see when messages are transmitted, even if he could not read them. During the Second World War, the Japanese for a while were using secret codes such as PURPLE; even before such codes were cracked, some basic information could be extracted about the content of the messages by looking at which relay stations sent a message onward. As another example of information leakage, GPU drivers do not erase their memories and thus, in shared/local/global memories, data values persist after deallocation. These data can be retrieved by a malicious agent. \n\nDesigners of secure systems often forget to take information leakage into account. A classic example of this is when the French government designed a mechanism to aid encrypted communications over an analog line, such as at a phone booth. It was a device that clamped onto both ends of the phone, performed the encrypting operations, and sent the signals over the phone line. Unfortunately for the French, the rubber seal that attached the device to the phone was not airtight. It was later discovered that although the encryption itself was solid, if heard carefully, one could hear the speaker, since the phone was picking up some of the speech. Information leakage can subtly or completely destroy the security of an otherwise secure system.\n\nA modern example of information leakage is the leakage of secret information via data compression, by using variations in data compression ratio to reveal correlations between known (or deliberately injected) plaintext and secret data combined in a single compressed stream. Another example is the key leakage that can occur when using some public-key systems when cryptographic nonce values used in signing operations are insufficiently random.\n\nInformation leakage can sometimes be deliberate: for example, an algorithmic converter may be shipped that intentionally leaks small amounts of information, in order to provide its creator with the ability to intercept the users' messages, while still allowing the user to maintain an illusion that the system is secure. This sort of deliberate leakage is sometimes known as a subliminal channel.\n\nGenerally, only very advanced systems employ defenses against information leakage.\n\nFollowing are the commonly implemented countermeasures :\n\n\n"}
{"id": "8931905", "url": "https://en.wikipedia.org/wiki?curid=8931905", "title": "Johann Christoph Heilbronner", "text": "Johann Christoph Heilbronner\n\nJohann Christoph Heilbronner (13 March 1706 in Ulm – 17 January 1745 (or c.1747) in Leipzig) was a German mathematical historian (\"Mathematikhistoriker\") and theologian.\n\n\nThese two books are the first books that named and used the phrase \"\"mathematical history\" (\", \")\".\n\n"}
{"id": "20779760", "url": "https://en.wikipedia.org/wiki?curid=20779760", "title": "Kakutani's theorem (geometry)", "text": "Kakutani's theorem (geometry)\n\nKakutani's theorem is a result in geometry named after Shizuo Kakutani. It states that every convex body in 3-dimensional space has a circumscribed cube, i.e. a cube all of whose faces touch the body. The result was further generalized by Yamabe and Yujobô to higher dimensions, and by Floyd to other circumscribed parallelepipeds.\n\n"}
{"id": "30235068", "url": "https://en.wikipedia.org/wiki?curid=30235068", "title": "Koecher–Maass series", "text": "Koecher–Maass series\n\nIn mathematics, a Koecher–Maass series is a type of Dirichlet series that can be expressed as a Mellin transform of a Siegel modular form, generalizing Hecke's method of associating a Dirichlet series to a modular form using Mellin transforms. They were introduced by and .\n\n"}
{"id": "35131387", "url": "https://en.wikipedia.org/wiki?curid=35131387", "title": "Kronheimer–Mrowka basic class", "text": "Kronheimer–Mrowka basic class\n\nIn mathematics, the Kronheimer–Mrowka basic classes are elements of the second cohomology H(\"X\") of a simple smooth 4-manifold \"X\" that determine its Donaldson polynomials. They were introduced by .\n\n"}
{"id": "46310740", "url": "https://en.wikipedia.org/wiki?curid=46310740", "title": "Kuratowski and Ryll-Nardzewski measurable selection theorem", "text": "Kuratowski and Ryll-Nardzewski measurable selection theorem\n\nIn mathematics, the Kuratowski–Ryll-Nardzewski measurable selection theorem is a result from measure theory that gives a sufficient condition for a multifunction to have a measurable selection. It is named after the Polish mathematicians Kazimierz Kuratowski and Czesław Ryll-Nardzewski.\n\nMany classical selection results follows from this theorem and it is widely used in mathematical economics and optimal control.\n\nLet \"X\" be a Polish space, ℬ(\"X\") the Borel σ-algebra of \"X\", (\"Ω\", \"B\") a measurable space and \"Ψ\" a multifunction on \"Ω\" taking values in the set of nonempty closed subsets of \"X\". \n\nSuppose that \"Ψ\" is \"B\"-weakly measurable, that is, for every open set \"U\" of \"X\", we have\n\nThen \"Ψ\" has a selection that is \"B\"-ℬ(\"X\")-measurable.\n\n"}
{"id": "2558855", "url": "https://en.wikipedia.org/wiki?curid=2558855", "title": "Leibniz integral rule", "text": "Leibniz integral rule\n\nIn calculus, Leibniz's rule for differentiation under the integral sign, named after Gottfried Leibniz, states that for an integral of the form\n\nwhere formula_2, the derivative of this integral is expressible as\n\nwhere the partial derivative indicates that inside the integral, only the variation of \"f\"(\"x\", \"t\") with \"x\" is considered in taking the derivative. Notice that if formula_4 and formula_5 are constants rather than functions of formula_6, we have a special case of Leibniz's rule:\n\nThus under certain conditions, one may interchange the integral and partial differential operators. This important result is particularly useful in the differentiation of integral transforms. An example of such is the moment generating function in probability theory, a variation of the Laplace transform, which can be differentiated to generate the moments of a random variable. Whether Leibniz's integral rule applies is essentially a question about the interchange of limits.\n\nThis formula is the general form of the Leibniz integral rule and can be derived using the fundamental theorem of calculus. The (first) fundamental theorem of calculus is just the particular case of the above formula where \"a\"(\"x\") = \"a\", a constant, \"b\"(\"x\") = \"x\", and \"f\"(\"x\", \"t\") = \"f\"(\"t\").\n\nIf both upper and lower limits are taken as constants, then the formula takes the shape of an operator equation:\n\nwhere formula_10 is the partial derivative with respect to formula_6 and formula_12 is the integral operator with respect to formula_13 over a fixed interval. That is, it is related to the symmetry of second derivatives, but involving integrals as well as derivatives. This case is also known as the Leibniz integral rule.\n\nThe following three basic theorems on the interchange of limits are essentially equivalent:\n\nA Leibniz integral rule for a two dimensional surface moving in three dimensional space is\n\nwhere:\n\nThe Leibniz integral rule can be extended to multidimensional integrals. In two and three dimensions, this rule is better known from the field of fluid dynamics as the Reynolds transport theorem:\n\nwhere formula_16 is a scalar function, \"D\"(\"t\") and ∂\"D\"(\"t\") denote a time-varying connected region of R and its boundary, respectively, formula_17 is the Eulerian velocity of the boundary (see Lagrangian and Eulerian coordinates) and \"d\" Σ = n \"dS\" is the unit normal component of the surface element.\n\nThe general statement of the Leibniz integral rule requires concepts from differential geometry, specifically differential forms, exterior derivatives, wedge products and interior products. With those tools, the Leibniz integral rule in \"p\"-dimensions is\n\nwhere Ω(\"t\") is a time-varying domain of integration, ω is a \"p\"-form, formula_19 is the vector field of the velocity, formula_20 denotes the interior product with formula_21, \"d\"ω is the exterior derivative of ω with respect to the space variables only and formula_22 is the time derivative of ω.\n\nHowever, all of these identities can be derived from a most general statement about Lie derivatives:\n\nHere, the ambient manifold on which the differential form formula_24 lives includes both space and time.\n\nSomething remarkable about this form, is that it can account for the case when formula_25 changes its shape and size over time, since such deformations are fully determined by formula_28.\n\nLet formula_38 be an open subset of formula_39, and formula_25 be a measure space. Suppose formula_41 satisfies the following conditions:\n\n\nThen by the Dominated convergence theorem for all formula_44,\n\nLet\n\nBy the definition of the derivative,\n\nSubstitute equation (1) into equation (2). The difference of two integrals equals the integral of the difference, and 1/\"h\" is a constant, so\n\nProvided that the limit can be passed through the integral sign, we obtain\n\nWe claim that the passage of the limit under the integral sign is valid by the bounded convergence theorem (a corollary of the dominated convergence theorem). For each δ > 0, consider the difference quotient\nFor \"t\" fixed, the mean value theorem implies there exists z in the interval [\"x\", \"x\" + δ] such that\nContinuity of \"f\"(\"x\", \"t\") and compactness of the domain together imply that \"f\"(\"x\", \"t\") is bounded. The above application of the mean value theorem therefore gives a uniform (independent of δ) bound on formula_60. The difference quotients converge pointwise to the partial derivative \"f\" by the assumption that the partial derivative exists.\n\nThe above argument shows that for every sequence {δ} → 0, the sequence formula_61 is uniformly bounded and converges pointwise to \"f\". The bounded convergence theorem states that if a sequence of functions on a set of finite measure is uniformly bounded and converges pointwise, then passage of the limit under the integral is valid. In particular, the limit and integral may be exchanged for every sequence {δ} → 0. Therefore, the limit as δ → 0 may be passed through the integral sign.\n\nFor a simpler proof using Fubini's theorem, see the references.\n\nFor a continuous real valued function \"g\" of one real variable, and real valued differentiable functions formula_62 and formula_63 of one real variable,\n\nThis follows from the chain rule and the First Fundamental Theorem of Calculus. Define\nand\n\nThen, formula_68 can be written as a composition: formula_69.\nThe Chain Rule then implies that\nBy the First Fundamental Theorem of Calculus, formula_71. Therefore, substituing this result above, we get the desired equation:\n\nSet\n\nwhere \"a\" and \"b\" are functions of α that exhibit increments Δ\"a\" and Δ\"b\", respectively, when α is increased by Δα. Then,\n\nA form of the mean value theorem, formula_75, where \"a\" < ξ < \"b\", may be applied to the first and last integrals of the formula for Δφ above, resulting in\n\nDivide by Δα and let Δα → 0. Notice ξ → \"a\" and ξ → \"b\". We may pass the limit through the integral sign:\n\nagain by the bounded convergence theorem. This yields the general form of the Leibniz integral rule,\n\nThe general form of Leibniz's Integral Rule with variable limits can be derived as a consequence of the basic form of Leibniz's Integral Rule, the Multivariable Chain Rule, and the First Fundamental Theorem of Calculus. Suppose formula_79 is defined in a rectangle in the formula_80 plane, for formula_81 and formula_82. Also, assume formula_79 and the partial derivative formula_84 are both continuous functions on this rectangle. Suppose formula_85 are differentiable real valued functions defined on formula_86, with values in formula_87 (i.e for every formula_88). Now, set\n\nand \n\nThen, by properties of Definite Integrals, we can write\n\nSince the functions formula_95 are all differentiable (see the remark at the end of the proof), by the Multivariable Chain Rule, it follows that formula_96 is differentiable, and it's derivative is given by the formula:\n\nNow, note that for every formula_81, and for every formula_91, we have that formula_100, because when taking the partial derivative with respect to formula_101 of formula_102, we are keeping formula_103 fixed in the expression formula_104; thus the basic form of Leibniz's Integral Rule with constant limits of integration applies. Next, by the First Fundamental Theorem of Calculus, we have that formula_105; because when taking the partial derivative with respect to formula_103 of formula_102, the first variable formula_101 is fixed, so the fundamental theorem can indeed be applied.\n\nSubstituting these results into the equation for formula_109 above gives:\nas desired.\n\nThere is a technical point in the proof above which is worth noting: applying the Chain Rule to formula_96 requires that formula_102 already be Differentiable. This is where we use our assumptions about formula_79. As mentioned above, the partial derivatives of formula_102 are given by the formulas formula_100 and formula_105. Since formula_117 is continuous, its integral is also a continuous function , and since formula_79 is also continuous, these two results show that both the partial derivatives of formula_102 are continuous. Since continuity of partial derivatives implies differentiability of the function, formula_102 is indeed differentiable.\n\nAt time \"t\" the surface Σ in Figure 1 contains a set of points arranged about a centroid formula_121. The function formula_122 can be written as\n\nwith formula_124 independent of time. Variables are shifted to a new frame of reference attached to the moving surface, with origin at formula_121. For a rigidly translating surface, the limits of integration are then independent of time, so:\n\nwhere the limits of integration confining the integral to the region Σ no longer are time dependent so differentiation passes through the integration to act on the integrand only:\n\nwith the velocity of motion of the surface defined by\n\nThis equation expresses the material derivative of the field, that is, the derivative with respect to a coordinate system attached to the moving surface. Having found the derivative, variables can be switched back to the original frame of reference. We notice that (see article on curl)\n\nand that Stokes theorem equates the surface integral of the curl over Σ with a line integral over ∂Σ:\n\nThe sign of the line integral is based on the right-hand rule for the choice of direction of line element \"ds. To establish this sign, for example, suppose the field F points in the positive \"z\"-direction, and the surface Σ is a portion of the \"xy\"-plane with perimeter ∂Σ. We adopt the normal to Σ to be in the positive \"z\"-direction. Positive traversal of ∂Σ is then counterclockwise (right-hand rule with thumb along \"z\"-axis). Then the integral on the left-hand side determines a \"positive\" flux of F through Σ. Suppose Σ translates in the positive \"x\"-direction at velocity v. An element of the boundary of Σ parallel to the \"y\"-axis, say \"ds, sweeps out an area vt\" × \"ds in time \"t\". If we integrate around the boundary ∂Σ in a counterclockwise sense, vt\" × \"ds points in the negative \"z\"-direction on the left side of ∂Σ (where \"ds points downward), and in the positive \"z\"-direction on the right side of ∂Σ (where \"ds points upward), which makes sense because Σ is moving to the right, adding area on the right and losing it on the left. On that basis, the flux of F is increasing on the right of ∂Σ and decreasing on the left. However, the dot product v × F • \"ds = −F × v • \"ds = −F • v × \"d\"s. Consequently, the sign of the line integral is taken as negative.\n\nIf v is a constant,\n\nwhich is the quoted result. This proof does not consider the possibility of the surface deforming as it moves.\n\nLemma. One has:\n\nProof. From proof of the fundamental theorem of calculus,\n\nand\n\nSuppose \"a\" and \"b\" are constant, and that \"f\"(\"x\") involves a parameter α which is constant in the integration but may vary to form different integrals. Assume that \"f\"(\"x\", α) is a continuous function of \"x\" and α in the compact set {(\"x\", α) : α ≤ α ≤ α and \"a\" ≤ \"x\" ≤ \"b\"}, and that the partial derivative \"f\"(\"x\", α) exists and is continuous. If one defines:\n\nthen formula_136 may be differentiated with respect to α by differentiating under the integral sign, i.e.,\n\nBy the Heine–Cantor theorem it is uniformly continuous in that set. In other words, for any ε > 0 there exists Δα such that for all values of \"x\" in [\"a\", \"b\"],\n\nOn the other hand,\n\nHence φ(α) is a continuous function.\n\nSimilarly if formula_140 exists and is continuous, then for all ε > 0 there exists Δα such that:\n\nTherefore,\n\nwhere\n\nNow, ε → 0 as Δα → 0, so\n\nThe limits of integration being independent of \"a\", we have:\n\nOn the other hand:\n\nEquating these two relations then yields\n\nIn a similar fashion, pursuing formula_148 yields\n\nAdding the two results then produces\n\nwhich computes formula_151 as desired.\n\nThis derivation may be generalized. Note that if we define\n\nit can easily be shown that\n\nGiven I, this integral reduction formula can be used to compute all of the values of I for \"n\" > 1.\n\nHere, we consider the integral\n\nDifferentiating under the integral with respect to α, we have\n\nTherefore:\n\nHowever, by definition, I(π/2) = 0, hence \"C\" = π/8 and\n\nHere, we consider the integral\n\nWe introduce a new variable φ and rewrite the integral as\n\nWhen φ = 1 this equals the original integral. However, this more general integral may be differentiated with respect to φ:\n\nThis is the line integral of formula_161over the unit circle. By Green's Theorem, it equals the double integral over the unit disk of formula_162 which equals 0.This implies that \"f\"(φ) is constant. The constant may be determined by evaluating \"f\" at φ = 0:\n\nTherefore, the original integral also equals 2π.\n\nThere are innumerable other integrals that can be solved using the technique of differentiation under the integral sign. For example, in each of the following cases, the original integral may be replaced by a similar integral having a new parameter α:\n\nThe first integral, the Dirichlet integral, is absolutely convergent for positive α but only conditionally convergent when α is 0. Therefore, differentiation under the integral sign is easy to justify when α > 0, but proving that the resulting formula remains valid when α is 0 requires some careful work.\n\nThe measure-theoretic version of differentiation under the integral sign also applies to summation (finite or infinite) by interpreting summation as counting measure. An example of an application is the fact that power series are differentiable in their radius of convergence.\n\nDifferentiation under the integral sign is mentioned in the late physicist Richard Feynman's best-selling memoir \"Surely You're Joking, Mr. Feynman!\" in the chapter \"A Different Box of Tools\". He describes learning it, while in high school, from an old text, \"Advanced Calculus\" (1926), by Frederick S. Woods (who was a professor of mathematics in the Massachusetts Institute of Technology). The technique was not often taught when Feynman later received his formal education in calculus, but using this technique, Feynman was able to solve otherwise difficult integration problems upon his arrival at graduate school at Princeton University:\nOne thing I never did learn was contour integration. I had learned to do integrals by various methods shown in a book that my high school physics teacher Mr. Bader had given me. One day he told me to stay after class. \"Feynman,\" he said, \"you talk too much and you make too much noise. I know why. You're bored. So I'm going to give you a book. You go up there in the back, in the corner, and study this book, and when you know everything that's in this book, you can talk again.\" So every physics class, I paid no attention to what was going on with Pascal's Law, or whatever they were doing. I was up in the back with this book: \"Advanced Calculus\", by Woods. Bader knew I had studied \"Calculus for the Practical Man\" a little bit, so he gave me the real works—it was for a junior or senior course in college. It had Fourier series, Bessel functions, determinants, elliptic functions—all kinds of wonderful stuff that I didn't know anything about. That book also showed how to differentiate parameters under the integral sign—it's a certain operation. It turns out that's not taught very much in the universities; they don't emphasize it. But I caught on how to use that method, and I used that one damn tool again and again. So because I was self-taught using that book, I had peculiar methods of doing integrals. The result was, when guys at MIT or Princeton had trouble doing a certain integral, it was because they couldn't do it with the standard methods they had learned in school. If it was contour integration, they would have found it; if it was a simple series expansion, they would have found it. Then I come along and try differentiating under the integral sign, and often it worked. So I got a great reputation for doing integrals, only because my box of tools was different from everybody else's, and they had tried all their tools on it before giving the problem to me.\n\n\n"}
{"id": "508022", "url": "https://en.wikipedia.org/wiki?curid=508022", "title": "List of factorial and binomial topics", "text": "List of factorial and binomial topics\n\nThis is a list of factorial and binomial topics in mathematics. See also binomial (disambiguation).\n\n"}
{"id": "3096183", "url": "https://en.wikipedia.org/wiki?curid=3096183", "title": "List of large cardinal properties", "text": "List of large cardinal properties\n\nThis page includes a list of cardinals with large cardinal properties. It is arranged roughly in order of the consistency strength of the axiom asserting the existence of cardinals with the given property. Existence of a cardinal number κ of a given type implies the existence of cardinals of most of the types listed above that type, and for most listed cardinal descriptions φ of lesser consistency strength, \"V\" satisfies \"there is an unbounded class of cardinals satisfying φ\".\n\nThe following table usually arranges cardinals in order of consistency strength, with size of the cardinal used as a tiebreaker. In a few cases (such as strongly compact cardinals) the exact consistency strength is not known and the table uses the current best guess.\n\nThe following even stronger large cardinal properties are not consistent with the axiom of choice, but their existence has not yet been refuted in ZF alone (that is, without use of the axiom of choice). \n\n\n"}
{"id": "22444348", "url": "https://en.wikipedia.org/wiki?curid=22444348", "title": "Louis Billera", "text": "Louis Billera\n\nLouis Joseph Billera is a Professor of Mathematics at Cornell University.\n\nBillera earned his Ph.D. from the City University of New York in 1968, under the joint supervision of Moses Richardson and Michel Balinski.\n\nLouis Billera served as the first Associate Director of the National Science Foundation Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) at Rutgers University.\n\nIn 2010 he gave the invited lecture, \"Flag enumeration in polytopes, Eulerian partially ordered sets and Coxeter groups\" at the International Congress of Mathematicians in Hyderabad.\n\nThe common thread through much of his research is to study problems motivated by discrete and convex geometry. A sampling includes constructing polytopes to prove the sufficiency condition for the g-theorem (with Carl Lee), discovering fiber polytopes (with Bernd Sturmfels), and studying the space of phylogenetic trees (with Susan Holmes and Karen Vogtmann).\n\nIn 1994 Billera won the Fulkerson Prize for his paper, \"Homology of smooth splines\". This prize is given every three years to the best paper in discrete mathematics.\n\nIn 2012 he became a fellow of the American Mathematical Society.\n\n\n\n"}
{"id": "11880982", "url": "https://en.wikipedia.org/wiki?curid=11880982", "title": "Material nonimplication", "text": "Material nonimplication\n\nMaterial nonimplication or abjunction (Latin \"ab\" = \"from\", \"junctio\" =–\"joining\") is the negation of material implication. That is to say that for any two propositions formula_1 and formula_2, the material nonimplication from formula_1 to formula_2 is true if and only if the negation of the material implication from formula_1 to formula_2 is true. This is more naturally stated as that the material nonimplication from formula_1 to formula_2 is true only if formula_1 is true and formula_2 is false.\n\nIt may be written using logical notation as formula_11, formula_12, or \"L\"pq\"\" (in Bocheński notation), and is logically equivalent to formula_13, and formula_14.\n\nMaterial nonimplication may be defined as the negation of material implication.\n\nIn classical logic, it is also equivalent to the negation of the disjunction of formula_15 and formula_2, and also the conjunction of formula_1 and formula_18\n\nfalsehood-preserving: The interpretation under which all variables are assigned a truth value of \"false\" produces a truth value of \"false\" as a result of material nonimplication.\n\nThe symbol for material nonimplication is simply a crossed-out material implication symbol. Its Unicode symbol is 8603 (decimal).\n\n\"p but not q.\"\n\nBitwise operation: A&(~B) \n\nLogical operation: A&&(!B)\n\n"}
{"id": "33004328", "url": "https://en.wikipedia.org/wiki?curid=33004328", "title": "Metric differential", "text": "Metric differential\n\nIn mathematical analysis, a metric differential is a generalization of a derivative for a Lipschitz continuous function defined on a Euclidean space and taking values in an arbitrary metric space. With this definition of a derivative, one can generalize Rademacher's theorem to metric space-valued Lipschitz functions.\n\nRademacher's theorem states that a Lipschitz map \"f\" : R → R is differentiable almost everywhere in R; in other words, for almost every \"x\", \"f\" is approximately linear in any sufficiently small range of \"x\". If \"f\" is a function from a Euclidean space R that takes values instead in a metric space \"X\", it doesn't immediately make sense to talk about differentiability since \"X\" has no linear structure a priori. Even if you assume that \"X\" is a Banach space and ask whether a Fréchet derivative exists almost everywhere, this does not hold. For example, consider the function \"f\" : [0,1] → \"L\"([0,1]), mapping the unit interval into the space of integrable functions, defined by \"f\"(\"x\") = \"χ\", this function is Lipschitz (and in fact, an isometry) since, if 0 ≤ \"x\" ≤ \"y\"≤ 1, then\n\nbut one can verify that lim(\"f\"(\"x\" + \"h\") −  \"f\"(\"x\"))/\"h\" does not converge to an \"L\" function for any \"x\" in [0,1], so it is not differentiable anywhere.\n\nHowever, if you look at Rademacher's theorem as a statement about how a Lipschitz function stabilizes as you zoom in on almost every point, then such a theorem exists but is stated in terms of the metric properties of \"f\" instead of its linear properties.\n\nA substitute for a derivative of \"f\":R → \"X\" is the metric differential of \"f\" at a point \"z\" in R which is a function on R defined by the limit\n\nwhenever the limit exists (here \"d\" denotes the metric on \"X\").\n\nA theorem due to Bernd Kirchheim states that a Rademacher theorem in terms of metric differentials holds: for almost every \"z\" in R, MD(\"f\", \"z\") is a seminorm and\n\nThe little-o notation employed here means that, at values very close to \"z\", the function \"f\" is approximately an isometry from R with respect to the seminorm MD(\"f\", \"z\") into the metric space \"X\".\n"}
{"id": "10297201", "url": "https://en.wikipedia.org/wiki?curid=10297201", "title": "Moshe Meiselman", "text": "Moshe Meiselman\n\nMoshe Meiselman is an American-born Orthodox rabbi and rosh yeshiva (dean) of Yeshiva Toras Moshe in Jerusalem, which he established in 1982. He also founded and served as principal of Yeshiva University of Los Angeles (YULA) from 1977 to 1982. He is a descendant of the Lithuanian Jewish Soloveitchik rabbinic dynasty.\n\nMeiselman was born to Harry Meiselman, a dental surgeon, and Shulamit Soloveitchik, a teacher and Jewish school principal who attended New York University and Radcliffe College.\nOn his mother's side, he is a descendant of the Soloveitchik rabbinic dynasty. His maternal grandfather was Rabbi Moshe Soloveichik and his maternal great-grandfather was Rabbi Chaim Soloveitchik, known as Reb Chaim Brisker. His mother, Shulamit, authored the book \"The Soloveitchik Heritage: A Daughter's Memoir\" (1995). Meiselman was a nephew of Rabbi Dr. Joseph B. Soloveitchik, rosh yeshiva of R.I.E.T.S., with whom, according to Meiselman, he had study sessions on a near daily basis from the time he was 18 until he was 29 years old.\n\nMeiselman graduated from high school at the Boston Latin School and then went on to attend Harvard University (the undergraduate school which all three of Soloveitchik's children and his American grandchildren attended) and the Massachusetts Institute of Technology. In the latter institution, he studied under Dr. Donald Werner Anderson and earned his doctorate in mathematics in 1967 with the thesis \"The Operation Ring for Connective K-Theory\". While Meiselman's sole formal education (including high school through post-graduate school) took place at secular institutions, rather than yeshivot, Meiselman's students report that he was strong in his haredi viewpoint even at this young age. They report that he would often debate teachers of philosophy on points of religion, stressing his strong religious views in an extremely secular environment.\n\nMeiselman began his career teaching mathematics at City University of New York. After his marriage in 1971, he became a \"maggid shiur\" at Beis Medrash L'Torah in Skokie. Afterward, he taught at Yeshivas Brisk (Brisk Rabbinical College) in Chicago, headed for a time by his uncle, Rabbi Ahron Soloveichik. In 1977 he moved to the West Coast and founded the Yeshiva University of Los Angeles (YULA), opening separate high school programs for boys and girls, a yeshivah gedolah, and a kolel. He also served as a posek (arbiter of Jewish law) for the local community.\n\nIn 1982, having built up enrollment to nearly 400 male and female students in YULA's various divisions, Meiselman moved to Israel to open a yeshiva for American students, together with co-rosh yeshiva Rabbi Doniel Lehrfield (Rabbi Lehrfield and several other faculty members subsequently left to start another yeshiva, Bais Yisroel). He named the new school Toras Moshe after his grandfather, Moshe. He selected Rabbis Michel Shurkin and Moshe Twersky, both close students of Rabbi Soloveitchik, to head the teaching staff. In 2011, Meiselman reported about his yeshiva that \"We have 96 boys in the beis medrash and 44 in the kollel, and almost all of our kollel yungerleit are home-grown\".\n\nMeiselman is one of several grandchildren of Rabbi Moshe Soloveichik who have established yeshivas in Israel, perhaps the most famous being Rabbi Aharon Lichtenstein, son-in-law of Rabbi Joseph Soloveitchik, who established Yeshivat Har Etzion in the late 1960s. Yeshivat Reshit, a popular yeshiva in Israel for American students in Beit Shemesh, was established by the Rabbis Marcus, also descendants of Rabbi Moshe Soloveitchik. Unlike these other two yeshivas, however, Toras Moshe discourages its students from attending Yeshiva University, and in fact virtually none of its students continue on to Yeshiva University.\n\nMeiselman is the author of several books and numerous magazine articles. His \"Jewish Woman in Jewish Law\" (1978) sparked much discussion among authors and feminists for his traditional Jewish response to feminism. Additionally, Meiselman has authored Tiferes Tzvi, a commentary to the Rambam, as well as numerous articles on Talmudic study and thought in Hebrew.\n\nMeiselman's 2013 book, \"Torah, Chazal and Science\", promotes the theory that all unqualified scientific statements of the Talmudic sages were divinely inspired and are therefore immutable: \"All of Chazal’s (the Talmudic sages') definitive statements are to be taken as absolute fact [even] outside the realm of halakhah (Jewish law)\". The flip side of this thesis, and another major theme of the book, is that modern science is transitory and unreliable compared to the divine wisdom of the sages.\n\nFollowing the opinion of some Haredi thinkers in the area of Holocaust theology, Meiselman has argued that the Holocaust was the result of Jewish cultural assimilation in Western Europe in the early twentieth century. He writes that \"the turning away from the status of an \"'am ha-nivhar\", a chosen people, and the frightening rush toward assimilation were, according to the rules that govern Jewish destiny, the real causes for the Holocaust\".\n\nMeiselman subscribes to Haredi views regarding the State of Israel and the Israel Defence Forces. He has stated that it is forbidden for a yeshiva student to join the Israeli army, and has criticized the Nachal Haredi, stating in an interview that Nachal Haredi has \"not been successful in maintaining commitment to Torah.\"\n\nIn 2013, Meiselman sat on the dais at a rally in NY against conscription of yeshiva students into the Israeli army. Both Satmar Rebbes were involved in the planning of, and also sat at the dais at, this rally.\n\nIn commenting on Modern Orthodox innovations with regard to women, Meiselman has stated that \"when it comes to the rabbis and the people who are at the forefront of pushing for these changes so that they can 'update' Orthodoxy to conform with today’s 'progressive' cultural norm ... [the] common denominator between nearly all of them is that they are largely ignorant of halacha and devoid of serious Torah scholarship. If your knowledge of Torah and halacha are limited, then you are not limited by halacha. One is never confined by things that one doesn't know and never learned!\"\n\nAs stated by one of its faculty members, \"Toras Moshe strongly opposes Y.U. Yeshiva University and actively tries to dissuade its students to enroll there.\"\n\nMeiselman is married to Rivkah Leah Eichenstein.\n\n\n\n"}
{"id": "670602", "url": "https://en.wikipedia.org/wiki?curid=670602", "title": "Perfect graph theorem", "text": "Perfect graph theorem\n\nIn graph theory, the perfect graph theorem of states that an undirected graph is perfect if and only if its complement graph is also perfect. This result had been conjectured by , and it is sometimes called the weak perfect graph theorem to distinguish it from the strong perfect graph theorem characterizing perfect graphs by their forbidden induced subgraphs.\n\nA perfect graph is an undirected graph with the property that, in every one of its induced subgraphs, the size of the largest clique equals the minimum number of colors in a coloring of the subgraph. Perfect graphs include many important graphs classes including bipartite graphs, chordal graphs, and comparability graphs.\n\nThe complement of a graph has an edge between two vertices if and only if the original graph does not have an edge between the same two vertices. Thus, a clique in the original graph becomes an independent set in the complement and a coloring of the original graph becomes a clique cover of the complement.\n\nThe perfect graph theorem states:\n\nEquivalently, in a perfect graph, the size of the maximum independent set equals the minimum number of cliques in a clique cover.\n\nLet \"G\" be a cycle graph of odd length greater than three (a so-called \"odd hole\"). Then \"G\" requires at least three colors in any coloring, but has no triangle, so it is not perfect. By the perfect graph theorem, the complement of \"G\" (an \"odd antihole\") must therefore also not be perfect. If \"G\" is a cycle of five vertices, it is isomorphic to its complement, but this property is not true for longer odd cycles, and it is not as trivial to compute the clique number and chromatic number in an odd antihole as it is in an odd hole. As the strong perfect graph theorem states, the odd holes and odd antiholes turn out to be the minimal forbidden induced subgraphs for the perfect graphs.\n\nIn a nontrivial bipartite graph, the optimal number of colors is (by definition) two, and (since bipartite graphs are triangle-free) the maximum clique size is also two. Also, any induced subgraph of a bipartite graph remains bipartite. Therefore, bipartite graphs are perfect. In \"n\"-vertex bipartite graphs, a minimum clique cover takes the form of a maximum matching together with an additional clique for every unmatched vertex, with size \"n\" − \"M\", where \"M\" is the cardinality of the matching. Thus, in this case, the perfect graph theorem implies Kőnig's theorem that the size of a maximum independent set in a bipartite graph is also \"n\" − \"M\", a result that was a major inspiration for Berge's formulation of the theory of perfect graphs.\n\nMirsky's theorem characterizing the height of a partially ordered set in terms of partitions into antichains can be formulated as the perfection of the comparability graph of the partially ordered set, and Dilworth's theorem characterizing the width of a partially ordered set in terms of partitions into chains can be formulated as the perfection of the complements of these graphs. Thus, the perfect graph theorem can be used to prove Dilworth's theorem from the (much easier) proof of Mirsky's theorem, or vice versa.\n\nTo prove the perfect graph theorem, Lovász used an operation of replacing vertices in a graph by cliques; it was already known to Berge that, if a graph is perfect, the graph formed by this replacement process is also perfect. Any such replacement process may be broken down into repeated steps of doubling a vertex. If the doubled vertex belongs to a maximum clique of the graph, it increases both the clique number and the chromatic number by one. If, on the other hand, the doubled vertex does not belong to a maximum clique, form a graph \"H\" by removing the vertices with the same color as the doubled vertex (but not the doubled vertex itself) from an optimal coloring of the given graph. The removed vertices meet every maximum clique, so \"H\" has clique number and chromatic number one less than that of the given graph. The removed vertices and the new copy of the doubled vertex can then be added back as a single color class, showing that in this case the doubling step leaves the chromatic number unchanged. The same argument shows that doubling preserves the equality of the clique number and the chromatic number in every induced subgraph of the given graph, so each doubling step preserves the perfection of the graph.\n\nGiven a perfect graph \"G\", Lovász forms a graph \"G\"* by replacing each vertex \"v\" by a clique of \"t\" vertices, where \"t\" is the number of distinct maximum independent sets in \"G\" that contain \"v\". It is possible to correspond each of the distinct maximum independent sets in \"G\" with one of the maximum independent sets in \"G\"*, in such a way that the chosen maximum independent sets in \"G\"* are all disjoint and each vertex of \"G\"* appears in a single chosen set; that is, \"G\"* has a coloring in which each color class is a maximum independent set. Necessarily, this coloring is an optimal coloring of \"G\"*. Because \"G\" is perfect, so is \"G\"*, and therefore it has a maximum clique \"K\"* whose size equals the number of colors in this coloring, which is the number of distinct maximum independent sets in \"G\"; necessarily, \"K\"* contains a distinct representative for each of these maximum independent sets. The corresponding set \"K\" of vertices in \"G\" (the vertices whose expanded cliques in \"G\"* intersect \"K\"*) is a clique in \"G\" with the property that it intersects every maximum independent set in \"G\". Therefore, the graph formed from \"G\" by removing \"K\" has clique cover number at most one less than the clique number of \"G\", and independence number at least one less than the independence number of \"G\", and the result follows by induction on this number.\n\nThe strong perfect graph theorem of states that a graph is perfect if and only if none of its induced subgraphs are cycles of odd length greater than or equal to five, or their complements. Because this characterization is unaffected by graph complementation, it immediately implies the weak perfect graph theorem.\n\n proved that, if the edges of a complete graph are partitioned into three subgraphs in such a way that every three vertices induce a connected graph in one of the three subgraphs, and if two of the subgraphs are perfect, then the third subgraph is also perfect. The perfect graph theorem is the special case of this result when one of the three subgraphs is the empty graph.\n\n"}
{"id": "454930", "url": "https://en.wikipedia.org/wiki?curid=454930", "title": "Positive linear functional", "text": "Positive linear functional\n\nIn mathematics, more specifically in functional analysis, a positive linear functional on an ordered vector space (\"V\", ≤) is a linear functional \"f\" on \"V\" so that for all positive elements \"v\" of \"V\", that is \"v\"≥0, it holds that\n\nIn other words, a positive linear functional is guaranteed to take nonnegative values for positive elements. The significance of positive linear functionals lies in results such as Riesz–Markov–Kakutani representation theorem.\n\nWhen \"V\" is a complex vector space, it is assumed that for all \"v\"≥0, \"f\"(\"v\") is real. As in the case when \"V\" is a C*-algebra with its partially ordered subspace of self-adjoint elements, sometimes a partial order is placed on only a subspace \"W\" of \"V\", and the partial order does not extend to all of \"V\", in which case the positive elements of \"V\" are the positive elements of \"W\", by abuse of notation. This implies that for a C*-algebra, a positive linear functional sends any \"x\" in \"V\" equal to \"s*s\" for some \"s\" in \"V\" to a real number, which is equal to its complex conjugate, and therefore all positive linear functionals preserve the self-adjointness of such \"x\". This property is exploited in the GNS construction to relate positive linear functionals on a C*-algebra to inner products.\n\n\nLet \"M\" be a C*-algebra (more generally, an operator system in a C*-algebra \"A\") with identity \"1\". Let \"M\" denote the set of positive elements in \"M\".\n\nA linear functional ρ on \"M\" is said to be \"positive\" if ρ(\"a\") ≥ 0, for all \"a\" in \"M\". \n\nIf ρ is a positive linear functional on a C*-algebra \"A\", then one may define a semidefinite sesquilinear form on \"A\" by <\"a\", \"b\"> := ρ(\"b\"\"a\"). Thus from the Cauchy–Schwarz inequality we have \n\n\n"}
{"id": "55330205", "url": "https://en.wikipedia.org/wiki?curid=55330205", "title": "Proper generalized decomposition", "text": "Proper generalized decomposition\n\nThe proper generalized decomposition (PGD) is a numerical method for solving boundary value problems. It assumes that the solution of a multidimensional (or multiparametric) problem can be expressed in a separated representation of the form\n\nwhere the number of terms \"N\", and the functions \"X\" are a priori unknown.\n\nSince solving decoupled problems is computationally much less expensive than solving multidimensional problems, PGD is usually considered a dimensionality reduction algorithm.\n\n"}
{"id": "22318886", "url": "https://en.wikipedia.org/wiki?curid=22318886", "title": "Robinson–Schensted–Knuth correspondence", "text": "Robinson–Schensted–Knuth correspondence\n\nIn mathematics, the Robinson–Schensted–Knuth correspondence, also referred to as the RSK correspondence or RSK algorithm, is a combinatorial bijection between matrices with non-negative integer entries and pairs of semistandard Young tableaux of equal shape, whose size equals the sum of the entries of . More precisely the weight of is given by the column sums of , and the weight of by its row sums. \nIt is a generalization of the Robinson–Schensted correspondence, in the sense that taking to be a permutation matrix, the pair will be the pair of standard tableaux associated to the permutation under the Robinson–Schensted correspondence.\n\nThe Robinson–Schensted–Knuth correspondence extends many of the remarkable properties of the Robinson–Schensted correspondence, notably its symmetry: transposition of the matrix results in interchange of the tableaux .\n\nThe Robinson–Schensted correspondence is a bijective mapping between permutations and pairs of standard Young tableaux, both having the same shape. This bijection can be constructed using an algorithm called Schensted insertion, starting with an empty tableau and successively inserting the values \"σ\",…,\"σ\" of the permutation \"σ\" at the numbers 1,2,…\"n\"; these form the second line when \"σ\" is given in two-line notation:\n\nformula_1.\n\nThe first standard tableau is the result of successive insertions; the other standard tableau records the successive shapes of the intermediate tableaux during the construction of .\n\nThe Schensted insertion easily generalizes to the case where σ has repeated entries; in that case the correspondence will produce a semistandard tableau rather than a standard tableau, but will still be a standard tableau. The definition of the RSK correspondence reestablishes symmetry between the \"P\" and \"Q\" tableaux by producing a semistandard tableau for as well.\n\nThe \"two-line array\" (or \"generalized permutation\") corresponding to a matrix is defined as\n\nin which for any pair that indexes an entry of , there are columns equal to formula_3, and all columns are in lexicographic order, which means that\n\nThe two-line array corresponding to\n\nis\n\nBy applying the Schensted insertion algorithm to the bottom line of this two-line array, one obtains a pair consisting of a semistandard tableau and a standard tableau , where the latter can be turned into a semistandard tableau by replacing each entry of by the -th entry of the top line of . One thus obtains a bijection from matrices to ordered pairs, of semistandard Young tableaux of the same shape, in which the set of entries of is that of the second line of , and the set of entries of is that of the first line of . The number of entries in is therefore equal to the sum of the entries in column of , and the number of entries in is equal to the sum of the entries in row of .\n\nIn the above example, the result of applying the Schensted insertion to successively insert 1,3,3,2,2,1,2 into an initially empty tableau results in a tableau , and an additional standard tableau recoding the successive shapes, given by\n\nand after replacing the entries 1,2,3,4,5,6,7 in successively by 1,1,1,2,2,3,3 one obtains the pair of semistandard tableaux\n\nThe above definition uses the Schensted algorithm, which produces a standard recording tableau , and modifies it to take into account the first line of the two-line array and produce a semistandard recording tableau; this makes the relation to the Robinson–Schensted correspondence evident. It is natural however to simplify the construction by modifying the shape recording part of the algorithm to directly take into account the first line of the two-line array; it is in this form that the algorithm for the RSK correspondence is usually described. This simply means that after every Schensted insertion step, the tableau is extended by adding, as entry of the new square, the -th entry of the first line of , where \"b\" is the current size of the tableaux. That this always produces a semistandard tableau follows from the property (first observed by Knuth) that for successive insertions with an identical value in the first line of , each successive square added to the shape is in a column strictly to the right of the previous one.\n\nHere is a detailed example of this construction of both semistandard tableaux. Corresponding to a matrix\n\none has the two-line array\n\nformula_13\n\nThe following table shows the construction of both tableaux for this example\n\nIf formula_14 is a permutation matrix then RSK outputs standard Young Tableaux (SYT), formula_15 of the same shape formula_16. Conversely, if formula_15 are SYT having the same shape formula_16, then the corresponding matrix formula_14 is a permutation matrix. As a result of this property by simply comparing the cardinalities of the two sets on the two sides of the bijective mapping we get the following corollary:\n\nCorollary 1: For each formula_20 we have formula_21\nwhere formula_22 means formula_16 varies over all partitions of formula_24 and formula_25 is the number of standard Young tableaux of shape formula_16.\n\nLet formula_14 be a matrix with non-negative entries. Suppose the RSK algorithm maps formula_14 to formula_29 then the RSK algorithm maps formula_30 to formula_31, where formula_30 is the transpose of formula_14.\n\nIn particular for the case of permutation matrices, one recovers the symmetry of the Robinson–Schensted correspondence:\n\nTheorem 2: If the permutation formula_34 corresponds to a triple formula_35, then the inverse permutation, formula_36, corresponds to formula_37.\n\nThis leads to the following relation between the number of involutions on formula_38 with the number of tableaux that can be formed from formula_38 (An \"involution\" is a permutation that is its own inverse):\n\nCorollary 2: The number of tableaux that can be formed from formula_40 is equal to the number of involutions on formula_40.\n\n\"Proof\": If formula_42 is an involution corresponding to formula_29, then formula_44 corresponds to formula_31; hence formula_46. Conversely, if formula_42 is any permutation corresponding to formula_48, then formula_49 also corresponds to formula_48; hence formula_44. So there is a one-one correspondence between involutions formula_42 and tableax formula_53\n\nThe number of involutions on formula_40 is given by the recurrence:\n\nWhere formula_56. By solving this recurrence we can get the number of involutions on formula_40,\n\nLet formula_59 and let the RSK algorithm map the matrix formula_14 to the pair formula_48, where formula_53 is an SSYT of shape formula_63. Let formula_64 where the formula_65 and formula_66. Then the map formula_67 establishes a bijection between symmetric matrices with row(formula_14) formula_69 and SSYT's of type formula_63.\n\nThe Robinson–Schensted–Knuth correspondence provides a direct bijective proof of the following celebrated identity for symmetric functions:\n\nwhere formula_72 are Schur functions.\n\nFix partitions formula_73, then\n\nwhere formula_75 and formula_76 denote the Kostka numbers and formula_77 is the number of matrices formula_14, with non-negative elements, with row(formula_14) formula_80 and column(formula_14) formula_82.\n"}
{"id": "42603924", "url": "https://en.wikipedia.org/wiki?curid=42603924", "title": "Russel E. Caflisch", "text": "Russel E. Caflisch\n\nRussel Caflisch is an American mathematician.\n\nCaflisch is Director of the Courant Institute of Mathematical Sciences at New York University (NYU), and a Professor in the Mathematics Department. He received his bachelor's degree from Michigan State University in 1975. He earned a master's degree and Ph.D. in Mathematics from the Courant Institute of Mathematical Sciences at New York University. His dissertation was titled \"The Fluid Dynamic Limit and Shocks for a Model Boltzmann Equation.\" He has also held faculty positions at Stanford and NYU. He has served as PhD advisor for 22 students, with 55 descendants. Up until August 2017, Caflisch was the director of the Institute for Pure & Applied Mathematics (IPAM) and a professor in the Mathematics department, where he also held a joint appointment in the department of Materials Science and Engineering. \nCaflisch was a founding member of California NanoSystems Institute (CNSI). Caflisch’s expertise includes topics in the field of applied mathematics, including partial differential equations, fluid dynamics, plasma physics, materials science, Monte Carlo methods, and computational finance.\n\nCaflisch was awarded the Hertz Foundation Graduate Fellowship in 1975\n\nthe American Mathematical Society in 2012,\n\nand the American Academy of Arts and Sciences in 2013.\n\nHe gave an Invited Lecture at the 2006 International Congress of Mathematicians.\n\n"}
{"id": "2258388", "url": "https://en.wikipedia.org/wiki?curid=2258388", "title": "Scaleogram", "text": "Scaleogram\n\nIn signal processing, a scaleogram or scalogram is a visual method of displaying a wavelet transform. There are 3 axes: x representing time, y representing scale, and z representing coefficient value. The z axis is often shown by varying the colour or brightness.\n\nA scaleogram is the equivalent of a spectrogram for wavelets, and can be used for estimation of instantaneous frequency.\n\n"}
{"id": "3656192", "url": "https://en.wikipedia.org/wiki?curid=3656192", "title": "Screw axis", "text": "Screw axis\n\nA screw axis (helical axis or twist axis) is a line that is simultaneously the axis of rotation and the line along which translation of a body occurs. Chasles' theorem shows that each Euclidean displacement in three-dimensional space has a screw axis, and the displacement can be decomposed into a rotation about and a slide along this screw axis.\n\nPlücker coordinates are used to locate a screw axis in space, and consist of a pair of three-dimensional vectors. The first vector identifies the direction of the axis, and the second locates its position. The special case when the first vector is zero is interpreted as a pure translation in the direction of the second vector. A screw axis is associated with each pair of vectors in the algebra of screws, also known as screw theory.\n\nThe spatial movement of a body can be represented by a continuous set of displacements. Because each of these displacements has a screw axis, the movement has an associated ruled surface known as a \"screw surface\". This surface is not the same as the \"axode\", which is traced by the instantaneous screw axes of the movement of a body. The instantaneous screw axis, or 'instantaneous helical axis' (IHA), is the axis of the helicoidal field generated by the velocities of every point in a moving body.\n\nWhen a spatial displacement specializes to a planar displacement, the screw axis becomes the \"displacement pole\", and the instantaneous screw axis becomes the \"velocity pole\", or instantaneous center of rotation, also called an \"instant center\". The term \"centro\" is also used for a velocity pole, and the locus of these points for a planar movement is called a centrode.\n\nThe proof that a spatial displacement can be decomposed into a rotation and slide around and along a line in space is attributed to Michel Chasles in 1830. Recently the work of Gulio Mozzi has been identified as presenting a similar result in 1763.\n\nA screw displacement (also screw operation or rotary translation) is the composition of a rotation by an angle \"φ\" about an axis (called the screw axis) with a translation by a distance \"d\" along this axis. A positive rotation direction usually means one that corresponds to the translation direction by the right-hand rule. Except for \"φ\" = 180°, we have to distinguish a screw displacement from its mirror image. Unlike for rotations, a righthand and lefthand screw operation generate different groups.\n\nThe combination of a rotation about an axis and a translation in a perpendicular direction is a rotation about a parallel axis. However, a screw operation with a nonzero translation vector along the axis cannot be reduced like that. Thus the effect of a rotation combined with \"any\" translation is a screw operation in the general sense, with as special cases a pure translation, a pure rotation and the identity. Together these are all the direct isometries in 3D.\nIn crystallography, a screw axis symmetry is combination of rotation about an axis and a translation parallel to that axis leaves a crystal unchanged. If \"φ\" = 360°/\"n\" for some positive integer \"n\", then screw axis symmetry implies translational symmetry with a translation vector which is \"n\" times that of the screw displacement.\n\nApplicable for space groups is a rotation by 360°/\"n\" about an axis, combined with a translation along the axis by a multiple of the distance of the translational symmetry, divided by \"n\". This multiple is indicated by a subscript. So, 6 is a rotation of 60° combined with a translation of 1/2 of the lattice vector, implying that there is also 3-fold rotational symmetry about this axis. The possibilities are 2, 3, 4, 4, 6, 6, and 6, and the enantiomorphous 3, 4, 6, and 6.\n\nA non-discrete screw axis isometry group contains all combinations of a rotation about some axis and a proportional translation along the axis (in rifling, the constant of proportionality is called the twist rate); in general this is combined with \"k\"-fold rotational isometries about the same axis (\"k\" ≥ 1); the set of images of a point under the isometries is a \"k\"-fold helix; in addition there may be a 2-fold rotation about a perpendicularly intersecting axis, and hence a \"k\"-fold helix of such axes.\n\nLet be an orientation-preserving rigid motion of R. The set of these transformations is a subgroup of Euclidean motions known as the special Euclidean group SE(3). These rigid motions are defined by transformations of x in R given by\nconsisting of a three-dimensional rotation \"A\" followed by a translation by the vector d.\n\nA three-dimensional rotation \"A\" has a unique axis that defines a line \"L\". Let the unit vector along this line be S so that the translation vector d can be resolved into a sum of two vectors, one parallel and one perpendicular to the axis \"L\", that is,\nIn this case, the rigid motion takes the form\n\nNow, the orientation preserving rigid motion \"D\"* = \"A\"(x) + d transforms all the points of R so that they remain in planes perpendicular to \"L\". For a rigid motion of this type there is a unique point c in the plane \"P\" perpendicular to \"L\" through 0, such that\nThe point C can be calculated as\nbecause d does not have a component in the direction of the axis of \"A\".\n\nA rigid motion \"D\"* with a fixed point must be a rotation of around the axis \"L\" through the point c. Therefore, the rigid motion\nconsists of a rotation about the line \"L\" followed by a translation by the vector d in the direction of the line \"L\".\n\nConclusion: every rigid motion of R is the result of a rotation of R about a line \"L\" followed by a translation in the direction of the line. The combination of a rotation about a line and translation along the line is called a screw motion.\n\nA point C on the screw axis satisfies the equation:\nSolve this equation for C using Cayley's formula for a rotation matrix\nwhere [B] is the skew-symmetric matrix constructed from Rodrigues' vector\nsuch that\n\nUse this form of the rotation \"A\" to obtain\nwhich becomes\nThis equation can be solved for C on the screw axis P(t) to obtain,\n\nThe screw axis of this spatial displacement has the Plücker coordinates .\n\nThe screw axis appears in the dual quaternion formulation of a spatial displacement . The dual quaternion is constructed from the dual vector defining the screw axis and the dual angle , where \"φ\" is the rotation about and \"d\" the slide along this axis, which defines the displacement D to obtain,\n\nA spatial displacement of points q represented as a vector quaternion can be defined using quaternions as the mapping\nwhere d is translation vector quaternion and \"S\" is a unit quaternion, also called a versor, given by\nthat defines a rotation by 2\"θ\" around an axis S.\n\nIn the proper Euclidean group E(3) a rotation may be conjugated with a translation to move it to a parallel rotation axis. Such a conjugation, using quaternion homographies, produces the appropriate screw axis to express the given spatial displacement as a screw displacement, in accord with Chasles’ theorem.\n\nThe motion of a rigid body may be the combination of rotation about an axis (the screw axis) and a translation along that axis. This screw move is characterized by the velocity vector for the translation and the angular velocity vector in the same or opposite direction. If these two vectors are constant and along one of the principal axes of the body, no external forces are needed for this motion (moving and spinning). As an example, if gravity and drag are ignored, this is the motion of a bullet fired from a rifled gun.\n\nThis parameter is often used in biomechanics, when describing the motion of joints of the body. For any period of time, joint motion can be seen as the movement of a single point on one articulating surface with respect to the adjacent surface (usually distal with respect to proximal). The total translation and rotations along the path of motion can be defined as the time integrals of the instantaneous translation and rotation velocities at the IHA for a given reference time.\n\nIn any single plane, the path formed by the locations of the moving instantaneous axis of rotation (IAR) is known as the 'centroid', and is used in the description of joint motion.\n"}
{"id": "27861521", "url": "https://en.wikipedia.org/wiki?curid=27861521", "title": "Self-sustainability", "text": "Self-sustainability\n\nSelf-sustainability and self-sufficiency are overlapping states of being in which a person or organization needs little or no help from, or interaction with, others. Self-sufficiency entails the self being enough (to fulfill needs), and a self-sustaining entity can maintain self-sufficiency indefinitely. These states represent types of personal or collective autonomy. On a national scale, a totally self-sufficient economy that requires little or no trade with the outside world is called an autarky. Absolute purity of personal self-sufficiency or national autarky is a theoretical concept rather than a reality, but relative degrees are observable in real-world examples. \n\nSelf-sustainability is a type of sustainable living in which nothing is consumed other than what is produced by the self-sufficient individuals. Examples of attempts at self-sufficiency in North America include simple living, homesteading, off-the-grid, survivalism, DIY ethic and the back-to-the-land movement.\n\nPractices that enable or aid self-sustainability include autonomous building, permaculture, sustainable agriculture, and renewable energy. The term is also applied to limited forms of self-sustainability, for example growing one's own food or becoming economically independent of state subsidies. The self-sustainability of an electrical installation measures its degree of grid independence and is defined as the ratio between the amount of locally produced energy that is locally consumed, either directly or after storage, and the total consumption.\n\nA system is self-sustaining (or self-sufficient) if it can maintain itself by independent effort. The system self-sustainability is:\n\n\nSelf-sustainability is considered one of the \"ilities\" and is closely related to sustainability and availability. In the economics literature, a system that has the quality of being self-sustaining is also referred to as an autarky.\n\n\nAutarky exists whenever an entity can survive or continue its activities without external assistance. Autarky is not necessarily economic. For example, a military autarky would be a state that could defend itself without help from another country.\n\nAccording to the Department of Labor of the state of Idaho, an employed adult shall be considered self-sufficient if the family income exceeds 200% of the Office of Management and Budget poverty income level guidelines.\n\nIn peer-to-peer swarming systems, a swarm is self-sustaining if all the blocks of its files are available among peers (excluding seeds and publishers).\n\nWhereas self-sustainability is a quality of one’s independence, survivability applies to the future maintainability of one’s self-sustainability and indeed one’s existence. Many believe that more self-sustainability guarantees a higher degree of survivability. But just as many oppose this, arguing that it is not self-sustainability that is essential for survivability, but on the contrary specialization and thus dependence.\n\nConsider the first two examples presented above. Among countries, commercial treats are as important as self-sustainability. An autarky is usually inefficient. Among people, social ties have been shown to be correlated to happiness and success as much as self-sustainability.\n\n\n"}
{"id": "40716202", "url": "https://en.wikipedia.org/wiki?curid=40716202", "title": "Smith space", "text": "Smith space\n\nIn functional analysis and related areas of mathematics, Smith space is a complete compactly generated locally convex space formula_1 having a compact set formula_2 which absorbs every other compact set formula_3 (i.e. formula_4 for some formula_5).\n\nSmith spaces are named after \nMarianne Ruth Freundlich Smith, who introduced them as duals to Banach spaces in some versions of duality theory for topological vector spaces. All Smith spaces are stereotype and are in the stereotype duality relations with Banach spaces:\n\n\n"}
{"id": "650789", "url": "https://en.wikipedia.org/wiki?curid=650789", "title": "Star (game theory)", "text": "Star (game theory)\n\nIn combinatorial game theory, star, written as formula_1 or formula_2, is the value given to the game where both players have only the option of moving to the zero game. Star may also be denoted as the surreal form {0|0}. This game is an unconditional first-player win.\n\nStar, as defined by John Conway in \"Winning Ways for your Mathematical Plays\", is a value, but not a number in the traditional sense. Star is not zero, but neither positive nor negative, and is therefore said to be \"fuzzy\" and \"confused with\" (a fourth alternative that means neither \"less than\", \"equal to\", nor \"greater than\") 0. It is less than all positive rational numbers, and greater than all negative rationals. Since the rationals are dense in the reals, this also makes * greater than any negative real, and less than any positive real. \n\nGames other than {0 | 0} may have value *. For example, the game formula_3, where the values are nimbers, has value * despite each player having more options than simply moving to 0.\n\nA combinatorial game has a positive and negative player; which player moves first is left ambiguous. The combinatorial game 0, or { | }, leaves no options and is a second-player win. Likewise, a combinatorial game is won (assuming optimal play) by the second player if and only if its value is 0. Therefore, a game of value *, which is a first-player win, is neither positive nor negative. However, * is not the only possible value for a first-player win game (see nimbers).\n\nStar does have the property that * + * = 0, because the sum of two value-* games is the zero game; the first-player's only move is to the game *, which the second-player will win.\n\nNim, with one pile and one piece, has value *. The first player will remove the piece, and the second player will lose. A single-pile Nim game with one pile of \"n\" pieces (also a first-player win) is defined to have value \"*n\". The numbers \"*z\" for integers \"z\" form an infinite field of characteristic 2, when addition is defined in the context of combinatorial games and multiplication is given a more complex definition.\n\n"}
{"id": "5502930", "url": "https://en.wikipedia.org/wiki?curid=5502930", "title": "Stella Cunliffe", "text": "Stella Cunliffe\n\nStella Vivian Cunliffe (12 January 1917 – 20 January 2012) was a British statistician. She was the first female president of the Royal Statistical Society.\n\nCunliffe was educated at Parsons Mead School, Ashtead, Surrey; and at the London School of Economics, where she gained a BSc (Econ).\n\nShe began her career working from 1939 to 1944 in the Danish Bacon Company.\n\nAt the end of the Second World War, Cunliffe interrupted her career to undertake voluntary relief work in Europe, from 1945 to 1947, with the Guide International Service. The service had been formed from specially trained ex-Girl Guide volunteers to help with the rehabilitation of Europe after the war. Cunliffe was among the first civilians to go into Belsen Concentration Camp in 1945, where the volunteers oversaw the so-called \"human laundry\", the delousing of the inmates.\n\nIn 1947 Cunliffe resumed her professional career by accepting a post as statistician at the Dublin brewers Arthur Guinness Son & Co., where she worked until 1970. In this role, she developed important principles of experimental methods that are taught to this day. In the most famous example, she redesigned the instructions for quality control workers who were tasked to either accept or reject handmade beer barrels. Before Cunliffe's redesign, workers accepted barrels by rolling them downhill and rejected barrels by pushing them uphill, the more difficult task; thus, workers were biased to accept barrels even if they were flawed. Cunliffe redesigned the quality control work station so that it was equally easy to reject or accept a barrel, eliminating the prior bias and saving Guinness money in the process.\n\nIn 1970 she became Head of Research Unit at the Home Office, before in 1972 being appointed Director of Statistics at the Home Office, a post she held until 1977. She was the first woman to reach this grade in the British Government Statistical Service. During her time at the Home Office she expanded the department's statistical and support staff, and established a dedicated computing team. She was a prison visitor, and promoted the use of statistics in criminal justice policy. She presented the Home Secretary, Roy Jenkins, with international comparisons to show that capital punishment had no effect on murder rates.\n\nShe was later Statistical Adviser to the Committee of Enquiry into the Engineering Profession from 1978 to 1980.\n\nShe served as the first female President of the Royal Statistical Society from 1975 to 1977.\n\n\nCunliffe was appointed MBE in 1993, for services to the Guides and the community in Surrey.\n\nCunliffe's other activities included work with youth organisations, gardening and prison after-care. She served as a Mole Valley District Councillor from 1981 to 1999, chaired the local Community Health Council, and served as Chair of Governors for Parsons Mead School.\n\n\n"}
{"id": "40358669", "url": "https://en.wikipedia.org/wiki?curid=40358669", "title": "TRACE (computer program)", "text": "TRACE (computer program)\n\nTRACE is a high-precision orbit determination and orbit propagation program. It was developed by The Aerospace Corporation in El Segundo, California. An early version is known to have run on the IBM 7090 computer in 1964. The Fortran source code can be compiled for any platform with a Fortran compiler.\n\nWhen Satellite Tool Kit's high-precision orbit propagator and parameter and coordinate frame transformations underwent an Independent Verification and Validation effort in 2000, TRACE v2.4.9 was the standard against which STK was compared.\n\nAs of 2013, TRACE is still used by the U.S. Government and some of its technical contractors.\n"}
{"id": "939333", "url": "https://en.wikipedia.org/wiki?curid=939333", "title": "Universal generalization", "text": "Universal generalization\n\nIn predicate logic, generalization (also universal generalization or universal introduction, GEN) is a valid inference rule. It states that if formula_1 has been derived, then formula_2 can be derived.\n\nThe full generalization rule allows for hypotheses to the left of the turnstile, but with restrictions. Assume Γ is a set of formulas, formula_3 a formula, and formula_4 has been derived. The generalization rule states that formula_5 can be derived if \"y\" is not mentioned in Γ and \"x\" does not occur in formula_3.\n\nThese restrictions are necessary for soundness. Without the first restriction, one could conclude formula_7 from the hypothesis formula_8. Without the second restriction, one could make the following deduction:\nThis purports to show that formula_13 which is an unsound deduction.\n\nProve: formula_14 is derivable from formula_15 and formula_16.\n\nProof:\nIn this proof, universal generalization was used in step 8. The deduction theorem was applicable in steps 10 and 11 because the formulas being moved have no free variables.\n\n"}
{"id": "40148474", "url": "https://en.wikipedia.org/wiki?curid=40148474", "title": "Upward planar drawing", "text": "Upward planar drawing\n\nIn graph drawing, an upward planar drawing of a directed acyclic graph is an embedding of the graph into the Euclidean plane, in which the edges are represented as non-crossing monotonic upwards curves. That is, the curve representing each edge should have the property that every horizontal line intersects it in at most one point, and no two edges may intersect except at a shared endpoint. In this sense, it is the ideal case for layered graph drawing, a style of graph drawing in which edges are monotonic curves that may cross, but in which crossings are to be minimized.\n\nA directed acyclic graph must be planar in order to have an upward planar drawing, but not every planar acyclic graph has such a drawing. Among the planar directed acyclic graphs with a single source (vertex with no incoming edges) and sink (vertex with no outgoing edges), the graphs with upward planar drawings are the \"st\"-planar graphs, planar graphs in which the source and sink both belong to the same face of at least one of the planar embeddings of the graph. More generally, a graph \"G\" has an upward planar drawing if and only if it is directed and acyclic, and is a subgraph of an \"st\"-planar graph on the same vertex set.\n\nIn an upward embedding, the sets of incoming and outgoing edges incident to each vertex are contiguous in the cyclic ordering of the edges at the vertex. A planar embedding of a given directed acyclic graph is said to be \"bimodal\" when it has this property. Additionally, the angle between two consecutive edges with the same orientation at a given vertex may be labeled as \"small\" if it is less than π, or \"large\" if it is greater than π. Each source or sink must have exactly one large angle, and each vertex that is neither a source nor a sink must have none. Additionally, each internal face of the drawing must have two more small angles than large ones, and the external face must have two more large angles than small ones. A \"consistent assignment\" is a labeling of the angles that satisfies these properties; every upward embedding has a consistent assignment. Conversely, every directed acyclic graph that has a bimodal planar embedding with a consistent assignment has an upward planar drawing, that can be constructed from it in linear time.\n\nAnother characterization is possible for graphs with a single source. In this case an upward planar embedding must have the source on the outer face, and every undirected cycle of the graph must have at least one vertex at which both cycle edges are incoming (for instance, the vertex with the highest placement in the drawing). Conversely, if an embedding has both of these properties, then it is equivalent to an upward embedding.\n\nSeveral special cases of upward planarity testing are known to be possible in polynomial time:\nHowever, it is NP-complete to determine whether a planar directed acyclic graph with multiple sources and sinks has an upward planar drawing.\n\nFáry's theorem states that every planar graph has a drawing in which its edges are represented by straight line segments, and the same is true of upward planar drawing: every upward planar graph has a straight upward planar drawing.\nA straight-line upward drawing of a transitively reduced \"st\"-planar graph may be obtained by the technique of dominance drawing, with all vertices having integer coordinates within an \"n\" × \"n\" grid. However, certain other upward planar graphs may require exponential area in all of their straight-line upward planar drawings. If a choice of embedding is fixed, even oriented series parallel graphs and oriented trees may require exponential area.\n\nUpward planar drawings are particularly important for Hasse diagrams of partially ordered sets, as these diagrams are typically required to be drawn upwardly. In graph-theoretic terms, these correspond to the transitively reduced directed acyclic graphs; such a graph can be formed from the covering relation of a partial order, and the partial order itself forms the reachability relation in the graph. If a partially ordered set has one minimal element, has one maximal element, and has an upward planar drawing, then it must necessarily form a lattice, a set in which every pair of elements has a unique greatest lower bound and a unique least upper bound. The Hasse diagram of a lattice is planar if and only if its order dimension is at most two. However, some partial orders of dimension two and with one minimal and maximal element do not have an upward planar drawing (take the order defined by the transitive closure of formula_1).\n\n\n"}
{"id": "46953393", "url": "https://en.wikipedia.org/wiki?curid=46953393", "title": "Zassenhaus algorithm", "text": "Zassenhaus algorithm\n\nIn mathematics, the Zassenhaus algorithm\nis a method to calculate a basis for the intersection and sum of two subspaces of a vector space.\nIt is named after Hans Zassenhaus, but no publication of this algorithm by him is known. It is used in computer algebra systems.\n\nLet be a vector space and , two finite-dimensional subspaces of with the following spanning sets:\nand\nFinally, let formula_3 be linearly independent vectors so that formula_4 and formula_5 can be written as\nand\n\nThe algorithm computes the base of the sum formula_8 and a base of the intersection formula_9.\n\nThe algorithm creates the following block matrix of size formula_10:\n\nUsing elementary row operations, this matrix is transformed to the row echelon form. Then, it has the following shape:\nHere, formula_13 stands for arbitrary numbers, and the vectors \nformula_14 for every formula_15 and formula_16 for every formula_17 are nonzero.\n\nThen formula_18 with\nis a basis of formula_20\nand formula_21 with\nis a basis of formula_9.\n\nFirst, we define formula_24 to be the projection to the first component.\n\nLet\nformula_25\nThen formula_26 and\nformula_27.\n\nAlso, formula_28 is the kernel of formula_29, the projection restricted to .\nTherefore, formula_30.\n\nThe Zassenhaus Algorithm calculates a basis of . In the first columns of this matrix, there is a basis formula_31 of formula_20.\n\nThe rows of the form formula_33 (with formula_34) are obviously in formula_28. Because the matrix is in row echelon form, they are also linearly independent.\nAll rows which are different from zero (formula_36 and formula_33) are a basis of , so there are formula_38 such formula_39s. Therefore, the formula_39s form a basis of formula_9.\n\nConsider the two subspaces formula_42 and formula_43 of the vector space formula_44.\n\nUsing the standard basis, we create the following matrix of dimension formula_45:\n\nUsing elementary row operations, we transform this matrix into the following matrix:\n\nTherefore,\nformula_49 is a basis of formula_20, and\nformula_51 is a basis of formula_9.\n\n"}
