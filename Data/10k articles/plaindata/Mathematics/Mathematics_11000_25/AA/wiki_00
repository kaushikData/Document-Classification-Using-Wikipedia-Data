{"id": "407375", "url": "https://en.wikipedia.org/wiki?curid=407375", "title": "114 (number)", "text": "114 (number)\n\n114 (one hundred [and] fourteen) is the natural number following 113 and preceding 115.\n\n\n\n"}
{"id": "391887", "url": "https://en.wikipedia.org/wiki?curid=391887", "title": "77 (number)", "text": "77 (number)\n\n77 (seventy-seven) is the natural number following 76 and preceding 78. Seventy-seven is the smallest positive integer requiring five syllables in English.\n\n77 is:\n\n\nIt is possible for a sudoku puzzle to have as many as 77 givens, yet lack a unique solution.\n\nIt and its \"sibling\" 49 are the only 2-digit numbers whose home primes (in base 10) have not been calculated.\n\n\nDuring World War II in Sweden at the border with Norway, \"77\" was used as a shibboleth (password), because the tricky pronunciation in Swedish made it easy to instantly discern whether the speaker was native Swedish, Norwegian, or German.\n\nIn the Islamic tradition, \"77\" figures prominently. Muhammad is reported to have explained, \"Faith has sixty-odd, or seventy-odd branches, the highest and best of which is to declare that there is no god but God, and the lowest of which is to remove something harmful from a road. Shyness, too, is a branch of faith.\" While some scholars refrain from clarifying \"sixty-odd or seventy-odd\", various numbers have been suggested, 77 being the most common. Some have gone so far as to delineate these branches.\n\nThe Gospel of Luke lists 77 generations from Adam to Jesus.\n\nIn certain numerological systems based on the English alphabet, the number 77 is associated with Jesus Christ. CHRIST is C = 3, H = 8, R = 18, I = 9, S = 19, T = 20, which added together equal 77.\n\n'Liber 77' is the gematrian name for Liber OZ- a brief but popular publication by Aliester Crowley. The word 'oz', which means 'strength', is composed of two hebrew letters- ayin and zayin, which have gematrian values of 70 and 7 respectively, thus adding up to 77.\n\nSeventy-seven is also:\n"}
{"id": "7495999", "url": "https://en.wikipedia.org/wiki?curid=7495999", "title": "Adaptive grammar", "text": "Adaptive grammar\n\nAn adaptive grammar is a formal grammar that explicitly provides mechanisms within the formalism to allow its own production rules to be manipulated.\n\nJohn N. Shutt defines adaptive grammars as follows:\n\nTypes of manipulation include rule addition, deletion, and modification.\n\nThe first description of grammar adaptivity (though not under that name) in the literature is generally taken to be in a paper by Alfonso Caracciolo di Forino published in 1963. The next generally accepted reference to an adaptive formalism (\"extensible context-free grammars\") came from Wegbreit in 1970 in the study of extensible programming languages, followed by the \"dynamic syntax\" of Hanford and Jones in 1973.\n\nUntil fairly recently, much of the research into the formal properties of adaptive grammars was uncoordinated between researchers, only first being summarized by Henning Christiansen in 1990 in response to a paper in \"ACM SIGPLAN Notices\" by Boris Burshteyn. The Department of Engineering at the University of São Paulo has its Adaptive Languages and Techniques Laboratory, specifically focusing on research and practice in adaptive technologies and theory. The LTA also maintains a page naming researchers in the field.\n\nWhile early efforts made reference to \"dynamic syntax\" and \"extensible\", \"modifiable\", \"dynamic\", and \"adaptable\" grammars, more recent usage has tended towards the use of the term \"adaptive\" (or some variant such as \"adaptativa\", depending on the publication language of the literature). Iwai refers to her formalism as \"adaptive grammars\", but this specific use of simply \"adaptive grammars\" is not typically currently used in the literature without name qualification. Moreover, no standardization or categorization efforts have been undertaken between various researchers, although several have made efforts in this direction.\n\nShutt categorizes adaptive grammar models into two main categories:\n\n\nJackson refines Shutt's taxonomy, referring to changes over time as global and changes over space as local, and adding a hybrid \"time-space\" category:\n\n\nAdaptive formalisms may be divided into two main categories: full grammar formalisms (adaptive grammars), and adaptive machines, upon which some grammar formalisms have been based.\n\nThe following is a list (by no means complete) of grammar formalisms that, by Shutt's definition above, are considered to be (or have been classified by their own inventors as being) adaptive grammars. They are listed in their historical order of first mention in the literature.\n\nDescribed in Wegbreit's doctoral dissertation in 1970, an extensible context-free grammar consists of a context-free grammar whose rule set is modified according to instructions output by a finite state transducer when reading the terminal prefix during a leftmost derivation. Thus, the rule set varies over position in the generated string, but this variation ignores the hierarchical structure of the syntax tree. Extensible context-free grammars were classified by Shutt as \"imperative\".\n\nFirst introduced in 1985 as \"Generative Grammars\" and later more elaborated upon, Christiansen grammars (apparently dubbed so by Shutt, possibly due to conflict with Chomsky generative grammars) are an adaptive extension of attribute grammars. Christiansen grammars were classified by Shutt as \"declarative\".\n\nThe redoubling language formula_1 is demonstrated as follows:\n\nFirst introduced in May 1990 and later expanded upon in December 1990, \"modifiable grammars\" explicitly provide a mechanism for the addition and deletion of rules during a parse. In response to the \"ACM SIGPLAN Notices\" responses, Burshteyn later modified his formalism and introduced his adaptive \"Universal Syntax and Semantics Analyzer\" (USSA) in 1992. These formalisms were classified by Shutt as \"imperative\".\n\nIntroduced in 1993, Recursive Adaptive Grammars (RAGs) were an attempt to introduce a Turing powerful formalism that maintained much of the elegance of context-free grammars. Shutt self-classifies RAGs as being a \"declarative\" formalism.\n\nBoullier's \"dynamic grammars\", introduced in 1994, appear to be the first adaptive grammar family of grammars to rigorously introduce the notion of a time continuum of a parse as part of the notation of the grammar formalism itself. Dynamic grammars are a sequence of grammars, with each grammar \"G\" differing in some way from other grammars in the sequence, over time. Boullier's main paper on dynamic grammars also defines a dynamic parser, the machine that effects a parse against these grammars, and shows examples of how his formalism can handle such things as type checking, extensible languages, polymorphism, and other constructs typically considered to be in the semantic domain of programming language translation.\n\nThe work of Iwai in 2000 takes the adaptive automata of Neto further by applying adaptive automata to context-sensitive grammars. Iwai's adaptive grammars (note the qualifier by name) allow for three operations during a parse: ? query (similar in some respects to a syntactic predicate, but tied to inspection of rules from which modifications are chosen), + addition, and - deletion (which it shares with its predecessor adaptive automata).\n\nIntroduced in 2000 and most fully discussed in 2006, the §-Calculus (§ here pronounced \"meta-ess\") allows for the explicit addition, deletion, and modification of productions within a grammar, as well as providing for syntactic predicates. This formalism is self-classified by its creator as both \"imperative\" and \"adaptive\", or, more specifically, as a \"time-space\" adaptive grammar formalism, and was further classified by others as being an analytic formalism.\n\nThe redoubling language formula_2 is demonstrated as follows:\n\nFirst described by Neto in 2001, adaptive devices were later enhanced and expanded upon by Pistori in 2003.\n\nIn 2002, Adam Carmi introduced an LALR(1)-based adaptive grammar formalism known as \"Adapser\". Specifics of the formalism do not appear to have been released.\n\nIn 2004, César Bravo introduced the notion of merging the concept of \"appearance checking\" with \"adaptive context-free grammars\", a restricted form of Iwai's adaptive grammars, showing these new grammars, called \"Adaptive CFGs with Appearance Checking\" to be Turing powerful.\n\nThe formalisms listed below, while not grammar formalisms, either serve as the basis of full grammar formalisms, or are included here because they are adaptive in nature. They are listed in their historical order of first mention in the literature.\n\n\n\n\n\n\n"}
{"id": "3683228", "url": "https://en.wikipedia.org/wiki?curid=3683228", "title": "Alligation", "text": "Alligation\n\nAlligation is an old and practical method of solving arithmetic problems related to mixtures of ingredients. There are two types of alligation: alligation medial, used to find the quantity of a mixture given the quantities of its ingredients, and alligation alternate, used to find the amount of each ingredient needed to make a mixture of a given quantity. Alligation medial is merely a matter of finding a weighted mean. Alligation alternate is more complicated and involves organizing the ingredients into high and low pairs which are then traded off.\n\nTwo further variations on Alligation occur : Alligation Partial and Alligation Total (see John King's Arithmetic Book 1795 which includes worked examples.) The technique is not used in schools although it is used still in pharmacies for quick calculation of quantities.\n\nSuppose you make a cocktail drink combination out of 1/2 Coke, 1/4 Sprite, and 1/4 orange soda. The Coke has 120 grams of sugar per liter, the Sprite has 100 grams of sugar per liter, and the orange soda has 150 grams of sugar per liter. How much sugar does the drink have? This is an example of alligation medial because you want to find the amount of sugar in the mixture given the amounts of sugar in its ingredients. The solution is just to find the weighted average by composition:\n\nSuppose you like 1% milk, but you have only 3% whole milk and ½% low fat milk. How much of each should you mix to make an 8-ounce cup of 1% milk? This is an example of alligation alternate because you want to find the amount of two ingredients to mix to form a mixture with a given amount of fat. Since there are only two ingredients, there is only one possible way to form a pair. The difference of 3% from the desired 1%, 2%, is assigned to the low fat milk, and the difference of ½% from the desired 1%, ½%, is assigned alternately to the whole milk. The total amount, 8 ounces, is then divided by the sum formula_2 to yield formula_3, and the amounts of the two ingredients are\n\nA general formula that works for both alligation \"alternate\" and alligation \"medial\" is the following:\nAa + Bb = Cc.\n\nIn this formula, A is the volume of ingredient A and a is its mixture coefficient (i.e. a= 3%); B is volume of ingredient B and b is its mixture coefficient; and C is the desired volume C, and c is its mixture coefficient. So in the above example we get: A(0.03) + B(0.005) = 8oz(0.01). We know B = (8oz-A), and so can easily solve for A and B to get 1.6 and 6.4oz, respectively. Using this formula you can solve for any of the 6 variables A,a,B,b,C,c, regardless of whether you're dealing with medial, alternate, etc.\n\n8 liters are drawn from a cask full of pure wine and is then filled with water. This operation is performed three more times. The ratio of the quantity of wine now left in cask to that of water is 16: 65. How much wine did the cask hold originally? This is an example of a problem that involves repeated dilutions of a given solution. \n\n\nX = original volume of wine/ total volume of liquid in the cask = Vw / Vt\n\nWhen 8 liters are drawn out, the volume of wine is reduced by 8 X liters while the total volume of liquid remains unchanged as it is re-filled with water.\n\nLet X’ be the new percentage of wine in the cask after this operation\n\nX’ = (original volume of wine – 8 X) / total volume of liquid in the cask\n\nX’ = [Vw – 8 (Vw/ Vt)] / Vt\n\nX’ = X (Vt – 8) / Vt\n\nAfter 4 such replacement operations, X’’’’ = X [(Vt – 8)/ Vt] ^ 4\n\nFrom the problem, X’’’’ = 16/ (16 + 65) = 16/ 81\n\nAlso, since originally the cask was full of pure wine, X = 1\n\n[(Vt – 8)/ Vt] ^ 4 = 16/ 81\n\n<nowiki>=> Vt = 24 liters</nowiki>\n\n\n"}
{"id": "20086937", "url": "https://en.wikipedia.org/wiki?curid=20086937", "title": "Bures metric", "text": "Bures metric\n\nIn mathematics, in the area of quantum information geometry, the Bures metric (named after Donald Bures) or Helstrom metric (named after Carl W. Helstrom) defines an infinitesimal distance between density matrix operators defining quantum states. It is a quantum generalization of the Fisher information metric, and is identical to the Fubini–Study metric when restricted to the pure states alone.\n\nThe metric may be defined as\nwhere formula_2 is Hermitian 1-form operator implicitly given by\nwhich is a special case of a continuous Lyapunov equation.\n\nSome of the applications of the Bures metric include that given a target error, it allows the calculation of the minimum number of measurements to distinguish two different states and the use of the volume element as a candidate for the Jeffreys prior probability density for mixed quantum states.\n\nThe Bures distance is the finite version of the infinitesimal square distance described above and is given\nby \nwhere the fidelity function is defined \nas\nAnother associated function is the Bures arc also known as Bures angle, Bures length or quantum angle, defined as\nwhich is a measure of the statistical distance\nbetween quantum states.\n\nThe Bures metric can be seen as the quantum equivalent of the Fisher information metric and can be rewritten in terms of the variation of coordinate parameters as \nwhich holds as long as formula_8 and formula_9 have the same rank. In cases where they do not have the same rank, there is an additional term on the right hand side.\nformula_10 is the Symmetric Logarithmic Derivative operator (SLD) defined from\n\nIn this way, one has\nwhere the quantum Fisher metric (tensor components) is identified as\n\nThe definition of the SLD implies that the quantum Fisher metric is 4 times the Bures metric. In other words, given that formula_14 are components of the Bures metric tensor, one has\n\nAs it happens with the classical Fisher information metric, the quantum Fisher metric can be used to find the Cramér–Rao bound of the covariance.\n\nThe actual computation of the Bures metric is not evident from the definition, so, some formulas were developed for that purpose. For 2x2 and 3x3 systems, respectively, the quadratic form of the Bures metric is calculated as\n\nFor general systems, the Bures metric can be written in terms of the eigenvectors and eigenvalues of the density matrix formula_18 as\nas an integral,\nor in terms of Kronecker product and vectorization,\nwhere the overbar denotes complex conjugate, and formula_22 denotes conjugate transpose.\n\nThe state of a two-level system can be parametrized with three variables as \nwith formula_24. \nThe components of the Bures metric in this parametrization can be calculated as\nThe Bures measure can be calculated by taking the square root of the determinant to find\n\nwhich can be used to calculate the Bures volume as\n\n\n"}
{"id": "29949380", "url": "https://en.wikipedia.org/wiki?curid=29949380", "title": "Classical involution theorem", "text": "Classical involution theorem\n\nIn mathematical finite group theory, the classical involution theorem of classifies simple groups with a classical involution and satisfying some other conditions, showing that they are mostly groups of Lie type over a field of odd characteristic. extended the classical involution theorem to groups of finite Morley rank.\n\nA classical involution \"t\" of a finite group \"G\" is an involution whose centralizer has a subnormal subgroup containing \"t\" with quaternion Sylow 2-subgroups.\n\n"}
{"id": "31585265", "url": "https://en.wikipedia.org/wiki?curid=31585265", "title": "Clock position", "text": "Clock position\n\nA clock position is the relative direction of an object described using the analogy of a 12-hour clock to describe angles and directions. One imagines a clock face lying either upright or flat in front of oneself, and identifies the twelve hour markings with the directions in which they point.\n\nUsing this analogy, \"12 o'clock\" means \"ahead or above\", \"3 o'clock\" means \"to the right\", \"6 o'clock\" means \"behind or below\", and \"9 o'clock\" means \"to the left\". The other eight hours refer to directions that are not directly in line with the four cardinal directions.\n\nIn aviation, a clock position refers to a horizontal direction; it may be supplemented with the word \"high\" or \"low\" to describe the vertical direction which is pointed towards your feet. \"6 o'clock high\" means \"behind and above the horizon\", while \"12 o'clock low\" means \"ahead and below the horizon\".\n\nThe 1949 movie \"Twelve O'Clock High\" takes its title from the system. In this case, the position would be \"ahead and above the horizon\".\n\nThe phrase \"on your six\" refers to the system, six referring to the six o'clock or following position.\n\n"}
{"id": "27351720", "url": "https://en.wikipedia.org/wiki?curid=27351720", "title": "Completely uniformizable space", "text": "Completely uniformizable space\n\nIn mathematics, a topological space (\"X\", \"T\") is called completely uniformizable (or Dieudonné complete) if there exists at least one complete uniformity that induces the topology \"T\". Some authors additionally require \"X\" to be Hausdorff. Some authors have called these spaces topologically complete, although that term has also been used in other meanings like \"completely metrizable\", which is a stronger property than \"completely uniformizable\".\n\n\nEvery metrizable space is paracompact, hence completely uniformizable. As there exist metrizable spaces that are not completely metrizable, complete uniformizability is a strictly weaker condition than complete metrizability.\n\n\n"}
{"id": "723392", "url": "https://en.wikipedia.org/wiki?curid=723392", "title": "Computable measure theory", "text": "Computable measure theory\n\nIn mathematics, computable measure theory is the part of computable analysis that deals with effective versions of measure theory. \n\n"}
{"id": "15878779", "url": "https://en.wikipedia.org/wiki?curid=15878779", "title": "Contact dynamics", "text": "Contact dynamics\n\nContact dynamics deals with the motion of multibody systems subjected to unilateral contacts and friction. Such systems are omnipresent in many multibody dynamics applications. Consider for example\nIn the following it is discussed how such mechanical systems with unilateral contacts and friction can be modeled and how the time evolution of such systems can be obtained by numerical integration. In addition, some examples are given.\n\nThe two main approaches for modeling mechanical systems with unilateral contacts and friction are the regularized and the non-smooth approach. In the following, the two approaches are introduced using a simple example. Consider a block which can slide or stick on a table (see figure 1a). The motion of the block is described by the equation of motion, whereas the friction force is unknown (see figure 1b). In order to obtain the friction force, a separate force law must be specified which links the friction force to the associated velocity of the block. \n\nA more sophisticated approach is the non-smooth approach, which uses set-valued force laws to model mechanical systems with unilateral contacts and friction. Consider again the block which slides or sticks on the table. The associated set-valued friction law of type Sgn is depicted in figure 3. Regarding the sliding case, the friction force is given. Regarding the sticking case, the friction force is set-valued and determined according to an additional algebraic constraint. \n\nTo conclude, the non-smooth approach changes the underlying mathematical structure if required and leads to a proper description of mechanical systems with unilateral contacts and friction. As a consequence of the changing mathematical structure, impacts can occur, and the time evolutions of the positions and the velocities can not be assumed to be smooth anymore. As a consequence, additional impact equations and impact laws have to be defined. In order to handle the changing mathematical structure, the set-valued force laws are commonly written as inequality or inclusion problems. The evaluation of these inequalities/inclusions is commonly done by solving linear (or nonlinear) complementarity problems, by quadratic programming or by transforming the inequality/inclusion problems into projective equations which can be solved iteratively by Jacobi or Gauss–Seidel techniques.\nThe non-smooth approach provides a new modeling approach for mechanical systems with unilateral contacts and friction, which incorporates also the whole classical mechanics subjected to bilateral constraints. The approach is associated to the classical DAE theory and leads to robust integration schemes.\n\nThe integration of regularized models can be done by standard stiff solvers for ordinary differential equations. However, oscillations induced by the regularization can occur. Considering non-smooth models of mechanical systems with unilateral contacts and friction, two main classes of integrators exist, the event-driven and the so-called time-stepping integrators.\n\nEvent-driven integrators distinguish between smooth parts of the motion in which the underlying structure of the differential equations does not change, and in events or so-called switching points at which this structure changes, i.e. time instants at which a unilateral contact closes or a stick slip transition occurs. At these switching points, the set-valued force (and additional impact) laws are evaluated in order to obtain a new underlying mathematical structure on which the integration can be continued. Event-driven integrators are very accurate but are not suitable for systems with many contacts.\n\nSo-called time-stepping integrators are dedicated numerical schemes for mechanical systems with many contacts. The first time-stepping integrator was introduced by J.J. Moreau. The integrators do not aim at resolving switching points and are therefore very robust in application. As the integrators do work with the integral of the contact forces and not with the forces itself, the methods can handle both non-impulsive motion and impulsive events like impacts. As a drawback, the accuracy of time-stepping integrators is low. This lack can be fixed by using a step-size refinement at switching points. Smooth parts of the motion are processed by larger step sizes, and higher order integration methods can be used to increase the integration order.\n\nThis section gives some examples of mechanical systems with unilateral contacts and friction. The results have been obtained by a non-smooth approach using time-stepping integrators.\n\nTime-stepping methods are especially well suited for the simulation of granular materials. Figure 4 depicts the simulation of mixing 1000 disks. \n\nConsider two colliding spheres in a billiard play. Figure 5a shows some snapshots of two colliding spheres, figure 5b depicts the associated trajectories.\n\nIf a motorbike is accelerated too fast, it does a wheelie. Figure 6 shows some snapshots of a simulation.\n\nThe woodpecker toy is a well known benchmark problem in contact dynamics. The toy consists of a pole, a sleeve with a hole that is slightly larger than the diameter of the pole, a spring and the woodpecker body. In operation, the woodpecker moves down the pole performing some kind of pitching motion, which is controlled by the sleeve. Figure 7 shows some snapshots of a simulation.\n\nA simulation and visualization can be found at https://github.com/gabyx/Woodpecker.\n\n\n\n"}
{"id": "7393195", "url": "https://en.wikipedia.org/wiki?curid=7393195", "title": "Cumulative hierarchy", "text": "Cumulative hierarchy\n\nIn mathematical set theory, a cumulative hierarchy is a family of sets \"W\" indexed by ordinals α such that\n\n\nIt is also sometimes assumed that \"W\"⊆\"P\"(\"W\") or that \"W\" is empty.\n\nThe union \"W\" of the sets of a cumulative hierarchy is often used as a model of set theory.\n\nThe phrase \"the cumulative hierarchy\" usually refers to the standard cumulative hierarchy \"V\" of the Von Neumann universe with \"V\"=\"P\"(\"V\") introduced by \n\nA cumulative hierarchy satisfies a form of the reflection principle: any formula of the language of set theory that holds in the union \"W\" of the hierarchy also holds in some stages \"W\".\n\n"}
{"id": "10470883", "url": "https://en.wikipedia.org/wiki?curid=10470883", "title": "Differentially closed field", "text": "Differentially closed field\n\nIn mathematics, a differential field \"K\" is differentially closed if every finite system of differential equations with a solution in some differential field extending \"K\" already has a solution in \"K\". This concept was introduced by . Differentially closed fields are the analogues\nfor differential equations of algebraically closed fields for polynomial equations.\n\nWe recall that a differential field is a field equipped with a derivation operator. Let \"K\" be a differential field with derivation operator ∂.\n\n\nTaking \"g\"=1 and \"f\" any ordinary separable polynomial shows that any differentially closed field is separably closed. In characteristic 0 this implies that it is algebraically closed, but in characteristic \"p\">0 differentially closed fields are never algebraically closed.\n\nUnlike the complex numbers in the theory of algebraically closed fields, there is no natural example of a differentially closed field.\nAny differentially perfect field \"K\" has a differential closure, a prime model extension, which is differentially closed. Shelah showed that the differential closure is unique up to isomorphism over \"K\". Shelah also showed that the prime differentially closed field of characteristic 0 (the differential closure of the rationals) is not minimal; this was a rather surprising result, as it is not what one would expect by analogy with algebraically closed fields.\n\nThe theory of DCF is complete and model complete (for \"p\"=0 this was shown by Robinson, and for \"p\">0 by ).\nThe theory DCF is the model companion of the theory of differential fields of characteristic \"p\". It is the model completion of the theory of differentially perfect fields of characteristic \"p\" if one adds to the language a symbol giving the \"p\"th root of constants when \"p\">0. The theory of differential fields of characteristic \"p\">0 does not have a model completion, and in characteristic \"p\"=0 is the same as the theory of differentially perfect fields so has DCF as its model completion.\n\nThe number of differentially closed fields of some infinite cardinality κ is 2; for κ uncountable this was proved by , and for κ countable by Hrushovski and Sokolovic.\n\nThe \"Kolchin topology\" on \"K\" is defined by taking sets of solutions of systems of differential equations over \"K\" in \"m\" variables as basic closed sets. Like the Zariski topology, the Kolchin topology is Noetherian.\n\nA d-constructible set is a finite union of closed and open sets in the Kolchin topology. Equivalently, a d-constructible set is the set of solutions to a quantifier-free, or atomic, formula with parameters in \"K\".\n\nLike the theory of algebraically closed fields, the theory DCF of differentially closed fields of characteristic 0 eliminates quantifiers. The geometric content of this statement is that the projection of a d-constructible set is d-constructible. It also eliminates imaginaries, is complete, and model complete.\n\nIn characteristic \"p\">0, the theory DCF eliminates quantifiers in the language of differential fields with a unary function \"r\" added that is the \"p\"th root of all constants, and is 0 on elements that are not constant.\n\nThe differential Nullstellensatz is the analogue in differential algebra of Hilbert's nullstellensatz.\n\n\nSuppose that \"K\" is a differentially closed field of characteristic 0. . Then Seidenberg's differential nullstellensatz states there is a bijection between\nThis correspondence maps a ∂-closed subset to the ideal of elements vanishing on it, and maps an ideal to its set of zeros.\n\nIn characteristic 0 showed that the theory of differentially closed fields is ω-stable and has Morley rank ω.\nIn non-zero characteristic showed that the theory of differentially closed fields is not ω-stable, and showed more precisely that it is stable but not superstable.\n\n\n"}
{"id": "41418803", "url": "https://en.wikipedia.org/wiki?curid=41418803", "title": "Equivariant differential form", "text": "Equivariant differential form\n\nIn differential geometry, an equivariant differential form on a manifold \"M\" acted by a Lie group \"G\" is a polynomial map\nfrom the Lie algebra formula_2 to the space of differential forms on \"M\" that are equivariant; i.e.,\nIn other words, an equivariant differential form is an invariant element of\n\nFor an equivariant differential form formula_5, the equivariant exterior derivative formula_6 of formula_5 is defined by\nwhere \"d\" is the usual exterior derivative and formula_9 is the interior product by the fundamental vector field generated by \"X\".\nIt is easy to see formula_10 (use the fact the Lie derivative of formula_11 along formula_12 is zero) and one then puts\nwhich is called the equivariant cohomology of \"M\" (which coincides with the ordinary equivariant cohomology defined in terms of Borel construction.) The definition is due to H. Cartan. The notion has an application to the equivariant index theory.\n\nformula_14-closed or formula_14-exact forms are called equivariantly closed or equivariantly exact.\n\nThe integral of an equivariantly closed form may be evaluated from its restriction to the fixed point by means of the localization formula.\n"}
{"id": "45031371", "url": "https://en.wikipedia.org/wiki?curid=45031371", "title": "Erable", "text": "Erable\n\nErable is a computer algebra system (CAS) for a family of Hewlett-Packard graphing scientific calculators of the HP 40, 48 and HP 49/50 series.\n\nOriginally named \"ALGB\" in 1993, it was developed by the French mathematician Bernard Parisse for the HP 48SX. Over time, the system integrated a lot of functionality from another math pack for the HP 48 series, ALG48 by Mika Heiskanen and Claude-Nicolas Fiechter. At some point, \"ALGB\" was renamed into \"Erable\", a French play-on-words on another CAS named Maple. Compatible with the HP 48S, 48SX, 48G, 48G+, 48GX, Erable became one of the \"must-have\" software packages to be installed by advanced users of these calculators.\n\nWhen Hewlett-Packard developed the HP 49G in 1999, the Erable and ALG48 packages became an integral part of the calculator's firmware, now just named \"HP49 CAS\".\n\nAs HP CAS it also showed up in the HP 40G, 40gs, 49g+, 48gII and 50g and was maintained by Parisse up to 2006.\n\nBased on his experiences with Erable, Parisse started developing a new and more general CAS system named Xcas / Giac in 2000. It is written in C++ rather than System RPL. This system was integrated into the HP Prime in 2013 under a dual-license scheme.\n\nThe last stable stand-alone version of Erable for the HP 48 series is 3.024 (1998-08-06), with source code as of 1998-07-14 available under the GNU GPL. The latest beta versions for these calculators are 3.117 (1998-10-17) and 3.201 (1999-02-07).\n\nParts of the CAS system for the HP 49/50 series (version 4) were released as open-source under the LGPL (since some parts of the CAS, which are copyrighted by Hewlett-Packard, remain proprietary software) and were maintained by Parisse up to 2006-02-02 (for firmware 2.14), and 2006-09-19 (for firmware 2.15 (2009-04-21) and 2.16 (2012-04-26)).\n\n"}
{"id": "42960", "url": "https://en.wikipedia.org/wiki?curid=42960", "title": "Fractal transform", "text": "Fractal transform\n\nThe fractal transform is a technique invented by Michael Barnsley \"et al.\" to perform lossy image compression.\nThis first practical fractal compression system for digital images resembles a vector quantization system using the image itself as the codebook.\n\nStart with a digital image A.\nDownsample it by a factor of 2 to produce image A.\nNow, for each block B of 4x4 pixels in A, find the corresponding block B in A most similar to B, and then find the grayscale or RGB offset and gain from A to B.\nFor each destination block, output the positions of the source blocks and the color offsets and gains.\n\nStarting with an empty destination image A, repeat the following algorithm several times:\nDownsample A down by a factor of 2 to produce image A. Then copy blocks from A to A as directed by the compressed data, multiplying by the respective gains and adding the respective color offsets.\n\nThis algorithm is guaranteed to converge to an image, and it should appear similar to the original image.\nIn fact, a slight modification of the decompressor to run at block sizes larger than 4x4 pixels produces a method of stretching images without causing the blockiness or blurriness of traditional linear resampling algorithms.\n\nThe basic patents covering Fractal Image Compression, U.S. Patents 4,941,193, 5,065,447, 5,384,867, 5,416,856, and 5,430,812 appear to be expired.\n\n\n"}
{"id": "20269925", "url": "https://en.wikipedia.org/wiki?curid=20269925", "title": "Free convolution", "text": "Free convolution\n\nFree convolution is the free probability analog of the classical notion of convolution of probability measures. Due to the non-commutative nature of free probability theory, one has to talk separately about additive and multiplicative free convolution, which arise from addition and multiplication of free random variables (see below; in the classical case, what would be the analog of free multiplicative convolution can be reduced to additive convolution by passing to logarithms of random variables). These operations have some interpretations in terms of empirical spectral measures of random matrices.\n\nThe notion of free convolution was introduced by Voiculescu.\n\nLet formula_1 and formula_2 be two probability measures on the real line, and assume that formula_3 is a random variable in a non commutative probability space with law formula_1 and formula_5 is a random variable in the same non commutative probability space with law formula_2. Assume finally that formula_3 and formula_5 are freely independent. Then the free additive convolution formula_9 is the law of formula_10. Random matrices interpretation: if formula_11 and formula_12 are some independent formula_13 by formula_13 Hermitian (resp. real symmetric) random matrices such that at least one of them is invariant, in law, under conjugation by any unitary (resp. orthogonal) matrix and such that the empirical spectral measures of formula_11 and formula_12 tend respectively to formula_1 and formula_2 as formula_13 tends to infinity, then the empirical spectral measure of formula_20 tends to formula_9.\n\nIn many cases, it is possible to compute the probability measure formula_9 explicitly by using complex-analytic techniques and the R-transform of the measures formula_1 and formula_2.\n\nThe rectangular free additive convolution (with ratio formula_25) formula_26 has also been defined in the non commutative probability framework by Benaych-Georges and admits the following random matrices interpretation. For formula_27, for formula_11 and formula_12 are some independent formula_13 by formula_31 complex (resp. real) random matrices such that at least one of them is invariant, in law, under multiplication on the left and on the right by any unitary (resp. orthogonal) matrix and such that the empirical singular values distribution of formula_11 and formula_12 tend respectively to formula_1 and formula_2 as formula_13 and formula_31 tend to infinity in such a way that formula_38 tends to formula_25, then the empirical singular values distribution of formula_20 tends to formula_41.\n\nIn many cases, it is possible to compute the probability measure formula_41 explicitly by using complex-analytic techniques and the rectangular R-transform with ratio formula_25 of the measures formula_1 and formula_2.\n\nLet formula_1 and formula_2 be two probability measures on the interval formula_48, and assume that formula_3 is a random variable in a non commutative probability space with law formula_1 and formula_5 is a random variable in the same non commutative probability space with law formula_2. Assume finally that formula_3 and formula_5 are freely independent. Then the free multiplicative convolution formula_55 is the law of formula_56 (or, equivalently, the law of formula_57. Random matrices interpretation: if formula_11 and formula_12 are some independent formula_13 by formula_13 non negative Hermitian (resp. real symmetric) random matrices such that at least one of them is invariant, in law, under conjugation by any unitary (resp. orthogonal) matrix and such that the empirical spectral measures of formula_11 and formula_12 tend respectively to formula_1 and formula_2 as formula_13 tends to infinity, then the empirical spectral measure of formula_67 tends to formula_55.\n\nA similar definition can be made in the case of laws formula_69 supported on the unit circle formula_70, with an orthogonal or unitary random matrices interpretation.\n\nExplicit computations of multiplicative free convolution can be carried out using complex-analytic techniques and the S-transform.\n\n\nThrough its applications to random matrices, free convolution has some strong connections with other works on G-estimation of Girko.\n\nThe applications in wireless communications, finance and biology have provided a useful framework when the number of observations is of the same order as the dimensions of the system.\n\n\n"}
{"id": "6933049", "url": "https://en.wikipedia.org/wiki?curid=6933049", "title": "General frame", "text": "General frame\n\nIn logic, general frames (or simply frames) are Kripke frames with an additional structure, which are used to model modal and intermediate logics. The general frame semantics combines the main virtues of Kripke semantics and algebraic semantics: it shares the transparent geometrical insight of the former, and robust completeness of the latter.\n\nA modal general frame is a triple formula_1, where formula_2 is a Kripke frame (i.e., \"R\" is a binary relation on the set \"F\"), and \"V\" is a set of subsets of \"F\" which is closed under the following:\nThey are thus a special case of fields of sets with additional structure. The purpose of \"V\" is to restrict the allowed valuations in the frame: a model formula_5 based on the Kripke frame formula_2 is admissible in the general frame F, if\nThe closure conditions on \"V\" then ensure that formula_8 belongs to \"V\" for \"every\" formula \"A\" (not only a variable).\n\nA formula \"A\" is valid in F, if formula_9 for all admissible valuations formula_10, and all points formula_11. A normal modal logic \"L\" is valid in the frame F, if all axioms (or equivalently, all theorems) of \"L\" are valid in F. In this case we call F an \"L\"-frame.\n\nA Kripke frame formula_2 may be identified with a general frame in which all valuations are admissible: i.e., formula_13, where formula_14 denotes the power set of \"F\".\n\nIn full generality, general frames are hardly more than a fancy name for Kripke \"models\"; in particular, the correspondence of modal axioms to properties on the accessibility relation is lost. This can be remedied by imposing additional conditions on the set of admissible valuations.\n\nA frame formula_1 is called\nKripke frames are refined and atomic. However, infinite Kripke frames are never compact. Every finite differentiated or atomic frame is a Kripke frame.\n\nDescriptive frames are the most important class of frames because of the duality theory (see below). Refined frames are useful as a common generalization of descriptive and Kripke frames.\n\nEvery Kripke model formula_20 induces the general frame formula_21, where \"V\" is defined as\n\nThe fundamental truth-preserving operations of generated subframes, p-morphic images, and disjoint unions of Kripke frames have analogues on general frames. A frame formula_23 is a generated subframe of a frame formula_1, if the Kripke frame formula_25 is a generated subframe of the Kripke frame formula_2 (i.e., \"G\" is a subset of \"F\" closed upwards under \"R\", and \"S\" is the restriction of \"R\" to \"G\"), and\nA p-morphism (or bounded morphism) formula_28 is a function from \"F\" to \"G\" which is a p-morphism of the Kripke frames formula_2 and formula_25, and satisfies the additional constraint\nThe disjoint union of an indexed set of frames formula_33, formula_34, is the frame formula_1, where \"F\" is the disjoint union of formula_36, \"R\" is the union of formula_37, and\n\nThe refinement of a frame formula_1 is a refined frame formula_23 defined as follows. We consider the equivalence relation\nand let formula_42 be the set of equivalence classes of formula_43. Then we put\n\nUnlike Kripke frames, every normal modal logic \"L\" is complete with respect to a class of general frames. This is a consequence of the fact that \"L\" is complete with respect to a class of Kripke models formula_20: as \"L\" is closed under substitution, the general frame induced by formula_20 is an \"L\"-frame. Moreover, every logic \"L\" is complete with respect to a single \"descriptive\" frame. Indeed, \"L\" is complete with respect to its canonical model, and the general frame induced by the canonical model (called the canonical frame of \"L\") is descriptive.\n\nGeneral frames bear close connection to modal algebras. Let formula_1 be a general frame. The set \"V\" is closed under Boolean operations, therefore it is a subalgebra of the power set Boolean algebra formula_49. It also carries an additional unary operation, formula_3. The combined structure formula_51 is a modal algebra, which is called the dual algebra of F, and denoted by formula_52.\n\nIn the opposite direction, it is possible to construct the dual frame formula_53 to any modal algebra formula_54. The Boolean algebra formula_55 has a Stone space, whose underlying set \"F\" is the set of all ultrafilters of A. The set \"V\" of admissible valuations in formula_56 consists of the clopen subsets of \"F\", and the accessibility relation \"R\" is defined by\nfor all ultrafilters \"x\" and \"y\".\n\nA frame and its dual validate the same formulas, hence the general frame semantics and algebraic semantics are in a sense equivalent. The double dual formula_58 of any modal algebra is isomorphic to formula_59 itself. This is not true in general for double duals of frames, as the dual of every algebra is descriptive. In fact, a frame formula_60 is descriptive if and only if it is isomorphic to its double dual formula_61.\n\nIt is also possible to define duals of p-morphisms on one hand, and modal algebra homomorphisms on the other hand. In this way the operators formula_62 and formula_63 become a pair of contravariant functors between the category of general frames, and the category of modal algebras. These functors provide a duality (called Jónsson–Tarski duality after Bjarni Jónsson and Alfred Tarski) between the categories of descriptive frames, and modal algebras. This is a special case of a more general duality between complex algebras and fields of sets on relational structures.\n\nThe frame semantics for intuitionistic and intermediate logics can be developed in parallel to the semantics for modal logics. An intuitionistic general frame is a triple formula_64, where formula_65 is a partial order on \"F\", and \"V\" is a set of upper subsets (\"cones\") of \"F\" which contains the empty set, and is closed under\nValidity and other concepts are then introduced similarly to modal frames, with a few changes necessary to accommodate for the weaker closure properties of the set of admissible valuations. In particular, an intuitionistic frame formula_67 is called\nTight intuitionistic frames are automatically differentiated, hence refined.\n\nThe dual of an intuitionistic frame formula_67 is the Heyting algebra formula_72. The dual of a Heyting algebra formula_73 is the intuitionistic frame formula_74, where \"F\" is the set of all prime filters of A, the ordering formula_65 is inclusion, and \"V\" consists of all subsets of \"F\" of the form\nwhere formula_77. As in the modal case, formula_62 and formula_63 are a pair of contravariant functors, which make the category of Heyting algebras dually equivalent to the category of descriptive intuitionistic frames.\n\nIt is possible to construct intuitionistic general frames from transitive reflexive modal frames and vice versa, see modal companion.\n\n"}
{"id": "30875270", "url": "https://en.wikipedia.org/wiki?curid=30875270", "title": "Giovanni Girolamo Saccheri", "text": "Giovanni Girolamo Saccheri\n\nGiovanni Girolamo Saccheri (; 5 September 1667 – 25 October 1733) was an Italian Jesuit priest, scholastic philosopher, and mathematician.\n\nSaccheri was born in Sanremo. He entered the Jesuit order in 1685 and was ordained as a priest in 1694. He taught philosophy at the University of Turin from 1694 to 1697 and philosophy, theology and mathematics at the University of Pavia from 1697 until his death. He was a protégé of the mathematician Tommaso Ceva and published several works including \"Quaesita geometrica\" (1693), \"Logica demonstrativa\" (1697), and \"Neo-statica\" (1708).\n\nHe is primarily known today for his last publication, in 1733 shortly before his death. Now considered the second work in non-Euclidean geometry, \"Euclides ab omni naevo vindicatus\" (\"Euclid Freed of Every Flaw\") languished in obscurity until it was rediscovered by Eugenio Beltrami, in the mid-19th century.\n\nMany of Saccheri's ideas have a precedent in the 11th-century Persian polymath Omar Khayyám's \"Discussion of Difficulties in Euclid\" (\"Risâla fî sharh mâ ashkala min musâdarât Kitâb 'Uglîdis\"), a fact ignored in most Western sources until recently.\n\nIt is unclear whether Saccheri had access to that work in translation or he developed his ideas independently. The Saccheri quadrilateral is now sometimes referred to as the Khayyam-Saccheri quadrilateral.\n\nThe intent of Saccheri's work was ostensibly to establish the validity of Euclid by means of a \"reductio ad absurdum\" proof of any alternative to Euclid's parallel postulate. To do so, he assumed that the parallel postulate was false and attempted to derive a contradiction.\n\nSince Euclid's postulate is equivalent to the statement that the sum of the internal angles of a triangle is 180°, he considered both the hypothesis that the angles add up to more or less than 180°.\n\nThe first led to the conclusion that straight lines are finite, contradicting Euclid's second postulate. So Saccheri correctly rejected it. However, the principle is now accepted as the basis of elliptic geometry, where both the second and fifth postulates are rejected.\n\nThe second possibility turned out to be harder to refute. In fact he was unable to derive a logical contradiction and instead derived many non-intuitive results; for example that triangles have a maximum finite area and that there is an absolute unit of length. He finally concluded that: \"the hypothesis of the acute angle is absolutely false; because it is repugnant to the nature of straight lines\". Today, his results are theorems of hyperbolic geometry.\n\nThere is some minor argument on whether Saccheri really meant that, as he published his work in the final year of his life, came extremely close to discovering non-Euclidean geometry and was a logician. Some believe Saccheri concluded as he did only to avoid the criticism that might come from seemingly-illogical aspects of hyperbolic geometry.\n\n"}
{"id": "42960994", "url": "https://en.wikipedia.org/wiki?curid=42960994", "title": "Graph coloring game", "text": "Graph coloring game\n\nThe graph coloring game is a mathematical game related to graph theory. Coloring game problems arose as game-theoretic versions of well-known graph coloring problems. In a coloring game, two players use a given set of colors to construct a coloring of a graph, following specific rules depending on the game we consider. One player tries to successfully complete the coloring of the graph, when the other one tries to prevent him from achieving it.\n\nThe vertex coloring game was introduced in 1981 by Brams and rediscovered ten years after by Bodlaender. Its rules are as follows: \n\nThe game chromatic number of a graph formula_1, denoted by formula_2, is the minimum number of colors needed for Alice to win the vertex coloring game on formula_1. Trivially, for every graph formula_1, we have formula_5, where formula_6 is the chromatic number of formula_1 and formula_8 its maximum degree.\n\nAcyclic coloring. Every graph formula_1 with acyclic chromatic number formula_10 has formula_11.\n\nMarking game. For every graph formula_1, formula_13, where formula_14 is the game coloring number of formula_1. Almost every known upper bound for the game chromatic number of graphs are obtained from bounds on the game coloring number.\n\nCycle-restrictions on edges. If every edge of a graph formula_1 belongs to at most formula_17 cycles, then formula_18.\n\nFor a class formula_19 of graphs, we denote by formula_20 the smallest integer formula_10 such that every graph formula_1 of formula_19 has formula_24. In other words, formula_20 is the exact upper bound for the game chromatic number of graphs in this class. This value is known for several standard graph classes, and bounded for some others:\n\nCartesian products.\nThe game chromatic number of the cartesian product formula_38 is not bounded by a function of formula_2 and formula_40. In particular, the game chromatic number of any complete bipartite graph formula_41 is equal to 3, but there is no upper bound for formula_42 for arbitrary formula_43.\n\nThese questions are still open to this date.\n\nThe edge coloring game, introduced by Lam, Shiu and Zu, is similar to the vertex coloring game, except Alice and Bob construct a proper edge coloring instead of a proper vertex coloring. Its rules are as follows:\n\nAlthough this game can be considered as a particular case of the vertex coloring game on line graphs, it is mainly considered in the scientific literature as a distinct game. The game chromatic index of a graph formula_1, denoted by formula_63, is the minimum number of colors needed for Alice to win this game on formula_1.\n\nFor every graph \"G\", formula_65. There are graphs reaching these bounds but all the graphs we know reaching this upper bound have small maximum degree. \nThere exists graphs with formula_66 for arbitrary large values of formula_8.\n\nConjecture. \"There is an formula_68 such that, for any arbitrary graph formula_1, we have formula_70.\"\nThis conjecture is true when formula_8 is large enough compared to the number of vertices in formula_1.\n\n\nFor a class formula_19 of graphs, we denote by formula_79 the smallest integer formula_10 such that every graph formula_1 of formula_19 has formula_83. In other words, formula_79 is the exact upper bound for the game chromatic index of graphs in this class. This value is known for several standard graph classes, and bounded for some others:\n\nUpper bound. Is there a constant formula_94 such that formula_95 for each graph formula_1 ? If it is true, is formula_97 enough ?\n\nConjecture on large minimum degrees. \"There are a formula_68 and an integer formula_99 such that any graph formula_1 with formula_101 satisfies formula_102.\" \n\nThe incidence coloring game is a graph coloring game, introduced by Andres, and similar to the vertex coloring game, except Alice and Bob construct a proper incidence coloring instead of a proper vertex coloring. Its rules are as follows:\n\nThe incidence game chromatic number of a graph formula_1, denoted by formula_104, is the minimum number of colors needed for Alice to win this game on formula_1.\n\nFor every graph formula_1 with maximum degree formula_107, we have formula_108.\n\n\nFor a class formula_19 of graphs, we denote by formula_123 the smallest integer formula_10 such that every graph formula_1 of formula_19 has formula_127.\n\n\n"}
{"id": "32519861", "url": "https://en.wikipedia.org/wiki?curid=32519861", "title": "Hilbert's twenty-fourth problem", "text": "Hilbert's twenty-fourth problem\n\nHilbert's twenty-fourth problem is a mathematical problem that was not published as part of the list of 23 problems known as Hilbert's problems but was included in David Hilbert's original notes. The problem asks for a criterion of simplicity in mathematical proofs and the development of a proof theory with the power to prove that a given proof is the simplest possible.\n\nThe 24th problem was rediscovered by German historian in 2000, noting that Hilbert did not include the 24th problem in the lecture presenting Hilbert's problems or any published texts. Hilbert's friends and fellow mathematicians Adolf Hurwitz and Hermann Minkowski were closely involved in the project but did not have any knowledge of this problem.\n\nThis is the full text from Hilbert's notes given in Rüdiger Thiele's paper. The section was translated by Rüdiger Thiele.\n"}
{"id": "664001", "url": "https://en.wikipedia.org/wiki?curid=664001", "title": "Imagining Numbers", "text": "Imagining Numbers\n\nImagining Numbers: (particularly the square root of minus fifteen) is a 2003 book by mathematician Barry Mazur to show that mathematics in human society is durative by nature. The book was published by Farrar, Straus and Giroux.\n"}
{"id": "6466838", "url": "https://en.wikipedia.org/wiki?curid=6466838", "title": "Immanant", "text": "Immanant\n\nIn mathematics, the immanant of a matrix was defined by Dudley E. Littlewood and Archibald Read Richardson as a generalisation of the concepts of determinant and permanent.\n\nLet formula_1 be a partition of formula_2 and let formula_3 be the corresponding irreducible representation-theoretic character of the symmetric group formula_4. The \"immanant\" of an formula_5 matrix formula_6 associated with the character formula_3 is defined as the expression\n\nThe determinant is a special case of the immanant, where formula_3 is the alternating character formula_10, of \"S\", defined by the parity of a permutation.\n\nThe permanent is the case where formula_3 is the trivial character, which is identically equal to 1.\n\nFor example, for formula_12 matrices, there are three irreducible representations of formula_13, as shown in the character table:\n\nAs stated above, formula_14 produces the permanent and formula_15 produces the determinant, but formula_16 produces the operation that maps as follows:\n\nLittlewood and Richardson also studied its relation to Schur functions in the representation theory of the symmetric group.\n\n\n"}
{"id": "31316105", "url": "https://en.wikipedia.org/wiki?curid=31316105", "title": "Jan van Leeuwen", "text": "Jan van Leeuwen\n\nJan van Leeuwen (born December 17, 1946 in Waddinxveen) is a Dutch computer scientist and Emeritus professor of computer science at the Department of Information and Computing Sciences at Utrecht University.\n\nVan Leeuwen completed his undergraduate studies in mathematics at Utrecht University in 1967 and received a Ph.D. in mathematics in 1972 from the same institution under the supervision of Dirk van Dalen. After postdoctoral studies at the University of California, Berkeley and faculty positions at SUNY at Buffalo and the Pennsylvania State University, he returned to Utrecht as a faculty member in 1977. He was head of his department from 1977 to 1983, and again from 1991 to 1994, and dean from 1994 to 2009. Jan van Leeuwen was one of the founders of Informatics Europe.\n\nJan van Leeuwen contributed to many fields of theoretical computer science, notably to algorithm design and computational complexity theory, and to the philosophy of computing. Among his doctoral students are algorithms researcher and Utrecht faculty member Hans Bodlaender and notable game software developer and former fellow Utrecht faculty member, Mark Overmars. Van Leeuwen is well known as a former series editor of the Lecture Notes in Computer Science.\n\nVan Leeuwen is a member of the Royal Dutch Society of Sciences and Humanities since 1992, and in 2006 he was elected to the Academia Europaea. In 2008 he received an honorary doctorate from the RWTH Aachen. In 2013 he received the ACM Distinguished Service Award, together with Gerhard Goos and Juris Hartmanis.\n\nJan van Leeuwen was the editor of the 2-volume Handbook of Theoretical Computer Science. In 2013, he and S. Barry Cooper published (Elsevier, ), a special edition of the collected works of Alan Turing. This book won the R.R. Hawkins Award 2013.\n\nHis son, Erik Jan van Leeuwen, is also an academic computer scientist. He was a senior researcher at the Max-Planck-Institut für Informatik, and currently is an assistant professor and research scientist in the Department of Information and Computing Sciences at Utrecht University.\n\n"}
{"id": "50761879", "url": "https://en.wikipedia.org/wiki?curid=50761879", "title": "Link distance", "text": "Link distance\n\nIn computational geometry, the link distance between two points in a polygon is the minimum number of line segments of any polygonal chain within the polygon that has the two points as its endpoints. The link diameter of the polygon is the maximum link distance of any two of its points.\n\nA polygon is a convex polygon if and only if its link diameter is one.\nEvery star-shaped polygon has link diameter at most two: every two points may be connected by a polygonal chain that bends once, inside the kernel of the polygon. However, this property does not characterize star-shaped polygons, as there also exist polygons with holes in which the link diameter is two.\n"}
{"id": "35763181", "url": "https://en.wikipedia.org/wiki?curid=35763181", "title": "List of things named after Charles Hermite", "text": "List of things named after Charles Hermite\n\nNumerous things are named after the French mathematician Charles Hermite (1822–1901):\n\n\n\n\n\n"}
{"id": "88116", "url": "https://en.wikipedia.org/wiki?curid=88116", "title": "Lorenzo Mascheroni", "text": "Lorenzo Mascheroni\n\nLorenzo Mascheroni (May 13, 1750 – July 14, 1800) was an Italian mathematician.\n\nHe was born near Bergamo, Lombardy. At first mainly interested in the humanities (poetry and Greek language), he eventually became professor of mathematics at Pavia.\nIn his \"Geometria del Compasso\" (Pavia, 1797), he proved that any geometrical construction which can be done with compass and straightedge, can also be done with compasses alone. However, the priority for this result (now known as the Mohr–Mascheroni theorem) belongs to the Dane Georg Mohr, who had previously published a proof in 1672 in an obscure book, \"Euclides Danicus\". \nThis problem was the source of a musical composition called \"Mascheroni Circles\", performed by David Stutz on the album Iolet.\n\nIn his \"Adnotationes ad calculum integrale Euleri\" (1790) he published a calculation of what is now known as the Euler–Mascheroni constant, usually denoted as formula_1 (gamma).\n\nHe died in Paris.\n"}
{"id": "19662", "url": "https://en.wikipedia.org/wiki?curid=19662", "title": "Mean value theorem", "text": "Mean value theorem\n\nIn mathematics, the mean value theorem states, roughly, that for a given planar arc between two endpoints, there is at least one point at which the tangent to the arc is parallel to the secant through its endpoints.\n\nThis theorem is used to prove statements about a function on an interval starting from local hypotheses about derivatives at points of the interval.\n\nMore precisely, if formula_1 is a continuous function on the closed interval formula_2, and differentiable on the open interval formula_3, then there exists a point formula_4 in formula_3 such that:\n\nIt is one of the most important results in real analysis.\n\nA special case of this theorem was first described by Parameshvara (1370–1460), from the Kerala School of Astronomy and Mathematics in India, in his commentaries on Govindasvāmi and Bhāskara II. A restricted form of the theorem was proved by Michel Rolle in 1691; the result was what is now known as Rolle's theorem, and was proved only for polynomials, without the techniques of calculus. The mean value theorem in its modern form was stated and proved by Augustin Louis Cauchy in 1823.\n\nLet formula_7 be a continuous function on the closed interval formula_2 , and differentiable on the open interval formula_3, where <math>a . Then there exists some formula_4 in formula_3 such that\n\nThe mean value theorem is a generalization of Rolle's theorem, which assumes formula_13, so that the right-hand side above is zero.\n\nThe mean value theorem is still valid in a slightly more general setting. One only needs to assume that formula_7 is continuous on formula_2 , and that for every formula_16 in formula_3 the limit\n\nexists as a finite number or equals formula_19 or formula_20 . If finite, that limit equals formula_21 . An example where this version of the theorem applies is given by the real-valued cube root function mapping formula_22 , whose derivative tends to infinity at the origin.\n\nNote that the theorem, as stated, is false if a differentiable function is complex-valued instead of real-valued. For example, define formula_23 for all real formula_16 . Then\nwhile formula_26 for any real formula_16 .\n\nThese formal statements are also known as Lagrange's Mean Value Theorem.\n\nThe expression formula_28 gives the slope of the line joining the points formula_29 and formula_30 , which is a chord of the graph of formula_1 , while formula_21 gives the slope of the tangent to the curve at the point formula_33 . Thus the Mean value theorem says that given any chord of a smooth curve, we can find a point lying between the end-points of the chord such that the tangent at that point is parallel to the chord. The following proof illustrates this idea.\n\nDefine formula_34 , where formula_35 is a constant. Since formula_1 is continuous on formula_2 and differentiable on formula_3 , the same is true for formula_39 . We now want to choose formula_35 so that formula_39 satisfies the conditions of Rolle's theorem. Namely\n\nBy Rolle's theorem, since formula_39 is differentiable and formula_44 , there is some formula_4 in formula_3 for which formula_47 , and it follows from the equality formula_34 that,\n\nAssume that \"f\" is a continuous, real-valued function, defined on an arbitrary interval \"I\" of the real line. If the derivative of \"f\" at every interior point of the interval \"I\" exists and is zero, then \"f\" is constant in the interior.\n\nProof: Assume the derivative of \"f\" at every interior point of the interval \"I\" exists and is zero. Let (\"a\", \"b\") be an arbitrary open interval in \"I\". By the mean value theorem, there exists a point \"c\" in (\"a\",\"b\") such that\n\nThis implies that \"f\"(\"a\") = \"f\"(\"b\"). Thus, \"f\" is constant on the interior of \"I\" and thus is constant on \"I\" by continuity. (See below for a multivariable version of this result.)\n\nRemarks: \n\nCauchy's mean value theorem, also known as the extended mean value theorem, is a generalization of the mean value theorem. It states: If functions \"f\" and \"g\" are both continuous on the closed interval [\"a\", \"b\"], and differentiable on the open interval (\"a\", \"b\"), then there exists some \"c\" ∈ (\"a\", \"b\"), such that\n\nOf course, if and if , this is equivalent to:\n\nGeometrically, this means that there is some tangent to the graph of the curve\n\nwhich is parallel to the line defined by the points (\"f\"(\"a\"), \"g\"(\"a\")) and (\"f\"(\"b\"), \"g\"(\"b\")). However Cauchy's theorem does not claim the existence of such a tangent in all cases where (\"f\"(\"a\"), \"g\"(\"a\")) and (\"f\"(\"b\"), \"g\"(\"b\")) are distinct points, since it might be satisfied only for some value \"c\" with , in other words a value for which the mentioned curve is stationary; in such points no tangent to the curve is likely to be defined at all. An example of this situation is the curve given by\n\nwhich on the interval [−1, 1] goes from the point (−1, 0) to (1, 0), yet never has a horizontal tangent; however it has a stationary point (in fact a cusp) at .\n\nCauchy's mean value theorem can be used to prove l'Hôpital's rule. The mean value theorem is the special case of Cauchy's mean value theorem when .\n\nThe proof of Cauchy's mean value theorem is based on the same idea as the proof of the mean value theorem.\n\n\n\nAssume that formula_58 and formula_59 are differentiable functions on formula_3 that are continuous on formula_2. Define\n\nThere exists formula_63 such that formula_64.\n\nNotice that\nand if we place formula_66, we get Cauchy's mean value theorem. If we place formula_66 and formula_68 we get Lagrange's mean value theorem.\n\nThe proof of the generalization is quite simple: each of formula_69 and formula_70 are determinants with two identical rows, hence formula_71. The Rolle's theorem implies that there exists formula_72 such that formula_73.\n\nThe mean value theorem generalizes to real functions of multiple variables. The trick is to use parametrization to create a real function of one variable, and then apply the one-variable theorem.\n\nLet formula_74 be an open convex subset of formula_75 , and let formula_76 be a differentiable function. Fix points formula_77 , and define formula_78 . Since formula_39 is a differentiable function in one variable, the mean value theorem gives:\n\nfor some formula_4 between 0 and 1. But since formula_82 and formula_83 , computing formula_84 explicitly we have:\n\nwhere formula_86 denotes a gradient and formula_87 a dot product. Note that this is an exact analog of the theorem in one variable (in the case formula_88 this \"is\" the theorem in one variable). By the Cauchy–Schwarz inequality, the equation gives the estimate:\n\nIn particular, when the partial derivatives of formula_1 are bounded, formula_1 is Lipschitz continuous (and therefore uniformly continuous). Note that formula_1 is not assumed to be continuously differentiable or continuous on the closure of formula_74 . However, in order to use the chain rule to compute formula_94, we really do need to know that formula_1 is differentiable; the existence of the formula_96 and formula_97 partial derivatives is not sufficient by itself .\n\nAs an application of the above, we prove that formula_1 is constant if formula_74 is open and connected and every partial derivative of formula_1 is 0. Pick some point formula_101 , and let formula_102 . We want to show formula_103 for every formula_104 . For that, let formula_105 . Then \"E\" is closed and nonempty. It is open too: for every formula_106 ,\n\nfor every formula_108 in some neighborhood of formula_16 . (Here, it is crucial that formula_16 and formula_108 are sufficiently close to each other.) Since formula_74 is connected, we conclude formula_113 .\n\nThe above arguments are made in a coordinate-free manner; hence, they generalize to the case when formula_74 is a subset of a Banach space.\n\nThere is no exact analog of the mean value theorem for vector-valued functions.\n\nIn \"Principles of Mathematical Analysis,\" Rudin gives an inequality which can be applied to many of the same situations to which the mean value theorem is applicable in the one dimensional case:\n\nTheorem. \"For a continuous vector-valued function formula_115 differentiable on formula_3, there exists formula_117 such that formula_118.\"\n\nJean Dieudonné in his classic treatise \"Foundations of Modern Analysis\" discards the mean value theorem and replaces it by mean inequality as the proof is not constructive and one cannot find the mean value and in applications one only needs mean inequality. Serge Lang in \"Analysis I \"uses the mean value theorem, in integral form, as an instant reflex but this use requires the continuity of the derivative. If one uses the Henstock–Kurzweil integral one can have the mean value theorem in integral form without the additional assumption that derivative should be continuous as every derivative is Henstock–Kurzweil integrable. The problem is roughly speaking the following: If \"f\" : \"U\" → R is a differentiable function (where \"U\" ⊂ R is open) and if \"x\" + \"th\", \"x, h\" ∈ R, \"t\" ∈ [0, 1] is the line segment in question (lying inside \"U\"), then one can apply the above parametrization procedure to each of the component functions \"f\" (\"i\" = 1, ..., \"m\") of \"f\" (in the above notation set \"y\" = \"x\" + \"h\"). In doing so one finds points \"x\" + \"th\" on the line segment satisfying\n\nBut generally there will not be a \"single\" point \"x\" + \"t*h\" on the line segment satisfying\n\nfor all \"i\" \"simultaneously\". For example, define:\n\nThen formula_122, but formula_123 and formula_124 are never simultaneously zero as formula_16 ranges over formula_126.\n\nHowever a certain type of generalization of the mean value theorem to vector-valued functions is obtained as follows: Let \"f\" be a continuously differentiable real-valued function defined on an open interval \"I\", and let \"x\" as well as \"x\" + \"h\" be points of \"I\". The mean value theorem in one variable tells us that there exists some \"t*\" between 0 and 1 such that\n\nOn the other hand, we have, by the fundamental theorem of calculus followed by a change of variables,\n\nThus, the value \"f′\"(\"x\" + \"t*h\") at the particular point \"t*\" has been replaced by the mean value\n\nThis last version can be generalized to vector valued functions:\n\nProof. Let \"f\", ..., \"f\" denote the components of \"f\" and define:\n\nThen we have\n\nThe claim follows since \"Df\" is the matrix consisting of the components formula_133\n\nProof. Let \"u\" in R denote the value of the integral\nNow we have (using the Cauchy–Schwarz inequality):\nNow cancelling the norm of \"u\" from both ends gives us the desired inequality.\n\nProof. From Lemma 1 and 2 it follows that\n\nLet \"f\" : [\"a\", \"b\"] → R be a continuous function. Then there exists \"c\" in (\"a\", \"b\") such that\n\nSince the mean value of \"f\" on [\"a\", \"b\"] is defined as\n\nwe can interpret the conclusion as \"f\" achieves its mean value at some \"c\" in (\"a\", \"b\").\n\nIn general, if \"f\" : [\"a\", \"b\"] → R is continuous and \"g\" is an integrable function that does not change sign on [\"a\", \"b\"], then there exists \"c\" in (\"a\", \"b\") such that\n\nSuppose \"f\" : [\"a\", \"b\"] → R is continuous and \"g\" is a nonnegative integrable function on [\"a\", \"b\"]. By the extreme value theorem, there exists \"m\" and \"M\" such that for each \"x\" in [\"a\", \"b\"], formula_142 and formula_143. Since \"g\" is nonnegative,\n\nNow let\n\nIf formula_146, we're done since\n\nmeans\n\nso for any \"c\" in (\"a\", \"b\"),\n\nIf \"I\" ≠ 0, then\n\nBy the intermediate value theorem, \"f\" attains every value of the interval [\"m\", \"M\"], so for some \"c\" in [\"a\", \"b\"]\n\nthat is,\n\nFinally, if \"g\" is negative on [\"a\", \"b\"], then\n\nand we still get the same result as above.\n\nQED\n\nThere are various slightly different theorems called the second mean value theorem for definite integrals. A commonly found version is as follows:\n\nHere formula_155 stands for formula_156, the existence of which follows from the conditions. Note that it is essential that the interval (\"a\", \"b\"] contains \"b\". A variant not having this requirement is:\n\nIf the function formula_74 returns a multi-dimensional vector, then the MVT for integration is not true, even if the domain of formula_74 is also multi-dimensional.\n\nFor example, consider the following 2-dimensional function defined on an formula_160-dimensional cube:\n\nThen, by symmetry it is easy to see that the mean value of formula_74 over its domain is (0,0):\n\nHowever, there is no point in which formula_164, because formula_165 everywhere.\n\nLet \"X\" and \"Y\" be non-negative random variables such that E[\"X\"] < E[\"Y\"] < ∞ and formula_166 (i.e. \"X\" is smaller than \"Y\" in the usual stochastic order). Then there exists an absolutely continuous non-negative random variable \"Z\" having probability density function\n\nLet \"g\" be a measurable and differentiable function such that E[\"g\"(\"X\")], E[\"g\"(\"Y\")] < ∞, and let its derivative \"g′\" be measurable and Riemann-integrable on the interval [\"x\", \"y\"] for all \"y\" ≥ \"x\" ≥ 0. Then, E[\"g′\"(\"Z\")] is finite and\n\nAs noted above, the theorem does not hold for differentiable complex-valued functions. Instead, a generalization of the theorem is stated such:\n\nLet \"f\" : Ω → C be a holomorphic function on the open convex set Ω, and let \"a\" and \"b\" be distinct points in Ω. Then there exist points \"u\", \"v\" on \"L\" (the line segment from \"a\" to \"b\") such that\n\nWhere Re() is the Real part and Im() is the Imaginary part of a complex-valued function.\n\n\n"}
{"id": "387934", "url": "https://en.wikipedia.org/wiki?curid=387934", "title": "Metalogic", "text": "Metalogic\n\nMetalogic is the study of the metatheory of logic. Whereas \"logic\" studies how logical systems can be used to construct valid and sound arguments, metalogic studies the properties of logical systems. Logic concerns the truths that may be derived using a logical system; metalogic concerns the truths that may be derived \"about\" the languages and systems that are used to express truths.\n\nThe basic objects of metalogical study are formal languages, formal systems, and their interpretations. The study of interpretation of formal systems is the branch of mathematical logic that is known as model theory, and the study of deductive systems is the branch that is known as proof theory.\n\nA \"formal language\" is an organized set of symbols, the symbols of which precisely define it by shape and place. Such a language therefore can be defined without reference to the meanings of its expressions; it can exist before any interpretation is assigned to it—that is, before it has any meaning. First order logic is expressed in some formal language. A formal grammar determines which symbols and sets of symbols are formulas in a formal language.\n\nA formal language can be formally defined as a set \"A\" of strings (finite sequences) on a fixed alphabet α. Some authors, including Rudolf Carnap, define the language as the ordered pair <α, \"A\">. Carnap also requires that each element of α must occur in at least one string in \"A\".\n\n\"Formation rules\" (also called \"formal grammar\") are a precise description of the well-formed formulas of a formal language. They are synonymous with the set of strings over the alphabet of the formal language that constitute well formed formulas. However, it does not describe their semantics (i.e. what they mean).\n\nA \"formal system\" (also called a \"logical calculus\", or a \"logical system\") consists of a formal language together with a deductive apparatus (also called a \"deductive system\"). The deductive apparatus may consist of a set of transformation rules (also called \"inference rules\") or a set of axioms, or have both. A formal system is used to derive one expression from one or more other expressions.\n\nA \"formal system\" can be formally defined as an ordered triple <α,formula_1,formula_2d>, where formula_2d is the relation of direct derivability. This relation is understood in a comprehensive sense such that the primitive sentences of the formal system are taken as directly derivable from the empty set of sentences. Direct derivability is a relation between a sentence and a finite, possibly empty set of sentences. Axioms are so chosen that every first place member of formula_2d is a member of formula_1 and every second place member is a finite subset of formula_1.\n\nA \"formal system\" can also be defined with only the relation formula_2d. Thereby can be omitted formula_1 and α in the definitions of \"interpreted formal language\", and \"interpreted formal system\". However, this method can be more difficult to understand and use.\n\nA \"formal proof\" is a sequence of well-formed formulas of a formal language, the last of which is a theorem of a formal system. The theorem is a syntactic consequence of all the well formed formulae that precede it in the proof system. For a well formed formula to qualify as part of a proof, it must result from applying a rule of the deductive apparatus of some formal system to the previous well formed formulae in the proof sequence.\n\nAn \"interpretation\" of a formal system is the assignment of meanings to the symbols and truth-values to the sentences of the formal system. The study of interpretations is called Formal semantics. \"Giving an interpretation\" is synonymous with \"constructing a model\".\n\nIn metalogic, formal languages are sometimes called \"object languages\". The language used to make statements about an object language is called a \"metalanguage\". This distinction is a key difference between logic and metalogic. While logic deals with \"proofs in a formal system\", expressed in some formal language, metalogic deals with \"proofs about a formal system\" which are expressed in a metalanguage about some object language.\n\nIn metalogic, 'syntax' has to do with formal languages or formal systems without regard to any interpretation of them, whereas, 'semantics' has to do with interpretations of formal languages. The term 'syntactic' has a slightly wider scope than 'proof-theoretic', since it may be applied to properties of formal languages without any deductive systems, as well as to formal systems. 'Semantic' is synonymous with 'model-theoretic'.\n\nIn metalogic, the words 'use' and 'mention', in both their noun and verb forms, take on a technical sense in order to identify an important distinction. The \"use–mention distinction\" (sometimes referred to as the \"words-as-words distinction\") is the distinction between \"using\" a word (or phrase) and \"mentioning\" it. Usually it is indicated that an expression is being mentioned rather than used by enclosing it in quotation marks, printing it in italics, or setting the expression by itself on a line. The enclosing in quotes of an expression gives us the name of an expression, for example:\n\nThe \"type-token distinction\" is a distinction in metalogic, that separates an abstract concept from the objects which are particular instances of the concept. For example, the particular bicycle in your garage is a token of the type of thing known as \"The bicycle.\" Whereas, the bicycle in your garage is in a particular place at a particular time, that is not true of \"the bicycle\" as used in the sentence: \"\"The bicycle\" has become more popular recently.\" This distinction is used to clarify the meaning of symbols of formal languages.\n\nMetalogical questions have been asked since the time of Aristotle. However, it was only with the rise of formal languages in the late 19th and early 20th century that investigations into the foundations of logic began to flourish. In 1904, David Hilbert observed that in investigating the foundations of mathematics that logical notions are presupposed, and therefore a simultaneous account of metalogical and metamathematical principles was required. Today, metalogic and metamathematics are largely synonymous with each other, and both have been substantially subsumed by mathematical logic in academia. A possible alternate, less mathematical model may be found in the writings of Charles Sanders Peirce and other semioticians.\n\nResults in metalogic consist of such things as formal proofs demonstrating the consistency, completeness, and decidability of particular formal systems.\n\nMajor results in metalogic include:\n\n\n\n"}
{"id": "31991866", "url": "https://en.wikipedia.org/wiki?curid=31991866", "title": "Method of normals", "text": "Method of normals\n\nIn calculus, the method of normals was a technique invented by Descartes for finding normal and tangent lines to curves. It represented one of the earliest methods for constructing tangents to curves. The method hinges on the observation that the radius of a circle is always normal to the circle itself. With this in mind Descartes would construct a circle that was tangent to a given curve. He could then use the radius at the point of intersection to find the slope of a normal line, and from this one can easily find the slope of a tangent line. \n\nThis was discovered about the same time as Fermat's method of adequality. While Fermat's method had more in common with the infinitesimal techniques that were to be used later, Descartes' method was more influential in the early history of calculus. \n\nOne reason Descartes' method fell from favor was the algebraic complexity it involved. On the other hand this method can be used to rigorously define the derivative for a wide class of functions using neither infinitesimal nor limit techniques. It is also related to a completely general definition of differentiability given by Carathéodory .\n\n"}
{"id": "46919484", "url": "https://en.wikipedia.org/wiki?curid=46919484", "title": "Monoidal category action", "text": "Monoidal category action\n\nIn algebra, an action of a monoidal category \"S\" on a category \"X\" is a functor\nsuch that there are natural isomorphisms formula_2 and formula_3 and those natural isomorphism satisfy the coherence conditions analogous to those in \"S\". If there is such an action, \"S\" is said to act on \"X\".\n\nFor example, \"S\" acts on itself via the monoid operation ⊗.\n\n"}
{"id": "9402045", "url": "https://en.wikipedia.org/wiki?curid=9402045", "title": "Pinwheel tiling", "text": "Pinwheel tiling\n\nIn geometry, pinwheel tilings are non-periodic tilings defined by Charles Radin and based on a construction due to John Conway.\nThey are the first known non-periodic tilings to each have the property that their tiles appear in infinitely many orientations.\n\nLet formula_1 be the right triangle with side length formula_2, formula_3 and formula_4.\nConway noticed that formula_1 can be divided in five isometric copies of its image by the dilation of factor formula_6.\nBy suitably rescaling and translating/rotating, this operation can be iterated to obtain an infinite increasing sequence of growing triangles all made of isometric copies of formula_1.\nThe union of all these triangles yields a tiling of the whole plane by isometric copies of formula_1.\n\nIn this tiling, isometric copies of formula_1 appears in infinitely many orientations (this is due to the angles formula_10 and formula_11 of formula_1, both non-commensurable with formula_13).\nDespite this, all the vertices have rational coordinates.\n\nRadin relied on the above construction of Conway to define pinwheel tilings.\nFormally, the pinwheel tilings are the tilings whose tiles are isometric copies of formula_1, in which a tile may intersect another tile only either on a whole side or on half the length formula_3 side, and such that the following property holds.\nGiven any pinwheel tiling formula_16, there is a pinwheel tiling formula_17 which, once each tile is divided in five following the Conway construction and the result is dilated by a factor formula_4, is equal to formula_16.\nIn other words, the tiles of any pinwheel tilings can be grouped in sets of five into homothetic tiles, so that these homothetic tiles form (up to rescaling) a new pinwheel tiling.\n\nThe tiling constructed by Conway is a pinwheel tiling, but there are uncountably many other different pinwheel tiling.\nThey are all \"locally undistinguishable\" (\"i.e.\", they have the same finite patches).\nThey all share with the Conway tiling the property that tiles appear in infinitely many orientations (and vertices have rational coordinates).\n\nThe main result proven by Radin is that there is a finite (though very large) set of so-called prototiles, with each being obtained by coloring the sides of formula_1, so that the pinwheel tilings are exactly the tilings of the plane by isometric copies of these prototiles, with the condition that whenever two copies intersect in a point, they have the same color in this point.\nIn terms of symbolic dynamics, this means that the pinwheel tilings form a sofic subshift.\n\nRadin and Conway proposed a three-dimensional analogue which was dubbed the quaquaversal tiling. There are other variants and generalizations of the original idea.\nOne gets a fractal by iteratively dividing formula_1 in five isometrics copies, following the Conway construction, and discarding the middle triangle (\"ad infinitum\"). This \"pinwheel fractal\" has Hausdorff dimension formula_22.\n\nFederation Square, a building complex in Melbourne, Australia, features the pinwheel tiling. In the project, the tiling pattern is used to create the structural sub-framing for the facades, allowing for the facades to be fabricated off-site, in a factory and later erected to form the facades. The pinwheel tiling system was based on the single triangular element, composed of zinc, perforated zinc, sandstone or glass (known as a tile), which was joined to 4 other similar tiles on an aluminum frame, to form a \"panel\". Five panels were affixed to a galvanized steel frame, forming a \"mega-panel\", which were then hoisted onto support frames for the facade. The rotational positioning of the tiles gives the facades a more random, uncertain compositional quality, even though the process of its construction is based on pre-fabrication and repetition. The same pinwheel tiling system is used in the development of the structural frame and glazing for the \"Atrium\" at Federation Square, although in this instance, the pin-wheel grid has been made \"3-dimensional\" to form a portal frame structure.\n\n"}
{"id": "22085817", "url": "https://en.wikipedia.org/wiki?curid=22085817", "title": "Polyakov formula", "text": "Polyakov formula\n\nIn differential geometry and mathematical physics (especially string theory), the Polyakov formula expresses the conformal variation of the zeta functional determinant of a Riemannian manifold. The corresponding density is local, and therefore is a Riemannian curvature invariant. In particular, whereas the functional determinant itself is prohibitively difficult to work with in general, its conformal variation can be written down explicitly.\n"}
{"id": "16525393", "url": "https://en.wikipedia.org/wiki?curid=16525393", "title": "Polyhedral space", "text": "Polyhedral space\n\nPolyhedral space is a certain metric space. A (Euclidean) polyhedral space is a (usually finite) simplicial complex in which every simplex has a flat metric. (Other spaces of interest are spherical and hyperbolic polyhedral spaces, where every simplex has a metric of constant positive or negative curvature). In the sequel all polyhedral spaces are taken to be Euclidean polyhedral spaces.\n\nAll 1-dimensional polyhedral spaces are just metric graphs. A good source of 2-dimensional examples constitute triangulations of 2-dimensional surfaces. The surface of a convex polyhedron in formula_1 is a 2-dimensional polyhedral space.\n\nAny PL-manifold (which is essentially the same as a simplicial manifold, just with some technical assumptions for convenience) is an example of a polyhedral space. In fact, one can consider pseudomanifolds, although it makes more sense to restrict the attention to normal manifolds.\n\nIn the study of polyhedral spaces (particularly of those that are also topological manifolds) metric singularities play a central role. Let a polyhedral space be an n-dimensional manifold. If a point in a polyhedral space that is an n-dimensional topological manifold has no neighborhood isometric to a Euclidean neighborhood in R^n, this point is said to be a metric singularity. It is a singularity of codimension k, if it has a neighborhood isometric to R^{n-k} with a metric cone. Singularities of codimension 2 are of major importance; they are characterized by a single number, the conical angle.\n\nThe singularities can also studied topologically. Then, for example, there are no topological singularities of codimension 2. In a 3-dimensional polyhedral space without a boundary (faces not glued to other faces) any point has a neighborhood homeomorphic either to an open ball or to a cone over the projective plane. In the former case, the point is necessarily a codimension 3 metric singularity. The general problem of topologically classifying singularities in polyhedral spaces is largely unresolved (apart from simple statements that e.g. any singularity is locally a cone over a spherical polyhedral space one dimension less and we can study singularities there).\n\nIt is interesting to study the curvature of polyhedral spaces (the curvature in the sense of Alexandrov spaces), specifically polyhedral spaces of nonnegative and nonpositive curvature. Nonnegative curvature on singularities of codimension 2 implies nonnegative curvature overall. However, this is false for nonpositive curvature. For example, consider R^3 with one octant removed. Then on the edges of this octant (singularities of codimension 2) the curvature is nonpositive (because of branching geodesics), yet it is not the case at the origin (singularity of codimension 3), where a triangle such as (0,0,e), (0,e,0), (e,0,0) has a median longer than would be in the Euclidean plane, which is characteristic of nonnegative curvature.\n\nMany concepts of Riemannian geometry can be applied. There is only one obvious notion of parallel transport and only one natural connection. The concept of holonomy is strikingly simple in this case. The restricted holonomy group is trivial, and so there is a homomorphism from the fundamental group onto the holonomy group. It may be especially convenient to remove all singularities to obtain a space with a flat Riemannian metric and to study the holonomies there. One concepts thus arising are polyhedral Kähler manifolds, when the holonomies are contained in a group, conjugate to the unitary matrices. In this case, the holonomies also preserve a symplectic form, together with a complex structure on this polyhedral space (manifold) with the singularities removed. \nAll the concepts such as differential form, L2 differential form, etc. are adjusted accordingly.\n\nAnother direction of research are developments of dynamical billiards in polyhedral spaces, e.g. of nonpositive curvature (hyperbolic billiards). Positively curved polyhedral spaces arise also as links of points (typically metric singularities) in Euclidean polyhedral spaces.\n\nIn full generality, polyhedral spaces were first defined by Milka \n\n"}
{"id": "14617622", "url": "https://en.wikipedia.org/wiki?curid=14617622", "title": "Pugh's closing lemma", "text": "Pugh's closing lemma\n\nIn mathematics, Pugh's closing lemma is a result that links periodic orbit solutions of differential equations to chaotic behaviour. It can be formally stated as follows:\n\nPugh's closing lemma means, for example, that any chaotic set in a bounded continuous dynamical system corresponds to a periodic orbit in a different but closely related dynamical system. As such, an open set of conditions on a bounded continuous dynamical system that rules out periodic behaviour also implies that the system cannot behave chaotically; this is the basis of some autonomous convergence theorems.\n\n"}
{"id": "24971503", "url": "https://en.wikipedia.org/wiki?curid=24971503", "title": "Radical symbol", "text": "Radical symbol\n\nIn mathematics, the radical sign or radical symbol or root symbol is a symbol for the square root or higher-order root of a number. The square root of a number formula_1 is written as\nwhile the formula_3th root of formula_1 is written as\nIt is also used for other meanings in more advanced mathematics, such as the radical of an ideal.\n\nEach positive real number has two square roots, one positive and the other negative. The square root symbol refers to the principal square root, which is the positive one. The two square roots of a negative number are both imaginary numbers, and the square root symbol refers to the principal square root, the one with positive imaginary part. For the definition of the principal square root of other complex numbers, see Square root#Principal square root of a complex number.\n\nThe origin of the root symbol √ is largely speculative. Some sources imply that the symbol was first used by Arab mathematicians. One of those mathematicians was Abū al-Hasan ibn Alī al-Qalasādī (1421–1486). Legend has it that it was taken from the Arabic letter \"\" (\"ǧīm\", which is the first letter in the Arabic word \"\" (\"jadhir\", meaning \"root\"). However, many scholars, including Leonhard Euler, believe it originates from the letter \"r\", the first letter of the Latin word \"radix\" (meaning \"root\"), referring to the same mathematical operation.\n\nThe symbol was first seen in print without the vinculum (the horizontal \"bar\" over the numbers inside the radical symbol) in the year 1525 in \"Die Coss\" by Christoff Rudolff, a German mathematician. In 1637 Descartes was the first to unite the German radical sign √ with the vinculum to create the radical symbol in common use today.\n\nThe Unicode and HTML character codes for the radical symbols are:\n\nHowever, these characters differ in appearance from most mathematical typesetting\nby omitting the overline connected to the radical symbol, which surrounds the argument of the square root function.\n\nIn LaTeX the square root symbol may be generated by the codice_1 macro,\nand the square root symbol without the overline may be generated by the codice_2 macro.\n"}
{"id": "8278198", "url": "https://en.wikipedia.org/wiki?curid=8278198", "title": "Random neural network", "text": "Random neural network\n\nThe random neural network (RNN) is a mathematical representation of an interconnected network of neurons or cells which exchange spiking signals. It was invented by Erol Gelenbe and is linked to the G-network model of queueing networks as well as to Gene Regulatory Network models. Each cell state is represented by an integer whose value rises when the cell receives an excitatory spike and drops when it receives an inhibitory spike. The spikes can originate outside the network itself, or they can come from other cells in the networks. Cells whose internal excitatory state has a positive value are allowed to send out spikes of either kind to other cells in the network according to specific cell-dependent spiking rates. The model has a mathematical solution in steady-state which provides the joint probability distribution of the network in terms of the individual probabilities that each cell is excited and able to send out spikes. Computing this solution is based on solving a set of non-linear algebraic equations whose parameters are related to the spiking rates of individual cells and their connectivity to other cells, as well as the arrival rates of spikes from outside the network. The RNN is a recurrent model, i.e. a neural network that is allowed to have complex feedback loops.\n\nA highly energy-efficient implementation of random neural networks was demonstrated by Krishna Palem et al. using the Probabilistic CMOS or PCMOS technology and was shown to be c. 226–300 times more efficient in terms of Energy-Performance-Product.\n\nRNNs are also related to artificial neural networks, which (like the random neural network) have gradient-based learning algorithms. The learning algorithm for an n-node random neural network that includes feedback loops (it is also a recurrent neural network) is of computational complexity O(n^3) (the number of computations is proportional to the cube of n, the number of neurons). The random neural network can also be used with other learning algorithms such as reinforcement learning. The RNN has been shown to be a universal approximator for bounded and continuous functions.\n\n\n\n"}
{"id": "39402121", "url": "https://en.wikipedia.org/wiki?curid=39402121", "title": "SAMPL", "text": "SAMPL\n\nSAMPL, which stands for \"Stochastic AMPL\", is an algebraic modeling language resulting by expanding the well-known language AMPL with extended syntax and keywords. It is designed specifically for representing stochastic programming problems and, through recent extensions, problems with chance constraints, integrated chance constraints and robust optimization problems. \nIt can generate the deterministic equivalent version of the instances, using all the solvers AMPL connects to, or generate an SMPS representation and use specialized decomposition based solvers, like FortSP.\n\nSAMPL shares all language features with AMPL, and adds some constructs specifically designed for expressing scenario based stochastic programming and robust optimization.\n\nTo express scenario-based SP problems, additional constructs describe the tree structure and group the decision variable into stages. Moreover, it is possible to specify which parameter stores the probabilities for each branch of the tree and which set represents the scenario set. Other constructs to easily define chance constraints and integrated chance constraint in an SP problem are available as well.\nUsing these language constructs allows to retain the structure of the problem, hence making it available to the solvers, which might exploit it using specialized decomposition methods like Benders' decomposition to speed-up the solution.\n\nSAMPL supports constructs to describe three types of robust optimization formulations:\n\nSAMPL is currently available as a part of the software AMPLDev (distributed by www.optirisk-systems.com). It supports many popular 32- and 64-bit platforms including Windows, Linux and Mac OS X. A free evaluation version with limited functionality is available.\n\nThe following is the SAMPL version of a simple problem (Dakota), to show the SP related constructs. It does not include the data file, which follows the normal AMPL syntax (see the example provided in the AMPL Wikipedia page for further reference).\n\nSAMPL instance level format for SP problems is SMPS, and therefore the problem can be solved by any solver which supports that standard. One of such solvers (FortSP) is included in the standard SAMPL distribution. Regarding robust optimization problems, the needed solver depend on the specific formulation used, as Ben-Tal and Nemirovski formulation need a second-order cone capable solver.\n\n\n"}
{"id": "44516416", "url": "https://en.wikipedia.org/wiki?curid=44516416", "title": "Sacks property", "text": "Sacks property\n\nIn mathematical set theory, the Sacks property holds between two models of Zermelo–Fraenkel set theory if they are not \"too dissimilar\" in the following sense.\n\nFor formula_1 and formula_2 transitive models of set theory, formula_2 is said to have the Sacks property over formula_1 if and only if for every function formula_5 mapping formula_6 to formula_7 such that formula_8 diverges to infinity, and every function formula_9 mapping formula_6 to formula_6 there is a tree formula_12 such that for every formula_13 the formula_14 level of formula_15 has cardinality at most formula_16 and formula_17 is a branch of formula_15.\n\nThe Sacks property is used to control the value of certain cardinal invariants in forcing arguments. It is named for Gerald Enoch Sacks.\n\nA forcing notion is said to have the Sacks property if and only if the forcing extension has the Sacks property over the ground model. Examples include Sacks forcing and Silver forcing.\n\nShelah proved that when proper forcings with the Sacks property are iterated using countable supports, the resulting forcing notion will have the Sacks property as well.\n\nThe Sacks property is equivalent to the conjunction of the Laver property and the formula_19-bounding property.\n"}
{"id": "3596006", "url": "https://en.wikipedia.org/wiki?curid=3596006", "title": "Schoof's algorithm", "text": "Schoof's algorithm\n\nSchoof's algorithm is an efficient algorithm to count points on elliptic curves over finite fields. The algorithm has applications in elliptic curve cryptography where it is important to know the number of points to judge the difficulty of solving the discrete logarithm problem in the group of points on an elliptic curve.\n\nThe algorithm was published by René Schoof in 1985 and it was a theoretical breakthrough, as it was the first deterministic polynomial time algorithm for counting points on elliptic curves. Before Schoof's algorithm, approaches to counting points on elliptic curves such as the naive and baby-step giant-step algorithms were, for the most part, tedious and had an exponential running time.\nThis article explains Schoof's approach, laying emphasis on the mathematical ideas underlying the structure of the algorithm.\nLet formula_1 be an elliptic curve defined over the finite field formula_2, where formula_3 for formula_4 a prime and formula_5 an integer formula_6. Over a field of characteristic formula_7 an elliptic curve can be given by a (short) Weierstrass equation\nwith formula_9. The set of points defined over formula_2 consists of the solutions formula_11 satisfying the curve equation and a point at infinity formula_12. Using the group law on elliptic curves restricted to this set one can see that this set formula_13 forms an abelian group, with formula_12 acting as the zero element.\nIn order to count points on an elliptic curve, we compute the cardinality of formula_13.\nSchoof's approach to computing the cardinality formula_16 makes use of Hasse's theorem on elliptic curves along with the Chinese remainder theorem and division polynomials.\n\nHasse's theorem states that if formula_17 is an elliptic curve over the finite field formula_2, then formula_19 satisfies\n\nThis powerful result, given by Hasse in 1934, simplifies our problem by narrowing down formula_21 to a finite (albeit large) set of possibilities. Defining formula_22 to be formula_23, and making use of this result, we now have that computing the cardinality of formula_22 modulo formula_25 where formula_26, is sufficient for determining formula_22, and thus formula_21. While there is no efficient way to compute formula_29 directly for general formula_25, it is possible to compute formula_31 for formula_32 a small prime, rather efficiently. We choose formula_33 to be a set of distinct primes such that formula_34. Given formula_35 for all formula_36, the Chinese remainder theorem allows us to compute formula_29.\n\nIn order to compute formula_31 for a prime formula_39, we make use of the theory of the Frobenius endomorphism formula_40 and division polynomials. Note that considering primes formula_39 is no loss since we can always pick a bigger prime to take its place to ensure the product is big enough. In any case Schoof's algorithm is most frequently used in addressing the case formula_42 since there are more efficient, so called formula_4 adic algorithms for small-characteristic fields.\n\nGiven the elliptic curve formula_1 defined over formula_2 we consider points on formula_1 over formula_47, the algebraic closure of formula_2; i.e. we allow points with coordinates in formula_47. The Frobenius endomorphism of formula_47 over formula_51 extends to the elliptic curve by formula_52.\n\nThis map is the identity on formula_13 and one can extend it to the point at infinity formula_12, making it a group morphism from formula_55 to itself.\n\nThe Frobenius endomorphism satisfies a quadratic polynomial which is linked to the cardinality of formula_13 by the following theorem:\nTheorem: The Frobenius endomorphism given by formula_40 satisfies the characteristic equation\n\nThus we have for all formula_60 that formula_61, where + denotes addition on the elliptic curve and formula_62 and formula_63\ndenote scalar multiplication of formula_64 by formula_65 and of formula_66 by formula_22.\n\nOne could try to symbolically compute these points formula_68, formula_69 and formula_70 as functions in the coordinate ring formula_71 of formula_1\nand then search for a value of formula_22 which satisfies the equation. However, the degrees get very large and this approach is impractical.\n\nSchoof's idea was to carry out this computation restricted to points of order formula_32 for various small primes formula_32.\nFixing an odd prime formula_32, we now move on to solving the problem of determining formula_77, defined as formula_31, for a given prime formula_79. \nIf a point formula_80 is in the formula_32-torsion subgroup formula_82, then formula_83 where formula_84 is the unique integer such that formula_85 and formula_86. \nNote that formula_87 and that for any integer formula_88 we have formula_89. Thus formula_90 will have the same order as formula_91. Thus for formula_80 belonging to formula_93, we also have formula_94 if formula_95. Hence we have reduced our problem to solving the equation\n\nwhere formula_97 and formula_84 have integer values in formula_99.\n\nThe th division polynomial is such that its roots are precisely the coordinates of points of order . Thus, to restrict the computation of formula_100 to the -torsion points means computing these expressions as functions in the coordinate ring of \"and\" modulo the th division polynomial. I.e. we are working in formula_101. This means in particular that the degree of and defined via formula_102 is at most 1 in and at most formula_103\nin .\n\nThe scalar multiplication formula_104 can be done either by double-and-add methods or by using the formula_84th division polynomial. The latter approach gives:\n\nwhere formula_107 is the th division polynomial. Note that \nformula_108 is a function in only and denote it by formula_109.\n\nWe must split the problem into two cases: the case in which formula_110, and the case in which formula_111. Note that these equalities are checked modulo formula_112.\n\nBy using the addition formula for the group formula_13 we obtain:\n\nNote that this computation fails in case the assumption of inequality was wrong.\n\nWe are now able to use the -coordinate to narrow down the choice of formula_97 to two possibilities, namely the positive and negative case. Using the -coordinate one later determines which of the two cases holds.\n\nWe first show that is a function in alone. Consider formula_117.\nSince formula_118 is even, by replacing formula_119 by formula_120, we rewrite the expression as\n\nand have that\n\nHere, it seems not right, we throw away formula_123?\n\nNow if formula_124 for one formula_125 then formula_97 satisfies\n\nfor all -torsion points .\n\nAs mentioned earlier, using and formula_128 we are now able to determine which of the two values of formula_97 (formula_97 or formula_131) works. This gives the value of formula_132. Schoof's algorithm stores the values of formula_133 in a variable formula_134 for each prime considered.\n\nWe begin with the assumption that formula_136. Since is an odd prime it cannot be that formula_137 and thus formula_138. The characteristic equation yields that formula_139. And consequently that formula_140. \nThis implies that is a square modulo . Let formula_141. Compute formula_142 in formula_101 and check whether formula_144. If so, formula_77 is formula_146 depending on the y-coordinate. \nIf turns out not to be a square modulo or if the equation does not hold for any of and formula_147, our assumption that formula_148 is false, thus formula_149. The characteristic equation gives formula_150.\n\nIf you recall, our initial considerations omit the case of formula_151. \nSince we assume to be odd, formula_153 and in particular, formula_154 if and only if formula_13 has an element of order 2. By definition of addition in the group, any element of order 2 must be of the form formula_156. Thus formula_154 if and only if the polynomial formula_158 has a root in formula_2, if and only if formula_160.\n\n Input:\n\nMost of the computation is taken by the evaluation of formula_169 and formula_170, for each prime formula_32, that is computing formula_172, formula_173, formula_174, formula_175 for each prime formula_32. This involves exponentiation in the ring formula_177 and requires formula_178 multiplications. Since the degree of formula_112 is formula_180, each element in the ring is a polynomial of degree formula_181. By the prime number theorem, there are around formula_178 primes of size formula_178, giving that formula_32 is formula_178 and we obtain that formula_186. Thus each multiplication in the ring formula_187 requires formula_188 multiplications in formula_2 which in turn requires formula_190 bit operations. In total, the number of bit operations for each prime formula_32 is formula_192. Given that this computation needs to be carried out for each of the formula_178 primes, the total complexity of Schoof's algorithm turns out to be formula_194. Using fast polynomial and integer arithmetic reduces this to formula_195.\n\nIn the 1990s, Noam Elkies, followed by A. O. L. Atkin, devised improvements to Schoof's basic algorithm by restricting the set of primes formula_196 considered before to primes of a certain kind. These came to be called Elkies primes and Atkin primes respectively. A prime formula_32 is called an Elkies prime if the characteristic equation: formula_198 splits over formula_199, while an Atkin prime is a prime that is not an Elkies prime. Atkin showed how to combine information obtained from the Atkin primes with the information obtained from Elkies primes to produce an efficient algorithm, which came to be known as the Schoof–Elkies–Atkin algorithm. The first problem to address is to determine whether a given prime is Elkies or Atkin. In order to do so, we make use of modular polynomials, which come from the study of modular forms and an interpretation of elliptic curves over the complex numbers as lattices. Once we have determined which case we are in, instead of using division polynomials, we are able to work with a polynomial that has lower degree than the corresponding division polynomial: formula_200 rather than formula_181. For efficient implementation, probabilistic root-finding algorithms are used, which makes this a Las Vegas algorithm rather than a deterministic algorithm.\nUnder the heuristic assumption that approximately half of the primes up to an formula_178 bound are Elkies primes, this yields an algorithm that is more efficient than Schoof's, with an expected running time of formula_203 using naive arithmetic, and formula_204 using fast arithmetic. Although this heuristic assumption is known to hold for most elliptic curves, it is not known to hold in every case, even under the GRH.\n\nSeveral algorithms were implemented in C++ by Mike Scott and are available with source code. The implementations are free (no terms, no conditions), and make use of the MIRACL library which is distributed under the AGPLv3.\n\n\n"}
{"id": "286947", "url": "https://en.wikipedia.org/wiki?curid=286947", "title": "Self-organization", "text": "Self-organization\n\nSelf-organization, also called (in the social sciences) spontaneous order, is a process where some form of overall order arises from local interactions between parts of an initially disordered system. The process is spontaneous, not needing control by any external agent. It is often triggered by random fluctuations, amplified by positive feedback. The resulting organization is wholly decentralized, distributed over all the components of the system. As such, the organization is typically robust and able to survive or self-repair substantial perturbation. Chaos theory discusses self-organization in terms of islands of predictability in a sea of chaotic unpredictability.\n\nSelf-organization occurs in many physical, chemical, biological, robotic, and cognitive systems. Examples of self-organization include crystallization, thermal convection of fluids, chemical oscillation, animal swarming, neural circuits, and artificial neural networks.\n\nSelf-organization is realized in the physics of non-equilibrium processes, and in chemical reactions, where it is often described as self-assembly. The concept has proven useful in biology, from molecular to ecosystem level.\nCited examples of self-organizing behaviour also appear in the literature of many other disciplines, both in the natural sciences and in the social sciences such as economics or anthropology. Self-organization has also been observed in mathematical systems such as cellular automata. Self-organization is not to be confused with the related concept of emergence.\n\nSelf-organization relies on three basic ingredients:\n\nThe cybernetician William Ross Ashby formulated the original principle of self-organization in 1947. It states that any deterministic dynamic system automatically evolves towards a state of equilibrium that can be described in terms of an attractor in a basin of surrounding states. Once there, the further evolution of the system is constrained to remain in the attractor. This constraint implies a form of mutual dependency or coordination between its constituent components or subsystems. In Ashby's terms, each subsystem has adapted to the environment formed by all other subsystems.\n\nThe cybernetician Heinz von Foerster formulated the principle of \"order from noise\" in 1960. It notes that self-organization is facilitated by random perturbations (\"noise\") that let the system explore a variety of states in its state space. This increases the chance that the system will arrive into the basin of a \"strong\" or \"deep\" attractor, from which it then quickly enters the attractor itself. The biophysicist Henri Atlan developed this concept by proposing the principle of \"complexity from noise\" () first in the 1972 book \"L'organisation biologique et la théorie de l'information\" and then in the 1979 book \"Entre le cristal et la fumée\". The thermodynamicist Ilya Prigogine formulated a similar principle as \"order through fluctuations\" or \"order out of chaos\". It is applied in the method of simulated annealing for problem solving and machine learning.\n\nThe idea that the dynamics of a system can lead to an increase in its organization has a long history. The ancient atomists such as Democritus and Lucretius believed that a designing intelligence is unnecessary to create order in nature, arguing that given enough time and space and matter, order emerges by itself.\n\nThe philosopher René Descartes presents self-organization hypothetically in the fifth part of his 1637 \"Discourse on Method\". He elaborated on the idea in his unpublished work \"The World\".\n\nImmanuel Kant used the term \"self-organizing\" in his 1790 \"Critique of Judgment\", where he argued that teleology is a meaningful concept only if there exists such an entity whose parts or \"organs\" are simultaneously ends and means. Such a system of organs must be able to behave as if it has a mind of its own, that is, it is capable of governing itself.\n\nSadi Carnot (1796-1832) and Rudolf Clausius (1822-1888) discovered the second law of thermodynamics in the 19th century. It states that total entropy, sometimes understood as disorder, will always increase over time in an isolated system. This means that a system cannot spontaneously increase its order without an external relationship that decreases order elsewhere in the system (e.g. through consuming the low-entropy energy of a battery and diffusing high-entropy heat).\n\n18th-century thinkers had sought to understand the \"universal laws of form\" to explain the observed forms of living organisms. This idea became associated with Lamarckism and fell into disrepute until the early 20th century, when D'Arcy Wentworth Thompson (1860-1948) attempted to revive it.\n\nThe psychiatrist and engineer W. Ross Ashby introduced the term \"self-organizing\" to contemporary science in 1947. It was taken up by the cyberneticians Heinz von Foerster, Gordon Pask, Stafford Beer; and von Foerster organized a conference on \"The Principles of Self-Organization\" at the University of Illinois' Allerton Park in June, 1960 which led to a series of conferences on Self-Organizing Systems. Norbert Wiener took up the idea in the second edition of his \"Cybernetics: or Control and Communication in the Animal and the Machine\" (1961).\n\nSelf-organization was associated with general systems theory in the 1960s, but did not become commonplace in the scientific literature until physicists Hermann Haken et al. and complex systems researchers adopted it in a greater picture from cosmology Erich Jantsch, chemistry with dissipative system, biology and sociology as autopoiesis to system thinking in the following 1980s (Santa Fe Institute) and 1990s (complex adaptive system), until our days with the disruptive emerging technologies profounded by a rhizomatic network theory.\n\nThe many self-organizing phenomena in physics include phase transitions and spontaneous symmetry breaking such as spontaneous magnetization and crystal growth in classical physics, and the laser, superconductivity and Bose–Einstein condensation in quantum physics. It is found in self-organized criticality in dynamical systems, in tribology, in spin foam systems, and in loop quantum gravity, river basins and deltas, in dendritic solidification (snow flakes), and in turbulent structure .\n\nSelf-organization in chemistry includes molecular self-assembly, reaction-diffusion systems and oscillating reactions, autocatalytic networks, liquid crystals, grid complexes, colloidal crystals, self-assembled monolayers, micelles, microphase separation of block copolymers, and Langmuir-Blodgett films.\n\nSelf-organization in biology can be observed in spontaneous folding of proteins and other biomacromolecules, formation of lipid bilayer membranes, pattern formation and morphogenesis in developmental biology, the coordination of human movement, social behaviour in insects (bees, ants, termites), and mammals, flocking behaviour in birds and fish.\n\nThe mathematical biologist Stuart Kauffman and other structuralists have suggested that self-organization may play roles alongside natural selection in three areas of evolutionary biology, namely population dynamics, molecular evolution, and morphogenesis. However, this does not take into account the essential role of energy in driving biochemical reactions in cells. The systems of reactions in any cell are self-catalyzing but not simply self-organizing as they are thermodynamically open systems relying on a continuous input of energy. Self-organization is not an alternative to natural selection, but it constrains what evolution can do and provides mechanisms such as the self-assembly of membranes which evolution then exploits.\n\nPhenomena from mathematics and computer science such as cellular automata, random graphs, and some instances of evolutionary computation and artificial life exhibit features of self-organization. In swarm robotics, self-organization is used to produce emergent behavior. In particular the theory of random graphs has been used as a justification for self-organization as a general principle of complex systems. In the field of multi-agent systems, understanding how to engineer systems that are capable of presenting self-organized behavior is an active research area. Optimization algorithms can be considered self-organizing because they aim to find the optimal solution to a problem. If the solution is considered as a state of the iterative system, the optimal solution is the selected, converged structure of the system. Self-organizing networks include small-world networks and scale-free networks. These emerge from bottom-up interactions, unlike top-down hierarchical networks within organizations, which are not self-organizing. Cloud computing systems have been argued to be inherently self-organising, but while they have some autonomy, they are not self-managing as they do not have the goal of reducing their own complexity.\n\nNorbert Wiener regarded the automatic serial identification of a black box and its subsequent reproduction as self-organization in cybernetics. The importance of phase locking or the \"attraction of frequencies\", as he called it, is discussed in the 2nd edition of his \"\". K. Eric Drexler sees self-replication as a key step in nano and universal assembly. By contrast, the four concurrently connected galvanometers of W. Ross Ashby's Homeostat hunt, when perturbed, to converge on one of many possible stable states. Ashby used his state counting measure of variety to describe stable states and produced the \"Good Regulator\" theorem which requires internal models for self-organized endurance and stability (e.g. Nyquist stability criterion). Warren McCulloch proposed \"Redundancy of Potential Command\" as characteristic of the organization of the brain and human nervous system and the necessary condition for self-organization. Heinz von Foerster proposed Redundancy, \"R\"=1 − \"H\"/\"H\", where \"H\" is entropy. In essence this states that unused potential communication bandwidth is a measure of self-organization.\n\nIn the 1970s Stafford Beer considered self-organization necessary for autonomy in persisting and living systems. He applied his viable system model to management. It consists of five parts: the monitoring of performance of the survival processes (1), their management by recursive application of regulation (2), homeostatic operational control (3) and development (4) which produce maintenance of identity (5) under environmental perturbation. Focus is prioritized by an alerting \"algedonic loop\" feedback: a sensitivity to both pain and pleasure produced from under-performance or over-performance relative to a standard capability.\n\nIn the 1990s Gordon Pask argued that von Foerster's H and Hmax were not independent, but interacted via countably infinite recursive concurrent spin processes which he called concepts. His strict definition of concept \"a procedure to bring about a relation\" permitted his theorem \"Like concepts repel, unlike concepts attract\" to state a general spin-based principle of self-organization. His edict, an exclusion principle, \"There are No Doppelgangers\" means no two concepts can be the same. After sufficient time, all concepts attract and coalesce as pink noise. The theory applies to all organizationally closed or homeostatic processes that produce enduring and coherent products which evolve, learn and adapt.\n\nThe self-organizing behaviour of social animals and the self-organization of simple mathematical structures both suggest that self-organization should be expected in human society. Tell-tale signs of self-organization are usually statistical properties shared with self-organizing physical systems. Examples such as critical mass, herd behaviour, groupthink and others, abound in sociology, economics, behavioral finance and anthropology.\n\nIn social theory, the concept of self-referentiality has been introduced as a sociological application of self-organization theory by Niklas Luhmann (1984). For Luhmann the elements of a social system are self-producing communications, i.e. a communication produces further communications and hence a social system can reproduce itself as long as there is dynamic communication. For Luhmann human beings are sensors in the environment of the system. Luhmann developed an evolutionary theory of Society and its subsystems, using functional \"analyses\" and systems \"theory\".\n\nIn economics, a market economy is sometimes said to be self-organizing. Paul Krugman has written on the role that market self-organization plays in the business cycle in his book \"The Self Organizing Economy\". Friedrich Hayek coined the term \"catallaxy\" to describe a \"self-organizing system of voluntary co-operation\", in regards to the spontaneous order of the free market economy. Neo-classical economists hold that imposing central planning usually makes the self-organized economic system less efficient. On the other end of the spectrum, economists consider that market failures are so significant that self-organization produces bad results and that the state should direct production and pricing. Most economists adopt an intermediate position and recommend a mixture of market economy and command economy characteristics (sometimes called a mixed economy). When applied to economics, the concept of self-organization can quickly become ideologically imbued.\n\nEnabling others to \"learn how to learn\" is often taken to mean instructing them how to submit to being taught. Self-organised learning (S.O.L.) denies that \"the expert knows best\" or that there is ever \"the one best method\", insisting instead on \"the construction of personally significant, relevant and viable meaning\" to be tested experientially by the learner. This may be collaborative, and more rewarding personally. It is seen as a lifelong process, not limited to specific learning environments (home, school, university) or under the control of authorities such as parents and professors. It needs to be tested, and intermittently revised, through the personal experience of the learner. It need not be restricted by either consciousness or language. Fritjof Capra argued that it is poorly recognised within psychology and education. It may be related to cybernetics as it involves a negative feedback control loop, or to systems theory. It can be conducted as a learning conversation or dialogue between learners or within one person.\n\nThe self-organizing behavior of drivers in traffic flow determines almost all the spatiotemporal behavior of traffic, such as traffic breakdown at a highway bottleneck, highway capacity, and the emergence of moving traffic jams. In 1996–2002 these complex self-organizing effects were explained by Boris Kerner's three-phase traffic theory.\n\nOrder appears spontaneously in the evolution of language as individual and population behaviour interacts with biological evolution.\n\nHeinz Pagels, in a 1985 review of Ilya Prigogine and Isabelle Stengers's book \"Order Out of Chaos\" in \"Physics Today\", appeals to authority:\n\nIn theology, Thomas Aquinas (1225–1274) in his \"Summa Theologica\" assumes a teleological created universe in rejecting the idea that something can be a self-sufficient cause of its own organization:\n\n\n"}
{"id": "26534180", "url": "https://en.wikipedia.org/wiki?curid=26534180", "title": "Sperner property of a partially ordered set", "text": "Sperner property of a partially ordered set\n\nIn order-theoretic mathematics, a graded partially ordered set is said to have the Sperner property (and hence is called a Sperner poset), if no antichain within it is larger than the largest rank level (one of the sets of elements of the same rank) in the poset. Since every rank level is itself an antichain, the Sperner property is equivalently the property that some rank level is a maximum antichain. The Sperner property and Sperner posets are named after Emanuel Sperner, who proved Sperner's theorem stating that the family of all subsets of a finite set (partially ordered by set inclusion) has this property. The lattice of partitions of a finite set typically lacks the Sperner property.\n\nA \"k\"-Sperner poset is a graded poset in which no union of \"k\" antichains is larger than the union of the \"k\" largest rank levels, or, equivalently, the poset has a maximum k-family consisting of \"k\" rank levels. \n\nA strict Sperner poset is a graded poset in which all maximum antichains are rank levels.\n\nA strongly Sperner poset is a graded poset which is \"k-Sperner\" for all values of 'k\" up to the largest rank value.\n"}
{"id": "1392495", "url": "https://en.wikipedia.org/wiki?curid=1392495", "title": "Stiefel manifold", "text": "Stiefel manifold\n\nIn mathematics, the Stiefel manifold formula_1 is the set of all orthonormal \"k\"-frames in formula_2 That is, it is the set of ordered \"k\"-tuples of orthonormal vectors in formula_2 It is named after Swiss mathematician Eduard Stiefel. Likewise one can define the complex Stiefel manifold formula_4 of orthonormal \"k\"-frames in formula_5 and the quaternionic Stiefel manifold formula_6 of orthonormal \"k\"-frames in formula_7 More generally, the construction applies to any real, complex, or quaternionic inner product space.\n\nIn some contexts, a non-compact Stiefel manifold is defined as the set of all linearly independent \"k\"-frames in formula_8 or formula_9 this is homotopy equivalent, as the compact Stiefel manifold is a deformation retract of the non-compact one, by Gram–Schmidt. Statements about the non-compact form correspond to those for the compact form, replacing the orthogonal group (or unitary or symplectic group) with the general linear group.\n\nLet formula_10 stand for formula_11 or formula_12 The Stiefel manifold formula_13 can be thought of as a set of \"n\" × \"k\" matrices by writing a \"k\"-frame as a matrix of \"k\" column vectors in formula_14 The orthonormality condition is expressed by \"A\"*\"A\" = formula_15 where \"A\"* denotes the conjugate transpose of \"A\" and formula_16 denotes the \"k\" × \"k\" identity matrix. We then have\n\nThe topology on formula_13 is the subspace topology inherited from formula_19 With this topology formula_13 is a compact manifold whose dimension is given by\n\nEach of the Stiefel manifolds formula_13 can be viewed as a homogeneous space for the action of a classical group in a natural manner.\n\nEvery orthogonal transformation of a \"k\"-frame in formula_23 results in another \"k\"-frame, and any two \"k\"-frames are related by some orthogonal transformation. In other words, the orthogonal group O(\"n\") acts transitively on formula_24 The stabilizer subgroup of a given frame is the subgroup isomorphic to O(\"n\"−\"k\") which acts nontrivially on the orthogonal complement of the space spanned by that frame.\n\nLikewise the unitary group U(\"n\") acts transitively on formula_4 with stabilizer subgroup U(\"n\"−\"k\") and the symplectic group Sp(\"n\") acts transitively on formula_6 with stabilizer subgroup Sp(\"n\"−\"k\").\n\nIn each case formula_13 can be viewed as a homogeneous space:\n\nWhen \"k\" = \"n\", the corresponding action is free so that the Stiefel manifold formula_29 is a principal homogeneous space for the corresponding classical group.\n\nWhen \"k\" is strictly less than \"n\" then the special orthogonal group SO(\"n\") also acts transitively on formula_1 with stabilizer subgroup isomorphic to SO(\"n\"−\"k\") so that\n\nThe same holds for the action of the special unitary group on formula_4\n\nThus for \"k\" = \"n\" − 1, the Stiefel manifold is a principal homogeneous space for the corresponding \"special\" classical group.\n\nThe Stiefel manifold can be equipped with a uniform measure, i.e. a Borel measure that is invariant under the action of the groups noted above. For example, formula_34 which is isomorphic to the unit circle in the Euclidean plane, has as its uniform measure the obvious uniform measure (arc length) on the circle. It is straightforward to sample this measure on formula_13 using Gaussian random matrices: if formula_36 is a random matrix with independent entries identically distributed according to the standard normal distribution on formula_10 and \"A\" = \"QR\" is the QR factorization of \"A\", then the matrices, formula_38 are independent random variables and \"Q\" is distributed according to the uniform measure on formula_39 This result is a consequence of the Bartlett decomposition theorem.\n\nA 1-frame in formula_40 is nothing but a unit vector, so the Stiefel manifold formula_41 is just the unit sphere in formula_42 Therefore:\n\nGiven a 2-frame in formula_44 let the first vector define a point in \"S\" and the second a unit tangent vector to the sphere at that point. In this way, the Stiefel manifold formula_45 may be identified with the unit tangent bundle \n\nWhen \"k\" = \"n\" or \"n\"−1 we saw in the previous section that formula_46 is a principal homogeneous space, and therefore diffeomorphic to the corresponding classical group:\n\nGiven an orthogonal inclusion between vector spaces formula_49 the image of a set of \"k\" orthonormal vectors is orthonormal, so there is an induced closed inclusion of Stiefel manifolds, formula_50 and this is functorial. More subtly, given an \"n\"-dimensional vector space \"X\", the dual basis construction gives a bijection between bases for \"X\" and bases for the dual space formula_51 which is continuous, and thus yields a homeomorphism of top Stiefel manifolds formula_52 This is also functorial for isomorphisms of vector spaces.\n\nThere is a natural projection\n\nfrom the Stiefel manifold formula_13 to the Grassmannian of \"k\"-planes in formula_40 which sends a \"k\"-frame to the subspace spanned by that frame. The fiber over a given point \"P\" in formula_56 is the set of all orthonormal \"k\"-frames contained in the space \"P\".\n\nThis projection has the structure of a principal \"G\"-bundle where \"G\" is the associated classical group of degree \"k\". Take the real case for concreteness. There is a natural right action of O(\"k\") on formula_1 which rotates a \"k\"-frame in the space it spans. This action is free but not transitive. The orbits of this action are precisely the orthonormal \"k\"-frames spanning a given \"k\"-dimensional subspace; that is, they are the fibers of the map \"p\". Similar arguments hold in the complex and quaternionic cases.\n\nWe then have a sequence of principal bundles:\n\nThe vector bundles associated to these principal bundles via the natural action of \"G\" on formula_59 are just the tautological bundles over the Grassmannians. In other words, the Stiefel manifold formula_13 is the orthogonal, unitary, or symplectic frame bundle associated to the tautological bundle on a Grassmannian.\n\nWhen one passes to the formula_61 limit, these bundles become the universal bundles for the classical groups.\n\nThe Stiefel manifolds fit into a family of fibrations: \n\nthus the first non-trivial homotopy group of the space formula_1 is in dimension \"n\" − \"k\". Moreover, \n\nThis result is used in the obstruction-theoretic definition of Stiefel–Whitney classes.\n\n\n"}
{"id": "29040", "url": "https://en.wikipedia.org/wiki?curid=29040", "title": "Stokes' theorem", "text": "Stokes' theorem\n\nIn vector calculus, and more generally differential geometry, Stokes' theorem (also called the generalized Stokes theorem or the Stokes–Cartan theorem) is a statement about the integration of differential forms on manifolds, which both simplifies and generalizes several theorems from vector calculus. Stokes' theorem says that the integral of a differential form over the boundary of some orientable manifold is equal to the integral of its exterior derivative over the whole of , i.e.,\n\nStokes' theorem was formulated in its modern form by Élie Cartan in 1945, following earlier work on the generalization of the theorems of vector calculus by Vito Volterra, Édouard Goursat, and Henri Poincaré.\n\nThis modern form of Stokes' theorem is a vast generalization of a classical result that Lord Kelvin communicated to George Stokes in a letter dated July 2, 1850. Stokes set the theorem as a question on the 1854 Smith's Prize exam, which led to the result bearing his name. It was first published by Hermann Hankel in 1861. This classical Kelvin–Stokes theorem relates the surface integral of the curl of a vector field over a surface in Euclidean three-space to the line integral of the vector field over its boundary: Let be a piecewise smooth Jordan plane curve. The Jordan curve theorem implies that divides into two components, a compact one and another that is non-compact. Let denote the compact part that is bounded by and suppose is smooth, with . If is the space curve defined by and is a smooth vector field on , then:\n\nThis classical statement, along with the classical divergence theorem, the fundamental theorem of calculus, and Green's theorem are simply special cases of the general formulation stated above.\n\nThe fundamental theorem of calculus states that the integral of a function over the interval can be calculated by finding an antiderivative of :\n\nStokes' theorem is a vast generalization of this theorem in the following sense. \nIn even simpler terms, one can consider the points as boundaries of curves, that is as 0-dimensional boundaries of 1-dimensional manifolds. So, just as one can find the value of an integral () over a 1-dimensional manifold () by considering the anti-derivative () at the 0-dimensional boundaries (), one can generalize the fundamental theorem of calculus, with a few additional caveats, to deal with the value of integrals () over -dimensional manifolds () by considering the antiderivative () at the -dimensional boundaries () of the manifold.\n\nSo the fundamental theorem reads:\n\nLet be an oriented smooth manifold with boundary of dimension and let be a smooth -differential form that is compactly supported on . First, suppose that is compactly supported in the domain of a single, oriented coordinate chart . In this case, we define the integral of over as\n\ni.e., via the pullback of to .\n\nMore generally, the integral of over is defined as follows: Let be a partition of unity associated with a locally finite cover of (consistently oriented) coordinate charts, then define the integral\n\nwhere each term in the sum is evaluated by pulling back to as described above. This quantity is well-defined; that is, it does not depend on the choice of the coordinate charts, nor the partition of unity.\n\nThe generalized Stokes theorem reads:\n\nConventionally, formula_7 is abbreviated as formula_8, since the pullback of a differential form by the inclusion map is simply its restriction to its domain: formula_9. Here formula_10 is the exterior derivative, which is defined using the manifold structure only. The right-hand side is sometimes written as formula_11 to stress the fact that the formula_12-manifold formula_13 has no boundary. (This fact is also an implication of Stokes' theorem, since for a given smooth formula_14-dimensional manifold formula_15, application of the theorem twice gives formula_16 for any formula_17-form formula_18, which implies that formula_19.) The right-hand side of the equation is often used to formulate \"integral\" laws; the left-hand side then leads to equivalent \"differential\" formulations (see below).\n\nThe theorem is often used in situations where formula_15 is an embedded oriented submanifold of some bigger manifold, often formula_21, on which the form formula_18 is defined.\n\nLet be a smooth manifold. A (smooth) singular -simplex in is defined as a smooth map from the standard simplex in to . The group of singular -chains on is defined to be the free abelian group on the set of singular -simplices in . These groups, together with the boundary map, , define a chain complex. The corresponding homology (resp. cohomology) group is isomorphic to the usual singular homology group (resp. the singular cohomology group ), defined using continuous rather than smooth simplices in .\n\nOn the other hand, the differential forms, with exterior derivative, , as the connecting map, form a cochain complex, which defines the de Rham cohomology groups .\n\nDifferential -forms can be integrated over a -simplex in a natural way, by pulling back to . Extending by linearity allows one to integrate over chains. This gives a linear map from the space of -forms to the th group of singular cochains, , the linear functionals on . In other words, a -form defines a functional\n\non the -chains. Stokes' theorem says that this is a chain map from de Rham cohomology to singular cohomology with real coefficients; the exterior derivative, , behaves like the \"dual\" of on forms. This gives a homomorphism from de Rham cohomology to singular cohomology. On the level of forms, this means:\n\n\nDe Rham's theorem shows that this homomorphism is in fact an isomorphism. So the converse to 1 and 2 above hold true. In other words, if are cycles generating the th homology group, then for any corresponding real numbers, , there exist a closed form, , such that\n\nand this form is unique up to exact forms.\n\nStokes' theorem on smooth manifolds can be derived from Stokes' theorem for chains in smooth manifolds, and vice versa. Formally stated, the latter reads:\n\nTo simplify these topological arguments, it is worthwhile to examine the underlying principle by considering an example for dimensions. The essential idea can be understood by the diagram on the left, which shows that, in an oriented tiling of a manifold, the interior paths are traversed in opposite directions; their contributions to the path integral thus cancel each other pairwise. As a consequence, only the contribution from the boundary remains. It thus suffices to prove Stokes' theorem for sufficiently fine tilings (or, equivalently, simplices), which usually is not difficult.\n\nThe formulation above, in which is a smooth manifold with boundary, does not suffice in many applications. For example, if the domain of integration is defined as the plane region between two -coordinates and the graphs of two functions, it will often happen that the domain has corners. In such a case, the corner points mean that is not a smooth manifold with boundary, and so the statement of Stokes' theorem given above does not apply. Nevertheless, it is possible to check that the conclusion of Stokes' theorem is still true. This is because and its boundary are well-behaved away from a small set of points (a measure zero set).\n\nA version of Stokes' theorem that extends to rough domains was proved by Whitney. Assume that is a connected bounded open subset of . Call a \"standard domain\" if it satisfies the following property: There exists a subset of , open in , whose complement in has Hausdorff -measure zero; and such that every point of has a \"generalized normal vector\". This is a vector such that, if a coordinate system is chosen so that is the first basis vector, then, in an open neighborhood around , there exists a smooth function such that is the graph and is the region . Whitney remarks that the boundary of a standard domain is the union of a set of zero Hausdorff -measure and a finite or countable union of smooth -manifolds, each of which has the domain on only one side. He then proves that if is a standard domain in , is an -form which is defined, continuous, and bounded on , smooth on , integrable on , and such that is integrable on , then Stokes' theorem holds, that is,\n\nThe study of measure-theoretic properties of rough sets leads to geometric measure theory. Even more general versions of Stokes' theorem have been proved by Federer and by Harrison.\n\nThe general form of the Stokes theorem using differential forms is more powerful and easier to use than the special cases. The traditional versions can be formulated using Cartesian coordinates without the machinery of differential geometry, and thus are more accessible. Further, they are older and their names are more familiar as a result. The traditional forms are often considered more convenient by practicing scientists and engineers but the non-naturalness of the traditional formulation becomes apparent when using other coordinate systems, even familiar ones like spherical or cylindrical coordinates. There is potential for confusion in the way names are applied, and the use of dual formulations.\n\nThis is a (dualized) (1 + 1)-dimensional case, for a 1-form (dualized because it is a statement about vector fields). This special case is often just referred to as \"Stokes' theorem\" in many introductory university vector calculus courses and is used in physics and engineering. It is also sometimes known as the curl theorem.\n\nThe classical Kelvin–Stokes theorem relates the surface integral of the curl of a vector field over a surface in Euclidean three-space to the line integral of the vector field over its boundary. It is a special case of the general Stokes theorem (with ) once we identify a vector field with a 1-form using the metric on Euclidean 3-space. The curve of the line integral, , must have positive orientation, meaning that points counterclockwise when the surface normal, , points toward the viewer.\n\nOne consequence of the Kelvin–Stokes theorem is that the field lines of a vector field with zero curl cannot be closed contours. The formula can be rewritten as:\n\nGreen's theorem is immediately recognizable as the third integrand of both sides in the integral in terms of , , and cited above.\n\nTwo of the four Maxwell equations involve curls of 3-D vector fields and their differential and integral forms are related by the Kelvin–Stokes theorem. Caution must be taken to avoid cases with moving boundaries: the partial time derivatives are intended to exclude such cases. If moving boundaries are included, interchange of integration and differentiation introduces terms related to boundary motion not included in the results below (see Differentiation under the integral sign):\nThe above listed subset of Maxwell's equations are valid for electromagnetic fields expressed in SI units. In other systems of units, such as CGS or Gaussian units, the scaling factors for the terms differ. For example, in Gaussian units, Faraday's law of induction and Ampère's law take the forms:\n\nrespectively, where is the speed of light in vacuum.\n\nLikewise, the Ostrogradsky–Gauss theorem (also known as the divergence theorem or Gauss's theorem)\n\nis a special case if we identify a vector field with the -form obtained by contracting the vector field with the Euclidean volume form. An application of this is the case where is an arbitrary constant vector. Working out the divergence of the product gives\nSince this holds for all we find\n\n\n\n"}
{"id": "40807599", "url": "https://en.wikipedia.org/wiki?curid=40807599", "title": "Susanne Brenner", "text": "Susanne Brenner\n\nSusanne Cecelia Brenner is an American mathematician, whose research concerns the finite element method and related techniques for the numerical solution of differential equations. She held the Michael F. and Roberta Nesbit McDonald Professorship at Louisiana State University, where she is now the Nicholson Professor of Mathematics, and she chairs the editorial committee of the journal \"Mathematics of Computation\".\n\nBrenner did her undergraduate studies in mathematics at Stony Brook University, graduating in 1982. She obtained her Ph.D. from the University of Michigan in 1988 under the joint supervision of Jeffrey Rauch and L. Ridgway Scott; her thesis was entitled \"Multigrid Methods for Nonconforming Finite Elements\". She held faculty positions at Clarkson University and the University of South Carolina before moving to LSU in 2006. With L. R. Scott, she is the author of \"The Mathematical Theory of Finite Element Methods\" (Springer-Verlag, 1994; 3rd edition, 2008).\n\nShe is a fellow of the Society for Industrial and Applied Mathematics, the American Mathematical Society, and the American Association for the Advancement of Science.\n"}
{"id": "14982946", "url": "https://en.wikipedia.org/wiki?curid=14982946", "title": "Turán number", "text": "Turán number\n\nIn mathematics, the Turán number T(\"n\",\"k\",\"r\") for \"r\"-uniform hypergraphs of order \"n\" is the smallest number of \"r\"-edges such that every induced subgraph on \"k\" vertices contains an edge. This number was determined for \"r\" = 2 by , and the problem for general \"r\" was introduced in . The paper gives a survey of Turán numbers.\n\nFix a set \"X\" of \"n\" vertices. For given \"r\", an \"r\"-edge or block is a set of \"r\" vertices. A set of blocks is called a Turán (\"n\",\"k\",\"r\") system (\"n\" ≥ \"k\" ≥ \"r\") if every \"k\"-element subset of \"X\" contains a block.\nThe Turán number T(\"n\",\"k\",\"r\") is the minimum size of such a system.\n\nThe complements of the lines of the Fano plane form a Turán (7,5,4)-system. T(7,5,4) = 7.\n\nIt can be shown that\nEquality holds if and only if there exists a Steiner system S(\"n\" - \"k\", \"n\" - \"r\", \"n\").\n\nAn (\"n\",\"r\",\"k\",\"r\")-lotto design is an (\"n\", \"k\", \"r\")-Turán system. Thus, T(\"n\",\"k\", \"r\") = L(\"n\",\"r\",\"k\",\"r\").\n\n\n"}
{"id": "34572835", "url": "https://en.wikipedia.org/wiki?curid=34572835", "title": "Veblen Research Instructorship", "text": "Veblen Research Instructorship\n\nThe Veblen Research Instructorship is a three-year position offered by the Department of Mathematics at Princeton University and the Institute for Advanced Study. This position was established in 1998 and offered each year to outstanding candidates in pure and applied mathematics who have received their Ph.D. within the last three years.\n\nThe Veblen instructors are Members of the Institute for Advanced Study and regular faculty members at Princeton University. The first and third year of the instructorship are spent at Princeton University and carry regular teaching responsibilities. The second year is spent at the Institute and dedicated to independent research of the instructor's choice.\n\nThe instructorship is named after Oswald Veblen (1880–1960), who was a Henry B. Fine Professor of Mathematics at the University of Princeton until 1932 and became the first professor at the Institute that same year.\n\nGeorgi S. Medvedev, 1999-2002\n\nYen-Hsi Tsai, 2002-2004\n\nJacob Sterbenz, 2003-2006\n\nWee Teck Gan, 1998-2001\n\nMaria Chudnovsky, 2003–2005\n\nCiprian Manolescu, 2004-2005\n\nAlireza Salehi Golsefidy, 2006–2009\n\nStefanos Aretakis, 2012–2015\n\nKai-Wen Lan\n\nCostante Bellettini\n\nDavid Geraghty\n\nTasho Kaletha\n\nVictor Lie\n\nNicholas Sheridan\n\nFang Wang\n\nAna Caraiani, 2013–2016\n\nFlorian Sprung\n\n"}
{"id": "33106720", "url": "https://en.wikipedia.org/wiki?curid=33106720", "title": "Victor Lidskii", "text": "Victor Lidskii\n\nVictor Borisovich Lidskii (, 4 May 1924, Odessa – 29 July 2008, Moscow) was a Soviet and Ukrainian mathematician who worked in spectral theory, operator theory, and shell theory. Lidskii discovered the Lidskii theorem in 1959. His adviser at Moscow State University was Israel Gelfand.\n"}
{"id": "4843588", "url": "https://en.wikipedia.org/wiki?curid=4843588", "title": "XGMML", "text": "XGMML\n\nXGMML (the eXtensible Graph Markup and Modeling Language) is an XML application based on GML which is used for graph description. Technically, while GML is not related to XML nor SGML, XGMML is an XML application that is so designed that there's a 1:1 relation towards GML for trivial conversion between the two formats.\n\n\n\n"}
{"id": "18692018", "url": "https://en.wikipedia.org/wiki?curid=18692018", "title": "Zero flag", "text": "Zero flag\n\nThe zero flag is a single bit flag that is a central feature on most conventional CPU architectures (including x86, ARM, PDP-11, 68000, 6502, and numerous others). It is often stored in a dedicated register, typically called status register or flag register, along with other flags. The zero flag is typically abbreviated Z or ZF or similar in most documentation and assembly languages.\n\nAlong with a carry flag, a sign flag and an overflow flag, the zero flag is used to check the result of an arithmetic operation, including bitwise logical instructions. It is set to 1, or true, if an arithmetic result is zero, and reset otherwise. This includes results which are not stored, as most traditional instruction sets implement the compare instruction as a subtract where the result is discarded. It is also common that processors have a bitwise AND-instruction that does not store the result.\n\nIn most processors, the zero flag is mainly used in conditional branch instructions, which alter control flow on previous instruction results, but there are often other uses as well.\n\nIn some instruction sets such as the MIPS architecture, a dedicated flag register is not used; jump instructions instead check a register for zero.\n"}
