{"id": "38965552", "url": "https://en.wikipedia.org/wiki?curid=38965552", "title": "(G,X)-manifold", "text": "(G,X)-manifold\n\nIf X is a manifold with an action of a topological group G by analytical diffeomorphisms, the notion of a (G, X)-structure on a topological space is a way to formalise it being locally isomorphic to X with its G-invariant structure; spaces with a (G, X)-structures are always manifolds and are called (G, X)-manifolds. This notion is often used with G being a Lie group and X a homogeneous space for G. Foundational examples are hyperbolic manifolds and affine manifolds.\n\nLet formula_1 be a connected differential manifold and formula_2 be a subgroup of the group of diffeomorphisms of formula_1 which act analytically in the following sense:\n\n(this definition is inspired by the analytic continuation property of analytic diffeomorphisms on an analytic manifold).\n\nA formula_9-structure on a topological space formula_10 is a manifold structure on formula_10 whose atlas' charts has values in formula_1 and transition maps belong to formula_2. This means that there exists:\n\n\nsuch that every transition map formula_18 is the restriction of a diffeomorphism in formula_2.\n\nTwo such structures formula_20 are equivalent when they are contained in a maximal one, equivalently when their union is also a formula_9 structure (i.e. the maps formula_22 and formula_23 are restrictions of diffeomorphisms in formula_2).\n\nIf formula_2 is a Lie group and formula_1 a Riemannian manifold with a faithful action of formula_2 by isometries then the action is analytic. Usually one takes formula_2 to be the full isometry group of formula_1. Then the category of formula_9 manifolds is equivalent to the category of Riemannian manifolds which are locally isometric to formula_1 (i.e. every point has a neighbourhood isometric to an open subset of formula_1).\n\nOften the examples of formula_1 are homogeneous under formula_2, for example one can take formula_35 with a left-invariant metric. A particularly simple example is formula_36 and formula_2 the group of euclidean isometries. Then a formula_38 manifold is simply a flat manifold.\n\nA particularly interesting example is when formula_1 is a Riemannian symmetric space, for example hyperbolic space. The simplest such example is the hyperbolic plane, whose isometry group is isomorphic to formula_40.\n\nWhen formula_1 is Minkowski space and formula_2 the Lorentz group the notion of a formula_9-structure is the same as that of a flat Lorentzian manifold.\n\nWhen formula_1 is the affine space and formula_2 the group of affine transformations then one gets the notion of an affine manifold.\n\nWhen formula_46 is the n-dimensional real projective space and formula_47 one gets the notion of a projective structure.\n\nLet formula_10 be a formula_38-manifold which is connected (as a topological space). The developing map is a map from the universal cover formula_50 to formula_1 which is only well-defined up to composition by an element of formula_2.\n\nA developing map is defined as follows: fix formula_53 and let formula_54 be any other point, formula_55 a path from formula_56 to formula_57, and formula_58 (where formula_7 is a small enough neighbourhood of formula_56) a map obtained by composing a chart of formula_10 with the projection formula_62. We may use analytic continuation along formula_55 to extend formula_64 so that its domain includes formula_57. Since formula_50 is simply connected the value of formula_67 thus obtained does not depend on the original choice of formula_55, and we call the (well-defined) map formula_69 a \"developing map\" for the formula_38-structure. It depends on the choice of base point and chart, but only up to composition by an element of formula_2.\n\nGiven a developing map formula_64, the \"monodromy\" or \"holonomy\" of a formula_38-structure is the unique morphism formula_74 which satisfies\n\nIt depends on the choice of a developing map but only up to an inner automorphism of formula_2.\n\nA formula_38 structure is said to be \"complete\" if it has a developing map which is also a covering map (this does not depend on the choice of developing map since they differ by a diffeomorphism). For example, if formula_1 is simply connected the structure is complete if and only if the developing map is a diffeomorphism.\n\nIf formula_1 is a Riemannian manifold and formula_2 its full group of isometry, then a formula_38-structure is complete if and only if the underlying Riemannian manifold is geodesically complete (equivalently metrically complete). In particular, in this case if the underlying space of a formula_38-manifold is compact then the latter is automatically complete.\n\nIn the case where formula_1 is the hyperbolic plane the developing map is the same map as given by the Uniformisation Theorem.\n\nIn general compactness of the space does not imply completeness of a formula_38-structure. For example, an affine structure on the torus is complete if and only if the monodromy map has its image inside the translations. But there are many affine tori which do not satisfy this condition, for example any quadrilateral with its opposite sides glued by an affine map yields an affine structure on the torus, which is complete if and only if the quadrilateral is a parallelogram.\n\nInteresting examples of complete, noncompact affine manifolds are given by the Margulis spacetimes.\n\nIn the work of Charles Ehresmann formula_9-structures on a manifold formula_10 are viewed as flat Ehresmann connections on fiber bundles with fiber formula_1 over formula_10, whose monodromy maps lie in formula_2.\n"}
{"id": "208156", "url": "https://en.wikipedia.org/wiki?curid=208156", "title": "11 (number)", "text": "11 (number)\n\n11 (eleven) is the natural number following 10 and preceding 12. It is the first repdigit. In English, it is the smallest positive integer requiring three syllables and the largest prime number with a single-morpheme name.\n\nEleven derives from the Old English ' which is first attested in Bede's late 9th-century \"Ecclesiastical History of the English People\". It has cognates in every Germanic language (for example, German \"elf\"), whose Proto-Germanic ancestor has been reconstructed as *\"ainalifa-\", from the prefix *\"aina-\" (adjectival \"one\") and suffix *\"-lifa-\" of uncertain meaning. It is sometimes compared with the Lithuanian ', although \"\" is used as the suffix for all numbers from 11 to 19 (analogous to \"-teen\").\n\nThe Old English form has closer cognates in Old Frisian, Saxon, and Norse, whose ancestor has been reconstructed as *\"ainlifun\". This has formerly been considered derived from Proto-Germanic *\"tehun\" (\"ten\"); it is now sometimes connected with *\"leikʷ-\" or *\"leip-\" (\"left; remaining\"), with the implicit meaning that \"one is left\" after having already counted to ten.\n\nWhile, as mentioned above, 11 has its own name in Germanic languages such as English, German, and Swedish. It is the first compound number in many other languages, e.g., Italian \"ùndici\" (but in Spanish and Portuguese, 16, and in French, 17 is the first compound number), Chinese 十一 \"shí yī\", Korean 열한 \"yeol han\".\n\n11 is a prime number. It is the smallest two-digit prime number in the decimal base.\n\nThe next prime is 13, with which it comprises a twin prime.\n\nIf a number is divisible by 11, reversing its digits will result in another multiple of 11. As long as no two adjacent digits of a number added together exceed 9, then multiplying the number by 11, reversing the digits of the product, and dividing that new number by 11, will yield a number that is the reverse of the original number. (For example: 142,312 × 11 = 1,565,432 → 2,345,651 ÷ 11 = 213,241.)\n\nMultiples of 11 by one-digit numbers all have matching double digits: 00 (=0), 11, 22, 33, 44, etc.\n\nAn 11-sided polygon is called a hendecagon or undecagon.\n\nThere are 11 regular and semiregular convex uniform tilings in the second dimension, and 11 planigons that correspond to these 11 regular and semiregular tilings.\n\nIn base 10, there is a simple test to determine if an integer is divisible by 11: take every digit of the number located in odd position and add them up, then take the remaining digits and add them up. If the difference between the two sums is a multiple of 11, including 0, then the number is divisible by 11. For instance, if the number is 65,637 then (6 + 6 + 7) - (5 + 3) = 19 - 8 = 11, so 65,637 is divisible by 11. This technique also works with groups of digits rather than individual digits, so long as the number of digits in each group is odd, although not all groups have to have the same number of digits. For instance, if one uses three digits in each group, one gets from 65,637 the calculation (065) - 637 = -572, which is divisible by 11.\n\nAnother test for divisibility is to separate a number into groups of two consecutive digits (adding a leading zero if there is an odd number of digits), and then add up the numbers so formed; if the result is divisible by 11, the number is divisible by 11. For instance, if the number is 65,637, 06 + 56 + 37 = 99, which is divisible by 11, so 65,637 is divisible by eleven. This also works by adding a trailing zero instead of a leading one: 65 + 63 + 70 = 198, which is divisible by 11. This also works with larger groups of digits, providing that each group has an even number of digits (not all groups have to have the same number of digits).\n\nAn easy way of multiplying numbers by 11 in base 10 is:\nIf the number has:\n\nIn base 13 and higher bases (such as hexadecimal), 11 is represented as B, where ten is A. In duodecimal, however, 11 is sometimes represented as E and ten as T or X.\n\nThere are 11 orthogonal curvilinear coordinate systems (to within a conformal symmetry) in which the 3-variable Helmholtz equation can be solved using the separation of variables technique.\n\nSee also 11-cell.\n\n11 of the thirty-five hexominoes can be folded to form cubes. 11 of the sixty-six octiamonds can be folded to form octahedra.\n\n11 is the fourth Sophie Germain prime, the third safe prime, the fourth Lucas prime, the first repunit prime, the second good prime, and the second unique prime. Although it is necessary for \"n\" to be prime for 2 − 1 to be a Mersenne prime, the converse is not true: 2 − 1 = 2047 which is 23 × 89.\n\n11 raised to the nth power is the nth row of Pascal's Triangle. (This works for any base, but the number eleven must be changed to the number represented as 11 in that base; for example, in duodecimal this must be done using thirteen.)\n\n11 is a Heegner number, meaning that the ring of integers of the field formula_1 has the property of unique factorization.\n\nOne consequence of this is that there exists at most one point on the elliptic curve x = y + 11 that has positive-integer coordinates. In this case, this unique point is (15, 58).\n\n\n\nAfter Judas Iscariot was disgraced, the remaining apostles of Jesus were sometimes described as \"the Eleven\" (; and ); this occurred even after Matthias was added to bring the number to twelve, as in Acts 2:14: \"Peter stood up with the eleven\" (New International Version). The New Living Translation says \"Peter stepped forward with the eleven other apostles\", making clear that the number of apostles was now twelve.\n\nSaint Ursula is said to have been martyred in the third or fourth century in Cologne with a number of companions, whose reported number \"varies from five to eleven\". A legend that Ursula died with eleven thousand virgin companions has been thought to appear from misreading \"XI. M. V.\" (Latin abbreviation for \"Eleven martyr virgins\") as \"Eleven thousand virgins\".\n\nIn the Enûma Eliš the goddess Tiamat creates eleven monsters to take revenge for the death of her husband, Apsû.\n\n\n\n\n\n\n\n"}
{"id": "252670", "url": "https://en.wikipedia.org/wiki?curid=252670", "title": "Absolute continuity", "text": "Absolute continuity\n\nIn calculus, absolute continuity is a smoothness property of functions that is stronger than continuity and uniform continuity. The notion of absolute continuity allows one to obtain generalizations of the relationship between the two central operations of calculus—differentiation and integration. This relationship is commonly characterized (by the fundamental theorem of calculus) in the framework of Riemann integration, but with absolute continuity it may be formulated in terms of Lebesgue integration. For real-valued functions on the real line two interrelated notions appear: \"absolute continuity of functions\" and \"absolute continuity of measures.\" These two notions are generalized in different directions. The usual derivative of a function is related to the \"Radon–Nikodym derivative\", or \"density\", of a measure.\n\nWe have the following chains of inclusions for functions over a compact subset of the real line:\n\nand:\n\nA continuous function fails to be absolutely continuous if it fails to be uniformly continuous, which can happen if the domain of the function is not compact – examples are tan(\"x\") over <nowiki>[</nowiki>0, /2<nowiki>)</nowiki>, \"x\" over the entire real line, and sin(1/\"x\") over (0, 1]. But a continuous function \"f\" can fail to be absolutely continuous even on a compact interval. It may not be \"differentiable almost everywhere\" (like the Weierstrass function, which is not differentiable anywhere). Or it may be differentiable almost everywhere and its derivative \"f\" ′ may be Lebesgue integrable, but the integral of \"f\" ′ differs from the increment of \"f\" (how much \"f\" changes over an interval). This happens for example with the Cantor function.\n\nLet formula_1 be an interval in the real line formula_2. A function formula_3 is absolutely continuous on formula_1 if for every positive number formula_5, there is a positive number formula_6 such that whenever a finite sequence of pairwise disjoint sub-intervals formula_7 of formula_1 with formula_9 satisfies\n\nthen\n\nThe collection of all absolutely continuous functions on formula_1 is denoted formula_13.\n\nThe following conditions on a real-valued function \"f\" on a compact interval [\"a\",\"b\"] are equivalent:\n\nIf these equivalent conditions are satisfied then necessarily \"g\" = \"f\" ′ almost everywhere.\n\nEquivalence between (1) and (3) is known as the fundamental theorem of Lebesgue integral calculus, due to Lebesgue.\n\nFor an equivalent definition in terms of measures see the section Relation between the two notions of absolute continuity.\n\n\nThe following functions are uniformly continuous but not absolutely continuous:\n\nThe following functions are absolutely continuous but not α-Hölder continuous:\n\nThe following functions are absolutely continuous and α-Hölder continuous but not Lipschitz continuous:\n\nLet (\"X\", \"d\") be a metric space and let \"I\" be an interval in the real line R. A function \"f\": \"I\" → \"X\" is absolutely continuous on \"I\" if for every positive number formula_21, there is a positive number formula_6 such that whenever a finite sequence of pairwise disjoint sub-intervals [\"x\", \"y\"] of \"I\" satisfies\n\nthen\n\nThe collection of all absolutely continuous functions from \"I\" into \"X\" is denoted AC(\"I\"; \"X\").\n\nA further generalization is the space AC(\"I\"; \"X\") of curves \"f\": \"I\" → \"X\" such that\n\nfor some \"m\" in the \"L\" space \"L\"(I).\n\n\nA measure formula_27 on Borel subsets of the real line is absolutely continuous with respect to Lebesgue measure formula_19 (in other words, dominated by formula_19) if for every measurable set formula_30, formula_31 implies formula_32 . This is written as formula_33.\n\nIn most applications, if a measure on the real line is simply said to be absolutely continuous — without specifying with respect to which other measure it is absolutely continuous — then absolute continuity with respect to Lebesgue measure is meant.\n\nThe same works for measures on Borel subsets of formula_34.\n\nThe following conditions on a finite measure \"μ\" on Borel subsets of the real line are equivalent:\n\nFor an equivalent definition in terms of functions see the section Relation between the two notions of absolute continuity.\n\nAny other function satisfying (3) is equal to \"g\" almost everywhere. Such a function is called Radon–Nikodym derivative, or density, of the absolutely continuous measure \"μ\".\n\nEquivalence between (1), (2) and (3) holds also in R for all \"n\" = 1, 2, 3, ...\n\nThus, the absolutely continuous measures on R are precisely those that have densities; as a special case, the absolutely continuous probability measures are precisely the ones that have probability density functions.\n\nIf \"μ\" and \"ν\" are two measures on the same measurable space then \"μ\" is said to be absolutely continuous with respect to \"ν, or dominated by \"ν if \"μ\"(\"A\") = 0 for every set \"A\" for which \"ν\"(\"A\") = 0. This is written as \"\"μ\" formula_36 \"ν\"\". In symbols:\n\nAbsolute continuity of measures is reflexive and transitive, but is not antisymmetric, so it is a preorder rather than a partial order. Instead, if \"μ\" formula_36 \"ν\" and \"ν\" formula_36 \"μ\", the measures \"μ\" and \"ν\" are said to be equivalent. Thus absolute continuity induces a partial ordering of such equivalence classes.\n\nIf \"μ\" is a signed or complex measure, it is said that \"μ\" is absolutely continuous with respect to \"ν\" if its variation |\"μ\"| satisfies |\"μ\"| ≪ ν; equivalently, if every set \"A\" for which \"ν\"(\"A\") = 0 is \"μ\"-null.\n\nThe Radon–Nikodym theorem states that if \"μ\" is absolutely continuous with respect to \"ν\", and both measures are σ-finite, then \"μ\" has a density, or \"Radon-Nikodym derivative\", with respect to \"ν\", which means that there exists a \"ν\"-measurable function \"f\" taking values in [0, +∞), denoted by \"f\" = \"dμ\"/\"dν\", such that for any \"ν\"-measurable set \"A\" we have\n\nVia Lebesgue's decomposition theorem, every measure can be decomposed into the sum of an absolutely continuous measure and a singular measure. See singular measure for examples of measures that are not absolutely continuous.\n\nA finite measure \"μ\" on Borel subsets of the real line is absolutely continuous with respect to Lebesgue measure if and only if the point function\nis an absolutely continuous real function.\nMore generally, a function is locally (meaning on every bounded interval) absolutely continuous if and only if its distributional derivative is a measure that is absolutely continuous with respect to the Lebesgue measure.\n\nIf absolute continuity holds then the Radon–Nikodym derivative of \"μ\" is equal almost everywhere to the derivative of \"F\".\n\nMore generally, the measure \"μ\" is assumed to be locally finite (rather than finite) and \"F\"(\"x\") is defined as \"μ\"((0,\"x\"]) for , 0 for , and −\"μ\"((\"x\",0]) for . In this case \"μ\" is the Lebesgue–Stieltjes measure generated by \"F\".\nThe relation between the two notions of absolute continuity still holds.\n\n\n"}
{"id": "19616384", "url": "https://en.wikipedia.org/wiki?curid=19616384", "title": "Abstract algebra", "text": "Abstract algebra\n\nIn algebra, which is a broad division of mathematics, abstract algebra (occasionally called modern algebra) is the study of algebraic structures. Algebraic structures include groups, rings, fields, modules, vector spaces, lattices, and algebras. The term \"abstract algebra\" was coined in the early 20th century to distinguish this area of study from the other parts of algebra.\n\nAlgebraic structures, with their associated homomorphisms, form mathematical categories. Category theory is a formalism that allows a unified way for expressing properties and constructions that are similar for various structures.\n\nUniversal algebra is a related subject that studies types of algebraic structures as single objects. For example, the structure of groups is a single object in universal algebra, which is called \"variety of groups\".\n\nAs in other parts of mathematics, concrete problems and examples have played important roles in the development of abstract algebra. Through the end of the nineteenth century, manyperhaps mostof these problems were in some way related to the theory of algebraic equations. Major themes include:\n\nNumerous textbooks in abstract algebra start with axiomatic definitions of various algebraic structures and then proceed to establish their properties. This creates a false impression that in algebra axioms had come first and then served as a motivation and as a basis of further study. The true order of historical development was almost exactly the opposite. For example, the hypercomplex numbers of the nineteenth century had kinematic and physical motivations but challenged comprehension. Most theories that are now recognized as parts of algebra started as collections of disparate facts from various branches of mathematics, acquired a common theme that served as a core around which various results were grouped, and finally became unified on a basis of a common set of concepts. An archetypical example of this progressive synthesis can be seen in the history of group theory.\n\nThere were several threads in the early development of group theory, in modern language loosely corresponding to \"number theory\", \"theory of equations\", and \"geometry\".\n\nLeonhard Euler considered algebraic operations on numbers modulo an integer, modular arithmetic, in his generalization of Fermat's little theorem. These investigations were taken much further by Carl Friedrich Gauss, who considered the structure of multiplicative groups of residues mod n and established many properties of cyclic and more general abelian groups that arise in this way. In his investigations of composition of binary quadratic forms, Gauss explicitly stated the associative law for the composition of forms, but like Euler before him, he seems to have been more interested in concrete results than in general theory. In 1870, Leopold Kronecker gave a definition of an abelian group in the context of ideal class groups of a number field, generalizing Gauss's work; but it appears he did not tie his definition with previous work on groups, particularly permutation groups. In 1882, considering the same question, Heinrich M. Weber realized the connection and gave a similar definition that involved the cancellation property but omitted the existence of the inverse element, which was sufficient in his context (finite groups).\n\nPermutations were studied by Joseph-Louis Lagrange in his 1770 paper \"Réflexions sur la résolution algébrique des équations (Thoughts on the algebraic solution of equations)\" devoted to solutions of algebraic equations, in which he introduced Lagrange resolvents. Lagrange's goal was to understand why equations of third and fourth degree admit formulas for solutions, and he identified as key objects permutations of the roots. An important novel step taken by Lagrange in this paper was the abstract view of the roots, i.e. as symbols and not as numbers. However, he did not consider composition of permutations. Serendipitously, the first edition of Edward Waring's \"Meditationes Algebraicae\" (\"Meditations on Algebra\") appeared in the same year, with an expanded version published in 1782. Waring proved the fundamental theorem of symmetric polynomials, and specially considered the relation between the roots of a quartic equation and its resolvent cubic. \"Mémoire sur la résolution des équations\" (\"Memoire on the Solving of Equations\") of Alexandre Vandermonde (1771) developed the theory of symmetric functions from a slightly different angle, but like Lagrange, with the goal of understanding solvability of algebraic equations.\n\nPaolo Ruffini was the first person to develop the theory of permutation groups, and like his predecessors, also in the context of solving algebraic equations. His goal was to establish the impossibility of an algebraic solution to a general algebraic equation of degree greater than four. En route to this goal he introduced the notion of the order of an element of a group, conjugacy, the cycle decomposition of elements of permutation groups and the notions of primitive and imprimitive and proved some important theorems relating these concepts, such as\n\nNote, however, that he got by without formalizing the concept of a group, or even of a permutation group.\nThe next step was taken by Évariste Galois in 1832, although his work remained unpublished until 1846, when he considered for the first time what is now called the \"closure property\" of a group of permutations, which he expressed as\nThe theory of permutation groups received further far-reaching development in the hands of Augustin Cauchy and Camille Jordan, both through introduction of new concepts and, primarily, a great wealth of results about special classes of permutation groups and even some general theorems. Among other things, Jordan defined a notion of isomorphism, still in the context of permutation groups and, incidentally, it was he who put the term \"group\" in wide use.\n\nThe abstract notion of a group appeared for the first time in Arthur Cayley's papers in 1854. Cayley realized that a group need not be a permutation group (or even \"finite\"), and may instead consist of matrices, whose algebraic properties, such as multiplication and inverses, he systematically investigated in succeeding years. Much later Cayley would revisit the question whether abstract groups were more general than permutation groups, and establish that, in fact, any group is isomorphic to a group of permutations.\n\nThe end of the 19th and the beginning of the 20th century saw a tremendous shift in the methodology of mathematics. Abstract algebra emerged around the start of the 20th century, under the name \"modern algebra\". Its study was part of the drive for more intellectual rigor in mathematics. Initially, the assumptions in classical algebra, on which the whole of mathematics (and major parts of the natural sciences) depend, took the form of axiomatic systems. No longer satisfied with establishing properties of concrete objects, mathematicians started to turn their attention to general theory. Formal definitions of certain algebraic structures began to emerge in the 19th century. For example, results about various groups of permutations came to be seen as instances of general theorems that concern a general notion of an \"abstract group\". Questions of structure and classification of various mathematical objects came to forefront.\n\nThese processes were occurring throughout all of mathematics, but became especially pronounced in algebra. Formal definition through primitive operations and axioms were proposed for many basic algebraic structures, such as groups, rings, and fields. Hence such things as group theory and ring theory took their places in pure mathematics. The algebraic investigations of general fields by Ernst Steinitz and of commutative and then general rings by David Hilbert, Emil Artin and Emmy Noether, building up on the work of Ernst Kummer, Leopold Kronecker and Richard Dedekind, who had considered ideals in commutative rings, and of Georg Frobenius and Issai Schur, concerning representation theory of groups, came to define abstract algebra. These developments of the last quarter of the 19th century and the first quarter of 20th century were systematically exposed in Bartel van der Waerden's \"Moderne algebra\", the two-volume monograph published in 1930–1931 that forever changed for the mathematical world the meaning of the word \"algebra\" from \"the theory of equations\" to the \"theory of algebraic structures\".\n\nBy abstracting away various amounts of detail, mathematicians have defined various algebraic structures that are used in many areas of mathematics. For instance, almost all systems studied are sets, to which the theorems of set theory apply. Those sets that have a certain binary operation defined on them form magmas, to which the concepts concerning magmas, as well those concerning sets, apply. We can add additional constraints on the algebraic structure, such as associativity (to form semigroups); identity, and inverses (to form groups); and other more complex structures. With additional structure, more theorems could be proved, but the generality is reduced. The \"hierarchy\" of algebraic objects (in terms of generality) creates a hierarchy of the corresponding theories: for instance, the theorems of group theory may be used when studying rings (algebraic objects that have two binary operations with certain axioms) since a ring is a group over one of its operations. In general there is a balance between the amount of generality and the richness of the theory: more general structures have usually fewer nontrivial theorems and fewer applications.\n\nExamples of algebraic structures with a single binary operation are:\n\nExamples involving several operations include:\n\nBecause of its generality, abstract algebra is used in many fields of mathematics and science. For instance, algebraic topology uses algebraic objects to study topologies. The Poincaré conjecture, proved in 2003, asserts that the fundamental group of a manifold, which encodes information about connectedness, can be used to determine whether a manifold is a sphere or not. Algebraic number theory studies various number rings that generalize the set of integers. Using tools of algebraic number theory, Andrew Wiles proved Fermat's Last Theorem.\n\nIn physics, groups are used to represent symmetry operations, and the usage of group theory could simplify differential equations. In gauge theory, the requirement of local symmetry can be used to deduce the equations describing a system. The groups that describe those symmetries are Lie groups, and the study of Lie groups and Lie algebras reveals much about the physical system; for instance, the number of force carriers in a theory is equal to the dimension of the Lie algebra, and these bosons interact with the force they mediate if the Lie algebra is nonabelian.\n\n\n"}
{"id": "37467193", "url": "https://en.wikipedia.org/wiki?curid=37467193", "title": "Applications of the calculus of variations", "text": "Applications of the calculus of variations\n\nApplications of the calculus of variations include:\n\n"}
{"id": "7411740", "url": "https://en.wikipedia.org/wiki?curid=7411740", "title": "Ars Magna (Gerolamo Cardano)", "text": "Ars Magna (Gerolamo Cardano)\n\nThe Ars Magna (\"The Great Art\") is an important Latin-language book on algebra written by Girolamo Cardano. It was first published in 1545 under the title \"Artis Magnæ, Sive de Regulis Algebraicis Liber Unus\" (\"Book number one about The Great Art, or The Rules of Algebra\"). There was a second edition in Cardano's lifetime, published in 1570. It is considered one of the three greatest scientific treatises of the early Renaissance, together with Copernicus' \"De revolutionibus orbium coelestium\" and Vesalius' \"De humani corporis fabrica\". The first editions of these three books were published within a two-year span (1543–1545).\n\nIn 1535 Niccolò Fontana Tartaglia became famous for having solved cubics of the form \"x\" + \"ax\" = \"b\" (with \"a\",\"b\" > 0). However, he chose to keep his method secret. In 1539, Cardano, then a lecturer in mathematics at the Piatti Foundation in Milan, published his first mathematical book, \"Pratica Arithmeticæ et mensurandi singularis\" (\"The Practice of Arithmetic and Simple Mensuration\"). That same year, he asked Tartaglia to explain to him his method for solving cubic equations. After some reluctance, Tartaglia did so, but he asked Cardano not to share the information until he published it. Cardano submerged himself in mathematics during the next several years working on how to extend Tartaglia's formula to other types of cubics. Furthermore, his student Lodovico Ferrari found a way of solving quartic equations, but Ferrari's method depended upon Tartaglia's, since it involved the use of an auxiliary cubic equation. Then Cardano became aware of the fact that Scipione del Ferro had discovered Tartaglia's formula before Tartaglia himself, a discovery that prompted him to publish these results.\n\nThe book, which is divided into forty chapters, contains the first published algebraic solution to cubic and quartic equations. Cardano acknowledges that Tartaglia gave him the formula for solving a type of cubic equations and that the same formula had been discovered by Scipione del Ferro. He also acknowledges that it was Ferrari who found a way of solving quartic equations.\n\nSince at the time negative numbers were not generally acknowledged, knowing how to solve cubics of the form \"x\" + \"ax\" = \"b\" did not mean knowing how to solve cubics of the form \"x\" = \"ax\" + \"b\" (with \"a\",\"b\" > 0), for instance. Besides, Cardano, also explains how to reduce equations of the form \"x\" + \"ax\" + \"bx\" + \"c\" = 0 to cubic equations without a quadratic term, but, again, he has to consider several cases. In all, Cardano was driven to the study of thirteen different types of cubic equations (chapters XI–XXIII).\n\nIn \"Ars Magna\" the concept of multiple root appears for the first time (chapter I). The first example that Cardano provides of a polynomial equation with multiple roots is \"x\" = 12\"x\" + 16, of which −2 is a double root.\n\n\"Ars Magna\" also contains the first occurrence of complex numbers (chapter XXXVII). The problem mentioned by Cardano which leads to square roots of negative numbers is: find two numbers whose sum is equal to 10 and whose product is equal to 40. The answer is 5 + √−15 and 5 − √−15. Cardano called this \"sophistic,\" because he saw no physical meaning to it, but boldly wrote \"nevertheless we will operate\" and formally calculated that their product does indeed equal 40. Cardano then says that this answer is “as subtle as it is useless”.\n\nIt is a common misconception that Cardano introduced complex numbers in solving cubic equations. Since (in modern notation) Cardano's formula for a root of the polynomial \"x\" + \"px\" + \"q\"  is\nsquare roots of negative numbers appear naturally in this context. However, \"q\"/4 + \"p\"/27 never happens to be negative in the specific cases in which Cardano applies the formula.\n\n\n"}
{"id": "2684734", "url": "https://en.wikipedia.org/wiki?curid=2684734", "title": "Blau space", "text": "Blau space\n\nBlau space consists of the multidimensional coordinate system, created by considering the set of socio-demographic variables as dimensions. All socio-demographic characteristics are potential elements of Blau space, including continuous characteristics such as age, years of education, income, occupational prestige, geographic location, and so forth. In addition, categorical measures of socio-demographic characteristics such as race, sex, religion, birthplace, and others are Blau dimensions. \"Blau space\" is a theoretical construct which was developed by Miller McPherson and named after Peter Blau. It was later elaborated by McPherson and Ranger-Moore.\n\nThe organizing force in Blau space is the homophily principle, which argues that the flow of information from person to person is a declining function of distance in Blau space. Persons located at great distance in Blau space are very unlikely to interact, which creates the conditions for social differences in any characteristic that is transmitted through social communication. The homophily principle thus localizes communication in Blau space, leading to the development of social niches for human activity and social organization.\n\nAlthough the idea of Blau Space was originally developed to consider individuals, it was extended to the context of cities (and other urban units) in Neal's \"Building a Blauürban Space\".\n"}
{"id": "49584628", "url": "https://en.wikipedia.org/wiki?curid=49584628", "title": "Bornhuetter-Ferguson method", "text": "Bornhuetter-Ferguson method\n\nThe Bornhuetter-Ferguson method is a prominent loss reserving technique.\n\nThe Bornhuetter-Ferguson method was introduced in the 1972 paper \"The Actuary and IBNR,\" co-authored by Ron Bornhuetter and Ron Ferguson.\n\nLike other loss reserving techniques, the Bornhuetter-Ferguson method aims to estimate incurred but not reported insurance claim amounts. It is primarily used in the property and casualty and health insurance fields.\n\nGenerally considered a blend of the chain-ladder and expected claims loss reserving methods, the Bornhuetter-Ferguson method uses both reported or paid losses as well as an \"a priori\" expected loss ratio to arrive at an ultimate loss estimate. Simply, reported (or paid) losses are added to \"a priori\" expected losses multiplied by an estimated percent unreported. The estimated percent unreported (or unpaid) is established by observing historical claims experience.\n\nThe Bornhuetter-Ferguson method can be used with either reported or paid losses.\n\nThere are two algebraically equivalent approaches to calculating the Bornhuetter-Ferguson ultimate loss.\n\nIn the first approach, undeveloped reported (or paid) losses are added directly to expected losses (based on an \"a priori\" loss ratio) multiplied by an estimated percent unreported.\n\nformula_1\n\nIn the second approach, reported (or paid) losses are first developed to ultimate using a chain-ladder approach and applying a loss development factor (LDF). Next, the chain-ladder ultimate is multiplied by an estimated percent reported. Finally, expected losses multiplied by an estimated percent unreported are added (as in the first approach).\n\nformula_2\n\nThe estimated percent reported is the reciprocal of the loss development factor.\n\nIncurred but not reported claims can then be determined by subtracting reported losses from the Bornhuetter-Ferguson ultimate loss estimate.\n\n"}
{"id": "18209571", "url": "https://en.wikipedia.org/wiki?curid=18209571", "title": "Campbell's theorem (geometry)", "text": "Campbell's theorem (geometry)\n\nCampbell's theorem, also known as Campbell’s embedding theorem and the Campbell-Magaarrd theorem, is a mathematical theorem that evaluates the asymptotic distribution of random impulses acting with a determined intensity on a damped system. The theorem guarantees that any n-dimensional Riemannian manifold can be locally embedded in an (\"n\" + 1)-dimensional Ricci-flat Riemannian manifold.\n\nCampbell's theorem states that any \"n\"-dimensional Riemannian manifold can be embedded locally in an (\"n\" + 1)-manifold with a Ricci curvature of \"R\" = 0. The theorem also states, in similar form, that an \"n\"-dimensional pseudo-Riemannian manifold can be both locally and isometrically embedded in an \"n\"(\"n\" + 1)/2-pseudo-Euclidean space.\n\nCampbell’s theorem can be used to produce the embedding of numerous 4-dimensional spacetimes in 5-dimensional Ricci-flat spaces. It is also used to embed a class of \"n\"-dimensional Einstein spaces.\n"}
{"id": "11946947", "url": "https://en.wikipedia.org/wiki?curid=11946947", "title": "Centre-to-centre distance", "text": "Centre-to-centre distance\n\nCentre-to-centre distance (c.t.c. distance or ctc distance) is a concept for distances, also called on-center spacing (o.c. spacing or oc spacing), heart distance, and pitch.\n\nIt is the distance between the centre (the heart) of a column and the centre (the heart) of another column. By expressing a distance in c.t.c., one can measure distances between columns with different diameters without confusion. This concept applies to other architectural features that may have variable diameters/widths and spacings, such as pillars or ceiling beams & baffles.\n"}
{"id": "1409006", "url": "https://en.wikipedia.org/wiki?curid=1409006", "title": "Common knowledge (logic)", "text": "Common knowledge (logic)\n\nCommon knowledge is a special kind of knowledge for a group of agents. There is \"common knowledge\" of \"p\" in a group of agents \"G\" when all the agents in \"G\" know \"p\", they all know that they know \"p\", they all know that they all know that they know \"p\", and so on \"ad infinitum\".\n\nThe concept was first introduced in the philosophical literature by David Kellogg Lewis in his study \"Convention\" (1969). The sociologist Morris Friedell defined common knowledge in a 1969 paper. It was first given a mathematical formulation in a set-theoretical framework by Robert Aumann (1976). Computer scientists grew an interest in the subject of epistemic logic in general – and of common knowledge in particular – starting in the 1980s. There are numerous puzzles based upon the concept which have been extensively investigated by mathematicians such as John Conway.\n\nThe philosopher Stephen Schiffer, in his book \"Meaning\", independently developed a notion he called \"mutual knowledge\" which functions quite similarly to Lewis's \"common knowledge\".\n\nThe idea of common knowledge is often introduced by some variant of the following puzzle:\n\nOn an island, there are \"k\" people who have blue eyes, and the rest of the people have green eyes. At the start of the puzzle, no one on the island ever knows their own eye color. By rule, if a person on the island ever discovers they have blue eyes, that person must leave the island at dawn; anyone not making such a discovery always sleeps until after dawn. On the island, each person knows every other person's eye color, there are no reflective surfaces, and there is no communication of eye color.\n\nAt some point, an outsider comes to the island, calls together all the people on the island, and makes the following public announcement: \"At least one of you has blue eyes\". The outsider, furthermore, is known by all to be truthful, and all know that all know this, and so on: it is common knowledge that he is truthful, and thus it becomes common knowledge that there is at least one islander who has blue eyes. The problem: assuming all persons on the island are completely logical and that this too is common knowledge, what is the eventual outcome?\n\nThe answer is that, on the \"k\"th dawn after the announcement, all the blue-eyed people will leave the island.\n\nThe solution can be seen with an inductive argument. If \"k\" = 1 (that is, there is exactly one blue-eyed person), the person will recognize that they alone have blue eyes (by seeing only green eyes in the others) and leave at the first dawn. If \"k\" = 2, no one will leave at the first dawn. The two blue-eyed people, seeing only one person with blue eyes, \"and\" that no one left on the 1st dawn (and thus that \"k\" > 1), will leave on the second dawn. Inductively, it can be reasoned that no one will leave at the first \"k\" − 1 dawns if and only if there are at least \"k\" blue-eyed people. Those with blue eyes, seeing \"k\" − 1 blue-eyed people among the others and knowing there must be at least \"k\", will reason that they must have blue eyes and leave.\n\nWhat's most interesting about this scenario is that, for \"k\" > 1, the outsider is only telling the island citizens what they already know: that there are blue-eyed people among them. However, before this fact is announced, the fact is not \"common knowledge\".\n\nFor \"k\" = 2, it is merely \"first-order\" knowledge. Each blue-eyed person knows that there is someone with blue eyes, but each blue eyed person does \"not\" know that the other blue-eyed person has this same knowledge.\n\nFor \"k\" = 3, it is \"second order\" knowledge. Each blue-eyed person knows that a second blue-eyed person knows that a third person has blue eyes, but no one knows that there is a \"third\" blue-eyed person with that knowledge, until the outsider makes his statement.\n\nIn general: For \"k\" > 1, it is \"(\"k\" − 1)th order\" knowledge. Each blue-eyed person knows that a second blue-eyed person knows that a third blue-eyed person knows that... (repeat for a total of \"k\" − 1 levels) a \"k\"th person has blue eyes, but no one knows that there is a \"\"k\"th\" blue-eyed person with that knowledge, until the outsider makes his statement. The notion of \"common knowledge\" therefore has a palpable effect. Knowing that everyone knows does make a difference. When the outsider's public announcement (a fact already known to all) becomes common knowledge, the blue-eyed people on this island eventually deduce their status, and leave.\n\nCommon knowledge can be given a logical definition in multi-modal logic systems in which the modal operators are interpreted epistemically. At the propositional level, such systems are extensions of propositional logic. The extension consists of the introduction of a group \"G\" of \"agents\", and of \"n\" modal operators \"K\" (with \"i\" = 1, ..., \"n\") with the intended meaning that \"agent \"i\" knows.\" Thus \"K formula_1\" (where formula_1 is a formula of the calculus) is read \"agent \"i\" knows formula_1.\" We can define an operator \"E\" with the intended meaning of \"everyone in group \"G\" knows\" by defining it with the axiom\n\nBy abbreviating the expression formula_5 with formula_6 and defining formula_7, we could then define common knowledge with the axiom\n\nThere is however a complication. The languages of epistemic logic are usually \"finitary\", whereas the axiom above defines common knowledge as an infinite conjunction of formulas, hence not a well-formed formula of the language. To overcome this difficulty, a \"fixed-point\" definition of common knowledge can be given. Intuitively, common knowledge is thought of as the fixed point of the \"equation\" formula_9. In this way, it is possible to find a formula formula_10 implying formula_11 from which, in the limit, we can infer common knowledge of formula_1.\n\nThis \"syntactic\" characterization is given semantic content through so-called \"Kripke structures\". A Kripke structure is given by (i) a set of states (or possible worlds) \"S\", (ii) \"n\" \"accessibility relations\" formula_13, defined on formula_14, intuitively representing what states agent \"i\" considers possible from any given state, and (iii) a valuation function formula_15 assigning a truth value, in each state, to each primitive proposition in the language. The semantics for the knowledge operator is given by stipulating that formula_16 is true at state \"s\" iff formula_1 is true at \"all\" states \"t\" such that formula_18. The semantics for the common knowledge operator, then, is given by taking, for each group of agents \"G\", the reflexive and transitive closure of the formula_19, for all agents \"i\" in \"G\", call such a relation formula_20, and stipulating that formula_21 is true at state \"s\" iff formula_1 is true at \"all\" states \"t\" such that formula_23.\n\nAlternatively (yet equivalently) common knowledge can be formalized using set theory (this was the path taken by the Nobel laureate Robert Aumann in his seminal 1976 paper). We will start with a set of states \"S\". We can then define an event \"E\" as a subset of the set of states \"S\". For each agent \"i\", define a partition on \"S\", \"P\". This partition represents the state of knowledge of an agent in a state. In state \"s\", agent \"i\" knows that one of the states in \"P\"(\"s\") obtains, but not which one. (Here \"P\"(\"s\") denotes the unique element of \"P\" containing \"s\". Note that this model excludes cases in which agents know things that are not true.)\n\nWe can now define a knowledge function \"K\" in the following way:\n\nThat is, \"K\"(\"e\") is the set of states where the agent will know that event \"e\" obtains. It is a subset of \"e\".\n\nSimilar to the modal logic formulation above, we can define an operator for the idea that \"everyone knows \"e\"\".\n\nAs with the modal operator, we will iterate the \"E\" function, formula_26 and formula_27. Using this we can then define a common knowledge function,\n\nThe equivalence with the syntactic approach sketched above can easily be seen: consider an Aumann structure as the one just defined. We can define a correspondent Kripke structure by taking (i) the same space \"S\", (ii) accessibility relations formula_19 that define the equivalence classes corresponding to the partitions formula_30, and (iii) a valuation function such that it yields value \"true\" to the primitive proposition \"p\" in all and only the states \"s\" such that formula_31, where formula_32 is the event of the Aumann structure corresponding to the primitive proposition \"p\". It is not difficult to see that the common knowledge accessibility function formula_20 defined in the previous section corresponds to the finest common coarsening of the partitions formula_30 for all formula_35, which is the finitary characterization of common knowledge also given by Aumann in the 1976 article.\n\nCommon knowledge was used by David Lewis in his pioneering game-theoretical account of convention. In this sense, common knowledge is a concept still central for linguists and philosophers of language (see Clark 1996) maintaining a Lewisian, conventionalist account of language.\n\nRobert Aumann introduced a set theoretical formulation of common knowledge (theoretically equivalent to the one given above) and proved the so-called agreement theorem through which: if two agents have common prior probability over a certain event, and the posterior probabilities are common knowledge, then such posterior probabilities are equal. A result based on the agreement theorem and proven by Milgrom shows that, given certain conditions on market efficiency and information, speculative trade is impossible.\n\nThe concept of common knowledge is central in game theory. For several years it has been thought that the assumption of common knowledge of rationality for the players in the game was fundamental. It turns out (Aumann and Brandenburger 1995) that, in 2-player games, common knowledge of rationality is not needed as an epistemic condition for Nash equilibrium strategies.\n\nComputer scientists use languages incorporating epistemic logics (and common knowledge) to reason about distributed systems. Such systems can be based on logics more complicated than simple propositional epistemic logic, see Wooldridge \"Reasoning about Artificial Agents\", 2000 (in which he uses a first-order logic incorporating epistemic and temporal operators) or van der Hoek et al. \"Alternating Time Epistemic Logic\".\n\nIn his 2007 book, \"The Stuff of Thought: Language as a Window into Human Nature,\" Steven Pinker uses the notion of common knowledge to analyze the kind of indirect speech involved in innuendoes.\n\n\n\n\n"}
{"id": "7832", "url": "https://en.wikipedia.org/wiki?curid=7832", "title": "Complete metric space", "text": "Complete metric space\n\nIn mathematical analysis, a metric space \"M\" is called complete (or a Cauchy space) if every Cauchy sequence of points in \"M\" has a limit that is also in \"M\" or, alternatively, if every Cauchy sequence in \"M\" converges in \"M\".\n\nIntuitively, a space is complete if there are no \"points missing\" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. formula_1 is \"missing\" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it. (See the examples below.) It is always possible to \"fill all the holes\", leading to the \"completion\" of a given space, as explained below.\n\nThe space Q of rational numbers, with the standard metric given by the absolute value of the difference, is not complete. Consider for instance the sequence defined by formula_2 and formula_3. This is a Cauchy sequence of rational numbers, but it does not converge towards any rational limit: If the sequence did have a limit \"x\", then by solving formula_4 necessarily \"x\" = 2, yet no rational number has this property. However, considered as a sequence of real numbers, it does converge to the irrational number formula_1.\n\nThe open interval , again with the absolute value metric, is not complete either. The sequence defined by \"x\" = is Cauchy, but does not have a limit in the given space. However the closed interval is complete; for example the given sequence does have a limit in this interval and the limit is zero.\n\nThe space R of real numbers and the space C of complex numbers (with the metric given by the absolute value) are complete, and so is Euclidean space R, with the usual distance metric. In contrast, infinite-dimensional normed vector spaces may or may not be complete; those that are complete are Banach spaces. The space C of continuous real-valued functions on a closed and bounded interval is a Banach space, and so a complete metric space, with respect to the supremum norm. However, the supremum norm does not give a norm on the space C of continuous functions on , for it may contain unbounded functions. Instead, with the topology of compact convergence, C can be given the structure of a Fréchet space: a locally convex topological vector space whose topology can be induced by a complete translation-invariant metric.\n\nThe space Q of \"p\"-adic numbers is complete for any prime number \"p\". This space completes Q with the \"p\"-adic metric in the same way that R completes Q with the usual metric.\n\nIf \"S\" is an arbitrary set, then the set \"S\" of all sequences in \"S\" becomes a complete metric space if we define the distance between the sequences (\"x\") and (\"y\") to be , where \"N\" is the smallest index for which \"x\" is distinct from \"y\", or 0 if there is no such index. This space is homeomorphic to the product of a countable number of copies of the discrete space \"S\".\n\nA metric space \"X\" is complete if and only if every decreasing sequence of non-empty closed subsets of \"X\", with diameters tending to 0, has a non-empty intersection: if \"F\" is closed and non-empty, for every \"n\", and , then there is a point common to all sets \"F\".\n\nEvery compact metric space is complete, though complete spaces need not be compact. In fact, a metric space is compact if and only if it is complete and totally bounded. This is a generalization of the Heine–Borel theorem, which states that any closed and bounded subspace \"S\" of R is compact and therefore complete.\n\nLet be a complete metric space. If is a closed set, then \"A\" is also complete. Let be a metric space. If is a complete set, then \"A\" is also closed.\n\nIf \"X\" is a set and \"M\" is a complete metric space, then the set of all bounded functions \"f\" from \"X\" to \"M\" is a complete metric space. Here we define the distance in in terms of the distance in \"M\" with the supremum norm\n\nIf \"X\" is a topological space and \"M\" is a complete metric space, then the set \"C\"(\"X\", \"M\") consisting of all continuous bounded functions \"f\" from \"X\" to \"M\" is a closed subspace of and hence also complete.\n\nThe Baire category theorem says that every complete metric space is a Baire space. That is, the union of countably many nowhere dense subsets of the space has empty interior.\n\nThe Banach fixed point theorem states that a contraction mapping on a complete metric space admits a fixed point. The fixed point theorem is often used to prove the inverse function theorem on complete metric spaces such as Banach spaces.\n\nThe expansion constant of a metric space is the infimum of all constants formula_7 such that whenever the family formula_8 intersects pairwise, the intersection\n\nis nonempty. A metric space is complete if and only if its expansion constant is ≤ 2.\n\nFor any metric space \"M\", one can construct a complete metric space \"M′\" (which is also denoted as ), which contains \"M\" as a dense subspace. It has the following universal property: if \"N\" is any complete metric space and \"f\" is any uniformly continuous function from \"M\" to \"N\", then there exists a unique uniformly continuous function \"f′\" from \"M′\" to \"N\", which extends \"f\". The space \"M\"' is determined up to isometry by this property, and is called the \"completion\" of \"M\".\n\nThe completion of \"M\" can be constructed as a set of equivalence classes of Cauchy sequences in \"M\". For any two Cauchy sequences x=(\"x\") and y=(\"y\") in \"M\", we may define their distance as\n\n(This limit exists because the real numbers are complete.) This is only a pseudometric, not yet a metric, since two different Cauchy sequences may have the distance 0. But \"having distance 0\" is an equivalence relation on the set of all Cauchy sequences, and the set of equivalence classes is a metric space, the completion of \"M\". The original space is embedded in this space via the identification of an element \"x\" of \"M\"' with the equivalence class of sequences in \"M\" converging to \"x\" (i.e., the equivalence class containing the sequence with constant value \"x\"). This defines an isometry onto a dense subspace, as required. Notice, however, that this construction makes explicit use of the completeness of the real numbers, so completion of the rational numbers needs a slightly different treatment.\n\nCantor's construction of the real numbers is similar to the above construction; the real numbers are the completion of the rational numbers using the ordinary absolute value to measure distances. The additional subtlety to contend with is that it is not logically permissible to use the completeness of the real numbers in their own construction. Nevertheless, equivalence classes of Cauchy sequences are defined as above, and the set of equivalence classes is easily shown to be a field that has the rational numbers as a subfield. This field is complete, admits a natural total ordering, and is the unique totally ordered complete field (up to isomorphism). It is \"defined\" as the field of real numbers (see also Construction of the real numbers for more details). One way to visualize this identification with the real numbers as usually viewed is that the equivalence class consisting of those Cauchy sequences of rational numbers that \"ought\" to have a given real limit is identified with that real number. The truncations of the decimal expansion give just one choice of Cauchy sequence in the relevant equivalence class.\n\nFor a prime \"p\", the \"p\"-adic numbers arise by completing the rational numbers with respect to a different metric.\n\nIf the earlier completion procedure is applied to a normed vector space, the result is a Banach space containing the original space as a dense subspace, and if it is applied to an inner product space, the result is a Hilbert space containing the original space as a dense subspace.\n\nNote that completeness is a property of the \"metric\" and not of the \"topology\", meaning that a complete metric space can be homeomorphic to a non-complete one. An example is given by the real numbers, which are complete but homeomorphic to the open interval , which is not complete.\n\nIn topology one considers \"completely metrizable spaces\", spaces for which there exists at least one complete metric inducing the given topology. Completely metrizable spaces can be characterized as those spaces that can be written as an intersection of countably many open subsets of some complete metric space. Since the conclusion of the Baire category theorem is purely topological, it applies to these spaces as well.\n\nCompletely metrizable spaces are often called \"topologically complete\". However, the latter term is somewhat arbitrary since metric is not the most general structure on a topological space for which one can talk about completeness (see the section Alternatives and generalizations). Indeed, some authors use the term \"topologically complete\" for a wider class of topological spaces, the completely uniformizable spaces.\n\nA topological space homeomorphic to a separable complete metric space is called a Polish space.\n\nSince Cauchy sequences can also be defined in general topological groups, an alternative to relying on a metric structure for defining completeness and constructing the completion of a space is to use a group structure. This is most often seen in the context of topological vector spaces, but requires only the existence of a continuous \"subtraction\" operation. In this setting, the distance between two points \"x\" and \"y\" is gauged not by a real number \"ε\" via the metric \"d\" in the comparison \"d\"(\"x\", \"y\") < \"ε\", but by an open neighbourhood \"N\" of 0 via subtraction in the comparison \"x\" − \"y\" ∈ \"N\".\n\nA common generalisation of these definitions can be found in the context of a uniform space, where an entourage is a set of all pairs of points that are at no more than a particular \"distance\" from each other.\n\nIt is also possible to replace Cauchy \"sequences\" in the definition of completeness by Cauchy \"nets\" or Cauchy filters. If every Cauchy net (or equivalently every Cauchy filter) has a limit in \"X\", then \"X\" is called complete. One can furthermore construct a completion for an arbitrary uniform space similar to the completion of metric spaces. The most general situation in which Cauchy nets apply is Cauchy spaces; these too have a notion of completeness and completion just like uniform spaces.\n\n\n"}
{"id": "490134", "url": "https://en.wikipedia.org/wiki?curid=490134", "title": "Connected sum", "text": "Connected sum\n\nIn mathematics, specifically in topology, the operation of connected sum is a geometric modification on manifolds. Its effect is to join two given manifolds together near a chosen point on each. This construction plays a key role in the classification of closed surfaces.\n\nMore generally, one can also join manifolds together along identical submanifolds; this generalization is often called the fiber sum. There is also a closely related notion of a connected sum on knots, called the knot sum or composition of knots.\n\nA connected sum of two \"m\"-dimensional manifolds is a manifold formed by deleting a ball inside each manifold and gluing together the resulting boundary spheres.\n\nIf both manifolds are oriented, there is a unique connected sum defined by having the gluing map reverse orientation. Although the construction uses the choice of the balls, the result is unique up to homeomorphism. One can also make this operation work in the smooth category, and then the result is unique up to diffeomorphism. There are subtle problems in the smooth case: not every diffeomorphism between the boundaries of the spheres gives the same composite manifold, even if the orientations are chosen correctly. For example, Milnor showed that two 7-cells can be glued along their boundary so that the result is an exotic sphere homeomorphic but not diffeomorphic to a 7-sphere.\n\nHowever, there is a canonical way to choose the gluing of formula_1 and formula_2 which gives a unique well defined connected sum. Choose embeddings formula_3 and formula_4 so that formula_5 preserves orientation and formula_6 reverses orientation. Now obtain formula_7 from the disjoint sum\n\nby identifying formula_9 with formula_10 for each unit vector formula_11 and each formula_12. Choose the orientation for formula_7 which is compatible with formula_1 and formula_2. The fact that this construction is well-defined depends crucially on the disc theorem, which is not at all obvious. For further details, see \n\nThe operation of connected sum is denoted by formula_16; for example formula_17 denotes the connected sum of formula_18 and formula_19.\n\nThe operation of connected sum has the sphere formula_20 as an identity; that is, formula_21 is homeomorphic (or diffeomorphic) to formula_22.\n\nThe classification of closed surfaces, a foundational and historically significant result in topology, states that any closed surface can be expressed as the connected sum of a sphere with some number formula_23 of tori and some number formula_24 of real projective planes.\n\nLet formula_1 and formula_2 be two smooth, oriented manifolds of equal dimension and formula_27 a smooth, closed, oriented manifold, embedded as a submanifold into both formula_1 and formula_2. Suppose furthermore that there exists an isomorphism of normal bundles\n\nthat reverses the orientation on each fiber. Then formula_31 induces an orientation-preserving diffeomorphism\n\nwhere each normal bundle formula_33 is diffeomorphically identified with a neighborhood formula_34 of formula_27 in formula_36, and the map\n\nis the orientation-reversing diffeomorphic involution\n\non normal vectors. The connected sum of formula_1 and formula_2 along formula_27 is then the space\n\nobtained by gluing the deleted neighborhoods together by the orientation-preserving diffeomorphism. The sum is often denoted\n\nIts diffeomorphism type depends on the choice of the two embeddings of formula_27 and on the choice of formula_31.\n\nLoosely speaking, each normal fiber of the submanifold formula_27 contains a single point of formula_27, and the connected sum along formula_27 is simply the connected sum as described in the preceding section, performed along each fiber. For this reason, the connected sum along formula_27 is often called the fiber sum.\n\nThe special case of formula_27 a point recovers the connected sum of the preceding section.\n\nAnother important special case occurs when the dimension of formula_27 is two less than that of the formula_36. Then the isomorphism formula_31 of normal bundles exists whenever their Euler classes are opposite:\n\nFurthermore, in this case the structure group of the normal bundles is the circle group formula_55; it follows that the choice of embeddings can be canonically identified with the group of homotopy classes of maps from formula_27 to the circle, which in turn equals the first integral cohomology group formula_57. So the diffeomorphism type of the sum depends on the choice of formula_31 and a choice of element from formula_57.\n\nA connected sum along a codimension-two formula_27 can also be carried out in the category of symplectic manifolds; this elaboration is called the symplectic sum.\n\nThe connected sum is a local operation on manifolds, meaning that it alters the summands only in a neighborhood of formula_27. This implies, for example, that the sum can be carried out on a single manifold formula_22 containing two disjoint copies of formula_27, with the effect of gluing formula_22 to itself. For example, the connected sum of a two-sphere at two distinct points of the sphere produces the two-torus.\n\nThere is a closely related notion of the connected sum of two knots. In fact, if one regards a knot merely as a one-manifold, then the connected sum of two knots is just their connected sum as a one-dimensional manifold. However, the essential property of a knot is not its manifold structure (under which every knot is equivalent to a circle) but rather its embedding into the ambient space. So the connected sum of knots has a more elaborate definition that produces a well-defined embedding, as follows.\n\nThis procedure results in the projection of a new knot, a connected sum (or knot sum, or composition) of the original knots. For the connected sum of knots to be well defined, one has to consider oriented knots in 3-space. To define the connected sum for two oriented knots:\n\n\nThe resulting connected sum knot inherits an orientation consistent with the orientations of the two original knots, and the oriented ambient isotopy class of the result is well-defined, depending only on the oriented ambient isotopy classes of the original two knots.\n\nUnder this operation, oriented knots in 3-space form a commutative monoid with unique prime factorization, which allows us to define what is meant by a prime knot. Proof of commutativity can be seen by letting one summand shrink until it is very small and then pulling it along the other knot. The unknot is the unit. The two trefoil knots are the simplest prime knots. Higher-dimensional knots can be added by splicing the formula_65-spheres.\n\nIn three dimensions, the unknot cannot be written as the sum of two non-trivial knots. This fact follows from additivity of knot genus; another proof relies on an infinite construction sometimes called the Mazur swindle. In higher dimensions (with codimension at least three), it is possible to get an unknot by adding two nontrivial knots.\n\nIf one does not take into account the orientations of the knots, the connected sum operation is not well defined on isotopy classes of (nonoriented) knots. To see this, consider two noninvertible knots \"K, L\" which are not equivalent (as unoriented knots); for example take the two pretzel knots \"K\" = \"P\"(3,5,7) and \"L\" = \"P\"(3,5,9). Let \"K\" and \"K\" be \"K\" with its two inequivalent orientations, and let \"L\" and \"L\" be \"L\" with its two inequivalent orientations. There are four oriented connected sums we may form:\n\n\nThe oriented ambient isotopy classes of these four oriented knots are all distinct. And, when one considers ambient isotopy of the knots without regard to orientation, there are two distinct equivalence classes: { \"A\" ~ \"B\" } and { \"C\" ~ \"D\" }. To see that \"A\" and \"B\" are unoriented equivalent, simply note that they both may be constructed from the same pair of disjoint knot projections as above, the only difference being the orientations of the knots. Similarly, one sees that \"C\" and \"D\" may be constructed from the same pair of disjoint knot projections.\n\n\n"}
{"id": "8336", "url": "https://en.wikipedia.org/wiki?curid=8336", "title": "Decision problem", "text": "Decision problem\n\nIn computability theory and computational complexity theory, a decision problem is a problem that can be posed as a yes-no question of the input values. An example of a decision problem is deciding whether a given natural number is prime. Another is the problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\". The answer is either 'yes' or 'no' depending upon the values of \"x\" and \"y\". A method for solving a decision problem, given in the form of an algorithm, is called a decision procedure for that problem. A decision procedure for the decision problem \"given two numbers \"x\" and \"y\", does \"x\" evenly divide \"y\"?\" would give the steps for determining whether \"x\" evenly divides \"y\". One such algorithm is long division. If the remainder is zero the answer is 'yes', otherwise it is 'no'. A decision problem which can be solved by an algorithm is called \"decidable\".\n\nDecision problems typically appear in mathematical questions of decidability, that is, the question of the existence of an effective method to determine the existence of some object or its membership in a set; some of the most important problems in mathematics are undecidable.\n\nThe field of computational complexity categorizes \"decidable\" decision problems by how difficult they are to solve. \"Difficult\", in this sense, is described in terms of the computational resources needed by the most efficient algorithm for a certain problem. The field of recursion theory, meanwhile, categorizes \"undecidable\" decision problems by Turing degree, which is a measure of the noncomputability inherent in any solution.\n\nA \"decision problem\" is a yes-or-no question on an infinite set of inputs. It is traditional to define the decision problem as the set of possible inputs together with the set of inputs for which the answer is \"yes\".\n\nThese inputs can be natural numbers, but can also be values of some other kind, like binary strings or strings over some other alphabet. The subset of strings for which the problem returns \"yes\" is a formal language, and often decision problems are defined as formal languages.\n\nUsing an encoding such as Gödel numberings, any string can be encoded as a natural number, via which a decision problem can be defined as a subset of the natural numbers.\n\nA classic example of a decidable decision problem is the set of prime numbers. It is possible to effectively decide whether a given natural number is prime by testing every possible nontrivial factor. Although much more efficient methods of primality testing are known, the existence of any effective method is enough to establish decidability.\n\nA decision problem \"A\" is \"decidable\" or \"effectively solvable\" if \"A\" is a recursive set. A problem is \"partially decidable\", \"semidecidable\", \"solvable\", or \"provable\" if \"A\" is a recursively enumerable set. Problems that are not decidable are \"undecidable\". For those it is not possible to create an algorithm, efficient or otherwise, that solves them.\n\nThe halting problem is an important undecidable decision problem; for more examples, see list of undecidable problems.\n\nDecision problems can be ordered according to many-one reducibility and related to feasible reductions such as polynomial-time reductions. A decision problem \"P\" is said to be \"complete\" for a set of decision problems \"S\" if \"P\" is a member of \"S\" and every problem in \"S\" can be reduced to \"P\". Complete decision problems are used in computational complexity theory to characterize complexity classes of decision problems. For example, the Boolean satisfiability problem is complete for the class NP of decision problems under polynomial-time reducibility.\n\nDecision problems are closely related to function problems, which can have answers that are more complex than a simple 'yes' or 'no'. A corresponding function problem is \"given two numbers \"x\" and \"y\", what is \"x\" divided by \"y\"?\".\n\nA function problem consists of a partial function \"f\"; the informal \"problem\" is to compute the values of \"f\" on the inputs for which it is defined.\n\nEvery function problem can be turned into a decision problem; the decision problem is just the graph of the associated function. (The graph of a function \"f\" is the set of pairs (\"x\",\"y\") such that \"f\"(\"x\") = \"y\".) If this decision problem were effectively solvable then the function problem would be as well. This reduction does not respect computational complexity, however. For example, it is possible for the graph of a function to be decidable in polynomial time (in which case running time is computed as a function of the pair (\"x\",\"y\") ) when the function is not computable in polynomial time (in which case running time is computed as a function of \"x\" alone). The function \"f\"(\"x\") = \"2\" has this property.\n\nEvery decision problem can be converted into the function problem of computing the characteristic function of the set associated to the decision problem. If this function is computable then the associated decision problem is decidable. However, this reduction is more liberal than the standard reduction used in computational complexity (sometimes called polynomial-time many-one reduction); for example, the complexity of the characteristic functions of an NP-complete problem and its co-NP-complete complement is exactly the same even though the underlying decision problems may not be considered equivalent in some typical models of computation.\n\nUnlike decision problems, for which there is only one correct answer for each input, optimization problems are concerned with finding the \"best\" answer to a particular input. Optimization problems arise naturally in many applications, such as the traveling salesman problem and many questions in linear programming.\n\nThere are standard techniques for transforming function and optimization problems into decision problems. For example, in the traveling salesman problem, the optimization problem is to produce a tour with minimal weight. The associated decision problem is: for each \"N\", to decide whether the graph has any tour with weight less than \"N\". By repeatedly answering the decision problem, it is possible to find the minimal weight of a tour.\n\nBecause the theory of decision problems is very well developed, research in complexity theory has typically focused on decision problems. Optimization problems themselves are still of interest in computability theory, as well as in fields such as operations research.\n\n\n"}
{"id": "44912952", "url": "https://en.wikipedia.org/wiki?curid=44912952", "title": "Dialgebra", "text": "Dialgebra\n\nDialgebra is the generalization of both algebra and coalgebra. Many algebraic notions have previously been generalized to dialgebras. Dialgebra also attempts to obtain Lie algebras from associated algebras.\n"}
{"id": "55064925", "url": "https://en.wikipedia.org/wiki?curid=55064925", "title": "Enrollment over Secure Transport", "text": "Enrollment over Secure Transport\n\nThe Enrollment over Secure Transport, or EST is a cryptographic protocol that describes an X.509 certificate management protocol targeting public key infrastructure (PKI) clients that need to acquire client certificates and associated certificate authority (CA) certificates. \n\n"}
{"id": "11101338", "url": "https://en.wikipedia.org/wiki?curid=11101338", "title": "Equiprobability", "text": "Equiprobability\n\nEquiprobability is a property for a collection of events that each have the same probability of occurring. In statistics and probability theory it is applied in the discrete uniform distribution and the equidistribution theorem for rational numbers. If there are formula_1 events under consideration, the probability of each occurring is formula_2\n\nIn philosophy it corresponds to a concept that allows one to assign equal probabilities to outcomes when they are judged to be equipossible or to be \"equally likely\" in some sense. The best-known formulation of the rule is Laplace's principle of indifference (or \"principle of insufficient reason\"), which states that, when \"we have no other information than\" that exactly formula_3 mutually exclusive events can occur, we are justified in assigning each the probability formula_4 This subjective assignment of probabilities is especially justified for situations such as rolling dice and lotteries since these experiments carry a symmetry structure, and one's state of knowledge must clearly be invariant under this symmetry.\n\nA similar argument could lead to the seemingly absurd conclusion that the sun is as likely to rise as to not rise tomorrow morning. However, the conclusion that the sun is equally likely to rise as it is to not rise is only absurd when additional information is known, such as the laws of gravity and the sun's history. Similar applications of the concept are effectively instances of circular reasoning, with \"equally likely\" events being assigned equal probabilities, which means in turn that they are equally likely. Despite this, the notion remains useful in probabilistic and statistical modeling.\n\nIn Bayesian probability, one needs to establish prior probabilities for the various hypotheses before applying Bayes' theorem. One procedure is to assume that these prior probabilities have some symmetry which is typical of the experiment, and then assign a prior which is proportional to the Haar measure for the symmetry group: this generalization of equiprobability is known as the principle of transformation groups and leads to misuse of equiprobability as a model for incertitude.\n\n\n"}
{"id": "3207091", "url": "https://en.wikipedia.org/wiki?curid=3207091", "title": "Fekete polynomial", "text": "Fekete polynomial\n\nIn mathematics, a Fekete polynomial is a polynomial\n\nwhere formula_2 is the Legendre symbol modulo some integer \"p\" > 1.\n\nThese polynomials were known in nineteenth-century studies of Dirichlet L-functions, and indeed to Peter Gustav Lejeune Dirichlet himself. They have acquired the name of Michael Fekete, who observed that the absence of real zeroes \"t\" of the Fekete polynomial with 0 < \"t\" < 1 implies an absence of the same kind for the L-function\n\nThis is of considerable potential interest in number theory, in connection with the hypothetical Siegel zero near \"s\" = 1. While numerical results for small cases had indicated that there were few such real zeroes, further analysis reveals that this may indeed be a 'small number' effect.\n\n\n"}
{"id": "1252846", "url": "https://en.wikipedia.org/wiki?curid=1252846", "title": "Graph rewriting", "text": "Graph rewriting\n\nIn computer science, graph transformation, or graph rewriting, concerns the technique of creating a new graph out of an original graph algorithmically. It has numerous applications, ranging from software engineering (software construction and also software verification) to layout algorithms and picture generation.\n\nGraph transformations can be used as a computation abstraction. The basic idea is that the state of a computation can be represented as a graph, further steps in that computation can then be represented as transformation rules on that graph. Such rules consist of an original graph, which is to be matched to a subgraph in the complete state, and a replacing graph, which will replace the matched subgraph.\n\nFormally, a graph rewriting system usually consists of a set of graph rewrite rules of the form formula_1, with formula_2 being called pattern graph (or left-hand side) and formula_3 being called replacement graph (or right-hand side of the rule). A graph rewrite rule is applied to the host graph by searching for an occurrence of the pattern graph (pattern matching, thus solving the subgraph isomorphism problem) and by replacing the found occurrence by an instance of the replacement graph. Rewrite rules can be further regulated in the case of labeled graphs, such as in string-regulated graph grammars.\n\nSometimes graph grammar is used as a synonym for graph rewriting system, especially in the context of formal languages; the different wording is used to emphasize the goal of constructions, like the enumeration of all graphs from some starting graph, i.e. the generation of a graph language – instead of simply transforming a given state (host graph) into a new state.\n\nThe algebraic approach to graph rewriting is based upon category theory. The algebraic approach is further divided into sub-approaches, the most common of which are the double-pushout (DPO) approach and the single-pushout (SPO) approach. Other sub-approaches include the \"sesqui-pushout\" and the \"pullback\" approach\".\n\nFrom the perspective of the DPO approach a graph rewriting rule is a pair of morphisms in the category of graphs and graph homomorphisms between them: formula_4 (or formula_5) where formula_6 is injective. The graph K is called \"invariant\" or sometimes the \"gluing graph\". A rewriting step or \"application\" of a rule r to a \"host graph\" G is defined by two pushout diagrams both originating in the same morphism formula_7, where D is a \"context graph\" (this is where the name \"double\"-pushout comes from). Another graph morphism formula_8 models an occurrence of L in G and is called a match. Practical understanding of this is that formula_2 is a subgraph that is matched from formula_10 (see subgraph isomorphism problem), and after a match is found, formula_2 is replaced with formula_3 in host graph formula_10 where formula_14 serves as an interface, containing the nodes and edges which are preserved when applying the rule. The graph formula_14 is needed to attach the pattern being matched to its context: if it is empty, the match can only designate a whole connected component of the graph formula_10.\n\nIn contrast a graph rewriting rule of the SPO approach is a single morphism in the category of labeled multigraphs and \"partial mappings\" that preserve the multigraph structure: formula_17. Thus a rewriting step is defined by a single pushout diagram. Practical understanding of this is similar to the DPO approach. The difference is, that there is no interface between the host graph G and the graph G' being the result of the rewriting step.\n\nFrom the practical perspective, the key distinction between DPO and SPO is how they deal with the deletion of nodes with adjacent edges, in particular, how they avoid that such deletions may leave behind \"dangling edges\". The DPO approach only deletes a node when the rule specifies the deletion of all adjacent edges as well (this \"dangling condition\" can be checked for a given match), whereas the SPO approach simply disposes the adjacent edges, without requiring an explicit specification.\n\nThere is also another algebraic-like approach to graph rewriting, based mainly on Boolean algebra and an algebra of matrices, called matrix graph grammars.\n\nYet another approach to graph rewriting, known as \"determinate\" graph rewriting, came out of logic and database theory. In this approach, graphs are treated as database instances, and rewriting operations as a mechanism for defining queries and views; therefore, all rewriting is required to yield unique results (up to isomorphism), and this is achieved by applying any rewriting rule concurrently throughout the graph, wherever it applies, in such a way that the result is indeed uniquely defined.\n\nAnother approach to graph rewriting is term graph rewriting, which involves the processing or transformation of term graphs (also known as \"abstract semantic graphs\") by a set of syntactic rewrite rules.\n\nTerm graphs are a prominent topic in programming language research since term graph rewriting rules are capable of formally expressing a compiler's operational semantics. Term graphs are also used as abstract machines capable of modelling chemical and biological computations as well as graphical calculi such as concurrency models. Term graphs can perform automated verification and logical programming since they are well-suited to representing quantified statements in first order logic. Symbolic programming software is another application for term graphs, which are capable of representing and performing computation with abstract algebraic structures such as groups, fields and rings.\n\nThe TERMGRAPH conference focuses entirely on research into term graph rewriting and its applications.\n\nGraph rewriting systems naturally group into classes according to the kind of representation of graphs that are used and how the rewrites are expressed. The term graph grammar, otherwise equivalent to graph rewriting system or graph replacement system, is most often used in classifications. Some common types are:\n\nGraphs are an expressive, visual and mathematically precise formalism for modelling of objects (entities) linked by relations; objects are represented by nodes and relations between them by edges. Nodes and edges are commonly typed and attributed. Computations are described in this model by changes in the relations between the entities or by attribute changes of the graph elements. They are encoded in graph rewrite/graph transformation rules and executed by graph rewrite systems/graph transformation tools.\n\n\n\n\n"}
{"id": "68274", "url": "https://en.wikipedia.org/wiki?curid=68274", "title": "Hero of Alexandria", "text": "Hero of Alexandria\n\nHero of Alexandria (; , \"Heron ho Alexandreus\"; also known as Heron of Alexandria ; c. 10 AD – c. 70 AD) was a mathematician and engineer who was active in his native city of Alexandria, Roman Egypt. He is considered the greatest experimenter of antiquity and his work is representative of the Hellenistic scientific tradition.\n\nHero published a well recognized description of a steam-powered device called an \"aeolipile\" (sometimes called a \"Hero engine\"). Among his most famous inventions was a windwheel, constituting the earliest instance of wind harnessing on land. He is said to have been a follower of the atomists. Some of his ideas were derived from the works of Ctesibius.\n\nMuch of Hero's original writings and designs have been lost, but some of his works were preserved - mostly in manuscripts from the Eastern Roman Empire, and a smaller part in Latin or Arabic translations.\n\nHero may have been either a Greek or a Hellenized Egyptian. It is almost certain that Hero taught at the Musaeum which included the famous Library of Alexandria, because most of his writings appear as lecture notes for courses in mathematics, mechanics, physics, and pneumatics. Although the field was not formalized until the twentieth century, it is thought that the work of Hero, his automated devices in particular, represents some of the first formal research into cybernetics.\n\nHero described the construction of the \"aeolipile\" (a version of which is known as \"Hero's engine\") which was a rocket-like reaction engine and the first-recorded steam engine (although Vitruvius mentioned the aeolipile in De Architectura some 100 years earlier than Hero). It was created almost two millennia before the industrial revolution. Another engine used air from a closed chamber heated by an altar fire to displace water from a sealed vessel; the water was collected and its weight, pulling on a rope, opened temple doors. Some historians have conflated the two inventions to assert that the aeolipile was capable of useful work.\n\n\nHero described a method for iteratively computing the square root of a number. Today, however, his name is most closely associated with Hero's formula for finding the area of a triangle from its side lengths. He also devised a method for calculating cube roots in the 1st century CE.\n\n\nThe most comprehensive edition of Hero's works was published in five volumes in Leipzig by the publishing house Teubner in 1903.\n\nWorks known to have been written by Hero:\n\nWorks that sometimes have been attributed to Hero, but are now thought most likely to have been written by someone else:\n\nWorks that are preserved only in fragments:\n\n\n\n"}
{"id": "12392648", "url": "https://en.wikipedia.org/wiki?curid=12392648", "title": "Hexaflake", "text": "Hexaflake\n\nA hexaflake is a fractal constructed by iteratively exchanging each hexagon by a flake of seven hexagons; it is a special case of the \"n\"-flake.\n\nA hexaflake has 7 hexagons in its \"n\"th iteration, each smaller by 1/3 than the hexagons in the previous iteration. Its exterior boundary is the von Koch flake, and the full boundary contains an infinite number of Koch snowflakes. The Hausdorff dimension of the hexaflake is equal to ln(7)/ln(3), approximately 1.7712. It may also be constructed by projecting the Cantor cube onto the plane orthogonal to its main diagonal.\n\nA closely related fractal, the Sierpinski hexagon, is formed by repeatedly replacing each hexagon by six smaller hexagons, omitting the central seventh hexagon. It is named after the work of Wacław Sierpiński and by analogy to the Sierpinski triangle, and has the same Koch snowflake exterior boundary as the hexaflake.\n\nThe hexaflake has been applied in the design of antennas and optical fibers.\n\n\n"}
{"id": "13660", "url": "https://en.wikipedia.org/wiki?curid=13660", "title": "Homeomorphism", "text": "Homeomorphism\n\nIn the mathematical field of topology, a homeomorphism or topological isomorphism or bi continuous function is a continuous function between topological spaces that has a continuous inverse function. Homeomorphisms are the isomorphisms in the category of topological spaces—that is, they are the mappings that preserve all the topological properties of a given space. Two spaces with a homeomorphism between them are called homeomorphic, and from a topological viewpoint they are the same. The word \"homeomorphism\" comes from the Greek words \"ὅμοιος\" (\"homoios\") = similar or same and \"μορφή\" (\"morphē\") = shape, form, introduced to mathematics by Henri Poincaré in 1895. \n\nVery roughly speaking, a topological space is a geometric object, and the homeomorphism is a continuous stretching and bending of the object into a new shape. Thus, a square and a circle are homeomorphic to each other, but a sphere and a torus are not. However, this description can be misleading. Some continuous deformations are not homeomorphisms, such as the deformation of a line into a point. Some homeomorphisms are not continuous deformations, such as the homeomorphism between a trefoil knot and a circle.\n\nAn often-repeated mathematical joke is that topologists can't tell the difference between a coffee cup and a donut, since a sufficiently pliable donut could be reshaped to the form of a coffee cup by creating a dimple and progressively enlarging it, while preserving the donut hole in a cup's handle.\n\nA function formula_1 between two topological spaces is a homeomorphism if it has the following properties:\n\n\nA homeomorphism is sometimes called a bicontinuous function. If such a function exists, we say formula_6 and formula_7 are homeomorphic. A self-homeomorphism is a homeomorphism from a topological space onto itself. \"Being homeomorphic\" is an equivalence relation on topological spaces. Its equivalence classes are called homeomorphism classes.\n\n\n\nThe third requirement, that formula_20 be continuous, is essential. Consider for instance the function formula_21 (the unit circle in formula_22) defined byformula_23. This function is bijective and continuous, but not a homeomorphism (formula_24 is compact but formula_25 is not). The function formula_20 is not continuous at the point formula_27, because although formula_20 maps formula_27 to formula_30, any neighbourhood of this point also includes points that the function maps close to formula_31, but the points it maps to numbers in between lie outside the neighbourhood.\n\nHomeomorphisms are the isomorphisms in the category of topological spaces. As such, the composition of two homeomorphisms is again a homeomorphism, and the set of all self-homeomorphisms formula_32 forms a group, called the homeomorphism group of \"X\", often denoted formula_33. This group can be given a topology, such as the compact-open topology, which under certain assumptions makes it a topological group.\n\nFor some purposes, the homeomorphism group happens to be too big, but by means of the isotopy relation, one can reduce this group to the mapping class group.\n\nSimilarly, as usual in category theory, given two spaces that are homeomorphic, the space of homeomorphisms between them, formula_34, is a torsor for the homeomorphism groups formula_33 and formula_36, and, given a specific homeomorphism between formula_6 and formula_7, all three sets are identified.\n\n\nThe intuitive criterion of stretching, bending, cutting and gluing back together takes a certain amount of practice to apply correctly—it may not be obvious from the description above that deforming a line segment to a point is impermissible, for instance. It is thus important to realize that it is the formal definition given above that counts. In this case, for example, the line segment possesses infinitely many points, and therefore cannot be put into a bijection with a set containing only a finite number of points, including a single point.\n\nThis characterization of a homeomorphism often leads to a confusion with the concept of homotopy, which is actually \"defined\" as a continuous deformation, but from one \"function\" to another, rather than one space to another. In the case of a homeomorphism, envisioning a continuous deformation is a mental tool for keeping track of which points on space \"X\" correspond to which points on \"Y\"—one just follows them as \"X\" deforms. In the case of homotopy, the continuous deformation from one map to the other is of the essence, and it is also less restrictive, since none of the maps involved need to be one-to-one or onto. Homotopy does lead to a relation on spaces: homotopy equivalence.\n\nThere is a name for the kind of deformation involved in visualizing a homeomorphism. It is (except when cutting and regluing are required) an isotopy between the identity map on \"X\" and the homeomorphism from \"X\" to \"Y\".\n\n\n"}
{"id": "29633061", "url": "https://en.wikipedia.org/wiki?curid=29633061", "title": "Kallman–Rota inequality", "text": "Kallman–Rota inequality\n\nIn mathematics, the Kallman–Rota inequality, introduced by , is a generalization of the Landau–Kolmogorov inequality to Banach spaces. It states that \nif \"A\" is the infinitesimal generator of a one-parameter contraction semigroup then\n"}
{"id": "27290087", "url": "https://en.wikipedia.org/wiki?curid=27290087", "title": "Ketan Mulmuley", "text": "Ketan Mulmuley\n\nKetan Mulmuley is a professor in the Department of Computer Science at the University of Chicago, and a sometime visiting professor at IIT Bombay. He specializes in theoretical computer science, especially computational complexity theory, and in recent years has been working on \"geometric complexity theory\", an approach to the P versus NP problem through the techniques of algebraic geometry, with Milind Sohoni of IIT Bombay. He is also known for his result with Umesh Vazirani and Vijay Vazirani that showed that \"Matching is as easy as matrix inversion\", in a paper that introduced the isolation lemma.\n\nHe earned his PhD in computer science from Carnegie Mellon University in 1985 under Dana Scott, winning the 1986 ACM Doctoral Dissertation Award for his thesis \"Full Abstraction and Semantic Equivalence\". He also won a Miller fellowship at the University of California, Berkeley for 1985–1987, and a Guggenheim Foundation Fellowship for the year 1999–2000.\n\n\n"}
{"id": "181417", "url": "https://en.wikipedia.org/wiki?curid=181417", "title": "Knaster–Tarski theorem", "text": "Knaster–Tarski theorem\n\nIn the mathematical areas of order and lattice theory, the Knaster–Tarski theorem, named after Bronisław Knaster and Alfred Tarski, states the following:\n\nIt was Tarski who stated the result in its most general form, and so the theorem is often known as Tarski's fixed point theorem. Some time earlier, Knaster and Tarski established the result for the special case where \"L\" is the lattice of subsets of a set, the power set lattice.\n\nThe theorem has important applications in formal semantics of programming languages and abstract interpretation.\n\nA kind of converse of this theorem was proved by Anne C. Davis: If every order preserving function \"f : L → L\" on a lattice \"L\" has a fixed point, then \"L\" is a complete lattice.\n\nSince complete lattices cannot be empty (they must contain supremum of empty set), the theorem in particular guarantees the existence of at least one fixed point of \"f\", and even the existence of a \"least\" (or \"greatest\") fixed point. In many practical cases, this is the most important implication of the theorem.\n\nThe least fixpoint of \"f\" is the least element \"x\" such that \"f\"(\"x\") = \"x\", or, equivalently, such that \"f\"(\"x\") ≤ \"x\"; the dual holds for the greatest fixpoint, the greatest element \"x\" such that \"f\"(\"x\") = \"x\".\n\nIf \"f\"(lim \"x\")=lim \"f\"(\"x\") for all ascending sequences \"x\", then the least fixpoint of \"f\" is lim \"f\"(0) where 0 is the least element of L, thus giving a more \"constructive\" version of the theorem. (See: Kleene fixed-point theorem.) More generally, if \"f\" is monotonic, then the least fixpoint of \"f\" is the stationary limit of \"f\"(0), taking α over the ordinals, where \"f\" is defined by transfinite induction: \"f\" = \"f\" ( \"f\") and \"f\" for a limit ordinal γ is the least upper bound of the \"f\" for all β ordinals less than γ. The dual theorem holds for the greatest fixpoint.\n\nFor example, in theoretical computer science, least fixed points of monotone functions are used to define program semantics. Often a more specialized version of the theorem is used, where \"L\" is assumed to be the lattice of all subsets of a certain set ordered by subset inclusion. This reflects the fact that in many applications only such lattices are considered. One then usually is looking for the smallest set that has the property of being a fixed point of the function \"f\". Abstract interpretation makes ample use of the Knaster–Tarski theorem and the formulas giving the least and greatest fixpoints.\n\nKnaster–Tarski theorem can be used for a simple proof of the Cantor–Bernstein–Schroeder theorem.\n\nWeaker versions of the Knaster–Tarski theorem can be formulated for ordered sets, but involve more complicated assumptions. For example:\n\nThis can be applied to obtain various theorems on invariant sets, e.g. the Ok's theorem:\n\nIn particular, using the Knaster-Tarski principle one can develop the theory of global attractors for noncontractive discontinuous (multivalued) iterated function systems. For weakly contractive iterated function systems Kantorovitch fixpoint theorem suffices.\n\nOther applications of fixed point principles for ordered sets come from the theory of differential, integral and operator equations.\n\nLet's restate the theorem.\n\nFor a complete lattice formula_3 and a monotone function formula_4 on \"L\", the set of all fixpoints of \"f\" is also a complete lattice formula_5, with:\n\n\"Proof.\" We begin by showing that \"P\" has least and greatest element. Let \"D\" = { \"x\" | \"x\" ≤ \"f(x)\" } and \"x\" ∈ \"D\" (we know that at least \"0\" belongs to \"D\"). Then because \"f\" is monotone we have \"f(x)\" ≤ \"f(f(x))\", that is \"f(x)\" ∈ \"D\".\n\nNow let formula_8 (u exists because \"D\" ⊆ \"L\"). Then for all \"x\" ∈ \"D\" it is true that \"x\" ≤ \"u\" and \"f(x)\" ≤ \"f(u)\", so \"x\" ≤ \"f(x)\" ≤ \"f(u)\". Therefore, \"f(u)\" is an upper bound of \"D\", but \"u\" is the least upper bound, so \"u\" ≤ \"f(u)\", i.e. \"u\" ∈ \"D\". Then \"f(u)\" ∈ \"D\" (because \"f(u)\" ≤ \"f(f(u))\") and so \"f(u)\" ≤ \"u\" from which follows \"f(u)\" = \"u\". Because every fixpoint is in \"D\" we have that \"u\" is the greatest fixpoint of \"f\".\n\nThe function \"f\" is monotone on the dual (complete) lattice formula_9. As we have just proved, its greatest fixpoint there exists. It is the least one on \"L\", so \"P\" has least and greatest elements, or more generally that every monotone function on a complete lattice has least and greatest fixpoints.\n\nIf \"a\" ∈ \"L\" and \"b\" ∈ \"L\", we'll write [\"a\", \"b\"] for the closed interval with bounds \"a\" and \"b\": { x ∈ \"L\" | \"a\" ≤ x ≤ \"b\" }. If \"a\" ≤ \"b\", then [\"a\", \"b\"] is a complete lattice.\n\nIt remains to be proven that P is a complete lattice. Let formula_10, \"W\" ⊆ \"P\" and formula_11. We′ll show that \"f\"([\"w\", \"1\"]) ⊆ [\"w\", \"1\"]. Indeed, for every \"x\" ∈ \"W\" we have \"x\" = \"f(x)\" ≤ \"f(w)\". Since \"w\" is the least upper bound of \"W\", \"w\" ≤ \"f(w)\". Then from \"y\" ∈ [\"w\", \"1\"] follows that \"w\" ≤ \"f(w)\" ≤ \"f(y)\", giving \"f(y)\" ∈ [\"w\", \"1\"] or simply \"f\"([\"w\", \"1\"]) ⊆ [\"w\", \"1\"]. This allows us to look at \"f\" as a function on the complete lattice [\"w\", \"1\"]. Then it has a least fixpoint there, giving us the least upper bound of \"W\". We′ve shown that an arbitrary subset of \"P\" has a supremum, which turns \"P\" into a complete lattice.\n\n\n\n\n"}
{"id": "27998286", "url": "https://en.wikipedia.org/wiki?curid=27998286", "title": "LH (complexity)", "text": "LH (complexity)\n\nIn computational complexity, the logarithmic time hierarchy (LH) is the complexity class of all computational problems solvable in a logarithmic amount of computation time on an alternating Turing machine with a bounded number of alternations. It is a special case of the hierarchy of bounded alternating Turing machines. It is equal to FO and to FO-uniform AC0. \n\nThe formula_1th level of the logarithmic time hierarchy is the set of languages recognised by alternating Turing machines in logarithmic time with random access and formula_2 alternations, beginning with an existential state. LH is the union of all levels.\n"}
{"id": "19080350", "url": "https://en.wikipedia.org/wiki?curid=19080350", "title": "Lambert summation", "text": "Lambert summation\n\nIn mathematical analysis, Lambert summation is a summability method for a class of divergent series.\n\nA series formula_1 is \"Lambert summable\" to \"A\", written formula_2, if\n\nIf a series is convergent to \"A\" then it is Lambert summable to \"A\" (an Abelian theorem).\n\n\n\n"}
{"id": "4954950", "url": "https://en.wikipedia.org/wiki?curid=4954950", "title": "List of common coordinate transformations", "text": "List of common coordinate transformations\n\nThis is a list of some of the most commonly used coordinate transformations.\n\nLet (x, y) be the standard Cartesian coordinates, and r and θ the standard polar coordinates.\n\nBy using complex numbers formula_3, the transformation can be written as\n\nI.e., it is given by the complex exponential function.\n\nNote: solving for formula_9 returns the resultant angle in the first quadrant (formula_10). To find formula_11, one must refer to the original Cartesian coordinate, determine the quadrant in which formula_11 lies (ex (3,-3) [Cartesian] lies in QIV), then use the following to solve for formula_11:\n\n\nThe value for formula_11 must be solved for in this manner because for all values of formula_11, formula_24 is only defined for formula_25, and is periodic (with period formula_26). This means that the inverse function will only give values in the domain of the function, but restricted to a single period. Hence, the range of the inverse function is only half a full circle.\n\nNote that one can also use\n\nWhere 2\"c\" is the distance between the poles.\n\nLet (x, y, z) be the standard Cartesian coordinates, and (ρ, θ, φ) the spherical coordinates, with θ the angle measured away from the +Z axis (as , see conventions in spherical coordinates). As φ has a range of 360° the same considerations as in polar (2 dimensional) coordinates apply whenever an arctangent of it is taken. θ has a range of 180°, running from 0° to 180°, and does not pose any problem when calculated from an arccosine, but beware for an arctangent. \n\nIf, in the alternative definition, \"θ\" is chosen to run from −90° to +90°, in opposite direction of the earlier definition, it can be found uniquely from an arcsine, but beware of an arccotangent. In this case in all formulas below all arguments in \"θ\" should have sine and cosine exchanged, and as derivative also a plus and minus exchanged.\n\nAll divisions by zero result in special cases of being directions along one of the main axes and are in practice most easily solved by observation.\n\nSo for the volume element:\n\nSo for the volume element:\n\nSee also the article on atan2 for how to elegantly handle some edge cases.\n\nSo for the element:\n"}
{"id": "23754958", "url": "https://en.wikipedia.org/wiki?curid=23754958", "title": "Lucio Lombardo-Radice", "text": "Lucio Lombardo-Radice\n\nLucio Lombardo-Radice (Catania, 10 July 1916; Bruxelles, 21 November 1982) was an Italian mathematician. A student of Gaetano Scorza, Lombardo-Radice contributed to finite geometry and geometric combinatorics together with Guido Zappa and Beniamino Segre, and wrote important works concerning the Non-Desarguesian plane. He was also a leading member of the Italian Communist Party and a member of its central committee.\n\nThe Istituto Tecnico Statale Commerciale \"Lucio Lombardo Radice\" per Programmatori, a school in Rome, Italy, founded in 1982 as the XXV Istituto Tecnico Commerciale per Programmatori, was in 1992 renamed after Lombardo-Radice. It is now name Istituto di Istruzione Superiore Lombardo Radice\n"}
{"id": "13290757", "url": "https://en.wikipedia.org/wiki?curid=13290757", "title": "Metagame analysis", "text": "Metagame analysis\n\nMetagame analysis involves framing a problem situation as a strategic game in which participants try to realise their objectives by means of the options available to them. The subsequent meta-analysis of this game gives insight in possible strategies and their outcome.\n\nMetagame theory was developed by Nigel Howard in the 1960s as a reconstruction of mathematical game theory on a non-quantitative basis, hoping that it would thereby make more practical and intuitive sense . Metagame analysis reflects on a problem in terms of decision issues, and stakeholders who may exert different options to gain control over these issues. The analysis reveals what likely scenarios exist, and who has the power to control the course of events. The practical application of metagame theory is based on the analysis of options method, first applied to study problems like the strategic arms race and nuclear proliferation.\n\nMetagame analysis proceeds in three phases: analysis of options, scenario development, and scenario analysis.\n\nThe first phase of analysis of options consists of the following four steps:\n\n\nThe dependencies between options should typically be formulated as \"option X can only be implemented if option Y is also implemented\", or \"options Y and Z are mutually exclusive\". The result is a metagame model, which can then be analysed in different ways.\n\nThe possible outcomes of the game, based on the combination of options, are called scenarios. In theory, a game with N stakeholders s, ..., s who have Oi options (i = 1, ..., N), there are O×...×O possible outcomes. As the number of stakeholders and the number of the options they have increase, the number of scenarios will increase steeply due to a combinatorial explosion. Conversely, the dependencies between options will reduce the number of scenarios, because they rule out those containing logically or physically impossible combinations of options.\n\nIf the set of feasible scenarios is too large to be analysed in full, some combinations may be eliminated because the analyst judges them to be not worth considering. When doing so, the analyst should take care to preserve these particular types of scenarios :\n\n\nThe next step in the metagame analysis consists of the actual analysis of the scenarios generated so far. This analysis centres around stability and is broken down in the following four steps :\n\nThis analysis procedure shows that the credibility of threats and promises (sanctions and improvements) is of importance in metagame analysis. A threat or promise, one that the stakeholder prefers to carry out for its own sake, is inherently credible. Sometimes a stakeholder may want to make credible an 'involuntary' threat or promise, to use this to move the situation in the desired direction. Such threats and promises can be made credible in three basic ways: preference change, irrationality, and deceit .\n\nMetagame analysis is still used as a technique in its own right. However it has been further developed in distinct ways as the basis of more recent approaches:\n"}
{"id": "18977553", "url": "https://en.wikipedia.org/wiki?curid=18977553", "title": "N! conjecture", "text": "N! conjecture\n\nIn mathematics, the \"n\"! conjecture is the conjecture that the dimension of a certain bi-graded module of diagonal harmonics is \"n\"!. It was made by A. M. Garsia and M. Haiman and later proved by M. Haiman. It implies Macdonald's positivity conjecture about the Macdonald polynomials.\n\nThe Macdonald polynomials formula_1 are a two-parameter family of orthogonal polynomials indexed by a positive weight λ of a root system, introduced by Ian G. Macdonald (1987). They generalize several other families of orthogonal polynomials, such as Jack polynomials and Hall–Littlewood polynomials. They are known to have deep relationships with affine Hecke algebras and Hilbert schemes, which were used to prove several conjectures made by Macdonald about them.\n\nIn fact, we can obtain in this manner the Schur functions, the Hall–Littlewood symmetric functions, the Jack symmetric functions, the zonal symmetric functions, the zonal spherical functions, and the elementary and monomial symmetric functions.\n\nThe so-called (\"q\",\"t\")-Kostka polynomials are the coefficients of a resulting transition matrix. Macdonald conjectured that they are polynomials in \"q\" and \"t\", with non-negative integer coefficients.\n\nIt was Adriano Garsia's idea to construct an appropriate module in order to prove positivity (as was done in his previous joint work with Procesi on Schur positivity of Kostka–Foulkes polynomials).\n\nIn an attempt to prove Macdonald's conjecture, introduced the bi-graded module formula_2 of diagonal harmonics and conjectured that the (modified) Macdonald polynomials are the Frobenius image of the character generating function of \"H\", under the diagonal action of the symmetric group.\n\nThe proof of Macdonald's conjecture was then reduced to the \"n\"! conjecture; i.e., to prove that the dimension of \"H\" is \"n\"!. In 2001, Haiman proved that the dimension is indeed \"n\"! (see [4]).\n\nThis breakthrough led to the discovery of many hidden connections and new aspects of symmetric group representation theory, as well as combinatorial objects (e.g., insertion tableaux, Haglund's inversion numbers, and the role of parking functions in representation theory).\n\n\n"}
{"id": "4140245", "url": "https://en.wikipedia.org/wiki?curid=4140245", "title": "Operation (mathematics)", "text": "Operation (mathematics)\n\nIn mathematics, an operation is a calculation from zero or more input values (called \"operands\") to an output value. The number of operands is the arity of the operation. The most commonly studied operations are binary operations, (that is, operations of arity 2) such as addition and multiplication, and unary operations (operations of arity 1), such as additive inverse and multiplicative inverse. An operation of arity zero, or nullary operation, is a constant. The mixed product is an example of an operation of arity 3, also called ternary operation. Generally, the arity is supposed to be finite. However, infinitary operations are sometimes considered, in which context the \"usual\" operations of finite arity are called finitary operations.\n\nThere are two common types of operations: unary and binary. Unary operations involve only one value, such as negation and trigonometric functions. Binary operations, on the other hand, take two values, and include addition, subtraction, multiplication, division, and exponentiation.\n\nOperations can involve mathematical objects other than numbers. The logical values \"true\" and \"false\" can be combined using logic operations, such as \"and\", \"or,\" and \"not\". Vectors can be added and subtracted. Rotations can be combined using the function composition operation, performing the first rotation and then the second. Operations on sets include the binary operations \"union\" and \"intersection\" and the unary operation of \"complementation\". Operations on functions include composition and convolution.\n\nOperations may not be defined for every possible value. For example, in the real numbers one cannot divide by zero or take square roots of negative numbers. The values for which an operation is defined form a set called its \"domain\". The set which contains the values produced is called the \"codomain\", but the set of actual values attained by the operation is its \"range\". For example, in the real numbers, the squaring operation only produces non-negative numbers; the codomain is the set of real numbers, but the range is the non-negative numbers.\n\nOperations can involve dissimilar objects. A vector can be multiplied by a scalar to form another vector. And the inner product operation on two vectors produces a scalar. An operation may or may not have certain properties, for example it may be associative, commutative, anticommutative, idempotent, and so on.\n\nThe values combined are called \"operands\", \"arguments\", or \"inputs\", and the value produced is called the \"value\", \"result\", or \"output\". Operations can have fewer or more than two inputs.\n\nAn operation is like an operator, but the point of view is different. For instance, one often speaks of \"the operation of addition\" or \"addition operation\" when focusing on the operands and result, but one says \"addition operator\" (rarely \"operator of addition\") when focusing on the process, or from the more abstract viewpoint, the function .\n\nAn operation ω is a function of the form , where . The sets \"X\" are called the \"domains\" of the operation, the set \"Y\" is called the \"codomain\" of the operation, and the fixed non-negative integer \"k\" (the number of arguments) is called the \"type\" or \"arity\" of the operation. Thus a unary operation has arity one, and a binary operation has arity two. An operation of arity zero, called a \"nullary\" operation, is simply an element of the codomain \"Y\". An operation of arity \"k\" is called a \"k\"-ary operation. Thus a \"k\"-ary operation is a (\"k\"+1)-ary relation that is functional on its first \"k\" domains.\n\nThe above describes what is usually called a \"finitary\" operation, referring to the finite number of arguments (the value \"k\"). There are obvious extensions where the arity is taken to be an infinite ordinal or cardinal, or even an arbitrary set indexing the arguments.\n\nOften, use of the term \"operation\" implies that the domain of the function is a power of the codomain (i.e. the Cartesian product of one or more copies of the codomain), although this is by no means universal, as in the example of multiplying a vector by a scalar.\n\n"}
{"id": "6473191", "url": "https://en.wikipedia.org/wiki?curid=6473191", "title": "Outline of arithmetic", "text": "Outline of arithmetic\n\nArithmetic is an elementary branch of mathematics that is used by almost everyone for tasks ranging from simple day-to-day counting to advanced science and business calculations. \n\n\n\n\n\n\n\n"}
{"id": "39409306", "url": "https://en.wikipedia.org/wiki?curid=39409306", "title": "Peter Scholze", "text": "Peter Scholze\n\nPeter Scholze (born 11 December 1987) is a German mathematician known for his work in algebraic geometry. He has been a professor at the University of Bonn since 2012, and director at the Max Planck Institute for Mathematics since 2018. He has been called one of the leading mathematicians in the world. He won the Fields Medal in 2018, which is regarded as the highest professional honor in mathematics.\n\nScholze was born in Dresden and grew up in Berlin. He attended the in Berlin-Friedrichshain, a gymnasium devoted to mathematics and science. As a student, Scholze participated in the International Mathematical Olympiad, winning three gold medals and one silver medal.\n\nHe studied at the University of Bonn and completed his Bachelor's degree in three semesters and his Master's degree in two further semesters. He obtained his Ph.D. in 2012 under the supervision of Michael Rapoport.\n\nFrom July 2011 until 2016, Scholze was a Research Fellow of the Clay Mathematics Institute in New Hampshire. In 2012 shortly after completing his PhD, he was made full professor at the University of Bonn, becoming the youngest full professor in Germany at the age of 24. \nIn Fall 2014, Scholze was appointed the Chancellor's Professor at University of California, Berkeley, where he taught a course on p-adic geometry. \nIn 2018, Scholze was appointed as a director of the Max Planck Institute for Mathematics in Bonn.\n\nScholze's work has concentrated on purely local aspects of arithmetic geometry such as \"p\"-adic geometry and its applications. He presented in a more compact form some of the previous fundamental theories pioneered by Gerd Faltings, Jean-Marc Fontaine and later by Kiran Kedlaya. His PhD thesis on perfectoid spaces yields the solution to a special case of the weight-monodromy conjecture.\n\nIn 2012, he was awarded the Prix and Cours Peccot. He was awarded the 2013 SASTRA Ramanujan Prize. In 2014, he received the Clay Research Award. In 2015, he was awarded the Frank Nelson Cole Prize in Algebra, and the Ostrowski Prize.\n\nHe received the Fermat Prize 2015 from the Institut de Mathématiques de Toulouse. In 2016, he was awarded the Leibniz Prize 2016 by the German Research Foundation. He declined the $100,000 \"New Horizons in Mathematics Prize\" of the 2016 Breakthrough Prizes by Yuri Milner, Mark Zuckerberg and others who use large cash prizes, and Hollywood style promotion \"to make scientists celebrities again\". Scholze’s turning down of the prize received little to no media attention.\n\nHe was awarded the Fields Medal in 2018, for \"transforming arithmetic algebraic geometry over p-adic fields through his introduction of perfectoid spaces, with application to Galois representations, and for the development of new cohomology theories.\"\n\nScholze is married to a fellow mathematician and has a daughter.\n\n"}
{"id": "57231802", "url": "https://en.wikipedia.org/wiki?curid=57231802", "title": "Point-normal triangle", "text": "Point-normal triangle\n\nThe curved point-normal triangle, in short PN triangle, is an interpolation algorithm to retrieve a cubic Bézier triangle from the vertex coordinates of a regular flat triangle and normal vectors. The PN triangle retains the vertices of the flat triangle as well as the corresponding normals. It was first introduced by A. Vlachos et al. in 2001 and is primarily used in the field of computer graphics. The usage of the PN triangle enables the visualization of triangle based surfaces in a smoother shape at low cost in terms of rendering complexity and time.\nWith information of the given vertex positions formula_1 of a flat triangle and the according normal vectors formula_2 at the vertices a cubic Bézier triangle is constructed. In contrast to the notation of the Bézier triangle page the nomenclature follows G. Farin (2002), therefore we denote the 10 control points as formula_3 with the positive indices holding the condition formula_4.\n\nThe first three control points are equal to the given vertices.formula_5Six control points related to the triangle edges, i.e. formula_6 are computed asformula_7This definition ensures that the original vertex normals are reproduced in the interpolated triangle.\n\nFinally the internal control point formula_8is derived from the previously calculated control points asformula_9\n"}
{"id": "2137523", "url": "https://en.wikipedia.org/wiki?curid=2137523", "title": "Prewellordering", "text": "Prewellordering\n\nIn set theory, a prewellordering is a binary relation formula_1 that is transitive, total, and wellfounded (more precisely, the relation formula_2 is wellfounded). In other words, if formula_3 is a prewellordering on a set formula_4, and if we define formula_5 by\nthen formula_5 is an equivalence relation on formula_4, and formula_3 induces a wellordering on the quotient formula_10. The order-type of this induced wellordering is an ordinal, referred to as the length of the prewellordering.\n\nA norm on a set formula_4 is a map from formula_4 into the ordinals. Every norm induces a prewellordering; if formula_13 is a norm, the associated prewellordering is given by\nConversely, every prewellordering is induced by a unique regular norm (a norm formula_13 is regular if, for any formula_16 and any formula_17, there is formula_18 such that formula_19).\n\nIf formula_20 is a pointclass of subsets of some collection formula_21 of Polish spaces, formula_21 closed under Cartesian product, and if formula_3 is a prewellordering of some subset formula_24 of some element formula_4 of formula_21, then formula_3 is said to be a formula_20-prewellordering of formula_24 if the relations formula_30 and formula_31 are elements of formula_20, where for formula_33,\n\nformula_20 is said to have the prewellordering property if every set in formula_20 admits a formula_20-prewellordering.\n\nThe prewellordering property is related to the stronger scale property; in practice, many pointclasses having the prewellordering property also have the scale property, which allows drawing stronger conclusions.\n\nformula_39 and formula_40 both have the prewellordering property; this is provable in ZFC alone. Assuming sufficient large cardinals, for every formula_41, formula_42 and formula_43\nhave the prewellordering property.\n\nIf formula_20 is an adequate pointclass with the prewellordering property, then it also has the reduction property: For any space formula_45 and any sets formula_46, formula_47 and formula_48 both in formula_20, the union formula_50 may be partitioned into sets formula_51, both in formula_20, such that formula_53 and formula_54.\n\nIf formula_20 is an adequate pointclass whose dual pointclass has the prewellordering property, then formula_20 has the separation property: For any space formula_45 and any sets formula_46, formula_47 and formula_48 \"disjoint\" sets both in formula_20, there is a set formula_62 such that both formula_63 and its complement formula_64 are in formula_20, with formula_66 and formula_67.\n\nFor example, formula_39 has the prewellordering property, so formula_69 has the separation property. This means that if formula_47 and formula_48 are disjoint analytic subsets of some Polish space formula_4, then there is a Borel subset formula_63 of formula_4 such that formula_63 includes formula_47 and is disjoint from formula_48.\n\n"}
{"id": "1820881", "url": "https://en.wikipedia.org/wiki?curid=1820881", "title": "Publications Mathématiques de l'IHÉS", "text": "Publications Mathématiques de l'IHÉS\n\nPublications Mathématiques de l'IHÉS is a mathematical journal. It is published by Institut des Hautes Études Scientifiques, with the help of the Centre National de la Recherche Scientifique.\n\n\"Publications Mathématiques\" was founded in 1959 and was published at irregular intervals, from one to five volumes a year. It is now biannual. \nThe current editor in chief is Claire Voisin, professor at the Collège de France.\n\n"}
{"id": "31441193", "url": "https://en.wikipedia.org/wiki?curid=31441193", "title": "Rectified Gaussian distribution", "text": "Rectified Gaussian distribution\n\nIn probability theory, the rectified Gaussian distribution is a modification of the Gaussian distribution when its negative elements are reset to 0 (analogous to an electronic rectifier). It is essentially a mixture of a discrete distribution (constant 0) and a continuous distribution (a truncated Gaussian distribution with interval formula_1) as a result of censoring.\n\nThe probability density function of a rectified Gaussian distribution, for which random variables \"X\" having this distribution, derived from the normal distribution formula_2 are displayed as formula_3, is given by\n\nHere, formula_5 is the cumulative distribution function (cdf) of the standard normal distribution:\nformula_7 is the Dirac delta function\nand, formula_9 is the unit step function:\n\nSince the unrectified normal distribution has mean formula_11 and since in transforming it to the rectified distribution some probability mass has been shifted to a higher value (from negative values to 0), the mean of the rectified distribution is greater than formula_12\n\nSince the rectified distribution is formed by moving some of the probability mass toward the rest of the probability mass, the rectification is a mean-preserving contraction combined with a mean-changing rigid shift of the distribution, and thus the variance is decreased; therefore the variance of the rectified distribution is less than formula_13\n\nTo generate values computationally, one can use\nand then\n\nA rectified Gaussian distribution is semi-conjugate to the Gaussian likelihood, and it has been recently applied to factor analysis, or particularly, (non-negative) rectified factor analysis.\nHarva proposed a variational learning algorithm for the rectified factor model, where the factors follow a mixture of rectified Gaussian; and later Meng proposed an infinite rectified factor model coupled with its Gibbs sampling solution, where the factors follow a Dirichlet process mixture of rectified Gaussian distribution, and applied it in computational biology for reconstruction of gene regulatory networks.\n"}
{"id": "36102164", "url": "https://en.wikipedia.org/wiki?curid=36102164", "title": "Richard M. Pollack", "text": "Richard M. Pollack\n\nRichard M. Pollack (January 25, 1935 – September 18, 2018) was an American geometer who spent most of his career at the Courant Institute of Mathematical Sciences at New York University, where he was Professor Emeritus till his death. In 1986 he and Jacob E. Goodman were the founding co-editors-in-chief of the journal \"Discrete & Computational Geometry\" (Springer-Verlag).\n\nIn combinatorics he is known principally for his work with Paul Erdős and János Pach. In discrete geometry he is known for a number of basic concepts and results, jointly with his long term collaborator, Jacob E. Goodman; of the City College, City University of New York, and some with others. His work with Goodman includes such results as the first nontrivial bounds on the number of order types and polytopes, and a generalization \nof the Hadwiger transversal theorem to higher dimensions.\nIn real algebraic geometry he is known principally for a series of papers authored jointly with Saugata Basu and Marie-Françoise Roy and for their book.\n\nIn 2003, a collection of original research papers in discrete and computational geometry entitled \"Discrete and Computational Geometry: The Goodman–Pollack Festschrift\" was published as a tribute to Jacob E. Goodman and Richard Pollack on the occasion of their 2/3 × 100 birthdays.\n\nIn 2012 he became a fellow of the American Mathematical Society.\n\n"}
{"id": "29586", "url": "https://en.wikipedia.org/wiki?curid=29586", "title": "Sigma-algebra", "text": "Sigma-algebra\n\nIn mathematical analysis and in probability theory, a σ-algebra (also σ-field) on a set \"X\" is a collection Σ of subsets of \"X\" that\nincludes \"X\" itself,\nis closed under complement, and is closed under\ncountable unions\n(the definition implies that it also includes \nthe empty subset and that it is closed under countable intersections). \nThe pair (\"X\", Σ) is called a measurable space or Borel space.\n\nA σ-algebra is a type of algebra of sets. An algebra of sets needs only to be closed under the union or intersection of \"finitely\" many subsets, which is a weaker condition.\n\nThe main use of σ-algebras is in the definition of measures; specifically, the collection of those subsets for which a given measure is defined is necessarily a σ-algebra. This concept is important in mathematical analysis as the foundation for Lebesgue integration, and in probability theory, where it is interpreted as the collection of events which can be assigned probabilities. Also, in probability, σ-algebras are pivotal in the definition of conditional expectation.\n\nIn statistics, (sub) σ-algebras are needed for the formal mathematical definition of a sufficient statistic, particularly when the statistic is a function or a random process and the notion of conditional density is not applicable.\n\nIf one possible σ-algebra on \"X\" is where ∅ is the empty set. In general, a finite algebra is always a σ-algebra.\n\nIf {\"A\", \"A\", \"A\", …} is a countable partition of \"X\" then the collection of all unions of sets in the partition (including the empty set) is a σ-algebra.\n\nA more useful example is the set of subsets of the real line formed by starting with all open intervals and adding in all countable unions, countable intersections, and relative complements and continuing this process (by transfinite iteration through all countable ordinals) until the relevant closure properties are achieved (a construction known as the Borel hierarchy).\n\nThere are at least three key motivators for σ-algebras: defining measures, manipulating limits of sets, and managing partial information characterized by sets.\n\nA measure on \"X\" is a function that assigns a non-negative real number to subsets of \"X\"; this can be thought of as making precise a notion of \"size\" or \"volume\" for sets. We want the size of the union of disjoint sets to be the sum of their individual sizes, even for an infinite sequence of disjoint sets.\n\nOne would like to assign a size to \"every\" subset of \"X\", but in many natural settings, this is not possible. For example, the axiom of choice implies that when the size under consideration is the ordinary notion of length for subsets of the real line, then there exist sets for which no size exists, for example, the Vitali sets. For this reason, one considers instead a smaller collection of privileged subsets of \"X\". These subsets will be called the measurable sets. They are closed under operations that one would expect for measurable sets; that is, the complement of a measurable set is a measurable set and the countable union of measurable sets is a measurable set. Non-empty collections of sets with these properties are called σ-algebras.\n\nMany uses of measure, such as the probability concept of almost sure convergence, involve limits of sequences of sets. For this, closure under countable unions and intersections is paramount. Set limits are defined as follows on σ-algebras.\n\nIn much of probability, especially when conditional expectation is involved, one is concerned with sets that represent only part of all the possible information that can be observed. This partial information can be characterized with a smaller σ-algebra which is a subset of the principal σ-algebra; it consists of the collection of subsets relevant only to and determined only by the partial information. A simple example suffices to illustrate this idea.\n\nImagine you and another person are betting on a game that involves flipping a coin repeatedly and observing whether it comes up Heads (\"H\") or Tails (\"T\"). Since you and your opponent are each infinitely wealthy, there is no limit to how long the game can last. This means the sample space Ω must consist of all possible infinite sequences of \"H\" or \"T\":\n\nHowever, after \"n\" flips of the coin, you may want to determine or revise your betting strategy in advance of the next flip. The observed information at that point can be described in terms of the 2 possibilities for the first \"n\" flips. Formally, since you need to use subsets of Ω, this is codified as the σ-algebra\n\nObserve that then\n\nwhere formula_8 is the smallest σ-algebra containing all the others.\n\nLet \"X\" be some set, and let formula_9 represent its power set. Then a subset formula_10 is called a \"σ\"-algebra if it satisfies the following three properties:\n\n\nFrom these properties, it follows that the σ-algebra is also closed under countable intersections (by applying De Morgan's laws).\n\nIt also follows that the empty set ∅ is in Σ, since by (1) \"X\" is in Σ and (2) asserts that its complement, the empty set, is also in Σ. Moreover, since } satisfies condition (3) as well, it follows that } is the smallest possible σ-algebra on \"X\". The largest possible σ-algebra on \"X\" is 2:=formula_9.\n\nElements of the \"σ\"-algebra are called measurable sets. An ordered pair , where \"X\" is a set and Σ is a \"σ\"-algebra over \"X\", is called a measurable space. A function between two measurable spaces is called a measurable function if the preimage of every measurable set is measurable. The collection of measurable spaces forms a category, with the measurable functions as morphisms. Measures are defined as certain types of functions from a \"σ\"-algebra to [0, ∞].\n\nA σ-algebra is both a π-system and a Dynkin system (λ-system). The converse is true as well, by Dynkin's theorem (below).\n\nThis theorem (or the related monotone class theorem) is an essential tool for proving many results about properties of specific σ-algebras. It capitalizes on the nature of two simpler classes of sets, namely the following.\n\nDynkin's π-λ theorem says, if \"P\" is a π-system and \"D\" is a Dynkin system that contains \"P\" then the σ-algebra σ(\"P\") generated by \"P\" is contained in \"D\". Since certain π-systems are relatively simple classes, it may not be hard to verify that all sets in \"P\" enjoy the property under consideration while, on the other hand, showing that the collection \"D\" of all subsets with the property is a Dynkin system can also be straightforward. Dynkin's π-λ Theorem then implies that all sets in σ(\"P\") enjoy the property, avoiding the task of checking it for an arbitrary set in σ(\"P\").\n\nOne of the most fundamental uses of the π-λ theorem is to show equivalence of separately defined measures or integrals. For example, it is used to equate a probability for a random variable \"X\" with the Lebesgue-Stieltjes integral typically associated with computing the probability:\n\nwhere \"F\"(\"x\") is the cumulative distribution function for \"X\", defined on R, while formula_13 is a probability measure, defined on a σ-algebra Σ of subsets of some sample space Ω.\n\nSuppose formula_14 is a collection of σ-algebras on a space \"X\".\n\n\n\nSuppose \"Y\" is a subset of \"X\" and let (\"X\", Σ) be a measurable space.\n\nA \"σ\"-algebra Σ is just a \"σ\"-ring that contains the universal set \"X\". A \"σ\"-ring need not be a \"σ\"-algebra, as for example measurable subsets of zero Lebesgue measure in the real line are a \"σ\"-ring, but not a \"σ\"-algebra since the real line has infinite measure and thus cannot be obtained by their countable union. If, instead of zero measure, one takes measurable subsets of finite Lebesgue measure, those are a ring but not a \"σ\"-ring, since the real line can be obtained by their countable union yet its measure is not finite.\n\n\"σ\"-algebras are sometimes denoted using calligraphic capital letters, or the Fraktur typeface. Thus may be denoted as formula_23 or formula_24.\n\nA separable σ-algebra (or separable σ-field) is a σ-algebra formula_25 that is a separable space when considered as a metric space with metric formula_26 for formula_27 and a given measure formula_28 (and with formula_29 being the symmetric difference operator). Note that any σ-algebra generated by a countable collection of sets is separable, but the converse need not hold. For example, the Lebesgue σ-algebra is separable (since every Lebesgue measurable set is equivalent to some Borel set) but not countably generated (since its cardinality is higher than continuum).\n\nA separable measure space has a natural pseudometric that renders it separable as a pseudometric space. The distance between two sets is defined as the measure of the symmetric difference of the two sets. Note that the symmetric difference of two distinct sets can have measure zero; hence the pseudometric as defined above need not to be a true metric. However, if sets whose symmetric difference has measure zero are identified into a single equivalence class, the resulting quotient set can be properly metrized by the induced metric. If the measure space is separable, it can be shown that the corresponding metric space is, too.\n\nLet \"X\" be any set.\n\nA stopping time formula_30 can define a formula_31-algebra formula_32, the\nso-called formula_33-Algebra of τ-past, which in a filtered probability space describes the information up to the random time formula_30 in the sense that, if the filtered probability space is interpreted as a random experiment, the maximum information that can be found out about the experiment from arbitrarily often repeating it until the time formula_30 is formula_32.\n\nLet \"F\" be an arbitrary family of subsets of \"X\". Then there exists a unique smallest σ-algebra which contains every set in \"F\" (even though \"F\" may or may not itself be a σ-algebra). It is, in fact, the intersection of all σ-algebras containing \"F\". (See intersections of σ-algebras above.) This σ-algebra is denoted σ(\"F\") and is called the σ-algebra generated by \"F\".\n\nIf \"F\" is empty, then σ(\"F\")=}. Otherwise σ(\"F\") consists of all the subsets of \"X\" that can be made from elements of \"F\" by a countable number of complement, union and intersection operations.\n\nFor a simple example, consider the set \"X\" = {1, 2, 3}. Then the σ-algebra generated by the single subset {1} is </nowiki>}}. By an abuse of notation, when a collection of subsets contains only one element, \"A\", one may write σ(\"A\") instead of σ({\"A\"}); in the prior example σ({1}) instead of σ(<nowiki></nowiki>). Indeed, using to mean is also quite common.\n\nThere are many families of subsets that generate useful σ-algebras. Some of these are presented here.\n\nIf formula_37 is a function from a set formula_38 to a set formula_39 and formula_40 is a formula_31-algebra of subsets of formula_39, then the formula_31-algebra generated by the function formula_37, denoted by formula_45, is the collection of all inverse images formula_46 of the sets formula_47 in formula_40. i.e.\n\nA function \"f\" from a set \"X\" to a set \"Y\" is measurable with respect to a σ-algebra Σ of subsets of \"X\" if and only if σ(\"f\") is a subset of Σ.\n\nOne common situation, and understood by default if \"B\" is not specified explicitly, is when \"Y\" is a metric or topological space and \"B\" is the collection of Borel sets on \"Y\".\n\nIf \"f\" is a function from \"X\" to R then σ(\"f\") is generated by the family of subsets which are inverse images of intervals/rectangles in R:\n\nA useful property is the following. Assume \"f\" is a measurable map from (\"X\", Σ) to (\"S\", Σ) and \"g\" is a measurable map from (\"X\", Σ) to (\"T\", Σ). If there exists a measurable map \"h\" from (\"T\", Σ) to (\"S\", Σ) such that \"f\"(\"x\") = \"h\"(\"g\"(\"x\")) for all \"x\", then σ(\"f\") ⊂ σ(\"g\"). If \"S\" is finite or countably infinite or, more generally, (\"S\", Σ) is a standard Borel space (e.g., a separable complete metric space with its associated Borel sets), then the converse is also true. Examples of standard Borel spaces include R with its Borel sets and R with the cylinder σ-algebra described below.\n\nAn important example is the Borel algebra over any topological space: the σ-algebra generated by the open sets (or, equivalently, by the closed sets). Note that this σ-algebra is not, in general, the whole power set. For a non-trivial example that is not a Borel set, see the Vitali set or Non-Borel sets.\n\nOn the Euclidean space R, another σ-algebra is of importance: that of all Lebesgue measurable sets. This σ-algebra contains more sets than the Borel σ-algebra on R and is preferred in integration theory, as it gives a complete measure space.\n\nLet formula_51 and formula_52 be two measurable spaces. The σ-algebra for the corresponding product space formula_53 is called the product σ-algebra and is defined by\n\nObserve that formula_55 is a π-system.\n\nThe Borel σ-algebra for R is generated by half-infinite rectangles and by finite rectangles. For example,\n\nFor each of these two examples, the generating family is a π-system.\n\nSuppose\n\nis a set of real-valued functions. Let formula_58 denote the Borel subsets of R. A cylinder subset of is a finitely restricted set defined as\n\nEach\n\nis a π-system that generates a σ-algebra formula_61. Then the family of subsets\n\nis an algebra that generates the cylinder σ-algebra for . This σ-algebra is a subalgebra of the Borel σ-algebra determined by the product topology of formula_63 restricted to .\n\nAn important special case is when formula_64 is the set of natural numbers and is a set of real-valued sequences. In this case, it suffices to consider the cylinder sets\n\nfor which\n\nis a non-decreasing sequence of σ-algebras.\n\nSuppose formula_67 is a probability space. If formula_68 is measurable with respect to the Borel σ-algebra on R then is called a random variable (\"n = 1\") or random vector (\"n\" > 1). The σ-algebra generated by is\n\nSuppose formula_67 is a probability space and formula_71 is the set of real-valued functions on formula_64. If formula_73 is measurable with respect to the cylinder σ-algebra formula_74 (see above) for then is called a stochastic process or random process. The σ-algebra generated by is\n\nthe σ-algebra generated by the inverse images of cylinder sets.\n\n\n"}
{"id": "24394535", "url": "https://en.wikipedia.org/wiki?curid=24394535", "title": "Stanley–Reisner ring", "text": "Stanley–Reisner ring\n\nIn mathematics, a Stanley–Reisner ring is a quotient of a polynomial algebra over a field by a square-free monomial ideal. Such ideals are described more geometrically in terms of finite simplicial complexes. The Stanley–Reisner ring construction is a basic tool within algebraic combinatorics and combinatorial commutative algebra. Its properties were investigated by Richard Stanley, Melvin Hochster, and Gerald Reisner in the early 1970s.\n\nGiven an abstract simplicial complex Δ on the vertex set {\"x\"...,\"x\"} and a field k, the corresponding Stanley–Reisner ring, or face ring, denoted k[Δ], is obtained from the polynomial ring k[\"x\"...,\"x\"] by quotienting out the ideal \"I\" generated by the square-free monomials corresponding to the non-faces of Δ:\n\nThe ideal \"I\" is called the Stanley–Reisner ideal or the face ideal of Δ.\n\n\n\n\nIt is common to assume that every vertex {\"x\"} is a simplex in Δ. Thus none of the variables belongs to the Stanley–Reisner ideal \"I\".\n\n\n\n\n\nThe face ring k[Δ] is a multigraded algebra over k all of whose components with respect to the fine grading have dimension at most 1. Consequently, its homology can be studied by combinatorial and geometric methods. An abstract simplicial complex Δ is called Cohen–Macaulay over k if its face ring is a Cohen–Macaulay ring. In his 1974 thesis, Gerald Reisner gave a complete characterization of such complexes. This was soon followed up by more precise homological results about face rings due to Melvin Hochster. Then Richard Stanley found a way to prove the Upper Bound Conjecture for simplicial spheres, which was open at the time, using the face ring construction and Reisner's criterion of Cohen–Macaulayness. Stanley's idea of translating difficult conjectures in algebraic combinatorics into statements from commutative algebra and proving them by means of homological techniques was the origin of the rapidly developing field of combinatorial commutative algebra.\n\nA simplicial complex Δ is Cohen–Macaulay over k if and only if for all simplices \"σ\" ∈ Δ, all reduced simplicial homology groups of the link of \"σ\" in Δ with coefficients in k are zero, except the top dimensional one:\n\nA result due to Munkres then shows that the Cohen–Macaulayness of Δ over k is a topological property: it depends only on the homeomorphism class of the simplicial complex Δ. Namely, let |Δ| be the geometric realization of Δ. Then the vanishing of the simplicial homology groups in Reisner's criterion is equivalent to the following statement about the reduced and relative singular homology groups of |Δ|:\n\nIn particular, if the complex Δ is a simplicial sphere, that is, |Δ| is homeomorphic to a sphere, then it is Cohen–Macaulay over any field. This is a key step in Stanley's proof of the Upper Bound Conjecture. By contrast, there are examples of simplicial complexes whose Cohen–Macaulayness depends on the characteristic of the field k.\n\n"}
{"id": "9395687", "url": "https://en.wikipedia.org/wiki?curid=9395687", "title": "Stefan Bergman", "text": "Stefan Bergman\n\nStefan Bergman (5 May 1895 – 6 June 1977) was a Polish-born American mathematician whose primary work was in complex analysis. His name is also written Bergmann; he dropped the second \"n\" when he came to the U. S. He is best known for the kernel function he discovered while at Berlin University in 1922. This function is known today as the Bergman kernel. Bergman taught for many years at Stanford University, and served as an advisor to several students.\n\nBorn in Częstochowa, Congress Poland, Russian Empire, Bergman received his Ph.D. at Berlin University in 1921 for a dissertation on Fourier analysis. His advisor, Richard von Mises, had a strong influence on him, lasting for the rest of his career. In 1933, Bergman was forced to leave his post at the Berlin University because he was a Jew. He fled first to Russia, where he stayed until 1939, and then to Paris. In 1939, he emigrated to the United States, where he would remain for the rest of life. He was elected a Fellow of the American Academy of Arts and Sciences in 1951. He was a professor at Stanford University from 1952 until his retirement in 1972. He was an invited speaker at the International Congress of Mathematicians in 1950 in Cambridge, Massachusetts and in 1962 in Stockholm (\"On meromorphic functions of several complex variables\"). He died in Palo Alto, California, aged 82.\n\nThe Stefan Bergman Prize in mathematics was initiated by Bergman's wife in her will, in memory of her husband's work. The American Mathematical Society supports the prize and selects the committee of judges. The prize is awarded for:\n\n\n\n\n"}
{"id": "3893690", "url": "https://en.wikipedia.org/wiki?curid=3893690", "title": "Trait (computer programming)", "text": "Trait (computer programming)\n\nIn computer programming, a trait is a concept used in object-oriented programming, which represents a set of methods that can be used to extend the functionality of a class.\n\nTraits both provide a set of methods that implement behaviour to a class, and require that the class implement a set of methods that parameterize the provided behaviour.\n\nFor inter-object communication, traits are somewhat between an object-oriented protocol (interface) and a mixin. An interface may define one or more behaviors via method signatures, while a trait defines behaviors via full method definitions: i.e., it includes the body of the methods. In contrast, mixins include full method definitions and may also carry state through member variable, while traits usually don't.\n\nHence an object defined as a trait is created as the composition of methods, which can be used by other classes without requiring multiple inheritance. In case of a naming collision, when more than one trait to be used by a class has a method with the same name, the programmer must explicitly disambiguate which one of those methods will be used in the class; thus manually solving the \"diamond problem\" of multiple inheritance. This is different from other composition methods in object-oriented programming, where conflicting names are automatically resolved by scoping rules.\n\nWhereas mixins can be composed only using the inheritance operation, traits offer a much wider selection of operations, including:\n\nTraits are composed in the following ways:\n\nTraits come originally from the programming language Self and are supported by the following programming languages:\n\n\nThis example uses a trait to enhance other classes:\nThis allows simulating aspects of multiple inheritance:\nA trait in Rust declares a set of methods that a type must implement. Rust compilers require traits to be explicated, which ensures the safety of generics in Rust. It also helps to avoid major problems of template in C++. \n// type T must have the \"Ord\" trait\n// so that \">\" and \"<\" operations can be done\nfn get_max<T: Ord>(a: &[T]) -> Option<&T> {\n\nTo simplify tedious and repeated implementation of traits like codice_3 and codice_4, codice_5 can be used to request compilers to generate certain codes automatically. Derivable traits include: codice_6, codice_7, codice_3, codice_9, codice_10, codice_11, codice_12, codice_4 and codice_14.\n\n"}
{"id": "591568", "url": "https://en.wikipedia.org/wiki?curid=591568", "title": "Trigonometric polynomial", "text": "Trigonometric polynomial\n\nIn the mathematical subfields of numerical analysis and mathematical analysis, a trigonometric polynomial is a finite linear combination of functions sin(\"nx\") and cos(\"nx\") with \"n\" taking on the values of one or more natural numbers. The coefficients may be taken as real numbers, for real-valued functions. For complex coefficients, there is no difference between such a function and a finite Fourier series.\n\nTrigonometric polynomials are widely used, for example in trigonometric interpolation applied to the interpolation of periodic functions. They are used also in the discrete Fourier transform.\n\nThe term \"trigonometric polynomial\" for the real-valued case can be seen as using the analogy: the functions sin(\"nx\") and cos(\"nx\") are similar to the monomial basis for polynomials. In the complex case the trigonometric polynomials are spanned by the positive and negative powers of \"e\".\n\nAny function \"T\" of the form\n\nwith formula_2 for formula_3, is called a complex trigonometric polynomial of degree \"N\" . Using Euler's formula the polynomial can be rewritten as\n\nAnalogously, letting formula_5 and formula_6 or formula_7, then\n\nis called a real trigonometric polynomial of degree \"N\" .\n\nA trigonometric polynomial can be considered a periodic function on the real line, with period some multiple of 2, or as a function on the unit circle.\n\nA basic result is that the trigonometric polynomials are dense in the space of continuous functions on the unit circle, with the uniform norm ; this is a special case of the Stone–Weierstrass theorem. More concretely, for every continuous function ƒ and every ε > 0, there exists a trigonometric polynomial \"T\" such that |ƒ(\"z\") − T(\"z\")| < \"ε\" for all \"z\". Fejér's theorem states that the arithmetic means of the partial sums of the Fourier series of ƒ converge uniformly to ƒ, provided ƒ is continuous on the circle, thus giving an explicit way to find an approximating trigonometric polynomial \"T\".\n\nA trigonometric polynomial of degree \"N\" has a maximum of 2\"N\" roots in any open interval <nowiki>[</nowiki>\"a\", \"a\" + 2<nowiki>)</nowiki> with a in R, unless it is the zero function .\n\n"}
{"id": "33591382", "url": "https://en.wikipedia.org/wiki?curid=33591382", "title": "Type-1 OWA operators", "text": "Type-1 OWA operators\n\nThe Yager's OWA (ordered weighted averaging) operators are used to aggregate the crisp values in decision making schemes (such as multi-criteria decision making, multi-expert decision making and multi-criteria/multi-expert decision making). It is widely accepted that Fuzzy sets are more suitable for representing preferences of criteria in decision making.\n\nThe type-1 OWA operators have been proposed for this purpose. The type-1 OWA operators provides a technique for directly aggregating uncertain information with uncertain weights via OWA mechanism in soft decision making and data mining, where these uncertain objects are modelled by fuzzy sets.\n\nThe two definitions for type-1 OWA operators are based on Zadeh's Extension Principle and formula_1-cuts of fuzzy sets. The two definitions lead to equivalent results.\n\nLet formula_2 be the set of fuzzy sets with domain of discourse formula_3, a type-1 OWA operator is defined as follows:\n\nGiven n linguistic weights formula_4 in the form of fuzzy sets defined on the domain of discourse formula_5, a type-1 OWA operator is a mapping, formula_6,\n\nsuch that\n\nwhere formula_10,and formula_11 is a permutation function such that formula_12, i.e., formula_13 is the formula_14th highest element in the set formula_15.\n\nUsing the alpha-cuts of fuzzy sets:\n\nGiven the n linguistic weights formula_16 in the form of fuzzy sets defined on the domain of discourse formula_17, then for each formula_18, an formula_19-level type-1 OWA operator with formula_19-level sets formula_21 to aggregate the formula_19-cuts of fuzzy sets formula_23 is:\n\nwhere formula_25, and formula_26 is a permutation function such that formula_27, i.e., formula_28 is the formula_14th largest\nelement in the set formula_15.\n\nGiven the \"n\" linguistic weights formula_16 in the form of fuzzy sets defined on the domain of discourse formula_17, and the fuzzy sets formula_33, then we have that\n\nwhere formula_35 is the aggregation result obtained by Definition 1, and formula_36 is the result obtained by in Definition 2.\n\nAccording to the Representation Theorem of Type-1 OWA Operators, a general type-1 OWA operator can be decomposed into a series of formula_1-level type-1 OWA operators. In practice, this series of formula_1-level type-1 OWA operators is used to construct the resulting aggregation fuzzy set. So we only need to compute the left end-points and right end-points of the intervals formula_39. Then, the resulting aggregation fuzzy set is constructed with the membership function as follows:\n\nFor the left end-points, we need to solve the following programming problem:\n\nwhile for the right end-points, we need to solve the following programming problem:\n\nA fast method has been presented to solve two programming problem so that the type-1 OWA aggregation operation can be performed efficiently, for details, please see the paper.\n\nThree-step process:\n\n\n\n\nType-2 OWA operators have been suggested to aggregate the type-2 fuzzy sets for soft decision making.\n"}
{"id": "36186626", "url": "https://en.wikipedia.org/wiki?curid=36186626", "title": "Uniformly bounded representation", "text": "Uniformly bounded representation\n\nIn mathematics, a uniformly bounded representation formula_1 of a locally compact group formula_2 on a Hilbert space formula_3 is a homomorphism into the bounded invertible operators which is continuous for the strong operator topology, and such that formula_4 is finite. In 1947 Béla Szőkefalvi-Nagy established that any uniformly bounded representation of the integers or the real numbers is unitarizable, i.e. conjugate by an invertible operator to a unitary representation. For the integers this gives a criterion for an invertible operator to be similar to a unitary operator: the operator norms of all the positive and negative powers must be uniformly bounded. The result on unitarizability of uniformly bounded representations was extended in 1950 by Dixmier, Day and Nakamura-Takeda to all locally compact amenable groups, following essentially the method of proof of Sz-Nagy. The result is known to fail for non-amenable groups such as SL(2,R) and the free group on two generators. conjectured that a locally compact group is amenable if and only if every uniformly bounded representation is unitarizable.\n\nLet \"G\" be a locally compact amenable group and let \"T\" be a homomorphism of \"G\" into \"GL\"(\"H\"), the group of an invertible operators on a Hilbert space such that\n\n\nThen there is a positive invertible operator \"S\" on \"H\" such that \"S\" \"T\" \"S\" is unitary for every \"g\" in \"G\".\n\nAs a consequence, if \"T\" is an invertible operator with all its positive and negative powers uniformly bounded in operator norm, then \"T\" is conjugate by a positive invertible operator to a unitary.\n\nBy assumption the continuous functions\n\ngenerate a separable unital C* subalgebra \"A\" of the uniformly bounded continuous functions on \"G\". By construction the algebra is invariant under left translation. By amenability there is an invariant state φ on \"A\". It follows that\n\nis a new inner product on \"H\" satisfying\n\nwhere\n\nSo there is a positive invertible operator \"P\" such that\n\nBy construction\n\nLet \"S\" be the unique positive square root of \"P\". Then\n\nApplying \"S\" to \"x\" and \"y\", it follows that\n\nSince the operators\n\nare invertible, it follows that they are unitary.\n\nThe complentary series of irreducible unitary representations of SL(2,R) was introduced by . These representations can be realized on functions on the circle or on the real line: the Cayley transform provides the unitary equivalence between the two realizations.\n\nIn fact for 0 < σ < 1/2 and \"f\", \"g\" continuous functions on the circle define\n\nwhere\n\nSince the function \"k\" is integrable, this integral converges. In fact\n\nwhere the norms are the usual L norms.\n\nThe functions\n\nare orthogonal with\n\nSince these quantities are positive, (\"f\",\"g\") defines an inner product. The Hilbert space completion is denoted by \"H\".\n\nFor \"F\", \"G\" continuous functions of compact support on R, define\n\nSince, regarded as distributions, the Fourier transform of |\"x\"| is C|\"t\"| for some positive constant C, the above expression can be rewritten:\n\nHence it is an inner product. Let \"H\"' denote its Hilbert space completion.\nThe Cayley transform gives rise to an operator \"U\":\n\n\"U\" extends to an isometry of \"H\" onto \"H\" '. Its adjoint is given by\n\nThe Cayley transform exchanges the actions by Möbius transformations of SU(1,1) on S and of SL(2, R) on R.\n\nThe operator \"U\" interwtines corresponding actions of SU(1,1) on \"H\" and SL(2,R) on \"H\" '.\n\nFor \"g\" in SU(1,1) given by\n\nwith\n\nIn fact it is easy to check that the operator \nλ(\"g\")\"T\"λ(\"g\") – \"T\" has finite rank, with range\"V\", the finite-dimensional space of functions supported on the set of vertices joining \"g\" to the origin. For on any function vanishing on this finite set, \"T\" and λ(\"g\")\"T\"λ(\"g\") are equal; and they both leave invariant \"V\", on which they acts as contractions and adjoints of each other. Hence if \"f\" has finite support and norm 1,\n\nFor |z| < 1/√3, these representations are all similar to the regular representation λ. If on the other hand 1/√3 < |z| <1, then the operator\n\nsatisfies\n\nwhere \"f\" in \"H\" is defined by\n\nThus, if \"z\" is not real, \"D\" has an eigenvalue which is not real. But then π cannot be unitarizable, since otherwise \"D\" would be similar to a self-adjoint operator.\n\nJacques Dixmier asked in 1950 whether amenable groups are characterized by unitarizability, i.e. the property that all their uniformly bounded representations are unitarizable. This problem remains open to this day.\n\nAn elementary induction argument shows that a subgroup of a unitarizable group remains unitarizable. Therefore, the von Neumann conjecture would have implied a positive answer to Dixmier's problem, had it been true. In any case, it follows that a counter-example to Dixmier's conjecture could only be a non-amenable group without free subgroups. In particular, Dixmier's conjecture is true for all linear groups by the Tits alternative.\n\nA criterion due to Epstein and Monod shows that there are also non-unitarizable groups without free subgroups. In fact, even some Burnside groups are non-unitarizable, as shown by Monod and Ozawa.\n\nConsiderable progress has been made by Pisier who linked unitarizability to a notion of factorization length. This allowed him to solve a modified form of the Dixmier problem.\n\nThe potential gap between unitarizability and amenability can be further illustrated by the following open problems, all of which become elementary if \"unitarizable\" were replaced by \"amenable\":\n\n\n"}
{"id": "21067650", "url": "https://en.wikipedia.org/wiki?curid=21067650", "title": "Volume of an n-ball", "text": "Volume of an n-ball\n\nIn geometry, a ball is a region in space comprising all points within a fixed distance from a given point; that is, it is the region enclosed by a sphere or hypersphere. An -ball is a ball in -dimensional Euclidean space. The volume of an -ball is an important constant that occurs in formulas throughout mathematics; it generalizes the notion of the volume enclosed by a sphere in 3-dimensional space.\n\nThe -dimensional volume of a Euclidean ball of radius in -dimensional Euclidean space is:\nwhere is Leonhard Euler's gamma function (which can be thought of as an extension of the factorial function to noninteger arguments). Using explicit formulas for particular values of the gamma function at the integers and half integers gives formulas for the volume of a Euclidean ball that do not require an evaluation of the gamma function. These are:\nIn the formula for odd-dimensional volumes, the double factorial is defined for odd integers as .\n\nInstead of expressing the volume of the ball in terms of its radius , the formula can be inverted to express the radius as a function of the volume:\nThis formula, too, can be separated into even- and odd-dimensional cases using factorials and double factorials in place of the gamma function:\n\nThe volume satisfies several recursive formulas. These formulas can either be proved directly or proved as consequences of the general volume formula above. The simplest to state is a formula for the volume of an -ball in terms of the volume of an -ball of the same radius:\n\nThere is also a formula for the volume of an -ball in terms of the volume of an -ball of the same radius:\nUsing explicit formulas for the gamma function again shows that the one-dimension recursion formula can also be written as:\n\nThe radius of an -ball of volume may be expressed recursively in terms of the radius of an -ball or an -ball. These formulas may be derived from the explicit formula for above.\nUsing explicit formulas for the gamma function shows that the one-dimension recursion formula is equivalent to\nand that the two-dimension recursion formula is equivalent to\n\nIn low dimensions, these volume and radius formulas simplify to the following, which demonstrates that the volume of the unit \"n\"-sphere peaks at dimension 5.\n\nSuppose that is fixed. Then the volume of an -ball of radius approaches zero as tends to infinity. This can be shown using the two-dimension recursion formula. At each step, the new factor being multiplied into the volume is proportional to , where the constant of proportionality is independent of . Eventually, is so large that the new factor is less than 1. From then on, the volume of an -ball must decrease at least geometrically, and therefore it tends to zero. A variant on this proof uses the one-dimension recursion formula. Here, the new factor is proportional to a quotient of gamma functions. Gautschi's inequality bounds this quotient above by . The argument concludes as before by showing that the volumes decrease at least geometrically.\n\nA more precise description of the high dimensional behavior of the volume can be obtained using Stirling's approximation. It implies the asymptotic formula:\nThe error in this approximation is a factor of . Stirling's approximation is in fact an underestimate of the gamma function, so the above formula is an upper bound. This provides another proof that the volume of the ball decreases exponentially: When is sufficiently large, the factor is less than one, and then the same argument as before applies.\n\nIf instead is fixed while is large, then by Stirling's approximation again, the radius of an -ball of volume is approximately\nThis expression is a lower bound for , and the error is again a factor of . As increases, grows as .\n\nLet denote the surface area of the -sphere of radius . The -sphere is the boundary of the -ball of radius . The -ball is a union of concentric spheres, and consequently the surface area and the volume are related by:\n\nSince the volume is proportional to a power of the radius, the above relation leads to a simple recurrence equation relating the surface area of an -ball and the volume of an -ball. By applying the two-dimension recursion formula, it also gives a recurrence equation relating the surface area of an -ball and the volume of an -ball:\n\nThere are many proofs of the above formulas.\n\nAn important step in several proofs about volumes of -balls, and a generally useful fact besides, is that the volume of the -ball of radius is proportional to :\nThe proportionality constant is the volume of the unit ball.\n\nThis is a special case of a general fact about volumes in -dimensional space: If \nis a body (measurable set) in that space and is the body obtained by stretching in all directions by the factor then the volume of equals times the volume of . This is a direct consequence of the change of variables formula:\nwhere and the substitution was made.\n\nAnother proof of the above relation, which avoids multi-dimensional integration, uses induction: The base case is , where the proportionality is obvious. For the inductive case, assume that proportionality is true in dimension . Note that the intersection of an -ball with a hyperplane is an -ball. When the volume of the -ball is written as an integral of volumes of -balls:\nit is possible by the inductive assumption to remove a factor of from the radius of the -ball to get:\nMaking the change of variables leads to:\nwhich demonstrates the proportionality relation in dimension . By induction, the proportionality relation is true in all dimensions.\n\nA proof of the recursion formula relating the volume of the -ball and an -ball can be given using the proportionality formula above and integration in cylindrical coordinates. Fix a plane through the center of the ball. Let denote the distance between a point in the plane and the center of the sphere, and let denote the azimuth. Intersecting the -ball with the -dimensional plane defined by fixing a radius and an azimuth gives an -ball of radius . The volume of the ball can therefore be written as an iterated integral of the volumes of the -balls over the possible radii and azimuths:\nThe azimuthal coordinate can be immediately integrated out. Applying the proportionality relation shows that the volume equals:\nThe integral can be evaluated by making the substitution to get:\nwhich is the two-dimension recursion formula.\n\nThe same technique can be used to give an inductive proof of the volume formula. The base cases of the induction are the 0-ball and the 1-ball, which can be checked directly using the facts and . The inductive step is similar to the above, but instead of applying proportionality to the volumes of the -balls, the inductive assumption is applied instead.\n\nThe proportionality relation can also be used to prove the recursion formula relating the volumes of an -ball and an -ball. As in the proof of the proportionality formula, the volume of an -ball can be written as an integral over the volumes of -balls. Instead of making a substitution, however, the proportionality relation can be applied to the volumes of the -balls in the integrand:\nThe integrand is an even function, so by symmetry the interval of integration can be restricted to . On the interval , it is possible to apply the substitution . This transforms the expression into:\nThe integral is a value of a well-known special function called the beta function , and the volume in terms of the beta function is:\nThe beta function can be expressed in terms of the gamma function in much the same way that factorials are related to binomial coefficients. Applying this relationship gives:\nUsing the value gives the one-dimension recursion formula:\n\nAs with the two-dimension recursive formula, the same technique can be used to give an inductive proof of the volume formula.\n\nThe volume can be computed by integrating the volume element in spherical coordinates. The spherical coordinate system has a radial coordinate and angular coordinates , where the domain of each except is , and the domain of is . The spherical volume element is:\nand the volume is the integral of this quantity over between 0 and and all possible angles:\nEach of the factors in the integrand depends on only a single variable, and therefore the iterated integral can be written as a product of integrals:\nThe integral over the radius is . The intervals of integration on the angular coordinates can, by symmetry, be changed to :\nEach of the remaining integrals is now a particular value of the beta function:\nThe beta functions can be rewritten in terms of gamma functions:\nThis product telescopes. Combining this with the values and and the functional equation leads to:\n\nThe volume formula can be proven directly using Gaussian integrals. Consider the function:\nThis function is both rotationally invariant and a product of functions of one variable each. Using the fact that it is a product and the formula for the Gaussian integral gives:\nwhere is the -dimensional volume element. Using rotational invariance, the same integral can be computed in spherical coordinates:\nwhere is an -sphere of radius and is the area element (equivalently, the -dimensional volume element). The surface area of the sphere satisfies a proportionality equation similar to the one for the volume of a ball: If is the surface area of an -sphere of radius , then:\nApplying this to the above integral gives the expression:\nBy substituting , the expression is transformed into:\nThis is the gamma function evaluated at .\n\nCombining the two integrations shows that:\nTo derive the volume of an -ball of radius from this formula, integrate the surface area of a sphere of radius for and apply the functional equation :\n\nThere are also explicit expressions for the volumes of balls in norms. The norm of the vector in is:\nand an ball is the set of all vectors whose norm is less than or equal to a fixed number called the radius of the ball. The case is the standard Euclidean distance function, but other values of occur in diverse contexts such as information theory, coding theory, and dimensional regularization.\n\nThe volume of an ball of radius is:\nThese volumes satisfy a recurrence relation similar to the one dimension recurrence for :\nFor , one recovers the recurrence for the volume of a Euclidean ball because .\n\nFor example, in the cases and , the volumes are:\nThese agree with elementary calculations of the volumes of cross-polytopes and hypercubes.\n\nFor most values of , the surface area of an sphere (the boundary of an ball) cannot be calculated by differentiating the volume of an ball with respect to its radius. While the volume can be expressed as an integral over the surface areas using the coarea formula, the coarea formula contains a correction factor that accounts for how the -norm varies from point to point. For and , this factor is one. However, if then the correction factor is : the surface area of an sphere of radius in is times the derivative of the volume of an ball. This can be seen most simply by applying the divergence theorem to the vector field to get\n\n}} formula_49 formula_50.\nFor other values of , the constant is a complicated integral.\n\nThe volume formula can be generalized even further. For positive real numbers , define the unit ball to be:\nThe volume of this ball has been known since the time of Dirichlet:\n\n\n"}
{"id": "45655492", "url": "https://en.wikipedia.org/wiki?curid=45655492", "title": "Wiener connector", "text": "Wiener connector\n\nIn mathematics applied to the study of networks, the Wiener connector, named in honor of chemist Harry Wiener who first introduced the Wiener Index, is a means of maximizing efficiency in connecting specified \"query vertices\" in a network. Given a connected, undirected graph and a set of query vertices in a graph, the minimum Wiener connector is an induced subgraph that connects the query vertices and minimizes the sum of shortest path distances among all pairs of vertices in the subgraph. In combinatorial optimization, the minimum Wiener connector problem is the problem of finding the minimum Wiener connector. It can be thought of as a version of the classic Steiner tree problem (one of Karp's 21 NP-complete problems), where instead of minimizing the size of the tree, the objective is to minimize the distances in the subgraph.\n\nThe minimum Wiener connector was first presented by Ruchansky, et al. in 2015.\n\nThe minimum Wiener connector has applications in many domains where there is a graph structure and an interest in learning about connections between sets of individuals. For example, given a set of patients infected with a viral disease, which other patients should be checked to find the culprit? Or given a set of proteins of interest, which other proteins participate in pathways with them?\n\nThe Wiener index is the sum of shortest path distances in a (sub)graph. Using formula_1 to denote the shortest path between formula_2 and formula_3, the Wiener index of a (sub)graph formula_4, denoted formula_5, is defined as\n\nThe minimum Wiener connector problem is defined as follows. Given an undirected and unweighted graph with vertex set formula_7 and edge set formula_8 and a set of query vertices formula_9, find a connector formula_10 of minimum Wiener index. More formally, the problem is to compute\nthat is, find a connector formula_12 that minimizes the sum of shortest paths in formula_12.\n\nThe minimum Wiener connector problem is related to the Steiner tree problem. In the former, the objective function in the minimization is the Wiener index of the connector, whereas in the latter, the objective function is the sum of the weights of the edges in the connector. The optimum solutions to these problems may differ, given the same graph and set of query vertices. In fact, a solution for the Steiner tree problem may be arbitrarily bad for the minimum Wiener connector problem; the graph on the right provides an example.\n\nThe problem is NP-hard, and does not admit a polynomial-time approximation scheme unless P = NP. This can be proven using the inapproximability of vertex cover in bounded degree graphs. Although there is no polynomial-time approximation scheme, there is a polynomial-time constant-factor approximation—an algorithm that finds a connector whose Wiener index is within a constant multiplicative factor of the Wiener index of the optimum connector. In terms of complexity classes, the minimum Wiener connector problem is in APX but is not in PTAS unless P = NP.\n\nAn exhaustive search over all possible subsets of vertices to find the one that induces the connector of minimum Wiener index yields an algorithm that finds the optimum solution in formula_14 time (that is, exponential time) on graphs with \"n\" vertices. In the special case that there are exactly two query vertices, the optimum solution is the shortest path joining the two vertices, so the problem can be solved in polynomial time by computing the shortest path. In fact, for any fixed constant number of query vertices, an optimum solution can be found in polynomial time.\n\nThere is a constant-factor approximation algorithm for the minimum Wiener connector problem that runs in time formula_15 on a graph with \"n\" vertices, \"m\" edges, and \"q\" query vertices, roughly the same time it takes to compute shortest-path distances from the query vertices to every other vertex in the graph. The central approach of this algorithm is to reduce the problem to the vertex-weighted Steiner tree problem, which admits a constant-factor approximation in particular instances related to the minimum Wiener connector problem.\n\nThe minimum Wiener connector behaves like betweenness centrality.\n\nWhen the query vertices belong to the same community, the non-query vertices that form the minimum Wiener connector tend to belong to the same community and have high centrality within the community. Such vertices are likely to be influential vertices playing leadership roles in the community. In a social network, these influential vertices might be good users for spreading information or to target in a viral marketing campaign.\n\nWhen the query vertices belong to different communities, the non-query vertices that form the minimum Wiener connector contain vertices adjacent to edges that bridge the different communities. These vertices span a structural hole in the graph and are important.\n\nThe minimum Wiener connector is useful in applications in which one wishes to learn about the relationship between a set of vertices in a graph. For example,\n"}
{"id": "17002765", "url": "https://en.wikipedia.org/wiki?curid=17002765", "title": "William W. Tait", "text": "William W. Tait\n\nWilliam Walker Tait (born 1929) is an emeritus professor of philosophy at the University of Chicago, where he served as a faculty member from 1972 to 1996, and as department chair from 1981 to 1987.\n\nTait received his B.A. from Lehigh University in 1952, and his Ph.D. from Yale University in 1958. Prior to teaching at Chicago he held positions at Stanford University from 1958 to 1964, the University of Illinois at Chicago from 1965 to 1971, and the University of Aarhus from 1971 to 1972. In 1966 he signed a tax resistance vow to protest the Vietnam War. In 2002 he was elected as a Fellow of the American Academy of Arts and Sciences.\n\n\n\n"}
