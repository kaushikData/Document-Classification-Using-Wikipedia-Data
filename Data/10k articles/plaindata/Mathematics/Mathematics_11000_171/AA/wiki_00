{"id": "49901691", "url": "https://en.wikipedia.org/wiki?curid=49901691", "title": "123-reg", "text": "123-reg\n\n123-reg is headquartered in England and is a domain registrar and web hosting company. The company claims to be the UK's largest accredited domain registrar that provides Internet services to small- and medium-sized business. Up until 2017, 123-reg was part of Host Europe Group (HEG), which at the time, was Europe's largest privately owned hosting company. In April 2017, GoDaddy Inc (GDDY.N), a U.S.-based website domain name provider, completed the acquisition of Host Europe Group (HEG) for 1.69 billion euros ($1.82 billion)\n\n123-reg was founded in 2000 by Jonathan Brealey and Tim Brealey who prior to this also set up Webfusion Internet Solutions Ltd in 1997. According to the company's parent, 123-reg became the UK's largest domain registrar in 2004 and passed the 3 million domain names under management in 2012.\n\n\nOn 16 April 2016, 123-reg admitted a major deletion of a large number of VPS servers caused by an error during what should have been routine maintenance. The event deleted hundreds of websites with users losing sites and access to data on their VPS service. By 24 April 2016 the situation was still ongoing. During this period 123-reg had a further data breach with customers being able to see the support tickets of other account holders\n"}
{"id": "1244529", "url": "https://en.wikipedia.org/wiki?curid=1244529", "title": "Algebra bundle", "text": "Algebra bundle\n\nIn mathematics, an algebra bundle is a fiber bundle whose fibers are algebras and local trivializations respect the algebra structure. It follows that the transition functions are algebra isomorphisms. Since algebras are also vector spaces, every algebra bundle is a vector bundle.\n\nExamples include the tensor-algebra bundle, exterior bundle, and symmetric bundle associated to a given vector bundle, as well as the Clifford bundle associated to any Riemannian vector bundle.\n\n\n"}
{"id": "18744973", "url": "https://en.wikipedia.org/wiki?curid=18744973", "title": "Analysis on fractals", "text": "Analysis on fractals\n\nAnalysis on fractals or calculus on fractals is a generalization of calculus on smooth manifolds to calculus on fractals.\n\nThe theory describes dynamical phenomena which occur on objects modelled by fractals.\nIt studies questions such as \"how does heat diffuse in a fractal?\" and \"How does a fractal vibrate?\"\n\nIn the smooth case the operator that occurs most often in the equations modelling these questions is the Laplacian, so the starting point for the theory of analysis on fractals is to define a Laplacian on fractals. This turns out not to be a full differential operator in the usual sense but has many of the desired properties. There are a number of approaches to defining the Laplacian: probabilistic, analytical or measure theoretic.\n\n\n\n"}
{"id": "1424210", "url": "https://en.wikipedia.org/wiki?curid=1424210", "title": "Annales de l'Institut Fourier", "text": "Annales de l'Institut Fourier\n\nThe Annales de l'Institut Fourier is a French mathematical journal publishing papers in all fields of mathematics. It was established in 1949. The journal publishes one volume per year, consisting of six issues. The current editor-in-chief is Hervé Pajot. Articles are published either in English or in French.\n\nThe journal is indexed in \"Mathematical Reviews\", \"Zentralblatt MATH\" and the Web of Science. According to the \"Journal Citation Reports\", the journal had a 2008 impact factor of 0.804.\n"}
{"id": "18992933", "url": "https://en.wikipedia.org/wiki?curid=18992933", "title": "Bogomolov conjecture", "text": "Bogomolov conjecture\n\nIn mathematics, the Bogomolov conjecture, named for Fedor Bogomolov, is the following statement:\n\nLet \"C\" be an algebraic curve of genus \"g\" at least two defined over a number field \"K\", let formula_1 denote the algebraic closure of \"K\", fix an embedding of \"C\" into its Jacobian variety \"J\", and let formula_2 denote the Néron-Tate height on \"J\" associated to an ample symmetric divisor. Then there exists an formula_3 such that the set\n\nSince formula_5 if and only if \"P\" is a torsion point, the Bogomolov conjecture generalises the Manin-Mumford conjecture. The original Bogomolov conjecture was proved by Emmanuel Ullmo and Shou-Wu Zhang in 1998.\nZhang proved the following generalization:\n\nLet \"A\" be an abelian variety defined over \"K\", and let formula_2 be the Néron-Tate height on \"A\" associated to an ample symmetric divisor. A subvariety formula_7 is called a \"torsion subvariety\" if it is the translate of an abelian subvariety of \"A\" by a torsion point. If \"X\" is not a torsion subvariety, then there is an formula_3 such that the set\n\n"}
{"id": "51628519", "url": "https://en.wikipedia.org/wiki?curid=51628519", "title": "CECPQ1", "text": "CECPQ1\n\nIn cryptography, CECPQ1 is a post-quantum cipher developed by Google to make web browsers secure via Transport Layer Security (TLS).\n\nCECPQ1 was designed to provide confidentiality even against an attacker who possesses a large quantum computer. It is a key-agreement algorithm plugged into TLS that combines X25519 and New Hope, a ring learning with errors primitive. Even if New Hope turns out to be breakable, the X25519 key-agreement will ensure that it provides at least the security of our existing connections.\n\nIt is available in Google Chrome 54 beta. In 2016, the experimental use in Chrome ended and it was planned to disable CECPQ1 in a later Chrome update.\n\nIn CECPQ1, 32 bytes of shared secret material are derived using X25519 key exchange, with a further 32 bytes being derived using the newhope lattice-based key exchange method (whence the quantum-resistance). The resulting bytes are concatenated and form a pre-master secret for deriving shared keys.\n\n"}
{"id": "43519034", "url": "https://en.wikipedia.org/wiki?curid=43519034", "title": "Centipede mathematics", "text": "Centipede mathematics\n\nCentipede mathematics is a term used, sometimes derogatorily, to describe the generalisation and study of mathematical objects satisfying progressively fewer and fewer restrictions. This type of study is likened to studying how a centipede behaves when its legs are removed one by one.\n\nThe term is attributed to Polish mathematician Antoni Zygmund. Zygmund is said to have described the metaphor of the centipede thus: \"You take a centipede and pull off ninety-nine of its legs and see what it can do.\"Thus, Zygmund has been known by many mathematicians as the \"Centipede Surgeon\".\n\nThe study of semigroups is cited as an example of doing centipede mathematics. One starts with the notion of an abelian group. First delete the commutativity restriction to obtain the concept of a group. The restriction of existence of inverses is then removed. This produces a monoid. If one now removes the restriction regarding the existence of identity, the resulting object turns out to be a semigroup. Still more legs can be removed. If the associativity restriction is also discarded one gets a magma or a groupoid. The restrictions that define an abelian group may be removed in different orders also. The study of ternary ring has been cited as an example of centipede mathematics. The progressive removal of axioms of Euclidean geometry and studying the resulting geometrical objects also illustrate the methodology of centipede mathematics.\n\nThe following quote summarises the value and usefulness of the concept: \"The term ‘centipede mathematics’ is new to me, but its practice is surely of great antiquity. The binomial theorem (tear off the leg that says that the exponent has to be a natural number) is a good example. A related notion is the importance of good notation and the importance of overloading, aka abuse of language, to establish useful analogies.\" — Gavin Wraith.\n"}
{"id": "138404", "url": "https://en.wikipedia.org/wiki?curid=138404", "title": "Chain complex", "text": "Chain complex\n\nIn mathematics, a chain complex is an algebraic structure that consists of a sequence of abelian groups (or modules) and a sequence of homomorphisms between consecutive groups such that the image of each homomorphism is included in the kernel of the next. Associated to a chain complex is its homology, which describes how the images are included in the kernels.\n\nA cochain complex is similar to a chain complex, except that its homomorphisms follow a different convention. The homology of a cochain complex is called its cohomology.\n\nIn algebraic topology, the singular chain complex of a topological space X is constructed using continuous maps from a simplex to X, and the homomorphisms of the chain complex capture how these maps restrict to the boundary of the simplex. The homology of this chain complex is called the singular homology of X, and is a commonly used invariant of a topological space.\n\nChain complexes are studied in homological algebra, but are used in several areas of mathematics, including abstract algebra, Galois theory, differential geometry and algebraic geometry. They can be defined more generally in abelian categories.\n\nA chain complex formula_1 is a sequence of abelian groups or modules ..., \"A\", \"A\", \"A\", \"A\", \"A\", ... connected by homomorphisms (called boundary operators or differentials) \"d\" : \"A\"→\"A\", such that the composition of any two consecutive maps is the zero map. Explicitly, the differentials satisfy \"d\" ∘ \"d\" = 0, or with indices suppressed, \"d\" = 0. The complex may be written out as follows.\n\nThe cochain complex formula_3 is the dual notion to a chain complex. It consists of a sequence of abelian groups or modules ..., \"A\", \"A\", \"A\", \"A\", \"A\", ... connected by homomorphisms \"d\" : \"A\"→\"A\" satisfying \"d\" ∘ \"d\" = 0. The cochain complex may be written out in a similar fashion to the chain complex.\n\nThe index \"n\" in either \"A\" or \"A\" is referred to as the degree (or dimension). The difference between chain and cochain complexes is that, in chain complexes, the differentials decrease dimension, whereas in cochain complexes they increase dimension. All the concepts and definitions for chain complexes apply to cochain complexes, except that they will follow this different convention for dimension, and often terms will be given the prefix \"co-\". In this article, definitions will be given for chain complexes when the distinction is not required.\n\nA bounded chain complex is one in which almost all the \"A\" are 0; that is, a finite complex extended to the left and right by 0. An example is the chain complex defining the simplicial homology of a finite simplicial complex. A chain complex is bounded above if all modules above some fixed degree \"N\" are 0, and is bounded below if all modules below some fixed degree are 0. Clearly, a complex is bounded both above and below if and only if the complex is bounded.\n\nThe elements of the individual groups of a (co)chain complex are called (co)chains. The elements in the kernel of \"d\" are called (co)cycles (or closed elements), and the elements in the image of \"d\" are called (co)boundaries (or exact elements). Right from the definition of the differential, all boundaries are cycles. The \"n\"-th (co)homology group \"H\" (\"H\") is the group of (co)cycles modulo (co)boundaries in degree \"n\", that is,\n\nAn exact sequence (or exact complex) is a chain complex whose homology groups are all zero. This means all closed elements in the complex are exact. A short exact sequence is a bounded exact sequence in which only the groups \"A\", \"A\", \"A\" may be nonzero. For example, the following chain complex is a short exact sequence.\nIn the middle group, the closed elements are the elements pZ; these are clearly the exact elements in this group.\n\nA chain map \"f\" between two chain complexes formula_7 and formula_8 is a sequence formula_9 of homomorphisms formula_10 for each \"n\" that commutes with the boundary operators on the two chain complexes, so formula_11. This is written out in the following commutative diagram.\n\nA chain map sends cycles to cycles and boundaries to boundaries, and thus induces a map on homology formula_12.\n\nA continuous map \"f\" between topological spaces \"X\" and \"Y\" induces a chain map between the singular chain complexes of \"X\" and \"Y\", and hence induces a map \"f\" between the singular homology of \"X\" and \"Y\" as well. When \"X\" and \"Y\" are both equal to the \"n\"-sphere, the map induced on homology defines the degree of the map \"f\".\n\nThe concept of chain map reduces to the one of boundary through the construction of the cone of a chain map.\n\nA chain homotopy offers a way to relate two chain maps that induce the same map on homology groups, even though the maps may be different. Given two chain complexes \"A\" and \"B\", and two chain maps \"f\",\"g\" : \"A\" → \"B\", a chain homotopy is a sequence of homomorphisms \"h\" : \"A\" → \"B\" such that \"hd\" + \"d\"\"h\" = \"f\" − \"g\". The maps may be written out in a diagram as follows, but this diagram is not commutative.\n\nThe map \"hd\" + \"d\"\"h\" is easily verified to induce the zero map on homology, for any \"h\". It immediately follows that \"f\" and \"g\" induce the same map on homology. One says \"f\" and \"g\" are chain homotopic (or simply homotopic), and this property defines an equivalence relation between chain maps.\n\nLet \"X\" and \"Y\" be topological spaces. In the case of singular homology, a homotopy between continuous maps \"f\",\"g\" : \"X\" → \"Y\" induces a chain homotopy between the chain maps corresponding to \"f\" and \"g\". This shows that two homotopic maps induce the same map on singular homology. The name \"chain homotopy\" is motivated by this example.\n\nLet \"X\" be a topological space. Define \"C\"(\"X\") for natural \"n\" to be the free abelian group formally generated by singular n-simplices in \"X\", and define the boundary map formula_13 to be\n\nwhere the hat denotes the omission of a vertex. That is, the boundary of a singular simplex is the alternating sum of restrictions to its faces. It can be shown that ∂ = 0, so formula_15 is a chain complex; the singular homology formula_16 is the homology of this complex.\n\nSingular homology is a useful invariant of topological spaces up to homotopy equivalence. The degree zero homology group is a free abelian group on the connected components of \"X\".\n\nThe differential \"k\"-forms on any smooth manifold \"M\" form a real vector space called Ω(\"M\") under addition. \nThe exterior derivative \"d\" maps Ω(\"M\") to Ω(\"M\"), and \"d\" = 0 follows essentially from symmetry of second derivatives, so the vector spaces of \"k\"-forms along with the exterior derivative are a cochain complex.\n\nThe cohomology of this complex is called the de Rham cohomology of \"X\". The homology group in dimension zero is isomorphic to the vector space of locally constant functions from \"M\" to R. Thus for a compact manifold, this is the real vector space whose dimension is the number of connected components of \"M\".\n\nSmooth maps between manifolds induce chain maps, and smooth homotopies between maps induce chain homotopies.\n\nChain complexes of \"K\"-modules with chain maps form a category Ch, where \"K\" is a commutative ring.\n\nIf \"V\" = \"V\"formula_18 and \"W\" = \"W\"formula_18 are chain complexes, their tensor product formula_20 is a chain complex with degree \"n\" elements given by \n\nand differential given by \nwhere \"a\" and \"b\" are any two homogeneous vectors in \"V\" and \"W\" respectively, and formula_23 denotes the degree of \"a\".\n\nThis tensor product makes the category Ch into a symmetric monoidal category. The identity object with respect to this monoidal product is the base ring \"K\" viewed as a chain complex in degree 0. The braiding is given on simple tensors of homogeneous elements by \nThe sign is necessary for the braiding to be a chain map.\n\nMoreover, the category of chain complexes of \"K\"-modules also has internal Hom: given chain complexes \"V\" and \"W\", the internal Hom of \"V\" and \"W\", denoted Hom(\"V\",\"W\"), is the chain complex with degree \"n\" elements given by formula_25 and differential given by\nWe have a natural isomorphism\n\n\n"}
{"id": "504404", "url": "https://en.wikipedia.org/wiki?curid=504404", "title": "Concyclic points", "text": "Concyclic points\n\nIn geometry, a set of points are said to be concyclic (or cocyclic) if they lie on a common circle. All concyclic points are the same distance from the center of the circle. Three points in the plane that do not all fall on a straight line are concyclic, but four or more such points in the plane are not necessarily concyclic.\n\nIn general the centre \"O\" of a circle on which points \"P\" and \"Q\" lie must be such that \"OP\" and \"OQ\" are equal distances. Therefore \"O\" must lie on the perpendicular bisector of the line segment \"PQ\". For \"n\" distinct points there are \"n\"(\"n\" − 1)/2 bisectors, and the concyclic condition is that they all meet in a single point, the centre \"O\".\n\nThe vertices of every triangle fall on a circle. (Because of this, some authors define \"concyclic\" only in the context of four or more points on a circle.) The circle containing the vertices of a triangle is called the circumscribed circle of the triangle. Several other sets of points defined from a triangle are also concyclic, with different circles; see nine-point circle and Lester's theorem.\n\nThe radius of the circle on which lie a set of points is, by definition, the radius of the circumcircle of any triangle with vertices at any three of those points. If the pairwise distances among three of the points are \"a\", \"b\", and \"c\", then the circle's radius is\n\nThe equation of the circumcircle of a triangle, and expressions for the radius and the coordinates of the circle's center, in terms of the Cartesian coordinates of the vertices are given here and here.\n\nA quadrilateral \"ABCD\" with concyclic vertices is called a cyclic quadrilateral; this happens if and only if formula_2 (the inscribed angle theorem) which is true if and only if the opposite angles inside the quadrilateral are supplementary. A cyclic quadrilateral with successive sides \"a\", \"b\", \"c\", \"d\" and semiperimeter \"s\" = (\"a\"+\"b\"+\"c\"+\"d\")/2 has its circumradius given by\nan expression that was derived by the Indian mathematician Vatasseri Parameshvara in the 15th century.\n\nBy Ptolemy's theorem, if a quadrilateral is given by the pairwise distances between its four vertices \"A\", \"B\", \"C\", and \"D\" in order, then it is cyclic if and only if the product of the diagonals equals the sum of the products of opposite sides: \n\nIf two lines, one containing segment \"AC\" and the other containing segment \"BD\", intersect at \"X\", then the four points \"A\", \"B\", \"C\", \"D\" are concyclic if and only if\n\nThe intersection \"X\" may be internal or external to the circle. This theorem is known as power of a point.\n\nMore generally, a polygon in which all vertices are concyclic is called a cyclic polygon. A polygon is cyclic if and only if the perpendicular bisectors of its edges are concurrent.\n\nSome authors consider collinear points (sets of points all belonging to a single line) to be a special case of concyclic points, with the line being viewed as a circle of infinite radius. This point of view is helpful, for instance, when studying inversion through a circle and Möbius transformations, as these transformations preserve the concyclicity of points only in this extended sense.\n\nIn the complex plane (formed by viewing the real and imaginary parts of a complex number as the \"x\" and \"y\" Cartesian coordinates of the plane), concyclicity has a particularly simple formulation: four points in the complex plane are either concyclic or collinear if and only if their cross-ratio is a real number.\n\nA set of five or more points is concyclic if and only if every four-point subset is concyclic. This property can be thought of as an analogue for concyclicity of the Helly property of convex sets.\n\nIn any triangle all of the following nine points are concyclic on what is called the nine-point circle: the midpoints of the three edges, the feet of the three altitudes, and the points halfway between the orthocenter and each of the three vertices.\n\nLester's theorem states that in any scalene triangle, the two Fermat points, the nine-point center, and the circumcenter are concyclic.\n\nIf lines are drawn through the Lemoine point parallel to the sides of a triangle, then the six points of intersection of the lines and the sides of the triangle are concyclic, in what is called the Lemoine circle.\n\nThe van Lamoen circle associated with any given triangle formula_6 contains the circumcenters of the six triangles that are defined inside formula_6 by its three medians.\n\nA triangle's circumcenter, its Lemoine point, and its first two Brocard points are concyclic, with the segment from the circumcenter to the Lemoine point being a diameter.\n\nA polygon is defined to be cyclic if its vertices are all concyclic. For example, all the vertices of a regular polygon of any number of sides are concyclic.\n\nA tangential polygon is one having an inscribed circle tangent to each side of the polygon; these tangency points are thus concyclic on the inscribed circle.\n\nA convex quadrilateral is orthodiagonal (has perpendicular diagonals) if and only if the midpoints of the sides and the feet of the four altitudes are eight concyclic points, on what is called the eight-point circle.\n\n"}
{"id": "45304281", "url": "https://en.wikipedia.org/wiki?curid=45304281", "title": "Consistent and inconsistent equations", "text": "Consistent and inconsistent equations\n\nIn mathematics and in particular in algebra, a linear or nonlinear system of equations is consistent if there is at least one set of values for the unknowns that satisfies every equation in the system—that is, that when substituted into each of the equations makes each equation hold true as an identity. In contrast, an equation system is inconsistent if there is no set of values for the unknowns that satisfies all of the equations.\n\nIf a system of equations is inconsistent, then it is possible to manipulate and combine the equations in such a way as to obtain contradictory information, such as 2 = 1, or \"x\" + \"y\" = 5 \"and\" \"x\" + \"y\" = 6 (which implies 5 = 6).\n\nBoth types of equation system, consistent and inconsistent, can be any of overdetermined (having more equations than unknowns), underdetermined (having fewer equations than unknowns), or exactly determined.\n\nThe system\n\nhas an infinite number of solutions, all of them having \"z\" = 1 (as can be seen by subtracting the first equation from the second), and all of them therefore having \"x+y\" = 2 for any values of \"x\" and \"y\".\n\nThe nonlinear system\n\nhas an infinitude of solutions, all involving formula_5\n\nSince each of these systems has more than one solution, it is an indeterminate system.\n\nThe system\n\nhas no solutions, as can be seen by subtracting the first equation from the second to obtain the impossible 0 = 1.\n\nThe nonlinear system\n\nhas no solutions, because if one equation is subtracted from the other we obtain the impossible 0 = 2.\n\nThe system \n\nhas exactly one solution: \"x\" = 1, \"y\"= 2.\n\nThe nonlinear system \n\nhas the two solutions (\"x, y\") = (1, 0) and (\"x, y\") = (0, 1), while\n\nhas an infinite number of solutions because the third equation is the first equation plus twice the second one and hence contains no independent information; thus any value of \"z\" can be chosen and values of \"x\" and \"y\" can be found to satisfy the first two (and hence the third) equations.\n\nThe system \n\nhas no solutions; the inconsistency can be seen by multiplying the first equation by 4 and subtracting the second equation to obtain the impossible 0 = 2.\n\nLikewise, \n\nis an inconsistent system because the first equation plus twice the second minus the third contains the contradiction 0 = 2.\n\nThe system \n\nhas a solution, \"x\" = –1, \"y\" = 4, because the first two equations do not contradict each other and the third equation is redundant (since it contains the same information as can be obtained from the first two equations by multiplying each through by 2 and summing them).\n\nThe system\n\nhas an infinitude of solutions since all three equations give the same information as each other (as can be seen by multiplying through the first equation by either 3 or 7). Any value of \"y\" is part of a solution, with the corresponding value of \"x\" being 7–2y.\n\nThe nonlinear system\n\nhas the three solutions (\"x, y\") = (1, –1), (–1, 1), and (1, 1).\n\nThe system\n\nis inconsistent because the last equation contradicts the information embedded in the first two, as seen by multiplying each of the first two through by 2 and summing them.\n\nThe system\n\nis inconsistent because the sum of the first two equations contradicts the third one.\n\nAs can be seen from the above examples, consistency versus inconsistency is a different issue from comparing the numbers of equations and unknowns.\n\nA linear system is consistent if and only if its coefficient matrix has the same rank as does its augmented matrix (the coefficient matrix with an extra column added, that column being the column vector of constants).\n"}
{"id": "749033", "url": "https://en.wikipedia.org/wiki?curid=749033", "title": "Dilworth's theorem", "text": "Dilworth's theorem\n\nIn mathematics, in the areas of order theory and combinatorics, Dilworth's theorem characterizes the width of any finite partially ordered set in terms of a partition of the order into a minimum number of chains. It is named for the mathematician .\n\nAn antichain in a partially ordered set is a set of elements no two of which are comparable to each other, and a chain is a set of elements every two of which are comparable. Dilworth's theorem states that there exists an antichain \"A\", and a partition of the order into a family \"P\" of chains, such that the number of chains in the partition equals the cardinality of \"A\". When this occurs, \"A\" must be the largest antichain in the order, for any antichain can have at most one element from each member of \"P\". Similarly, \"P\" must be the smallest family of chains into which the order can be partitioned, for any partition into chains must have at least one chain per element of \"A\". The width of the partial order is defined as the common size of \"A\" and \"P\".\n\nAn equivalent way of stating Dilworth's theorem is that, in any finite partially ordered set, the maximum number of elements in any antichain equals the minimum number of chains in any partition of the set into chains. A version of the theorem for infinite partially ordered sets states that, in this case, a partially ordered set has finite width \"w\" if and only if it may be partitioned into \"w\" chains, but not less.\n\nThe following proof by induction on the size of the partially ordered set formula_1 is based on that of .\n\nLet formula_1 be a finite partially ordered set. The theorem holds trivially if formula_1 is empty. So, assume that formula_1 has at least one element, and let formula_5 be a maximal element of formula_1.\n\nBy induction, we assume that for some integer formula_7 the partially ordered set formula_8 can be covered by formula_7 disjoint chains formula_10 and has at least one antichain formula_11 of size formula_7. Clearly, formula_13 for formula_14. For formula_14, let formula_16 be the maximal element in formula_17 that belongs to an antichain of size formula_7 in formula_19, and set formula_20. \nWe claim that formula_21 is an antichain. \nLet formula_22 be an antichain of size formula_7 that contains formula_16. Fix arbitrary distinct indices formula_25 and formula_26. Then formula_27. Let formula_28. Then formula_29, by the definition of formula_30. This implies that formula_31, since formula_32. By interchanging the roles of formula_25 and formula_26 in this argument we also have formula_35. This verifies that formula_21 is an antichain.\n\nWe now return to formula_1. Suppose first that formula_38 for some formula_39. Let formula_40 be the chain formula_41. Then by the choice of formula_16, formula_43 does not have an antichain of size formula_7. Induction then implies that formula_43 can be covered by formula_46 disjoint chains since formula_47 is an antichain of size formula_48 in formula_49. \nThus, formula_1 can be covered by formula_7 disjoint chains, as required. Next, if formula_52 for each formula_39, then formula_54 is an antichain of size formula_55 in formula_1 (since formula_5 is maximal in formula_1). Now formula_1 can be covered by the formula_55 chains formula_61, completing the proof.\n\nLike a number of other results in combinatorics, Dilworth's theorem is equivalent to Kőnig's theorem on bipartite graph matching and several other related theorems including Hall's marriage theorem .\n\nTo prove Dilworth's theorem for a partial order \"S\" with \"n\" elements, using Kőnig's theorem, define a bipartite graph \"G\" = (\"U\",\"V\",\"E\") where \"U\" = \"V\" = \"S\" and where (\"u\",\"v\") is an edge in \"G\" when \"u\" < \"v\" in \"S\". By Kőnig's theorem, there exists a matching \"M\" in \"G\", and a set of vertices \"C\" in \"G\", such that each edge in the graph contains at least one vertex in \"C\" and such that \"M\" and \"C\" have the same cardinality \"m\". Let \"A\" be the set of elements of \"S\" that do not correspond to any vertex in \"C\"; then \"A\" has at least \"n\" - \"m\" elements (possibly more if \"C\" contains vertices corresponding to the same element on both sides of the bipartition). Let \"P\" be a family of chains formed by including \"x\" and \"y\" in the same chain whenever there is an edge (\"x\",\"y\") in \"M\"; then \"P\" has \"n\" - \"m\" chains. Therefore, we have constructed an antichain and a partition into chains with the same cardinality.\n\nTo prove Kőnig's theorem from Dilworth's theorem, for a bipartite graph \"G\" = (\"U\",\"V\",\"E\"), form a partial order on the vertices of \"G\" in which \"u\" < \"v\" exactly when \"u\" is in \"U\", \"v\" is in \"V\", and there exists an edge in \"E\" from \"u\" to \"v\". By Dilworth's theorem, there exists an antichain \"A\" and a partition into chains \"P\" both of which have the same size. But the only nontrivial chains in the partial order are pairs of elements corresponding to the edges in the graph, so the nontrivial chains in \"P\" form a matching in the graph. The complement of \"A\" forms a vertex cover in \"G\" with the same cardinality as this matching.\n\nThis connection to bipartite matching allows the width of any partial order to be computed in polynomial time. More precisely, \"n\"-element partial orders of width \"k\" can be recognized in time \"O\"(\"kn\") .\n\nDilworth's theorem for infinite partially ordered sets states that a partially ordered set has finite width \"w\" if and only if it may be partitioned into \"w\" chains. For, suppose that an infinite partial order \"P\" has width \"w\", meaning that there are at most a finite number \"w\" of elements in any antichain. For any subset \"S\" of \"P\", a decomposition into \"w\" chains (if it exists) may be described as a coloring of the incomparability graph of \"S\" (a graph that has the elements of \"S\" as vertices, with an edge between every two incomparable elements) using \"w\" colors; every color class in a proper coloring of the incomparability graph must be a chain. By the assumption that \"P\" has width \"w\", and by the finite version of Dilworth's theorem, every finite subset \"S\" of \"P\" has a \"w\"-colorable incomparability graph. Therefore, by the De Bruijn–Erdős theorem, \"P\" itself also has a \"w\"-colorable incomparability graph, and thus has the desired partition into chains .\n\nHowever, the theorem does not extend so simply to partially ordered sets in which the width, and not just the cardinality of the set, is infinite. In this case the size of the largest antichain and the minimum number of chains needed to cover the partial order may be very different from each other. In particular, for every infinite cardinal number κ there is an infinite partially ordered set of width ℵ whose partition into the fewest chains has κ chains .\n\nA dual of Dilworth's theorem states that the size of the largest chain in a partial order (if finite) equals the smallest number of antichains into which the order may be partitioned . The proof of this is much simpler than the proof of Dilworth's theorem itself: for any element \"x\", consider the chains that have \"x\" as their largest element, and let \"N\"(\"x\") denote the size of the largest of these \"x\"-maximal chains. Then each set \"N\"(\"i\"), consisting of elements that have equal values of \"N\", is an antichain, and these antichains partition the partial order into a number of antichains equal to the size of the largest chain.\n\nA comparability graph is an undirected graph formed from a partial order by creating a vertex per element of the order, and an edge connecting any two comparable elements. Thus, a clique in a comparability graph corresponds to a chain, and an independent set in a comparability graph corresponds to an antichain. Any induced subgraph of a comparability graph is itself a comparability graph, formed from the restriction of the partial order to a subset of its elements.\n\nAn undirected graph is perfect if, in every induced subgraph, the chromatic number equals the size of the largest clique. Every comparability graph is perfect: this is essentially just Mirsky's theorem, restated in graph-theoretic terms . By the perfect graph theorem of , the complement of any perfect graph is also perfect. Therefore, the complement of any comparability graph is perfect; this is essentially just Dilworth's theorem itself, restated in graph-theoretic terms . Thus, the complementation property of perfect graphs can provide an alternative proof of Dilworth's theorem.\n\nThe Boolean lattice \"B\" is the power set of an \"n\"-element set \"X\"—essentially {1, 2, …, \"n\"}—ordered by inclusion or, notationally, (2, ⊆). Sperner's theorem states that a maximum antichain of \"B\" has size at most\nIn other words, a largest family of incomparable subsets of \"X\" is obtained by selecting the subsets of \"X\" that have median size. The Lubell–Yamamoto–Meshalkin inequality also concerns antichains in a power set and can be used to prove Sperner's theorem.\n\nIf we order the integers in the interval [1, 2\"n\"] by divisibility, the subinterval [\"n\" + 1, 2\"n\"] forms an antichain with cardinality \"n\". A partition of this partial order into \"n\" chains is easy to achieve: for each odd integer \"m\" in [1,2\"n\"], form a chain of the numbers of the form \"m\"2. Therefore, by Dilworth's theorem, the width of this partial order is \"n\".\n\nThe Erdős–Szekeres theorem on monotone subsequences can be interpreted as an application of Dilworth's theorem to partial orders of order dimension two .\n\nThe \"convex dimension\" of an antimatroid is defined as the minimum number of chains needed to define the antimatroid, and Dilworth's theorem can be used to show that it equals the width of an associated partial order; this connection leads to a polynomial time algorithm for convex dimension .\n\n\n"}
{"id": "39813016", "url": "https://en.wikipedia.org/wiki?curid=39813016", "title": "Dis-unification (computer science)", "text": "Dis-unification (computer science)\n\nDis-unification, in computer science and logic, is an algorithmic process of solving inequations between symbolic expressions.\n\n\n"}
{"id": "9087", "url": "https://en.wikipedia.org/wiki?curid=9087", "title": "Dynamical system", "text": "Dynamical system\n\nIn mathematics, a dynamical system is a system in which a function describes the time dependence of a point in a geometrical space. Examples include the mathematical models that describe the swinging of a clock pendulum, the flow of water in a pipe, and the number of fish each springtime in a lake.\n\nAt any given time, a dynamical system has a state given by a tuple of real numbers (a vector) that can be represented by a point in an appropriate state space (a geometrical manifold). The \"evolution rule\" of the dynamical system is a function that describes what future states follow from the current state. Often the function is deterministic, that is, for a given time interval only one future state follows from the current state. However, some systems are stochastic, in that random events also affect the evolution of the state variables.\n\nIn physics, a dynamical system is described as a \"particle or ensemble of particles whose state varies over time and thus obeys differential equations involving time derivatives.\" In order to make a prediction about the system’s future behavior, an analytical solution of such equations or their integration over time through computer simulation is realized.\n\nThe study of dynamical systems is the focus of dynamical systems theory, which has applications to a wide variety of fields such as mathematics, physics, biology, chemistry, engineering, economics, and medicine. Dynamical systems are a fundamental part of chaos theory, logistic map dynamics, bifurcation theory, the self-assembly process, and the edge of chaos concept.\n\nThe concept of a dynamical system has its origins in Newtonian mechanics. There, as in other natural sciences and engineering disciplines, the evolution rule of dynamical systems is an implicit relation that gives the state of the system for only a short time into the future. (The relation is either a differential equation, difference equation or other time scale.) To determine the state for all future times requires iterating the relation many times—each advancing time a small step. The iteration procedure is referred to as \"solving the system\" or \"integrating the system\". If the system can be solved, given an initial point it is possible to determine all its future positions, a collection of points known as a \"trajectory\" or \"orbit\".\n\nBefore the advent of computers, finding an orbit required sophisticated mathematical techniques and could be accomplished only for a small class of dynamical systems. Numerical methods implemented on electronic computing machines have simplified the task of determining the orbits of a dynamical system.\n\nFor simple dynamical systems, knowing the trajectory is often sufficient, but most dynamical systems are too complicated to be understood in terms of individual trajectories. The difficulties arise because:\n\nMany people regard Henri Poincaré as the founder of dynamical systems. Poincaré published two now classical monographs, \"New Methods of Celestial Mechanics\" (1892–1899) and \"Lectures on Celestial Mechanics\" (1905–1910). In them, he successfully applied the results of their research to the problem of the motion of three bodies and studied in detail the behavior of solutions (frequency, stability, asymptotic, and so on). These papers included the Poincaré recurrence theorem, which states that certain systems will, after a sufficiently long but finite time, return to a state very close to the initial state.\n\nAleksandr Lyapunov developed many important approximation methods. His methods, which he developed in 1899, make it possible to define the stability of sets of ordinary differential equations. He created the modern theory of the stability of a dynamic system.\n\nIn 1913, George David Birkhoff proved Poincaré's \"Last Geometric Theorem\", a special case of the three-body problem, a result that made him world-famous. In 1927, he published his \"Dynamical Systems\"Birkhoff's most durable result has been his 1931 discovery of what is now called the ergodic theorem. Combining insights from physics on the ergodic hypothesis with measure theory, this theorem solved, at least in principle, a fundamental problem of statistical mechanics. The ergodic theorem has also had repercussions for dynamics.\n\nStephen Smale made significant advances as well. His first contribution is the Smale horseshoe that jumpstarted significant research in dynamical systems. He also outlined a research program carried out by many others.\n\nOleksandr Mykolaiovych Sharkovsky developed Sharkovsky's theorem on the periods of discrete dynamical systems in 1964. One of the implications of the theorem is that if a discrete dynamical system on the real line has a periodic point of period 3, then it must have periodic points of every other period.\n\nA dynamical system is a manifold \"M\" called the phase (or state) space endowed with a family of smooth evolution functions Φ that for any element of \"t\" ∈ \"T\", the time, map a point of the phase space back into the phase space. The notion of smoothness changes with applications and the type of manifold. There are several choices for the set \"T\". When \"T\" is taken to be the reals, the dynamical system is called a \"flow\"; and if \"T\" is restricted to the non-negative reals, then the dynamical system is a \"semi-flow\". When \"T\" is taken to be the integers, it is a \"cascade\" or a \"map\"; and the restriction to the non-negative integers is a \"semi-cascade\".\n\nThe evolution function Φ is often the solution of a \"differential equation of motion\"\n\nThe equation gives the time derivative, represented by the dot, of a trajectory \"x\"(\"t\") on the phase space starting at some point \"x\". The vector field \"v\"(\"x\") is a smooth function that at every point of the phase space \"M\" provides the velocity vector of the dynamical system at that point. (These vectors are not vectors in the phase space \"M\", but in the tangent space \"TM\" of the point \"x\".) Given a smooth Φ, an autonomous vector field can be derived from it.\n\nThere is no need for higher order derivatives in the equation, nor for time dependence in \"v\"(\"x\") because these can be eliminated by considering systems of higher dimensions. Other types of differential equations can be used to define the evolution rule:\n\nis an example of an equation that arises from the modeling of mechanical systems with complicated constraints.\n\nThe differential equations determining the evolution function Φ are often ordinary differential equations; in this case the phase space \"M\" is a finite dimensional manifold. Many of the concepts in dynamical systems can be extended to infinite-dimensional manifolds—those that are locally Banach spaces—in which case the differential equations are partial differential equations. In the late 20th century the dynamical system perspective to partial differential equations started gaining popularity.\n\nLinear dynamical systems can be solved in terms of simple functions and the behavior of all orbits classified. In a linear system the phase space is the \"N\"-dimensional Euclidean space, so any point in phase space can be represented by a vector with \"N\" numbers. The analysis of linear systems is possible because they satisfy a superposition principle: if \"u\"(\"t\") and \"w\"(\"t\") satisfy the differential equation for the vector field (but not necessarily the initial condition), then so will \"u\"(\"t\") + \"w\"(\"t\").\n\nFor a flow, the vector field Φ(\"x\") is an affine function of the position in the phase space, that is,\nwith \"A\" a matrix, \"b\" a vector of numbers and \"x\" the position vector. The solution to this system can be found by using the superposition principle (linearity).\nThe case \"b\" ≠ 0 with \"A\" = 0 is just a straight line in the direction of \"b\":\n\nWhen \"b\" is zero and \"A\" ≠ 0 the origin is an equilibrium (or singular) point of the flow, that is, if \"x\" = 0, then the orbit remains there.\nFor other initial conditions, the equation of motion is given by the exponential of a matrix: for an initial point \"x\",\n\nWhen \"b\" = 0, the eigenvalues of \"A\" determine the structure of the phase space. From the eigenvalues and the eigenvectors of \"A\" it is possible to determine if an initial point will converge or diverge to the equilibrium point at the origin.\n\nThe distance between two different initial conditions in the case \"A\" ≠ 0 will change exponentially in most cases, either converging exponentially fast towards a point, or diverging exponentially fast. Linear systems display sensitive dependence on initial conditions in the case of divergence. For nonlinear systems this is one of the (necessary but not sufficient) conditions for chaotic behavior.\n\nA discrete-time, affine dynamical system has the form of a matrix difference equation:\nwith \"A\" a matrix and \"b\" a vector. As in the continuous case, the change of coordinates \"x\" → \"x\" + (1 − \"A\")\"b\" removes the term \"b\" from the equation. In the new coordinate system, the origin is a fixed point of the map and the solutions are of the linear system \"A\"\"x\".\nThe solutions for the map are no longer curves, but points that hop in the phase space. The orbits are organized in curves, or fibers, which are collections of points that map into themselves under the action of the map.\n\nAs in the continuous case, the eigenvalues and eigenvectors of \"A\" determine the structure of phase space. For example, if \"u\" is an eigenvector of \"A\", with a real eigenvalue smaller than one, then the straight lines given by the points along \"α\" \"u\", with \"α\" ∈ R, is an invariant curve of the map. Points in this straight line run into the fixed point.\n\nThere are also many other discrete dynamical systems.\n\nThe qualitative properties of dynamical systems do not change under a smooth change of coordinates (this is sometimes taken as a definition of qualitative): a \"singular point\" of the vector field (a point where \"v\"(\"x\") = 0) will remain a singular point under smooth transformations; a \"periodic orbit\" is a loop in phase space and smooth deformations of the phase space cannot alter it being a loop. It is in the neighborhood of singular points and periodic orbits that the structure of a phase space of a dynamical system can be well understood. In the qualitative study of dynamical systems, the approach is to show that there is a change of coordinates (usually unspecified, but computable) that makes the dynamical system as simple as possible.\n\nA flow in most small patches of the phase space can be made very simple. If \"y\" is a point where the vector field \"v\"(\"y\") ≠ 0, then there is a change of coordinates for a region around \"y\" where the vector field becomes a series of parallel vectors of the same magnitude. This is known as the rectification theorem.\n\nThe \"rectification theorem\" says that away from singular points the dynamics of a point in a small patch is a straight line. The patch can sometimes be enlarged by stitching several patches together, and when this works out in the whole phase space \"M\" the dynamical system is \"integrable\". In most cases the patch cannot be extended to the entire phase space. There may be singular points in the vector field (where \"v\"(\"x\") = 0); or the patches may become smaller and smaller as some point is approached. The more subtle reason is a global constraint, where the trajectory starts out in a patch, and after visiting a series of other patches comes back to the original one. If the next time the orbit loops around phase space in a different way, then it is impossible to rectify the vector field in the whole series of patches.\n\nIn general, in the neighborhood of a periodic orbit the rectification theorem cannot be used. Poincaré developed an approach that transforms the analysis near a periodic orbit to the analysis of a map. Pick a point \"x\" in the orbit γ and consider the points in phase space in that neighborhood that are perpendicular to \"v\"(\"x\"). These points are a Poincaré section \"S\"(\"γ\", \"x\"), of the orbit. The flow now defines a map, the Poincaré map \"F\" : \"S\" → \"S\", for points starting in \"S\" and returning to \"S\". Not all these points will take the same amount of time to come back, but the times will be close to the time it takes \"x\".\n\nThe intersection of the periodic orbit with the Poincaré section is a fixed point of the Poincaré map \"F\". By a translation, the point can be assumed to be at \"x\" = 0. The Taylor series of the map is \"F\"(\"x\") = \"J\" · \"x\" + O(\"x\"), so a change of coordinates \"h\" can only be expected to simplify \"F\" to its linear part\n\nThis is known as the conjugation equation. Finding conditions for this equation to hold has been one of the major tasks of research in dynamical systems. Poincaré first approached it assuming all functions to be analytic and in the process discovered the non-resonant condition. If \"λ\", ..., \"λ\" are the eigenvalues of \"J\" they will be resonant if one eigenvalue is an integer linear combination of two or more of the others. As terms of the form \"λ\" – ∑ (multiples of other eigenvalues) occurs in the denominator of the terms for the function \"h\", the non-resonant condition is also known as the small divisor problem.\n\nThe results on the existence of a solution to the conjugation equation depend on the eigenvalues of \"J\" and the degree of smoothness required from \"h\". As \"J\" does not need to have any special symmetries, its eigenvalues will typically be complex numbers. When the eigenvalues of \"J\" are not in the unit circle, the dynamics near the fixed point \"x\" of \"F\" is called \"hyperbolic\" and when the eigenvalues are on the unit circle and complex, the dynamics is called \"elliptic\".\n\nIn the hyperbolic case, the Hartman–Grobman theorem gives the conditions for the existence of a continuous function that maps the neighborhood of the fixed point of the map to the linear map \"J\" · \"x\". The hyperbolic case is also \"structurally stable\". Small changes in the vector field will only produce small changes in the Poincaré map and these small changes will reflect in small changes in the position of the eigenvalues of \"J\" in the complex plane, implying that the map is still hyperbolic.\n\nThe Kolmogorov–Arnold–Moser (KAM) theorem gives the behavior near an elliptic point.\n\nWhen the evolution map Φ (or the vector field it is derived from) depends on a parameter μ, the structure of the phase space will also depend on this parameter. Small changes may produce no qualitative changes in the phase space until a special value \"μ\" is reached. At this point the phase space changes qualitatively and the dynamical system is said to have gone through a bifurcation.\n\nBifurcation theory considers a structure in phase space (typically a fixed point, a periodic orbit, or an invariant torus) and studies its behavior as a function of the parameter \"μ\". At the bifurcation point the structure may change its stability, split into new structures, or merge with other structures. By using Taylor series approximations of the maps and an understanding of the differences that may be eliminated by a change of coordinates, it is possible to catalog the bifurcations of dynamical systems.\n\nThe bifurcations of a hyperbolic fixed point \"x\" of a system family \"F\" can be characterized by the eigenvalues of the first derivative of the system \"DF\"(\"x\") computed at the bifurcation point. For a map, the bifurcation will occur when there are eigenvalues of \"DF\" on the unit circle. For a flow, it will occur when there are eigenvalues on the imaginary axis. For more information, see the main article on Bifurcation theory.\n\nSome bifurcations can lead to very complicated structures in phase space. For example, the Ruelle–Takens scenario describes how a periodic orbit bifurcates into a torus and the torus into a strange attractor. In another example, Feigenbaum period-doubling describes how a stable periodic orbit goes through a series of period-doubling bifurcations.\n\nIn many dynamical systems, it is possible to choose the coordinates of the system so that the volume (really a ν-dimensional volume) in phase space is invariant. This happens for mechanical systems derived from Newton's laws as long as the coordinates are the position and the momentum and the volume is measured in units of (position) × (momentum). The flow takes points of a subset \"A\" into the points Φ(\"A\") and invariance of the phase space means that\nIn the Hamiltonian formalism, given a coordinate it is possible to derive the appropriate (generalized) momentum such that the associated volume is preserved by the flow. The volume is said to be computed by the Liouville measure.\n\nIn a Hamiltonian system, not all possible configurations of position and momentum can be reached from an initial condition. Because of energy conservation, only the states with the same energy as the initial condition are accessible. The states with the same energy form an energy shell Ω, a sub-manifold of the phase space. The volume of the energy shell, computed using the Liouville measure, is preserved under evolution.\n\nFor systems where the volume is preserved by the flow, Poincaré discovered the recurrence theorem: Assume the phase space has a finite Liouville volume and let \"F\" be a phase space volume-preserving map and \"A\" a subset of the phase space. Then almost every point of \"A\" returns to \"A\" infinitely often. The Poincaré recurrence theorem was used by Zermelo to object to Boltzmann's derivation of the increase in entropy in a dynamical system of colliding atoms.\n\nOne of the questions raised by Boltzmann's work was the possible equality between time averages and space averages, what he called the ergodic hypothesis. The hypothesis states that the length of time a typical trajectory spends in a region \"A\" is vol(\"A\")/vol(Ω).\n\nThe ergodic hypothesis turned out not to be the essential property needed for the development of statistical mechanics and a series of other ergodic-like properties were introduced to capture the relevant aspects of physical systems. Koopman approached the study of ergodic systems by the use of functional analysis. An observable \"a\" is a function that to each point of the phase space associates a number (say instantaneous pressure, or average height). The value of an observable can be computed at another time by using the evolution function φ. This introduces an operator \"U\", the transfer operator,\n\nBy studying the spectral properties of the linear operator \"U\" it becomes possible to classify the ergodic properties of Φ. In using the Koopman approach of considering the action of the flow on an observable function, the finite-dimensional nonlinear problem involving Φ gets mapped into an infinite-dimensional linear problem involving \"U\".\n\nThe Liouville measure restricted to the energy surface Ω is the basis for the averages computed in equilibrium statistical mechanics. An average in time along a trajectory is equivalent to an average in space computed with the Boltzmann factor exp(−β\"H\"). This idea has been generalized by Sinai, Bowen, and Ruelle (SRB) to a larger class of dynamical systems that includes dissipative systems. SRB measures replace the Boltzmann factor and they are defined on attractors of chaotic systems.\n\nSimple nonlinear dynamical systems and even piecewise linear systems can exhibit a completely unpredictable behavior, which might seem to be random, despite the fact that they are fundamentally deterministic. This seemingly unpredictable behavior has been called \"chaos\". Hyperbolic systems are precisely defined dynamical systems that exhibit the properties ascribed to chaotic systems. In hyperbolic systems the tangent space perpendicular to a trajectory can be well separated into two parts: one with the points that converge towards the orbit (the \"stable manifold\") and another of the points that diverge from the orbit (the \"unstable manifold\").\n\nThis branch of mathematics deals with the long-term qualitative behavior of dynamical systems. Here, the focus is not on finding precise solutions to the equations defining the dynamical system (which is often hopeless), but rather to answer questions like \"Will the system settle down to a steady state in the long term, and if so, what are the possible attractors?\" or \"Does the long-term behavior of the system depend on its initial condition?\"\n\nNote that the chaotic behavior of complex systems is not the issue. Meteorology has been known for years to involve complex—even chaotic—behavior. Chaos theory has been so surprising because chaos can be found within almost trivial systems. The logistic map is only a second-degree polynomial; the horseshoe map is piecewise linear.\n\nA dynamical system is the tuple formula_10, with formula_11 a manifold (locally a Banach space or Euclidean space), formula_12 the domain for time (non-negative reals, the integers, ...) and \"f\" an evolution rule \"t\" → \"f\" (with formula_13) such that \"f\" is a diffeomorphism of the manifold to itself. So, f is a mapping of the time-domain formula_14 into the space of diffeomorphisms of the manifold to itself. In other terms, \"f\"(\"t\") is a diffeomorphism, for every time \"t\" in the domain formula_14 .\n\nA dynamical system may be defined formally, as a measure-preserving transformation of a sigma-algebra, the quadruplet (\"X\", Σ, μ, τ). Here, \"X\" is a set, and Σ is a sigma-algebra on \"X\", so that the pair (\"X\", Σ) is a measurable space. μ is a finite measure on the sigma-algebra, so that the triplet (\"X\", Σ, μ) is a probability space. A map τ: \"X\" → \"X\" is said to be Σ-measurable if and only if, for every σ ∈ Σ, one has formula_16. A map τ is said to preserve the measure if and only if, for every σ ∈ Σ, one has formula_17. Combining the above, a map τ is said to be a measure-preserving transformation of \"X\" , if it is a map from \"X\" to itself, it is Σ-measurable, and is measure-preserving. The quadruple (\"X\", Σ, μ, τ), for such a τ, is then defined to be a dynamical system.\n\nThe map τ embodies the time evolution of the dynamical system. Thus, for discrete dynamical systems the iterates formula_18 for integer \"n\" are studied. For continuous dynamical systems, the map τ is understood to be a finite time evolution map and the construction is more complicated.\n\nDynamical systems are defined over a single independent variable, usually thought of as time. A more general class of systems are defined over multiple independent variables and are therefore called multidimensional systems. Such systems are useful for modeling, for example, image processing.\n\nWorks providing a broad coverage:\n\nIntroductory texts with a unique perspective:\n\nTextbooks\n\nPopularizations:\n\n\n\n"}
{"id": "12158034", "url": "https://en.wikipedia.org/wiki?curid=12158034", "title": "Edge (geometry)", "text": "Edge (geometry)\n\nIn geometry, an edge is a particular type of line segment joining two vertices in a polygon, polyhedron, or higher-dimensional polytope. In a polygon, an edge is a line segment on the boundary, and is often called a side. In a polyhedron or more generally a polytope, an edge is a line segment where two faces meet. A segment joining two vertices while passing through the interior or exterior is not an edge but instead is called a diagonal.\n\nIn graph theory, an edge is an abstract object connecting two graph vertices, unlike polygon and polyhedron edges which have a concrete geometric representation as a line segment.\nHowever, any polyhedron can be represented by its skeleton or edge-skeleton, a graph whose vertices are the geometric vertices of the polyhedron and whose edges correspond to the geometric edges. Conversely, the graphs that are skeletons of three-dimensional polyhedra can be characterized by Steinitz's theorem as being exactly the 3-vertex-connected planar graphs.\n\nAny convex polyhedron's surface has Euler characteristic\n\nwhere \"V\" is the number of vertices, \"E\" is the number of edges, and \"F\" is the number of faces. This equation is known as Euler's polyhedron formula. Thus the number of edges is 2 less than the sum of the numbers of vertices and faces. For example, a cube has 8 vertices and 6 faces, and hence 12 edges.\n\nIn a polygon, two edges meet at each vertex; more generally, by Balinski's theorem, at least \"d\" edges meet at every vertex of a \"d\"-dimensional convex polytope.\nSimilarly, in a polyhedron, exactly two two-dimensional faces meet at every edge, while in higher dimensional polytopes three or more two-dimensional faces meet at every edge.\n\nIn the theory of high-dimensional convex polytopes, a facet or \"side\" of a \"d\"-dimensional polytope is one of its (\"d\" − 1)-dimensional features, a ridge is a (\"d\" − 2)-dimensional feature, and a peak is a (\"d\" − 3)-dimensional feature. Thus, the edges of a polygon are its facets, the edges of a 3-dimensional convex polyhedron are its ridges, and the edges of a 4-dimensional polytope are its peaks.\n\n\n"}
{"id": "26992157", "url": "https://en.wikipedia.org/wiki?curid=26992157", "title": "Eigenvalues and eigenvectors of the second derivative", "text": "Eigenvalues and eigenvectors of the second derivative\n\nExplicit formulas for eigenvalues and eigenvectors of the second derivative with different boundary conditions are provided both for the continuous and discrete cases. In the discrete case, the standard central difference approximation of the second derivative is used on a uniform grid. \n\nThese formulas are used to derive the expressions for eigenfunctions of Laplacian in case of separation of variables, as well as to find eigenvalues and eigenvectors of multidimensional discrete Laplacian on a regular grid, which is presented as a Kronecker sum of discrete Laplacians in one-dimension.\n\nThe index j represents the jth eigenvalue or eigenvector and runs from 1 to formula_1. Assuming the equation is defined on the domain formula_2, the following are the eigenvalues and normalized eigenvectors. The eigenvalues are ordered in descending order.\n\n(That is: formula_8 is a simple eigenvalue and all further eigenvalues are given by formula_9, formula_10, each with multiplicity 2).\n\nNotation: The index j represents the jth eigenvalue or eigenvector. The index i represents the ith component of an eigenvector. Both i and j go from 1 to n, where the matrix is size n x n. Eigenvectors are normalized. The eigenvalues are ordered in descending order.\n\nIn the 1D discrete case with Dirichlet boundary conditions, we are solving\n\nRearranging terms, we get\n\nNow let formula_28. Also, assuming formula_29, we can scale eigenvectors by any nonzero scalar, so scale formula_30 so that formula_31.\n\nThen we find the recurrence\n\nConsidering formula_35 as an indeterminate,\n\nwhere formula_37 is the kth Chebyshev polynomial of the 2nd kind.\n\nSince formula_38, we get that \n\nIt is clear that the eigenvalues of our problem will be the zeros of the nth Chebyshev polynomial of the second kind, with the relation formula_28.\n\nThese zeros are well known and are:\n\nPlugging these into the formula for formula_42,\n\nAnd using a trig formula to simplify, we find\n\nIn the Neumann case, we are solving\n\nIn the standard discretization, we introduce formula_47 and formula_48 and define\n\nThe boundary conditions are then equivalent to\n\nIf we make a change of variables,\n\nwe can derive the following:\n\nwith formula_53 being the boundary conditions.\n\nThis is precisely the Dirichlet formula with formula_54 interior grid points and grid spacing formula_55. Similar to what we saw in the above, assuming formula_56, we get\n\nThis gives us formula_54 eigenvalues and there are formula_59. If we drop the assumption that formula_56, we find there is also a solution with formula_61 and this corresponds to eigenvalue formula_8.\n\nRelabeling the indices in the formula above and combining with the zero eigenvalue, we obtain,\n\nFor the Dirichlet-Neumann case, we are solving\n\nwhere formula_65\n\nWe need to introduce auxiliary variables formula_66\n\nConsider the recurrence\n\nAlso, we know formula_68 and assuming formula_69, we can scale formula_70 so that formula_71\n\nWe can also write\n\nTaking the correct combination of these three equations, we can obtain\n\nAnd thus our new recurrence will solve our eigenvalue problem when\n\nSolving for formula_42 we get \n\nOur new recurrence gives \n\nwhere formula_79 again is the kth Chebyshev polynomial of the 2nd kind.\n\nAnd combining with our Neumann boundary condition, we have\n\nA well-known formula relates the Chebyshev polynomials of the first kind, formula_81, to those of the second kind by\n\nThus our eigenvalues solve \n\nThe zeros of this polynomial are also known to be\n\nAnd thus \n\nNote that there are 2n + 1 of these values, but only the first n + 1 are unique. The (n + 1)th value gives us the zero vector as an eigenvector with eigenvalue 0, which is trivial. This can be seen by returning to the original recurrence. So we consider only the first n of these values to be the n eigenvalues of the Dirichlet - Neumann problem.\n"}
{"id": "47503508", "url": "https://en.wikipedia.org/wiki?curid=47503508", "title": "Eugenia Cheng", "text": "Eugenia Cheng\n\nEugenia Loh-Gene Cheng is an English mathematician, pianist, Scientist-in-Residence at the School of the Art Institute of Chicago and an honorary fellow of pure mathematics at the University of Sheffield. Her mathematical interests include higher-dimensional category theory, and as a pianist she specialises in lieder and art song. She is also passionate about explaining mathematics to non-mathematicians to rid the world of math phobia, often using entertaining analogies with food and baking.\nCheng was born in Hampshire, England but moved to Sussex when she was one, and spent the rest of her childhood there. Her interest in mathematics stemmed from a young age thanks largely to her mother who made mathematics a part of life. Her father was also supportive, encouraging her to be imaginative; but Cheng's biggest influence was her mother, who introduced stimulating mathematical ideas and used the language of logic naturally.\n\nCheng attended Roedean School. She was bored by school when she was young, but practised the piano every day and was an avid reader. She was also “very serious about eating”. She studied the Mathematical Tripos at the University of Cambridge where she was a student of Gonville and Caius College, Cambridge. Her postgraduate research was supervised by Martin Hyland.\n\nBefore working at the School of the Art Institute of Chicago, Cheng has held academic appointments at the University of Nice Sophia Antipolis, the University of Sheffield and the University of Chicago. Cheng is still affiliated to the University of Sheffield as a senior lecturer of pure mathematics, but is now based at the School of the Art Institute of Chicago, where she teaches mathematics to arts students. She has published over a dozen research papers across several journals within her area of category theory. Former doctoral students include Nick Gurski and Thomas Cottrell.\n\nCheng's research interests are in category theory, which she has written about for a general audience by using analogies from baking. Her vision is to rid the world of mathematics phobia. In \"How to Bake Pi\", each chapter begins with a recipe for a dessert, to illustrate the commonalities in the methods and principles of mathematics and cooking. The book was well received and has since been translated into French. \n\nCheng has also written a number of papers with similar themes, such as \"On the perfect quantity of cream for a scone\" and \"On the perfect size for a pizza\". Cheng has presented similar topics through YouTube in a light-hearted manner, and has explored mathematics in other entertaining ways such as in her speech \"Mathematics and Lego: the untold story\".\n\nCheng's second book, \"Beyond Infinity,\" explains set theory for lay audiences using analogies and anecdotes, including Cantor's diagonal argument and Zeno's paradoxes. It was shortlisted for the 2017 Insight Investment Science Book Prize under the Royal Society Prizes for Science Books. \n\nShe published her third book, \"The Art of Logic in an Illogical World,\" in 2018. It explores arguments on real-world topics like same-sex marriage, white privilege, and police brutality in the United States using methods from logic, including explanations of Russell's paradox and Euclid's axioms on the way.\n\nCheng writes a column called \"Everyday Math\" for The Wall Street Journal on topics including probability theory, set theory, and Rubik's Cube solutions. \n\nCheng is a pianist who specializes in lieder and art song. She was awarded the Sheila Mossman Memorial Award from the Associated Board of the Royal Schools of Music, and was the first recipient of the Brighton and Hove Arts Council Award for the Musician of the Year. In Chicago, she gave a recital in the Pianoforte Chicago recital series; she performed \"Schwanengesang\" and \"Winterreise\" with Paul Geiger at Schubertiade Chicago in 2005 and 2006 respectively, and \"Die Schöne Müllerin\" with Ryan de Ryan at Schubertiade Chicago 2007. She performed lieder with tenor Nicholas Harkness in the Noontime Recital Series at the University of Chicago, the Salon Series at the Tower Club, and the Maxwell Recital Series, and she gave recitals for the Auxiliary Board Chapter of the Lyric Opera; she also performed \"La Traviata\" at the Oak Park Village Players.\n\nIn 2013, Cheng founded Liederstube as an oasis for art song in the Fine Arts Building, in downtown Chicago. The mission of Liederstube is to present and enjoy classical music in an intimate and informal setting. The Liederstube is a Not For Profit 501(c)(3) organization.\n\nCheng has appeared on \"The Late Show with Stephen Colbert\" making Mille-feuille with Stephen Colbert in 2015 to demonstrate exponentials. She was interviewed for the morning magazine show \"The Morning Shift\" on Chicago's Public Radio station \"WBEZ\" in 2017. She was interviewed by Jim Al-Khalili for \"The Life Scientific\" on BBC Radio 4, first broadcast in January 2018. She appeared on the WGBH podcast Innovation Hub in spring 2018.\n\n\n"}
{"id": "6613227", "url": "https://en.wikipedia.org/wiki?curid=6613227", "title": "Friedrichs's inequality", "text": "Friedrichs's inequality\n\nIn mathematics, Friedrichs's inequality is a theorem of functional analysis, due to Kurt Friedrichs. It places a bound on the \"L\" norm of a function using \"L\" bounds on the weak derivatives of the function and the geometry of the domain, and can be used to show that certain norms on Sobolev spaces are equivalent. Friedrichs's inequality is a general case of the Poincaré–Wirtinger inequality which deals with the case \"k\" = 1.\n\nLet formula_1 be a bounded subset of Euclidean space formula_2 with diameter formula_3. Suppose that formula_4 lies in the Sobolev space formula_5, i.e., formula_6 and the trace of formula_7 on the boundary formula_8 is zero. Then\n\n"}
{"id": "9395279", "url": "https://en.wikipedia.org/wiki?curid=9395279", "title": "Grothendieck inequality", "text": "Grothendieck inequality\n\nIn mathematics, the Grothendieck inequality states that there is a universal constant \"k\" with the following property. If \"a\" is an \"n\" by \"n\" (real or complex) matrix with\n\nfor all (real or complex) numbers \"s\", \"t\" of absolute value at most 1, then\n\nfor all vectors \"S\", \"T\" in the unit ball \"B\"(\"H\") of a (real or complex) Hilbert space \"H\", the constant \"k\" being independent of \"n\". For a fixed \"n\", the smallest constant which satisfies this property for all \"n\" by \"n\" matrices is called a Grothendieck constant and denoted \"k\"(\"n\"). In fact there are two Grothendieck constants \"k\"(\"n\") and \"k\"(\"n\") for each \"n\" depending on whether one works with real or complex numbers, respectively.\n\nThe Grothendieck inequality and Grothendieck constants are named after Alexander Grothendieck, who proved the inequality and the existence of the constants in a paper published in 1953.\n\nThe sequences \"k\"(\"n\") and \"k\"(\"n\") are easily seen to be increasing, and Grothendieck's result states that they are bounded, so they have limits.\n\nWith \"k\" defined to be sup \"k\"(\"n\") then Grothendieck proved that: formula_3.\n\nIf we replace the (real or complex) Hilbert space \"H\" in the above definition with a (real or complex) \"d\"-dimensional Euclidean space, we get the constants \"k\"(\"n\", \"d\") and \"k\"(\"n\", \"d\") for the real and complex case, respectively. With increasing \"d\" these constants are monotone increasing and their limit is \"k\"(\"n\") and \"k\"(\"n\"), respectively. For each \"d\", with increasing \"n\" the constants are also increasing and their limit is the Grothendieck constant of order \"d\" which can be denoted as \"k\"(∞, \"d\") and \"k\"(∞, \"d\"), respectively.\n\nThe Grothendieck constant \"k\"(∞, 3) plays an essential role in the quantum nonlocality problem of the two-qubit Werner states.\n\nSome historical data on best known lower bounds of \"k\"(∞, \"d\") is summarized in the following table.\nImplied bounds are shown in italics.\n\nSome historical data on best known upper bounds of \"k\"(∞, \"d\"):\n\n\n"}
{"id": "681049", "url": "https://en.wikipedia.org/wiki?curid=681049", "title": "H-cobordism", "text": "H-cobordism\n\nIn geometric topology and differential topology, an (\"n\" + 1)-dimensional cobordism \"W\" between \"n\"-dimensional manifolds \"M\" and \"N\" is an \"h\"-cobordism (the \"h\" stands for homotopy equivalence) if the inclusion maps\n\nare homotopy equivalences.\n\nThe \"h\"-cobordism theorem gives sufficient conditions for an \"h\"-cobordism to be trivial, i.e., to be C-isomorphic to the cylinder \"M\" × [0, 1]. Here C refers to any of the categories of smooth, piecewise linear, or topological manifolds.\n\nThe theorem was first proved by Stephen Smale for which he received the Fields Medal and is a fundamental result in the theory of high-dimensional manifolds. For a start, it almost immediately proves the Generalized Poincaré Conjecture.\n\nBefore Smale proved this theorem, mathematicians became stuck while trying to understand manifolds of dimension 3 or 4, and assumed that the higher-dimensional cases were even harder. The \"h\"-cobordism theorem showed that (simply connected) manifolds of dimension at least 5 are much easier than those of dimension 3 or 4. The proof of the theorem depends on the \"Whitney trick\" of Hassler Whitney, which geometrically untangles homologically-tangled spheres of complementary dimension in a manifold of dimension >4. An informal reason why manifolds of dimension 3 or 4 are unusually hard is that the trick fails to work in lower dimensions, which have no room for untanglement.\n\nLet \"n\" be at least 5 and let \"W\" be a compact (\"n\" + 1)-dimensional \"h\"-cobordism between \"M\" and \"N\" in the category C=Diff, PL, or Top such that \"W\", \"M\" and \"N\" are simply connected, then \"W\" is C-isomorphic to \"M\" × [0, 1]. The isomorphism can be chosen to be the identity on \"M\" × {0}.\n\nThis means that the homotopy equivalence between M, W, and N is homotopic to a C-isomorphism.\n\nFor \"n\" = 4, the \"h\"-cobordism theorem is true topologically (proved by Michael Freedman using a 4-dimensional Whitney trick) but is false PL and smoothly (as shown by Simon Donaldson).\n\nFor \"n\" = 3, the \"h\"-cobordism theorem for smooth manifolds has not been proved and, due to the 3-dimensional Poincaré conjecture, is equivalent to the hard open question of whether the 4-sphere has non-standard smooth structures.\n\nFor \"n\" = 2, the \"h\"-cobordism theorem is equivalent to the Poincaré conjecture stated by Poincaré in 1904 (one of the Millennium Problems) and was proved by Grigori Perelman in a series of three papers in 2002 and 2003, where he follows Richard S. Hamilton's program using Ricci flow.\n\nFor \"n\" = 1, the \"h\"-cobordism theorem is vacuously true, since there is no closed simply-connected 1-dimensional manifold.\n\nFor \"n\" = 0, the \"h\"-cobordism theorem is trivially true: the interval is the only connected cobordism between connected 0-manifolds.\n\nA Morse function formula_2 induces a handle decomposition of \"W\", i.e., if there is a single critical point of index \"k\" in formula_3, then the ascending cobordism formula_4 is obtained from formula_5 by attaching a \"k\"-handle. The goal of the proof is to find a handle decomposition with no handles at all so that integrating the non-zero gradient vector field of \"f\" gives the desired diffeomorphism to the trivial cobordism.\n\nThis is achieved through a series of techniques.\n\n1) Handle rearrangement\n\nFirst, we want to rearrange all handles by order so that lower order handles are attached first. The question is thus when can we slide an \"i\"-handle off of a \"j\"-handle? This can be done by a radial isotopy so long as the \"i\" attaching sphere and the \"j\" belt sphere do not intersect. We thus want formula_6 which is equivalent to formula_7.\n\nWe then define the handle chain complex formula_8 by letting formula_9 be the free abelian group on the \"k\"-handles and defining formula_10 by sending a \"k\"-handle formula_11 to formula_12, where formula_13 is the intersection number of the \"k\"-attaching sphere and the (\"k\" − 1)-belt sphere.\n\n2) Handle cancellation\n\nNext, we want to \"cancel\" handles. The idea is that attaching a \"k\"-handle formula_14 might create a hole that can be filled in by attaching a (\"k\" + 1)-handle formula_15. This would imply that formula_16 and so the formula_17 entry in the matrix of formula_18 would be formula_19. However, when is this condition sufficient? That is, when can we geometrically cancel handles if this condition is true? The answer lies in carefully analyzing when the manifold remains simply-connected after removing the attaching and belt spheres in question, and finding an embedded disk using the Whitney trick. This analysis leads to the requirement that \"n\" must be at least 5. Moreover, during the proof one requires that the cobordism has no 0-,1-,\"n\"-, or (\"n\" + 1)-handles which is obtained by the next technique.\n\n3) Handle trading\n\nThe idea of handle trading is to create a cancelling pair of (\"k\" + 1)- and (\"k\" + 2)-handles so that a given \"k\"-handle cancels with the (\"k\" + 1)-handle leaving behind the (\"k\" + 2)-handle. To do this, consider the core of the \"k\"-handle which is an element in formula_20. This group is trivial since \"W\" is an \"h\"-cobordism. Thus, there is a disk formula_21 which we can fatten to a cancelling pair as desired, so long as we can embed this disk into the boundary of \"W\". This embedding exists if formula_22. Since we are assuming \"n\" is at least 5 this means that \"k\" is either 0 or 1. Finally, by considering the negative of the given Morse function, −\"f\", we can turn the handle decomposition upside down and also remove the \"n\"- and (\"n\" + 1)-handles as desired.\n\n4) Handle sliding\n\nFinally, we want to make sure that doing row and column operations on formula_23 corresponds to a geometric operation. Indeed, it isn't hard to show (best done by drawing a picture) that sliding a \"k\"-handle formula_14 over another \"k\"-handle formula_25 replaces formula_14 by formula_27 in the basis for formula_9.\n\nThe proof of the theorem now follows: the handle chain complex is exact since formula_29. Thus formula_30 since the formula_9 are free. Then formula_23, which is an integer matrix, restricts to an invertible morphism which can thus be diagonalized via elementary row operations (handle sliding) and must have only formula_19 on the diagonal because it is invertible. Thus, all handles are paired with a single other cancelling handle yielding a decomposition with no handles.\n\nIf the assumption that \"M\" and \"N\" are simply connected is dropped, \"h\"-cobordisms need not be cylinders; the obstruction is exactly the Whitehead torsion τ (\"W\", \"M\") of the inclusion formula_34.\n\nPrecisely, the \"s\"-cobordism theorem (the \"s\" stands for simple-homotopy equivalence), proved independently by Barry Mazur, John Stallings, and Dennis Barden, states (assumptions as above but where \"M\" and \"N\" need not be simply connected):\nThe torsion vanishes if and only if the inclusion formula_34 is not just a homotopy equivalence, but a simple homotopy equivalence.\n\nNote that one need not assume that the other inclusion formula_36 is also a simple homotopy equivalence—that follows from the theorem.\n\nCategorically, \"h\"-cobordisms form a groupoid.\n\nThen a finer statement of the \"s\"-cobordism theorem is that the isomorphism classes of this groupoid (up to C-isomorphism of \"h\"-cobordisms) are torsors for the respective Whitehead groups Wh(π), where formula_37\n\n\n"}
{"id": "42787595", "url": "https://en.wikipedia.org/wiki?curid=42787595", "title": "Hanani–Tutte theorem", "text": "Hanani–Tutte theorem\n\nIn topological graph theory, the Hanani–Tutte theorem is a result on the parity of edge crossings in a graph drawing. It states that every drawing in the plane of a non-planar graph contains a pair of independent edges (not both sharing an endpoint) that cross each other an odd number of times. Equivalently, it can be phrased as a planarity criterion: a graph is planar if and only if it has a drawing in which every pair of independent edges crosses evenly (or not at all).\n\nThe result is named after Haim Hanani, who proved in 1934 that every drawing of the two minimal non-planar graphs \"K\" and \"K\" has a pair of edges with an odd number of crossings, and after W. T. Tutte, who stated the full theorem explicitly in 1970. A parallel development of similar ideas in algebraic topology has been credited to Egbert van Kampen, Arnold S. Shapiro, and Wu Wenjun.\n\nOne consequence of the theorem is that testing whether a graph is planar may be formulated as solving a system of linear equations over the finite field of order two. These equations may be solved in polynomial time, but the resulting algorithms are less efficient than other known planarity tests.\n\nFor other surfaces \"S\" than the plane, a graph can be drawn on \"S\" without crossings if and only if it can be drawn in such a way that all pairs of edges cross an even number of times; this is known as the weak Hanani–Tutte theorem for \"S\". The strong Hanani–Tutte theorem, known for the projective plane as well as for the Euclidean plane, states that a graph can be drawn without crossings on \"S\" if and only if it can be drawn in such a way that all independent pairs of edges cross an even number of times, without regard for the number of crossings between edges that share an endpoint.\n\nThe same approach, in which one shows that pairs of edges with an even number of crossings can be disregarded or eliminated in some type of graph drawing and uses this fact to set up a system of linear equations describing the existence of a drawing, has been applied to several other graph drawing problems, including upward planar drawings, drawings minimizing the number of uncrossed edges, and clustered planarity.\n"}
{"id": "5125115", "url": "https://en.wikipedia.org/wiki?curid=5125115", "title": "Homoclinic bifurcation", "text": "Homoclinic bifurcation\n\nA homoclinic bifurcation is a global bifurcation which often occurs when a periodic orbit collides with a saddle point.\n\nThe image below shows a phase portrait before, at, and after a homoclinic bifurcation in 2D. The periodic orbit grows until it collides with the saddle point. At the bifurcation point the period of the periodic orbit has grown to infinity and it has become a homoclinic orbit. After the bifurcation there is no longer a periodic orbit.\n\nHomoclinic bifurcations can occur supercritically or subcritically. The variant above is the \"small\" or \"type I\" homoclinic bifurcation.\nIn 2D there is also the \"big\" or \"type II\" homoclinic bifurcation in which the homoclinic orbit \"traps\" the other ends of the unstable and stable manifolds of the saddle. In three or more dimensions, higher codimension bifurcations can occur, producing complicated, possibly chaotic dynamics.\n"}
{"id": "5110268", "url": "https://en.wikipedia.org/wiki?curid=5110268", "title": "Horace Romano Harré", "text": "Horace Romano Harré\n\nHorace Romano Harré (; born 1927), known widely as Rom Harré, is a distinguished British philosopher and psychologist.\n\nHarré was born in Apiti, in northern Manawatu, near Palmerston North, New Zealand, but held British citizenship. He studied chemical engineering (for which he retains a great affection) and later graduated with a BSc in mathematics (1948) and a Master's in Philosophy (1952), both at the University of New Zealand, now the University of Auckland.\n\nHe taught mathematics at King's College, Auckland (1948–53) and the University of Punjab in Lahore, Pakistan (1953–4). He then studied at University College, Oxford, where he completed a B.Phil. under the supervision of J. L. Austin in 1956. After a fellowship at the University of Birmingham he was lecturer at the University of Leicester from 1957 to 1959.\n\nHe returned to Oxford as the successor to Frederick Waismann as University Lecturer in Philosophy of Science in 1960 (age 34). At Oxford he was active in the founding of the Honours School of Physics and Philosophy and played an important part in the discursive turn in social psychology, a field he came to in the middle of his career. After mandatory retirement from Oxford in 1995 he joined the psychology department of Georgetown University, Washington, D.C. where he continues as Distinguished Research Professor teaching every year in the Spring Semester.\n\nHe has given occasional courses at both American University in Washington, D.C. and at George Mason University at Fairfax, Virginia. From 2009 until 2011 he served as Director Centre for Philosophy of Natural and Social Science at the London School of Economics in conjunction with his US post. He has been Visiting Professor at many places, teaching courses at Aoyama University, Tokyo; Universidad Santiago de Compostela, Spain; Universidad Caetano, Peru; Free University at Brussels; Aarhus University in Denmark and elsewhere.\n\nHarré is one of the world's most prolific social scientists. He has written on a wide variety of subjects including: philosophy of mathematics, philosophy of science, ontology, psychology, social psychology, sociology and philosophy. He was an important early influence on the British philosophical movement critical realism, publishing \"Causal Powers\" with Madden in 1975, the same year as \"A Realist Theory of Science\". He supervised Roy Bhaskar's doctoral studies, and has continued to maintain close involvement with realism. He also supervised Patrick Baert, German Berrios, and Jonathan Smith's doctoral studies, respectively in social theory, history and epistemology of psychiatry, and social psychology. Another one of Harré's distinctive contributions was to the understanding of the social self in microsociology, which he called \"ethogenics:\" this method attempts to understand the systems of belief or means by which individuals can attach significance to their actions and form their identities, in addition to the structure of rules and cultural resources that underlie these actions.\n\nTheodore Sarbin Award for 2014 (American Psychological Association, Div 24).\n\nBooks\n\nEdited books\n\n\n"}
{"id": "4477491", "url": "https://en.wikipedia.org/wiki?curid=4477491", "title": "Intracule", "text": "Intracule\n\nAn intracule is a quantum mechanical mathematical function for the two electron density which depends not upon the absolute values of position or momentum but rather upon their relative values. Its use is leading to new methods in physics and computational chemistry to investigate the electronic structure of molecules and solids. These methods are a development of Density functional theory (DFT), but with the two electron density replacing the one electron density.\n\nP. M. W. Gill, D. L. Crittenden, D. P. O'Neill and N. A. Besley, \"A family of intracules, a conjecture and the electron correlation problem\", Physical Chemistry Chemical Physics, 2006, 8, 15 - 25.\n"}
{"id": "23107812", "url": "https://en.wikipedia.org/wiki?curid=23107812", "title": "Jennifer Tour Chayes", "text": "Jennifer Tour Chayes\n\nJennifer Tour Chayes is a Technical Fellow and Managing Director of Microsoft Research New England in Cambridge, Massachusetts, which she founded in 2008, and Microsoft Research New York City, which she founded in 2012 . Chayes is best known for her work on phase transitions in discrete mathematics and computer science, structural and dynamical properties of self-engineered networks, and algorithmic game theory. She is considered one of the world's experts in the modeling and analysis of dynamically growing graphs. Chayes has been with Microsoft Research since 1997, when she co-founded the Theory Group. She received her Ph.D. in mathematical physics at Princeton University in 1983. She is Affiliate Professor of Mathematics and Physics at the University of Washington, and was for many years Professor of Mathematics at UCLA. She is an author on almost 120 scientific papers and the inventor on more than 25 patents.\n\nChayes was born in New York City and grew up in White Plains, N.Y., the child of Iranian immigrants. She received her B.A. in Biology and Physics from Wesleyan University in 1979 where she graduated first in her class. She received her Ph.D. in Mathematical Physics at Princeton University. She did her postdoctoral work in the Mathematics and Physics departments at Harvard and Cornell. She moved to UCLA as a tenured Professor of Mathematics in 1987.\n\nWhile she was on sabbatical at the Institute for Advanced Study in 1997, Microsoft CTO Nathan Myhrvold, a classmate of Chayes's from Princeton, asked her to start and lead the Theory Group at Microsoft Research Redmond. The Theory Group analyzes fundamental questions in theoretical computer science using techniques from statistical physics and discrete mathematics. Chayes opened Microsoft Research New England in July 2008 with Borgs. The lab is located at the Microsoft New England Research & Development Center and is pursuing new, interdisciplinary areas of research that bring together core computer scientists and social scientists to understand, model, and enable future computing and online experiences. On May 3, 2012, the \"New York Times\" reported that, \"Microsoft is opening a research lab in New York City…\" which Chayes will co-manage. The new lab also brings together computer scientists and social scientists, particularly in the areas of economics, computational and behavioral social sciences, and machine learning. Chayes is currently Managing Director of both Microsoft Research New England and Microsoft Research New York City. She has contributed the development of methods to analyze the structure and behavior of various networks, the design of auction algorithms, and the design and analysis of various business models for the online world. \n\nChayes serves on numerous institute boards, advisory committees and editorial boards, including the Turing Award Selection Committee of the Association for Computing Machinery, the Board of Trustees of the Mathematical Sciences Research Institute and the Institute for Computational and Experimental Research in Mathematics, the Advisory Boards of the Center for Discrete Mathematics and Computer Science, the Howard Hughes Medical Institute Janelia Farm Research Campus, and Women Entrepreneurs in Science and Technology. Chayes is a past Chair of the Mathematics Section of the American Association for the Advancement of Science, and a past Vice-President of the American Mathematical Society. She is the recipient of a National Science Foundation Postdoctoral Fellowship, a Sloan Fellowship, and the UCLA Distinguished Teaching Award.\n\nChayes is a Fellow of the American Association for the Advancement of Science, the Fields Institute, the Association for Computing Machinery, and the American Mathematical Society, as well as a National Associate of the National Academies. She has been the recipient of many leadership awards, including one of the 2012 Anita Borg Institute Women of Vision Awards. \n\n\nChayes married Christian Borgs in 1993 and was previously married to Lincoln Chayes whom she met at Princeton. She has had extremely successful collaborations with both her husbands; of her 94 papers in MathSciNet (as of February 2014), 51 are coauthored with Christian Borgs and 37 are coauthored with Lincoln Chayes.\n\n"}
{"id": "3107845", "url": "https://en.wikipedia.org/wiki?curid=3107845", "title": "Klee's measure problem", "text": "Klee's measure problem\n\nIn computational geometry, Klee's measure problem is the problem of determining how efficiently the measure of a union of (multidimensional) rectangular ranges can be computed. Here, a \"d\"-dimensional rectangular range is defined to be a Cartesian product of \"d\" intervals of real numbers, which is a subset of R.\n\nThe problem is named after Victor Klee, who gave an algorithm for computing the length of a union of intervals (the case \"d\" = 1) which was later shown to be optimally efficient in the sense of computational complexity theory. The computational complexity of computing the area of a union of 2-dimensional rectangular ranges is now also known, but the case \"d\" ≥ 3 remains an open problem.\n\nIn 1977, Victor Klee considered the following problem: given a collection of \"n\" intervals in the real line, compute the length of their union. He then presented an algorithm to solve this problem with computational complexity (or \"running time\") formula_1 — see Big O notation for the meaning of this statement. This algorithm, based on sorting the intervals, was later shown by Michael Fredman and Bruce Weide (1978) to be optimal.\n\nLater in 1977, Jon Bentley considered a 2-dimensional analogue of this problem: given a collection of \"n\" rectangles, find the area of their union. He also obtained a complexity formula_1 algorithm, now known as Bentley's algorithm, based on reducing the problem to \"n\" \"1\"-dimensional problems: this is done by sweeping a vertical line across the area. Using this method, the area of the union can be computed without explicitly constructing the union itself. Bentley's algorithm is now also known to be optimal (in the 2-dimensional case), and is used in computer graphics, among other areas.\n\nThese two problems are the 1- and 2-dimensional cases of a more general question: given a collection of \"n\" \"d\"-dimensional rectangular ranges, compute the measure of their union. This general problem is Klee's measure problem.\n\nWhen generalized to the \"d\"-dimensional case, Bentley's algorithm has a running time of formula_3. This turns out \"not\" to be optimal, because it only decomposes the \"d\"-dimensional problem into \"n\" (\"d-1\")-dimensional problems, and does not further decompose those subproblems. In 1981, Jan van Leeuwen and Derek Wood improved the running time of this algorithm to formula_4 for \"d\" ≥ 3 by using dynamic quadtrees.\n\nIn 1988, Mark Overmars and Chee Yap proposed an formula_5 algorithm for \"d\" ≥ 3. Their algorithm uses a particular data structure similar to a kd-tree to decompose the problem into 2-dimensional components and aggregate those components efficiently; the 2-dimensional problems themselves are solved efficiently using a trellis structure. Although asymptotically faster than Bentley's algorithm, its data structures use significantly more space, so it is only used in problems where either \"n\" or \"d\" is large. In 1998, Bogdan Chlebus proposed a simpler algorithm with the same asymptotic running time for the common special cases where \"d\" is 3 or 4.\n\nIn 2013, Timothy M. Chan developed a simpler algorithm that avoids the need for dynamic data structures and eliminates the logarithmic factor, lowering the best known running time for d ≥ 3 to formula_6.\n\nThe only known lower bound for any \"d\" is formula_7, and optimal algorithms with this running time are known for \"d\"=1 and \"d\"=2. The Chan algorithm provides an upper bound of formula_6 for \"d\" ≥ 3, so for \"d\" ≥ 3, it remains an open question whether faster algorithms are possible, or alternatively whether tighter lower bounds can be proven. In particular, it remains open whether the algorithm's running time must depend on \"d\". In addition, the question of whether there are faster algorithms that can deal with special cases (for example, when the input coordinates are integers within a bounded range) remains open.\n\nThe 1D Klee's measure problem (union of intervals) can be solved in formula_9 where \"p\" denotes the number of piercing points required to stab all intervals (the union of intervals pierced by a common point can be calculated in linear time by computing the extrema). \nParameter \"p\" is an adaptive parameter that depends on the input configuration, and the piercing algorithm yields an adaptive algorithm for Klee's measure problem.\n\n\n"}
{"id": "47290999", "url": "https://en.wikipedia.org/wiki?curid=47290999", "title": "List of Brazilian mathematicians", "text": "List of Brazilian mathematicians\n\nThis list of Brazilian mathematicians includes the famous mathematicians from Brazil and also those who were born in other countries but later became Brazilians.\n\n<onlyinclude>\n\n</onlyinclude>\n\n"}
{"id": "5971806", "url": "https://en.wikipedia.org/wiki?curid=5971806", "title": "List of mathematicians (G)", "text": "List of mathematicians (G)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "49503899", "url": "https://en.wikipedia.org/wiki?curid=49503899", "title": "List of things named after George Airy", "text": "List of things named after George Airy\n\nThis is a list of things named after George Biddell Airy, a 19th-century mathematician and astronomer.\n\n\n\n"}
{"id": "795501", "url": "https://en.wikipedia.org/wiki?curid=795501", "title": "Luigi Federico Menabrea", "text": "Luigi Federico Menabrea\n\nLuigi Federico Menabrea (4 September 1809 – 24 May 1896), later made 1st Count Menabrea and 1st Marquess of Valdora, was an Italian general, statesman and mathematician who served as the Prime Minister of Italy from 1867 to 1869.\n\nMenabrea was born at Chambéry, then part of the First French Empire. He was educated at the University of Turin, where he qualified as an engineer and became a doctor of mathematics. As an officer of engineers he replaced Cavour in 1831 at the fortress of Bard. He then became professor of mechanics and construction at the military academy and at the university of Turin. Among his notable publications: \"Sketch of the Analytical Engine Invented by Charles Babbage, Esq.\" with notes by translator Ada Lovelace (1842), which described many aspects of computer architecture and programming. King Charles Albert sent him in 1848 on diplomatic missions to secure the adhesion of Modena and Parma to Sardinia. He entered the Piedmontese parliament, and was attached successively to the Ministries of War and Foreign Affairs.\n\nHe belonged to the right centre, and until the events of 1859 he believed in the possibility of a compromise between the Vatican and the state. He was major-general and commander-in-chief of the engineers in the Lombard campaign of 1859. He superintended the siege works against Peschiera, was present at Palestro and Solferino, and repaired the fortifications of some of the northern fortresses. In 1860 he became lieutenant-general and conducted the siege of Gaeta. He was appointed senator and received the title of count.\n\nEntering the Ricasoli cabinet of 1861 as minister for the navy, he held the portfolio of public works until 1864 in the succeeding Farini and Minghetti cabinets. After the war of 1866, he was chosen as Italian plenipotentiary for the negotiation of the Treaty of Prague and for the transfer of Venetia to Italy. In October 1867, he succeeded Rattazzi in the premiership, and was called upon to deal with the difficult situation created by Garibaldi's invasion of the Papal States and by the catastrophe of Mentana.\n\nMenabrea disavowed Garibaldi and instituted judicial proceedings against him; but in negotiations with the French government he protested against the retention of the temporal power by the pope and insisted on the Italian right of interference in Rome. He was in the secret of the direct negotiations between Victor Emmanuel and Napoleon III in June 1869, and refused to entertain the idea of a French alliance unless Italy were allowed to occupy the Papal States, and, on occasion, Rome itself. On the eve of the assembly of the Oecumenical Council at Rome Menabrea reserved to the Italian government its right in respect of any measures directed against Italian institutions.\n\nHe withdrew from seminary students in 1860 the exemption from military service which they had hitherto enjoyed. Throughout his term of office he was supported by the finance minister Count Cambray Digny, who forced through parliament the grist tax proposed by Quintino Sella, though in an altered form from the earlier proposal. After a series of changes in the cabinet, and many crises, Menabrea resigned in December 1869 on the election of a new chamber in which he did not command a majority. He was made marquis of Valdora in 1875. His successor in the premiership, Giovanni Lanza, in order to remove him from his influential position as \"aide-de-camp\" to the king, sent him to London as ambassador, where he remained until in 1882 he replaced General Cialdini at the Paris Embassy. Ten years later he withdrew from public life, and died at Saint Capin on 24 May 1896.\n\n"}
{"id": "22061787", "url": "https://en.wikipedia.org/wiki?curid=22061787", "title": "Magnus expansion", "text": "Magnus expansion\n\nIn mathematics and physics, the Magnus expansion, named after Wilhelm Magnus (1907–1990), provides an exponential representation of the solution of a first order homogeneous linear differential equation for a linear operator. In particular it furnishes the fundamental matrix of a system of linear ordinary differential equations of order with varying coefficients. The exponent is aggregated as an infinite series whose terms involve multiple integrals and nested commutators.\n\nGiven the coefficient matrix , one wishes to solve the initial value problem associated with the linear ordinary differential equation\n\nfor the unknown -dimensional vector function .\n\nWhen \"n\" = 1, the solution simply reads \nThis is still valid for \"n\" > 1 if the matrix satisfies for any pair of values of \"t\", \"t\" and \"t\". In particular, this is the case if the matrix is independent of . In the general case, however, the expression above is no longer the solution of the problem.\nThe approach introduced by Magnus, to solve the matrix initial value problem, is to express the solution by means of the exponential of a certain matrix function \nwhich is subsequently constructed as a series expansion,\nwhere, for simplicity, it is customary to write for and to take \"t\" = 0.\n\nMagnus appreciated that, since , using a Poincaré−Hausdorff matrix identity, he could relate the time-derivative of to the generating function of Bernoulli numbers and \nthe adjoint endomorphism of , \nto solve for recursively in terms of , \"in a continuous analog of the CBH expansion\", as outlined in a subsequent section.\n\nThe equation above constitutes the Magnus expansion or Magnus series for the solution of matrix linear initial value problem. The first four terms of this series read\nwhere is the matrix commutator of \"A\" and \"B\".\n\nThese equations may be interpreted as follows: coincides exactly with the exponent in the scalar ( = 1) case, but this equation cannot give the whole solution. If one insists in having an exponential representation (Lie group), the exponent needs to be corrected. The rest of the Magnus series provides that correction systematically: or parts of it are in the Lie algebra of the Lie group on the solution.\n\nIn applications, one can rarely sum exactly the Magnus series and one has to truncate it to get approximate solutions. The main advantage of the Magnus proposal is that the truncated series very often shares important qualitative properties with the exact solution, at variance with other conventional perturbation theories. For instance, in classical mechanics the symplectic character of the time evolution is preserved at every order of approximation. Similarly the unitary character of the time evolution operator in quantum mechanics is also preserved (in contrast, e.g., to the Dyson series solving the same problem).\n\nFrom a mathematical point of view, the convergence problem is the following: given a certain matrix , when can the exponent be obtained as the sum of the Magnus series?\n\nA sufficient condition for this series to converge for is \nwhere formula_8 denotes a matrix norm. This result is generic, in the sense that one may construct specific matrices for which the series diverges for any .\n\nA recursive procedure to generate all the terms in the Magnus expansion utilizes the matrices , defined recursively through\nwhich then furnish\n\nHere, ad is a shorthand for an iterated commutator, (see adjoint endomorphism),\nwhile are the Bernoulli numbers with .\n\nFinally, when this recursion is worked out explicitly, it is possible to express as a linear combination of \"n\"-fold integrals of \"n\"−1 nested commutators involving matrices ,\nan expression which becomes increasingly intricate with .\n\nSince the 1960s, the Magnus expansion has been successfully applied as a perturbative tool in numerous areas of physics and chemistry, from atomic and molecular physics to nuclear magnetic resonance and quantum electrodynamics. It has been also used since 1998 as a tool to construct practical algorithms for the numerical integration of matrix linear differential equations. As they inherit from the Magnus expansion the\npreservation of qualitative traits of the problem, the corresponding schemes are prototypical examples of geometric numerical integrators.\nIn 2015, Magnus expansion has been used to analyze the transient time behavior of electronic oscillators . Moreover, using this approach, a generalized theory is proposed to model the operation of super-regenerative receivers unifying all four modes of operation that was modeled and analyzed separately in the past. In addition, this Magnus expansion based solution models the behavior of a super-regenerative receiver that operates beyond the four conventional modes .\n\n\n"}
{"id": "29258614", "url": "https://en.wikipedia.org/wiki?curid=29258614", "title": "Marc Culler", "text": "Marc Culler\n\nMarc Edward Culler (born November 22, 1953) is an American mathematician who works in geometric group theory and low-dimensional topology. A native Californian, Culler did his undergraduate work at the University of California at Santa Barbara and his graduate work at Berkeley where he graduated in 1978. He is now at the University of Illinois at Chicago. Culler is the son of Glen Jacob Culler who was an important early innovator in the development of the Internet.\n\nCuller specializes in group theory, low dimensional topology, 3-manifolds, and hyperbolic geometry. Culler frequently collaborates with Peter Shalen and they have co-authored many papers. Culler and Shalen did joint work that related properties of representation varieties of hyperbolic 3-manifold groups to decompositions of 3-manifolds. In particular, Culler and Shalen used the Bass–Serre theory, applied to the function field of the SL(2,C)-Character variety of a 3-manifold, to obtain information about\nincompressible surfaces in the manifold. Based on this work, Shalen, Cameron Gordon, John Luecke, and Culler proved the cyclic surgery theorem.\n\nAnother important contribution by Culler came in a 1986 paper with Karen Vogtmann called \"Moduli of graphs and automorphisms of free groups\". This paper introduced an object that came to be known as Culler–Vogtmann Outer space.\n\nCuller is one of the authors of a 1994 paper called \"Plane curves associated to character varieties of 3-manifolds\" which introduced the A-polynomial of a knot or, more generally, of a 3-manifold with one torus boundary component.\n\nCuller is an editor of \"The New York Journal of Mathematics\". He was a Sloan Foundation Research Fellow (1986–1988) and a UIC University Scholar (2008). In 2014, he became a Fellow of the American Mathematical Society.\n\n\n"}
{"id": "3832701", "url": "https://en.wikipedia.org/wiki?curid=3832701", "title": "Math Suks", "text": "Math Suks\n\n\"Math Suks\" is a song by Jimmy Buffett, from the album \"Beach House on the Moon\" (1999).\n\nThe lyrics tell of the author's frustration as a math student. According to the lyrics, the inspiration for the song and title came from a candid interview on TV:\n\nHowever, in later interviews Jimmy said that the inspiration actually came from graffiti on a bridge in Key West Florida.\n\nConsistent with its stated theme, the song lyrics are largely an emotional catharsis; mathematical terms are used only in a very superficial way. Presumably for that reason, the song seems to have little appeal to mathematicians, and even less to mathematics teachers (unlike other songs that make fun at mathematics, such as Tom Lehrer's \"Nikolai Ivanovich Lobachevsky\" and \"New Math\"). The song was in fact promptly condemned by the US National Council of Teachers of Mathematics and the National Education Association for its alleged negative effect on children's education. Jon Stewart also criticized the song on \"The Daily Show\" during a segment called \"Math Is Quite Pleasant\".\n"}
{"id": "150169", "url": "https://en.wikipedia.org/wiki?curid=150169", "title": "Noetherian", "text": "Noetherian\n\nIn mathematics, the adjective Noetherian is used to describe objects that satisfy an ascending or descending chain condition on certain kinds of subobjects, meaning that certain ascending or descending sequences of subobjects must have finite length. Noetherian objects are named after Emmy Noether, who was the first to study the ascending and descending chain conditions for rings. \n\n"}
{"id": "414824", "url": "https://en.wikipedia.org/wiki?curid=414824", "title": "Nonagon", "text": "Nonagon\n\nIn geometry, a nonagon () or enneagon () is a nine-sided polygon or 9-gon.\n\nThe name \"nonagon\" is a prefix hybrid formation, from Latin (\"nonus\", \"ninth\" + \"gonon\"), used equivalently, attested already in the 16th century in French \"nonogone\" and in English from the 17th century. The name \"enneagon\" comes from Greek \"enneagonon\" (εννεα, \"nine\" + γωνον (from γωνία = \"corner\")), and is arguably more correct, though less common than \"nonagon\".\n\nA \"regular nonagon\" is represented by Schläfli symbol {9} and has internal angles of 140°. The area of a regular nonagon of side length \"a\" is given by\n\nwhere the radius \"r\" of the inscribed circle of the regular nonagon is\n\nand where \"R\" is the radius of its circumscribed circle:\n\nAlthough a regular nonagon is not constructible with compass and straightedge (as 9 = 3, which is not a product of distinct Fermat primes), there are very old methods of construction that produce very close approximations.\n\nIt can be also constructed using neusis, or by allowing the use of an angle trisector.\nThe following is an \"approximate\" construction of a nonagon using a straightedge and compass.\n\n\"Example to illustrate the error, when the constructed central angle is 39.99906°:\"\nAt a circumscribed circle radius r = 100 m, the absolute error of the 1 side would be approximately 1.6 mm.\n\n\nSee also the calculation (Berechnung, German).\n\nThe \"regular enneagon\" has Dih symmetry, order 18. There are 2 subgroup dihedral symmetries: Dih and Dih, and 3 cyclic group symmetries: Z, Z, and Z.\n\nThese 6 symmetries can be seen in 6 distinct symmetries on the enneagon. John Conway labels these by a letter and group order. Full symmetry of the regular form is r18 and no symmetry is labeled a1. The dihedral symmetries are divided depending on whether they pass through vertices (d for diagonal) or edges (p for perpendiculars), and i when reflection lines path through both edges and vertices. Cyclic symmetries in the middle column are labeled as g for their central gyration orders.\n\nEach subgroup symmetry allows one or more degrees of freedom for irregular forms. Only the g9 subgroup has no degrees of freedom but can seen as directed edges.\n\nThe regular enneagon can tessellate the euclidean tiling with gaps. These gaps can be filled with regular hexagons and isosceles triangles. In the notation of symmetrohedron this tiling is called H(*;3;*;[2]) with H representing *632 hexagonal symmetry in the plane.\n\nThe K complete graph is often drawn as a \"regular enneagon\" with all 36 edges connected. This graph also represents an orthographic projection of the 9 vertices and 36 edges of the 8-simplex.\n\nThey Might Be Giants have a song entitled \"Nonagon\" on their children's album \"Here Come the 123s\". It refers to both an attendee at a party at which \"everybody in the party is a many-sided polygon\" and a dance they perform at this party. Slipknot's logo is also a version of a nonagon, being a nine-pointed star made of three triangles. King Gizzard & the Lizard Wizard have an album titled 'Nonagon Infinity', the album art featuring a nonagonal complete graph.\n\nTemples of the Baha'i Faith are required to be nonagonal.\n\nThe U.S. Steel Tower is an irregular nonagon.\n\n\n"}
{"id": "21910632", "url": "https://en.wikipedia.org/wiki?curid=21910632", "title": "PPGMAp", "text": "PPGMAp\n\nThe PPGMAp, or (Program of Graduation in Applied Mathematics), of the Mathematics Institute of the Universidade Federal do Rio Grande do Sul was created in 1995, in Porto Alegre, RS, Brasil.\n\nPPGMAp offers programs that lead to a M.S. or Ph.D. degree in Applied Mathematics.\n\nThe research interests of the program encompass core areas of analysis, numerical analysis, fluid dynamics, scientific computation, mathematical biology, mathematical physics, nonlinear systems, control and signals.\n\nPPGMAp has grants of study from CAPES and CNPq. The selection of the students for the grants is decided after the academic analysis and is subject to disponibility of grants.\n\n"}
{"id": "4023241", "url": "https://en.wikipedia.org/wiki?curid=4023241", "title": "Penelope Maddy", "text": "Penelope Maddy\n\nPenelope Maddy (born 4 July 1950) is an American philosopher. She is a UCI Distinguished Professor of Logic and Philosophy of Science and of Mathematics at the University of California, Irvine. She is well known for her influential work in the philosophy of mathematics, where she has worked on mathematical realism (especially set-theoretic realism) and mathematical naturalism.\n\nMaddy received her Ph.D. from Princeton University in 1979. Her early work, culminating in \"Realism in Mathematics\", defended Kurt Gödel's position that mathematics is a true description of a mind-independent realm that we can access through our intuition. However, she suggested that some mathematical entities are in fact concrete, unlike, notably, Gödel, who assumed all mathematical objects are abstract. She suggested that sets can be causally efficacious, and in fact share all the causal and spatiotemporal properties of their elements. Thus, when one sees three cups on a table, one also sees the set. She used contemporary work in cognitive science and psychology to support this position, pointing out that just as at a certain age we begin to see objects rather than mere sense perceptions, there is also a certain age at which we begin to see sets rather than just objects.\n\nIn the 1990s, she moved away from this position, towards a position described in \"Naturalism in Mathematics\". Her \"naturalist\" position, like Quine's, suggests that since science is our most successful project so far for knowing about the world, philosophers should adopt the methods of science in their own discipline, and especially when discussing science. As Maddy stated in an interview, \"If you’re a ‘naturalist’, you think that science shouldn’t be held to extra-scientific standards, that it doesn’t require extra-scientific ratification.\" However, rather than a unified picture of the sciences like Quine's, she has a picture on which mathematics is separate. This way, mathematics is neither supported nor undermined by the needs and goals of science, but is allowed to obey its own criteria. This means that traditional metaphysical and epistemological concerns of the philosophy of mathematics are misplaced. Like Wittgenstein, she suggests that many of these puzzles arise merely because of the application of language outside its proper domain of significance.\n\nShe has been dedicated to understanding and explaining the methods that set theorists use in agreeing on axioms, especially those that go beyond ZFC.\n\nThe German Mathematical Society awarded her a Gauss Lectureship in 2006.\n\n\n\n"}
{"id": "32439784", "url": "https://en.wikipedia.org/wiki?curid=32439784", "title": "Physical mathematics", "text": "Physical mathematics\n\nThe subject of physical mathematics is concerned with physically motivated mathematics and is different from mathematical physics. The \"Journal of Physical Mathematics\" is an important journal in the field.\n\nString theorist Greg Moore said this about physical mathematics in his vision talk at Strings 2014.\n\n"}
{"id": "57197043", "url": "https://en.wikipedia.org/wiki?curid=57197043", "title": "Prime omega function", "text": "Prime omega function\n\nIn number theory, the prime omega function formula_1 counts the number of \"distinct\" prime factors of a natural number formula_2, where the related function formula_3 counts the \"total\" number of prime factors of formula_2 counting multiplicity (see arithmetic function). For example, if we have a prime factorization of formula_2 of the form formula_6 for distinct primes formula_7 (formula_8), then each of these respective prime omega functions are given by formula_9 and formula_10. These prime factor counting functions have many important number theoretic relations.\n\nThe functions formula_1 is additive and formula_3 is completely additive. \nIf formula_2 is squarefree then formula_1 is related to the Möbius function by \n\nIt is known that the average order of the divisor function satisfies formula_16.\n\nAn asymptotic series for formula_1 is given by \n\nwhere formula_19 is the Mertens constant and formula_20 are the Stieltjes constants.\n\nThe function formula_1 is related to divisor sums over the Möbius function and the divisor function including the next sums \n\nA known Dirichlet series involving formula_1 and the Riemann zeta function is given by \n\nA partition-related exact identity for formula_1 is given by \n\nwhere formula_31 is the partition function, formula_32 is the Möbius function, and the triangular sequence formula_33 is expanded by\n\nin terms of the infinite q-Pochhammer symbol and the restricted partition functions formula_35 which respectively denote the number of formula_36's in all partitions of formula_2 into an \"odd\" (\"even\") number of distinct parts.\n\nThe average order of formula_1 is given by formula_39 and formula_40. When formula_41 is prime a lower bound on the value of the function is formula_42. Similarly, if formula_2 is primorial then the function is as large as \nformula_44 on average order. When formula_2 is a power of 2, then formula_46 \n\nAsymptotics for the summatory functions over formula_1, formula_3, and formula_49 \nare respectively computed in Hardy and Wright as \n\nwhere formula_51 is again the Mertens constant and the constant formula_52 is defined by\n\nOther sums relating the two variants of the prime omega functions include \n\nand\n\nIn this example we suggest a variant of the summatory functions formula_56 estimated in the above results for sufficiently large formula_57. We then prove an asymptotic formula for the growth of this modified summatory function derived from the asymptotic estimate of formula_58 provided in the formulas in the main subsection of this article above.\n\nTo be completely precise, let the odd-indexed summatory function be defined as\n\nwhere formula_60 denotes Iverson's convention. Then we have that\n\nThe proof of this result follows by first observing that\n\nand then applying the asymptotic result from Hardy and Wright for the summatory function over formula_1, denoted by formula_56, in the following form:\n\nThe computations expanded in Chapter 22.11 of Hardy and Wright provide asymptotic estimates for the summatory function\n\nby estimating the product of these two component omega functions as\n\nWe can similarly calculate asymptotic formulas more generally for the related summatory functions over so-termed factorial moments of the function formula_1.\n\n\n\n"}
{"id": "50162037", "url": "https://en.wikipedia.org/wiki?curid=50162037", "title": "Quaternionic polytope", "text": "Quaternionic polytope\n\nIn geometry, a quaternionic polytope is a generalization of a polytope in real space to an analogous structure in a quaternionic module, where each real dimension is accompanied by three imaginary ones. Similarly to complex polytopes, points are not ordered and there is no sense of \"between\", and thus a quaternionic polytope may be understood as an arrangement of connected points, lines, planes and so on, where every point is the junction of multiple lines, every line of multiple planes, and so on. Likewise, each line must contain multiple points, each plane multiple lines, and so on. Since the quaternions are non-commutative, a convention must be made for the multiplication of vectors by scalars, which is usually in favour of left-multiplication.\n\nAs is the case for the complex polytopes, the only quaternionic polytopes to have been systematically studied are the regular ones. Like the real and complex regular polytopes, their symmetry groups may be described as reflection groups. For example, the regular quaternionic lines are in a one-to-one correspondence with the finite subgroups of \"U\"(H): the binary cyclic groups, binary dihedral groups, binary tetrahedral group, binary octahedral group, and binary icosahedral group.\n"}
{"id": "317263", "url": "https://en.wikipedia.org/wiki?curid=317263", "title": "Quine–McCluskey algorithm", "text": "Quine–McCluskey algorithm\n\nThe Quine–McCluskey algorithm (or the method of prime implicants) is a method used for minimization of Boolean functions that was developed by Willard V. Quine and extended by Edward J. McCluskey. It is functionally identical to Karnaugh mapping, but the tabular form makes it more efficient for use in computer algorithms, and it also gives a deterministic way to check that the minimal form of a Boolean function has been reached. It is sometimes referred to as the tabulation method.\n\nThe method involves two steps:\n\nAlthough more practical than Karnaugh mapping when dealing with more than four variables, the Quine–McCluskey algorithm also has a limited range of use since the problem it solves is NP-complete. The running time of the Quine–McCluskey algorithm grows exponentially with the number of variables. For a function of \"n\" variables the number of prime implicants can be as large as 3ln(\"n\"), e.g. for 32 variables there may be over 534 * 10 prime implicants. Functions with a large number of variables have to be minimized with potentially non-optimal heuristic methods, of which the Espresso heuristic logic minimizer was the de-facto standard in 1995.\n\nStep two of the algorithm amounts to solving the set cover problem;\nNP-hard instances of this problem may occur in this algorithm step.\n\nIn this example, the input is a Boolean function in four variables, formula_1 which evaluates to formula_2 on the values formula_3 and formula_4, evaluates to an unknown value on formula_5 and formula_6, and to formula_7 everywhere else (where these integers are interpreted in their binary form for input to formula_8 for succinctness of notation). The inputs that evaluate to formula_2 are called 'minterms'. We encode all of this information by writing\n\nThis expression says that the output function f will be 1 for the minterms formula_3 and formula_4 (denoted by the 'm' term) and that we don't care about the output for formula_5 and formula_6 combinations (denoted by the 'd' term).\n\nFirst, we write the function as a table (where 'x' stands for don't care):\n\nOne can easily form the canonical sum of products expression from this table, simply by summing the minterms (leaving out don't-care terms) where the function evaluates to one:\n\nwhich is not minimal. So to optimize, all minterms that evaluate to one are first placed in a minterm table. Don't-care terms are also added into this table, so they can be combined with minterms:\n\nAt this point, one can start combining minterms with other minterms. If two terms vary by only a single digit changing, that digit can be replaced with a dash indicating that the digit doesn't matter. Terms that can't be combined any more are marked with an asterisk (*). When going from Size 2 to Size 4, treat '-' as a third bit value. For instance, -110 and -100 can be combined, as well as -110 and -11-, but -110 and 011- cannot. (Trick: Match up the '-' first.)\n\nNote: In this example, none of the terms in the size 4 implicants table can be combined any further. Be aware that this processing should be continued otherwise (size 8 etc.).\n\nNone of the terms can be combined any further than this, so at this point we construct an essential prime implicant table. Along the side goes the prime implicants that have just been generated, and along the top go the minterms specified earlier. The don't care terms are not placed on top—they are omitted from this section because they are not necessary inputs.\n\nTo find the essential prime implicants, we run along the top row. We have to look for columns with only 1 \"X\". If a column has only 1 \"X\", this means that the minterm can only be covered by 1 prime implicant. This prime implicant is \"essential\".\n\nFor example: in the first column, with minterm 4, there is only 1 \"X\". This means that m(4,12) is essential. So we place a star next to it. Minterm 15 also has only 1 \"X\", so m(10,11,14,15) is also essential. Now all columns with 1 \"X\" are covered.\n\nThe second prime implicant can be 'covered' by the third and fourth, and the third prime implicant can be 'covered' by the second and first, and neither is thus essential. If a prime implicant is essential then, as would be expected, it is necessary to include it in the minimized boolean equation. In some cases, the essential prime implicants do not cover all minterms, in which case additional procedures for chart reduction can be employed. The simplest \"additional procedure\" is trial and error, but a more systematic way is Petrick's method. In the current example, the essential prime implicants do not handle all of the minterms, so, in this case, one can combine the essential implicants with one of the two non-essential ones to yield one equation:\n\nor\n\nBoth of those final equations are functionally equivalent to the original, verbose equation:\n\n\n\n"}
{"id": "18734196", "url": "https://en.wikipedia.org/wiki?curid=18734196", "title": "Ramachandran Balasubramanian", "text": "Ramachandran Balasubramanian\n\nRamachandran Balasubramanian (born 15 March 1951) is an Indian mathematician and was Director of the Institute of Mathematical Sciences in Chennai, India. He is known for his work in number theory, which includes settling the final g(4) case of Waring's problem in 1986.\n\nHis works on moments of Riemann zeta function is highly appreciated and he was a plenary speaker from India at ICM in 2010. He was a visiting scholar at the Institute for Advanced Study in 1980-81.\n\nHe has received the following awards:\n\n"}
{"id": "12069013", "url": "https://en.wikipedia.org/wiki?curid=12069013", "title": "Recurrence period density entropy", "text": "Recurrence period density entropy\n\nRecurrence period density entropy (RPDE) is a method, in the fields of dynamical systems, stochastic processes, and time series analysis, for determining the periodicity, or repetitiveness of a signal.\n\nRecurrence period density entropy is useful for characterising the extent to which a time series repeats the same sequence, and is therefore similar to linear autocorrelation and time delayed mutual information, except that it measures repetitiveness in the phase space of the system, and is thus a more reliable measure based upon the dynamics of the underlying system that generated the signal. It has the advantage that it does not require the assumptions of linearity, Gaussianity or dynamical determinism. It has been successfully used to detect abnormalities in biomedical contexts such as speech signal.\n\nThe RPDE value formula_1 is a scalar in the range zero to one. For purely periodic signals, formula_2, whereas for purely i.i.d., uniform white noise, formula_3.\n\nThe RPDE method first requires the embedding of a time series in phase space, which, according to stochastic extensions to Taken's embedding theorems, can be carried out by forming time-delayed vectors:\n\nfor each value \"x\" in the time series, where \"M\" is the embedding dimension, and τ is the embedding delay. These parameters are obtained by systematic search for the optimal set (due to lack of practical embedding parameter techniques for stochastic systems) (Stark et al. 2003). Next, around each point formula_5 in the phase space, an formula_6-neighbourhood (an \"m\"-dimensional ball with this radius) is formed, and every time the time series returns to this ball, after having left it, the time difference \"T\" between successive returns is recorded in a histogram. This histogram is normalised to sum to unity, to form an estimate of the recurrence period density function \"P\"(\"T\"). The normalised entropy of this density:\n\nis the RPDE value, where formula_8 is the largest recurrence value (typically on the order of 1000 samples). Note that RPDE is intended to be applied to both deterministic and stochastic signals, therefore, strictly speaking, Taken's original embedding theorem does not apply, and needs some modification.\n\nRPDE has the ability to detect subtle changes in natural biological time series such as the breakdown of regular periodic oscillation in abnormal cardiac function which are hard to detect using classical signal processing tools such as the Fourier transform or linear prediction. The recurrence period density is a sparse representation for nonlinear, non-Gaussian and nondeterministic signals, whereas the Fourier transform is only sparse for purely periodic signals.\n\n\n"}
{"id": "248619", "url": "https://en.wikipedia.org/wiki?curid=248619", "title": "Small number", "text": "Small number\n\nWithin a set of positive numbers, a number is small if it is close to zero. A number is smaller if it is less than another number.\n\nWithin a set of positive and negative numbers there is ambiguity, because being closer to zero does not correspond to being less, but to being less in absolute value. Depending on context a negative number may be called \"smaller\" if it is closer to zero, or if it is more negative.\n\nThis article deals with positive numbers, and is also applicable to negative numbers by taking the absolute value.\n\nSmall numbers are numbers that are small compared with the numbers used in everyday life. Very small numbers often occur in fields such as chemistry, electronics and quantum physics.\n\nAs soon as systems of weights and measures were devised, units were subdivided into smaller units: pounds were divided into ounces, pounds into shillings and pence. Beyond the smallest units, there was a need to use vulgar fractions to represent even smaller quantities. In systems such as the degrees-minutes-seconds system, it is possible to represent one second of arc, equal to\n\nof a circle.\n\nEven smaller numbers are often found in science, which are so small that they are not easily dealt with using fractions. Scientific notation was created to handle very small and very large numbers. \n\nExamples of small numbers describing everyday real-world objects are:\n\nOther small numbers are found in particle physics and quantum physics:\n\nExtremely small numbers can be described through their reciprocals, extremely large numbers. The notation is similar, with a minus sign at the first level of exponents, e.g. \n\nformula_2\n\nAlthough all these numbers above are very small, they are all still real numbers greater than zero. Some fields of mathematics define infinitesimal numbers. An infinitesimal is a number greater than zero yet smaller than any positive real number. \n\nInfinitesimal numbers were originally developed to create the differential and integral calculus, but were replaced by systems using limits when they were shown to lack theoretical rigor. More recent work has restored rigor to infinitesimals, making them once more a legitimate mathematical topic (see non-standard analysis).\n\nSystems of infinitesimals can be generated in the same way as systems of transfinite numbers can be generated.\nSome mathematical systems such as surreal numbers and hyperreal numbers generate elaborate systems of infinitesimals with amazing properties.\n\n"}
{"id": "28858", "url": "https://en.wikipedia.org/wiki?curid=28858", "title": "Stone–Weierstrass theorem", "text": "Stone–Weierstrass theorem\n\nIn mathematical analysis, the Weierstrass approximation theorem states that every continuous function defined on a closed interval can be uniformly approximated as closely as desired by a polynomial function. Because polynomials are among the simplest functions, and because computers can directly evaluate polynomials, this theorem has both practical and theoretical relevance, especially in polynomial interpolation. The original version of this result was established by Karl Weierstrass in 1885 using the Weierstrass transform.\n\nMarshall H. Stone considerably generalized the theorem and simplified the proof . His result is known as the Stone–Weierstrass theorem. The Stone–Weierstrass theorem generalizes the Weierstrass approximation theorem in two directions both regressive and progressive: instead of the real interval , an arbitrary compact Hausdorff space is considered, and instead of the algebra of polynomial functions, approximation with elements from more general subalgebras of is investigated. The Stone–Weierstrass theorem is a vital result in the study of the algebra of continuous functions on a compact Hausdorff space.\n\nFurther, there is a generalization of the Stone–Weierstrass theorem to noncompact Tychonoff spaces, namely, any continuous function on a Tychonoff space is approximated uniformly on compact sets by algebras of the type appearing in the Stone–Weierstrass theorem and described below.\n\nA different generalization of Weierstrass' original theorem is Mergelyan's theorem, which generalizes it to functions defined on certain subsets of the complex plane.\n\nThe statement of the approximation theorem as originally discovered by Weierstrass is as follows:\n\nA constructive proof of this theorem using Bernstein polynomials is outlined on that page.\n\nAs a consequence of the Weierstrass approximation theorem, one can show that the space is separable: the polynomial functions are dense, and each polynomial function can be uniformly approximated by one with rational coefficients; there are only countably many polynomials with rational coefficients. Since is Hausdorff and separable it follows that has cardinality equal to — the same cardinality as the cardinality of the reals. (Remark: This cardinality result also follows from the fact that a continuous function on the reals is uniquely determined by its restriction to the rationals.)\n\nThe set of continuous real-valued functions on , together with the supremum norm , is a Banach algebra, (that is, an associative algebra and a Banach space such that for all ). The set of all polynomial functions forms a subalgebra of (that is, a vector subspace of that is closed under multiplication of functions), and the content of the Weierstrass approximation theorem is that this subalgebra is dense in .\n\nStone starts with an arbitrary compact Hausdorff space and considers the algebra of real-valued continuous functions on , with the topology of uniform convergence. He wants to find subalgebras of which are dense. It turns out that the crucial property that a subalgebra must satisfy is that it \"separates points\": a set of functions defined on is said to separate points if, for every two different points and in there exists a function in with . Now we may state:\n\nThis implies Weierstrass’ original statement since the polynomials on form a subalgebra of which contains the constants and separates points.\n\nA version of the Stone–Weierstrass theorem is also true when is only locally compact. Let be the space of real-valued continuous functions on which vanish at infinity; that is, a continuous function is in if, for every , there exists a compact set such that on . Again, is a Banach algebra with the supremum norm. A subalgebra of is said to vanish nowhere if not all of the elements of simultaneously vanish at a point; that is, for every in , there is some in such that . The theorem generalizes as follows:\n\nThis version clearly implies the previous version in the case when is compact, since in that case . There are also more general versions of the Stone–Weierstrass that weaken the assumption of local compactness.\n\nThe Stone–Weierstrass theorem can be used to prove the following two statements which go beyond Weierstrass's result.\n\n\nThe theorem has many other applications to analysis, including:\n\n\nSlightly more general is the following theorem, where we consider the algebra of complex-valued continuous functions on the compact space , again with the topology of uniform convergence. This is a C*-algebra with the *-operation given by pointwise complex conjugation.\n\nThe complex unital *-algebra generated by consists of all those functions that can be obtained from the elements of by throwing in the constant function and adding them, multiplying them, conjugating them, or multiplying them with complex scalars, and repeating finitely many times.\n\nThis theorem implies the real version, because if a sequence of complex-valued functions uniformly approximate a given function , then the real parts of those functions uniformly approximate the real part of . As in the real case, an analog of this theorem is true for locally compact Hausdorff spaces.\n\nFollowing : consider the algebra of quaternion-valued continuous functions on the compact space , again with the topology of uniform convergence. If a quaternion \"q\" is written in the form \"q\" = \"a\" + \"ib\";+ \"jc\" + \"kd\" then the scalar part a is the real number (\"q\" − \"iqi\" − \"jqj\" − \"kqk\")/4. Likewise being the scalar part of −\"qi\", −\"qj\" and −\"qk\" : b,c and d are respectively the real numbers (−\"qi\" − \"iq\" + \"jqk\" − \"kqj\")/4,\n(−\"qj\" − \"iqk\" − \"jq\" + \"kqi\")/4 and (−\"qk\" + \"iqj\" − \"jqk\" − \"kq\")/4. Then we may state :\n\nThe space of complex-valued continuous functions on a compact Hausdorff space \"X\" i.e. C(\"X\", C) is the canonical example of a unital commutative C*-algebra formula_1. The space \"X\" may be viewed as the space of pure states on formula_1, with the weak-* topology. Following the above cue, a non-commutative extension of the Stone–Weierstrass theorem, which has remain unsolved, is as follows:\n\nIn 1960, Jim Glimm proved a weaker version of the above conjecture.\n\nLet be a compact Hausdorff space. Stone's original proof of the theorem used the idea of lattices in . A subset of is called a lattice if for any two elements , the functions also belong to . The lattice version of the Stone–Weierstrass theorem states:\n\nThe above versions of Stone–Weierstrass can be proven from this version once one realizes that the lattice property can also be formulated using the absolute value which in turn can be approximated by polynomials in . A variant of the theorem applies to linear subspaces of closed under max :\n\nMore precise information is available:\n\nAnother generalization of the Stone–Weierstrass theorem is due to Errett Bishop. Bishop's theorem is as follows :\n\nNachbin's theorem gives an analog for Stone–Weierstrass theorem for algebras of complex valued smooth functions on a smooth manifold . Nachbin's theorem is as follows :\n\n\n\nThe historical publication of Weierstrass (in German language) is freely available from the digital online archive of the \"Berlin Brandenburgische Akademie der Wissenschaften\":\n\n\nImportant historical works of Stone include:\n"}
{"id": "1938936", "url": "https://en.wikipedia.org/wiki?curid=1938936", "title": "Sum-free sequence", "text": "Sum-free sequence\n\nIn mathematics, a sum-free sequence is an increasing positive integer sequence \n\nsuch that for each formula_2, formula_3 cannot be represented as a sum of any subset of the preceding elements of the same sequence. \n\nThe definition of sum-free sequence is different of that of sum-free set, because in a sum-free set only the sums of two elements must be avoided, while a sum-free sequence must avoid sums of larger sets of elements as well.\n\nThe powers of two,\nform a sum-free sequence: each term in the sequence is one more than the sum of all preceding terms, and so cannot be represented as a sum of preceding terms.\n\nA set of integers is said to be small if the sum of its reciprocals converges to a finite value. For instance, by the prime number theorem, the prime numbers are not small. proved that every sum-free sequence is small, and asked how large the sum of reciprocals could be. For instance, the sum of the reciprocals of the powers of two (a geometric series) is two.\n\nIf formula_4 denotes the maximum sum of reciprocals of a sum-free sequence, then through subsequent research it is known that formula_5.\n\nIt follows from the fact that sum-free sequences are small that they have zero Schnirelmann density; that is, if formula_6 is defined to be the number of sequence elements that are less than or equal to formula_7, then formula_8. showed that for every sum-free sequence there exists an unbounded sequence of numbers formula_9 for which formula_10 where formula_11 is the golden ratio, and he exhibited a sum-free sequence for which, for all values of formula_7, formula_13, subsequently improved to formula_14 by Deshouillers, Erdős and Melfi in 1999 and to formula_15 by Luczak and Schoen in 2000, who also proved that the exponent \"1/2\" cannot be furthermore improved.\n\n"}
{"id": "19186304", "url": "https://en.wikipedia.org/wiki?curid=19186304", "title": "The Beauty of Fractals", "text": "The Beauty of Fractals\n\nThe Beauty of Fractals is a 1986 book by Heinz-Otto Peitgen and Peter Richter which publicises the fields of complex dynamics, chaos theory and the concept of fractals. It is lavishly illustrated and as a mathematics book became an unusual success.\n\nThe book includes a total of 184 illustrations, including 88 full-colour pictures of Julia sets. Although the format suggests a coffee table book, the discussion of the background of the presented images addresses some sophisticated mathematics which would not be found in popular science books. In 1987 the book won an Award for distinguished technical communication.\n\nThe books starts with a general introduction to Complex Dynamics, Chaos and fractals. In particular the Feigenbaum scenario and the relation to Julia sets and the Mandelbrot set is discussed. The following special sections provide in depth detail for the shown images: Verhulst Dynamics, Julia Sets and Their Computergraphical Generation, Sullivan's Classification of Critical Points, The Mandelbrot Set, External Angles and Hubbard Trees, Newton's Method for Complex Polynomials: Cayley's Problem, Newtons's Method for Real Equations, A Discrete Volterra-Lotka System, Yang-Lee Zeros, Renormalization (Magnetism and Complex Boundaries).\n\nThe book also includes invited Contributions by Benoît Mandelbrot, Adrien Douady, Gert Eilenberger and Herbert W. Franke, which provide additional formality and some historically interesting detail. Benoit Mandelbrot gives a very personal account of his discovery of fractals in general and the fractal named after him in particular. Adrien Douady explains the solved and unsolved problems relating to the almost amusingly complex Mandelbrot set.\n\nPart of the text was originally conceived as a supplemented catalogue to the exhibition Frontiers of Chaos of the German Goethe-Institut, first seen in Europe and the United States. It described the context and meaning of these images. The images were created at the \"Computer Graphics Laboratory Dynamical Systems\" at the University of Bremen in 1984 and 1985. Dedicated software had to be developed to make the necessary computations which at that time took hours of computer time to create a single image. For the exhibit and the book the computed images had to be captured as photographs. Digital image capturing and archiving were not feasible at that time.\n\nThe book was cited and its images were reproduced in a number of publications. Some images were even used before the book was published. The cover article of the \"Scientific American\" August 1985 edition showed some the images and provided reference to the book to be published.\n\nOne particular image sequence of the book is the close up series \"seahorse valley\". While the first publication of such a close up series was the June 1984 cover article of the Magazine \"Geo\", \"The Beauty of Fractals\" provided the first such publication within a book.\n\n\n"}
{"id": "15537009", "url": "https://en.wikipedia.org/wiki?curid=15537009", "title": "Variational vector field", "text": "Variational vector field\n\nIn the mathematical fields of the calculus of variations and differential geometry, the variational vector field is a certain type of vector field defined on the tangent bundle of a differentiable manifold which gives rise to variations along a vector field in the manifold itself.\n\nSpecifically, let \"X\" be a vector field on \"M\". Then \"X\" generates a one-parameter group of local diffeomorphisms \"Fl\", the flow along \"X\". The differential of \"Fl\" gives, for each \"t\", a mapping\n\nwhere \"TM\" denotes the tangent bundle of \"M\". This is a one-parameter group of local diffeomorphisms of the tangent bundle. The variational vector field of \"X\", denoted by \"T\"(\"X\") is the tangent to the flow of \"d Fl\".\n"}
{"id": "8175877", "url": "https://en.wikipedia.org/wiki?curid=8175877", "title": "Vizing's conjecture", "text": "Vizing's conjecture\n\nIn graph theory, Vizing's conjecture concerns a relation between the domination number and the cartesian product of graphs. \nThis conjecture was first stated by , and states that, if γ(\"G\") denotes the minimum number of vertices in a dominating set for \"G\", then\n\nA 4-cycle \"C\" has domination number two: any single vertex only dominates itself and its two neighbors, but any pair of vertices dominates the whole graph. The product formula_2 is a four-dimensional hypercube graph; it has 16 vertices, and any single vertex can only dominate itself and four neighbors, so three vertices could only dominate 15 of the 16 vertices. Therefore, at least four vertices are required to dominate the entire graph, the bound given by Vizing's conjecture.\n\nIt is possible for the domination number of a product to be much larger than the bound given by Vizing's conjecture. For instance, for a star K, its domination number γ(K) is one: it is possible to dominate the entire star with a single vertex at its hub. Therefore, for the graph formula_3 formed as the product of two stars, Vizing's conjecture states only that the domination number should be at least 1 × 1 = 1. However, the domination number of this graph is actually much higher. It has \"n\" + 2\"n\" + 1 vertices: \"n\" formed from the product of a leaf in both factors, 2\"n\" from the product of a leaf in one factor and the hub in the other factor, and one remaining vertex formed from the product of the two hubs. Each leaf-hub product vertex in \"G\" dominates exactly \"n\" of the leaf-leaf vertices, so \"n\" leaf-hub vertices are needed to dominate all of the leaf-leaf vertices. However, no leaf-hub vertex dominates any other such vertex, so even after \"n\" leaf-hub vertices are chosen to be included in the dominating set, there remain \"n\" more undominated leaf-hub vertices, which can be dominated by the single hub-hub vertex. Thus, the domination number of this graph is formula_4 far higher than the trivial bound of one given by Vizing's conjecture.\n\nThere exist infinite families of graph products for which the bound of Vizing's conjecture is exactly met. For instance, if \"G\" and \"H\" are both connected graphs, each having at least four vertices and having exactly twice as many total vertices as their domination numbers, then formula_5. The graphs \"G\" and \"H\" with this property consist of the four-vertex cycle \"C\" together with the rooted products of a connected graph and a single edge.\n\nClearly, the conjecture holds when either \"G\" or \"H\" has domination number one: for, the product contains an isomorphic copy of the other factor, dominating which requires at least γ(\"G\")γ(\"H\") vertices.\n\nVizing's conjecture is also known to hold for cycles and for graphs with domination number two.\n\n observed that\n\nA dominating set meeting this bound may be formed as the cartesian product of a dominating set in one of \"G\" or \"H\" with the set of all vertices in the other graph.\n\n"}
{"id": "3852079", "url": "https://en.wikipedia.org/wiki?curid=3852079", "title": "Word problem (mathematics)", "text": "Word problem (mathematics)\n\nIn mathematics and computer science, a word problem for a set S with respect to a system of finite encodings of its elements is the algorithmic problem of deciding whether two given representatives represent the same element of the set. The problem is commonly encountered in abstract algebra, where given a presentation of an algebraic structure by generators and relators, the problem is to determine if two expressions represent the same element; a prototypical example is the word problem for groups. Less formally, the word problem in an algebra is: given a set of identities \"E\", and two expressions \"x\" and \"y\", is it possible to transform \"x\" into \"y\" using the identities in \"E\" as rewriting rules in both directions? While answering this question may not seem hard, the remarkable (and deep) result that emerges, in many important cases, is that the problem is undecidable.\n\nMany, if not most all, undecidable problems in mathematics can be posed as word problems; see the list of undecidable problems for many examples.\n\nMany occasions arise in mathematics where one wishes to use a finite amount of information to describe an element of a (typically infinite) set. This issue is particularly apparent in computational mathematics. Traditional models of computation (such as the Turing machine) have storage capacity which is unbounded, so it is in principle possible to perform computations with the elements of infinite sets. On the other hand, since the amount of storage space in use at any one time is finite, we need each element to have a finite representation.\n\nFor various reasons, it is not always possible or desirable to use a system of \"unique\" encodings, that is, one in which every element has a single encoding. When using an encoding system without uniqueness, the question naturally arises of whether there is an algorithm which, given as input two encodings, decides whether they represent the same element. Such an algorithm is called a \"solution to the word problem\" for the encoding system.\n\nThe simplest example of an undecidable word problem occurs in combinatory logic: when are two strings of combinators equivalent? Because combinators encode all possible Turing machines, and the equivalence of two Turing machines is undecidable, it follows that the equivalence of two strings of combinators is undecidable.\n\nLikewise, one has essentially the same problem in (untyped) lambda calculus: given two distinct lambda expressions, there is no algorithm which can discern whether they are equivalent or not; equivalence is undecidable. For several typed variants of the lambda calculus, equivalence is decidable by comparison of normal forms.\n\nIn algebra, one often studies infinite algebras which are generated (under the finitary operations of the algebra) by finitely many elements. In this case, the elements of the algebra have a natural system of finite encoding as expressions in terms of the generators and operations. The word problem here is thus to determine, given two such expressions, whether they represent the same element of the algebra.\n\nRoughly speaking, the word problem in an algebra is: given a set \"E\" of identities (an equational theory), and two terms \"s\" and \"t\", is it possible to transform \"s\" into \"t\" using the identities in \"E\" as rewriting rules in both directions?. \n\nA proper extension of the \"word problem\" is known as the \"unification problem\" (a.k.a. the \"equation solving problem\").\nWhile the former asks whether two terms \"are\" equal, the latter asks whether they have \"instances\" that are equal.\nAs a common example, \"formula_1\" is a word problem in the integer group ℤ,\nwhile \"formula_2\" is a unification problem in the same group; since the former terms happen to be equal in ℤ, the latter problem has the substitution formula_3 as a solution.\n\nSubstitutions may be ordered into a partial order, thus, unification is the act of finding a join on a lattice. \nIn this sense, the word problem on a lattice has a solution, namely, the set of all equivalent words is the free lattice.\n\nOne of the most deeply studied cases of the word problem is in the theory of semigroups and groups. \nThere are many groups for which the word problem is not decidable, in that there is no Turing machine that can determine the equivalence of two \"arbitrary\" words in a finite time.\n\nThe word problem on ground terms is not decidable. \n\nThe word problem on free Heyting algebras is difficult. \nThe only known results are that the free Heyting algebra on one generator is infinite, and that the free complete Heyting algebra on one generator exists (and has one more element than the free Heyting algebra).\n\nBläsius and Bürckert \n\ndemonstrate the Knuth–Bendix algorithm on an axiom set for groups. \nThe algorithm yields a confluent and noetherian term rewrite system that transforms every term into a unique normal form. \nThe rewrite rules are numbered incontiguous since some rules became redundant and were deleted during the algorithm run.\nThe equality of two terms follows from the axioms if and only if both terms are transformed into literally the same normal form term. For example, the terms\nshare the same normal form, viz. formula_6; therefore both terms are equal in every group.\nAs another example, the term formula_7 and formula_8 has the normal form formula_9 and formula_10, respectively. Since the normal forms are literally different, the original terms cannot be equal in every group. In fact, they are usually different in non-abelian groups.\n\n"}
