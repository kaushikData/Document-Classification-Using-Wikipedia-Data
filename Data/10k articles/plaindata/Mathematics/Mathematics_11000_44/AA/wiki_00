{"id": "39832362", "url": "https://en.wikipedia.org/wiki?curid=39832362", "title": "Adam Marcus (mathematician)", "text": "Adam Marcus (mathematician)\n\nAdam Wade Marcus (born August 1979) is an American mathematician. He is an assistant professor in the mathematics department and applied mathematics program at Princeton University.\nAlong with Daniel Spielman and Nikhil Srivastava, Marcus was awarded the Pólya Prize in 2014 for a positive solution to the Kadison-Singer problem.\n\nMarcus grew up in Marietta, Georgia and was a boarding student at the Darlington School in Rome, Georgia. \nHe attended the Washington University in St. Louis for his undergraduate degree and then completed his doctoral studies under the supervision of Prasad Tetali at the Georgia Institute of Technology.\nFollowing his graduation in 2008, he spent four years as a Gibbs Assistant Professor in Applied Mathematics at Yale University.\nIn 2012, Marcus cofounded Crisply, an analytics company in Boston, Massachusetts, where he served as chief scientist until 2015. \nHe is an alumnus of the Hampshire College Summer Studies in Mathematics.\n\nDuring 2003–2004, Marcus was a Fulbright scholar in Hungary.\nIn 2008, he was awarded the inaugural Dénes König Prize in Discrete Mathematics from the Society for Industrial and Applied Mathematics for his work in solving the Stanley–Wilf conjecture.\nA team consisting of Marcus, Daniel Spielman, and Nikhil Srivastava was awarded the 2014 Pólya Prize for their resolution of the Kadison-Singer problem. He was an invited speaker at the 2014 International Congress of Mathematicians in Seoul, South Korea.\n\n"}
{"id": "49322650", "url": "https://en.wikipedia.org/wiki?curid=49322650", "title": "Algorismus (Norse text)", "text": "Algorismus (Norse text)\n\nAlgorismus is a short treatise on mathematics, written in Old Icelandic. It is the oldest text on mathematics in a Scandinavian language and survives in the early fourteenth-century manuscript Hauksbók. It is probably a translation from Latin into Old Norse of some pages included in more ancient books such as \"Carmen de Algorismo\" by De Villa Dei of 1200, \"Liber Abaci\" by Fibonacci of 1202, and \"Algorismus Vulgaris\" by De Sacrobosco of 1230.\n"}
{"id": "53014208", "url": "https://en.wikipedia.org/wiki?curid=53014208", "title": "Algorithmic Choreography", "text": "Algorithmic Choreography\n\nAlgorithmic choreography is the technique of using algorithms to create dance. It is commonly described as using computers for choreographing dances, creating computer animations, studying or teaching aspects of human movement, illustrating dance movements, or assistance in notating dances. It may also be applied in terms of choreographic software for stimulation, enabling real-time choreography and generative dance, or simulation with virtual dancers in the field of Dance technology. Historically, computers and dance can be traced back to the 1960s, for example, Michael Noll wrote an article about his work, titled \"Choreography and Computers\", published in Dance Magazine in 1967.\n\nMultiple projects have worked with computers and choreography to create movement materials, choreographic scores, and other digital outcomes, for example:\n"}
{"id": "38347715", "url": "https://en.wikipedia.org/wiki?curid=38347715", "title": "Barbara Keyfitz", "text": "Barbara Keyfitz\n\nBarbara Lee Keyfitz is a Canadian-American mathematician, the Dr. Charles Saltzer Professor of Mathematics at Ohio State University. In her research, she studies nonlinear partial differential equations and associated conservation laws.\n\nKeyfitz did her undergraduate studies at the University of Toronto, and earned a Ph.D. in 1970 from New York University, under the supervision of Peter Lax. Before taking her present position at Ohio State, she taught at Columbia University, Princeton University, Arizona State University, and the University of Houston; at Houston, she was the John and Rebecca Moores Professor of Mathematics. She was also the director of the Fields Institute from 2004 to 2008.\n\nShe was president of the Association for Women in Mathematics from 2005 to 2006, and in 2011 she became president of the International Council for Industrial and Applied Mathematics.\n\nKeyfitz is the 2005 winner of the Krieger–Nelson Prize of the Canadian Mathematical Society, the 2011 Noether Lecturer of the Association for Women in Mathematics, the 2012 winner of the SIAM Prize for Distinguished Service to the Profession, and the 2012 AWM-SIAM Sonia Kovalevsky Lecturer.\n\nIn 2012 she became a fellow of the American Mathematical Society. She is also a fellow of the American Association for the Advancement of Science and of the Society for Industrial and Applied Mathematics.\n\nIn 2017, she was selected as a fellow of the Association for Women in Mathematics in the inaugural class.\n\nKeyfitz was born in Ottawa, and is the daughter of Canadian demographer Nathan Keyfitz.\n"}
{"id": "46605765", "url": "https://en.wikipedia.org/wiki?curid=46605765", "title": "Bousfield class", "text": "Bousfield class\n\nIn algebraic topology, the Bousfield class of, say, a spectrum \"X\" is the set of all (say) spectra \"Y\" whose smash product with \"X\" is zero: formula_1. Two objects are Bousfield equivalent if their Bousfield classes are the same.\n\nThe notion applies to module spectra and in that case one usually qualifies a ring spectrum over which the smash product is taken.\n\n\n"}
{"id": "12506060", "url": "https://en.wikipedia.org/wiki?curid=12506060", "title": "CIECAM02", "text": "CIECAM02\n\nIn colorimetry, CIECAM02 is the color appearance model published in 2002 by the International Commission on Illumination (CIE) Technical Committee 8-01 (\"Color Appearance Modelling for Color Management Systems\") and the successor of CIECAM97s.\n\nThe two major parts of the model are its chromatic adaptation transform, CIECAT02, and its equations for calculating mathematical correlates for the six technically defined dimensions of color appearance: brightness (luminance), lightness, colorfulness, chroma, saturation, and hue.\n\nBrightness is the subjective appearance of how bright an object appears given its surroundings and how it is illuminated. Lightness is the subjective appearance of how light a color appears to be. Colorfulness is the degree of difference between a color and grey. Chroma is the colorfulness relative to the brightness of another color that appears white under similar viewing conditions. This allows for the fact that a surface of a given chroma displays increasing colorfulness as the level of illumination increases. Saturation is the colorfulness of a color relative to its own brightness. Hue is the degree to which a stimulus can be described as similar to or different from stimuli that are described as red, green, blue, and yellow, the so-called unique hues. The colors that make up an object’s appearance are best described in terms of lightness and chroma when talking about the colors that make up the object’s surface, and it in terms of brightness, saturation and colorfulness when talking about the light that is emitted by or reflected off the object.\n\nCIECAM02 takes for its input the tristimulus values of the stimulus, the tristimulus values of an adapting white point, adapting background, and surround luminance information, and whether or not observers are discounting the illuminant (color constancy is in effect). The model can be used to predict these appearance attributes or, with forward and reverse implementations for distinct viewing conditions, to compute corresponding colors.\n\nCIECAM02 is used in Windows Vista's Windows Color System.\n\nThe inner circle is the \"stimulus\", from which the tristimulus values should be measured in CIE XYZ using the 2° standard observer. The intermediate circle is the \"proximal field\", extending out another 2°. The outer circle is the \"background\", reaching out to 10°, from which the relative luminance (Y) need be measured. If the proximal field is the same color as the background, the background is considered to be adjacent to the stimulus. Beyond the circles which comprise the \"display field\" (\"display area\", \"viewing area\") is the \"surround field\" (or \"peripheral area\"), which can be considered to be the entire room. The totality of the proximal field, background, and surround is called the \"adapting field\" (the field of view that supports adaptation—extends to the limit of vision).\n\nWhen referring to the literature, it is also useful to be aware of the difference between the terms \"adopted white point\" (the computational white point) and the \"adapted white point\" (the observer white point). The distinction may be important in mixed mode illumination, where psychophysical phenomena come into play. This is a subject of research.\n\nCIECAM02 defines three surround(ing)s – average, dim, and dark – with associated parameters defined here for reference in the rest of this article:\n\n\nFor intermediate conditions, these values can be linearly interpolated.\n\nThe absolute luminance of the adapting field, which is a quantity that will be needed later, should be measured with a photometer. If one is not available, it can be calculated using a reference white:\n\nwhere \"Y\" is the relative luminance of background, the is the illuminance of the reference white in lux, \"L\" is the absolute luminance of the reference white in cd/m, and \"Y\" is the relative luminance of the reference white in the adapting field. If unknown, the adapting field can be assumed to have average reflectance (\"gray world\" assumption): .\n\n\"Note\": Care should be taken not to confuse \"L\", the absolute luminance of the reference white in cd/m, and \"L\" the red cone response in the LMS color space.\n\n\nGiven a set of tristimulus values in XYZ, the corresponding LMS values can be determined by the M transformation matrix (calculated using the CIE 1931 2° standard colorimetric observer). The sample color in the \"test\" illuminant is:\n\nOnce in LMS, the white point can be adapted to the desired degree by choosing the parameter \"D\". For the general CAT02, the \"corresponding\" color in the reference illuminant is:\n\nwhere the factor accounts for the two illuminants having the same chromaticity but different reference whites. The subscripts indicate the cone response for white under the test (\"w\") and reference illuminant (\"wr\"). The degree of adaptation (discounting) \"D\" can be set to zero for no adaptation (stimulus is considered self-luminous) and unity for complete adaptation (color constancy). In practice, it ranges from 0.65 to 1.0, as can be seen from the diagram. Intermediate values can be calculated by:\n\nwhere surround \"F\" is as defined above and \"L\" is the \"adapting field luminance\" in cd/m.\n\nIn CIECAM02, the reference illuminant has equal energy ) and the reference white is the \"perfect reflecting diffuser\" (i.e., unity reflectance, and ) hence:\n\nFurthermore, if the reference white in both illuminants have the \"Y\" tristimulus value () then:\n\nAfter adaptation, the cone responses are converted to the Hunt–Pointer–Estévez space by going to XYZ and back:\n\nFinally, the response is compressed based on the generalized Michaelis–Menten equation (as depicted aside):\n\n\"F\" is the luminance level adaptation factor.\n\nAs previously mentioned, if the luminance level of the background is unknown, it can be estimated from the absolute luminance of the white point as using the \"medium gray\" assumption. (The expression for \"F\" is given in terms of 5\"L\" for convenience.) In photopic conditions, the luminance level adaptation factor (\"F\") is proportional to the cube root of the luminance of the adapting field (\"L\"). In scotopic conditions, it is proportional to \"L\" (meaning no luminance level adaptation). The photopic threshold is roughly (see \"F\"–\"L\" graph above).\n\nCIECAM02 defines correlates for yellow-blue, red-green, brightness, and colorfulness. Let us make some preliminary definitions.\n\nThe correlate for red–green (\"a\") is the magnitude of the departure of \"C\" from the criterion for unique yellow (), and the correlate for yellow–blue (\"b\") is based on the mean of the magnitude of the departures of \"C\" from unique red () and unique green ().\n\nThe 4.5 factor accounts for the fact that there are fewer cones at shorter wavelengths (the eye is less sensitive to blue). The order of the terms is such that b is positive for yellowish colors (rather than blueish).\n\nThe hue angle (\"h\") can be found by converting the rectangular coordinate (\"a\", \"b\") into polar coordinates:\n\nTo calculate the eccentricity (\"e\") and hue composition (\"H\"), determine which quadrant the hue is in with the aid of the following table. Choose \"i\" such that , where if and otherwise.\n\nCalculate the achromatic response \"A\":\n\nwhere\n\nThe correlate of lightness is\n\nwhere \"c\" is the impact of surround (see above), and\n\nThe correlate of brightness is\n\nThen calculate a temporary quantity \"t\",\n\nThe correlate of chroma is\n\nThe correlate of colorfulness is\n\nThe correlate of saturation is\n\nLike many color models, CIECAM02 aims to model the human perception of color. The CIECAM02 model has been shown to be a plausible model of neural activity in the primary visual cortex, compared to the earlier CIELAB model.\n\n\n"}
{"id": "20814602", "url": "https://en.wikipedia.org/wiki?curid=20814602", "title": "Collapse (topology)", "text": "Collapse (topology)\n\nIn topology, a branch of mathematics, a collapse reduces a simplicial complex (or more generally, a CW complex) to a homotopy-equivalent subcomplex. Collapses, like CW complexes themselves, were invented by J. H. C. Whitehead. Collapses find applications in computational homology.\n\nLet formula_1 be an abstract simplicial complex.\n\nSuppose that formula_2 such that the following two conditions are satisfied: \n\n\nthen formula_7 is called a free face. \n\nA simplicial collapse of K is the removal of all simplices formula_8 such that formula_9, where formula_10 is a free face. If additionally we have dim τ = dim σ-1, then this is called an elementary collapse. \n\nA simplicial complex that has a sequence of collapses leading to a point is called collapsible. Every collapsible complex is contractible, but the converse is not true.\n\nThis definition can be extended to CW-complexes and is the basis for the concept of simple-homotopy equivalence.\n\n\n"}
{"id": "89371", "url": "https://en.wikipedia.org/wiki?curid=89371", "title": "Combinational logic", "text": "Combinational logic\n\nIn digital circuit theory, combinational logic (sometimes also referred to as time-independent logic\n) is a type of digital logic which is implemented by Boolean circuits, where the output is a pure function of the present input only. This is in contrast to sequential logic, in which the output depends not only on the present input but also on the history of the input. In other words, sequential logic has \"memory\" while combinational logic does not.\n\nCombinational logic is used in computer circuits to perform Boolean algebra on input signals and on stored data. Practical computer circuits normally contain a mixture of combinational and sequential logic. For example, the part of an arithmetic logic unit, or ALU, that does mathematical calculations is constructed using combinational logic. Other circuits used in computers, such as half adders, full adders, half subtractors, full subtractors, multiplexers, demultiplexers, encoders and decoders are also made by using combinational logic.\n\nAn alternate term is combinatorial logic, though this usage may be considered controversial.\n\nCombinational logic is used to build circuits that produce specified outputs from certain inputs. The construction of combinational logic is generally done using one of two methods: a sum of products, or a product of sums. Consider the following truth table:\n\nUsing sum of products, all logical statements which yield true results are summed, giving the result:\n\nUsing Boolean algebra, the result simplifies to the following equivalent of the truth table:\n\nMinimization (simplification) of combinational logic formulas is done using the following rules based on the laws of Boolean algebra:\n\nWith the use of minimization (sometimes called logic optimization), a simplified logical function or circuit may be arrived upon, and the logic combinational circuit becomes smaller, and easier to analyse, use, or build.\n\n\n\n"}
{"id": "11574361", "url": "https://en.wikipedia.org/wiki?curid=11574361", "title": "Computable model theory", "text": "Computable model theory\n\nComputable model theory is a branch of model theory which deals with questions of computability as they apply to model-theoretical structures. \nIt was developed almost simultaneously by mathematicians in the West, primarily located in the United States and Australia, and Soviet Russia during the middle of the 20th century. Because of the Cold War there was little communication between these two groups and so a number of important results were discovered independently.\n\nComputable model theory introduces the ideas of computable and decidable models and theories and one of the basic problems is discovering whether or not computable or decidable models fulfilling certain model-theoretic conditions can be shown to exist.\n"}
{"id": "7824950", "url": "https://en.wikipedia.org/wiki?curid=7824950", "title": "Computer-based mathematics education", "text": "Computer-based mathematics education\n\nComputer-based mathematics education (CBME) is an approach to teaching mathematics that emphasizes the use of computers. \n\nComputers are used in education in a number of ways, such as interactive tutorials, hypermedia, simulations and educational games.\n\nTutorials are types of software that present information, check learning by question/answer method, judge responses, and provide feedback. \n\nEducational games are more like simulations and are used from the elementary to college level. The Incredible Machines is a good example of this type.\n\nE learning systems can deliver math lessons and exercises and manage homework assignments.\n\n"}
{"id": "978911", "url": "https://en.wikipedia.org/wiki?curid=978911", "title": "Concepts of Modern Mathematics", "text": "Concepts of Modern Mathematics\n\nConcepts of Modern Mathematics is a 1975 book by mathematician and science popularizer Ian Stewart about recent developments in mathematics.\n\nThe book arose out of an extramural class that Ian Stewart taught at the University of Warwick about \"Modern mathematics\". In the 1995 Dover edition Stewart wrote that the aim of the class was:\n\nThe book is aimed at non-mathematicians. However, there are frequent equations and diagrams and the level of presentation is more technical than some of Stewart's other popular books such as \"Flatterland\". Topics covered include analytic geometry, set theory, abstract algebra, group theory, topology, and probability.\n"}
{"id": "12089705", "url": "https://en.wikipedia.org/wiki?curid=12089705", "title": "Continuous function (set theory)", "text": "Continuous function (set theory)\n\nIn mathematics, specifically set theory, a continuous function is a sequence of ordinals such that the values assumed at limit stages are the limits (limit suprema and limit infima) of all values at previous stages. More formally, let γ be an ordinal, and formula_1 be a γ-sequence of ordinals. Then \"s\" is continuous if at every limit ordinal β < γ,\n\nand\n\nAlternatively, \"s\" is continuous if \"s\": γ → range(s) is a continuous function when the sets are each equipped with the order topology. These continuous functions are often used in cofinalities and cardinal numbers. \n\nA normal function is a function that is both continuous and increasing.\n\n"}
{"id": "58525823", "url": "https://en.wikipedia.org/wiki?curid=58525823", "title": "Elza Furtado Gomide", "text": "Elza Furtado Gomide\n\nElza Furtado Gomide (August 20, 1925 – October 26, 2013) was a Brazilian mathematician and the first women to receive a doctorate in mathematics from the University of São Paulo, in 1950. Furtado was involved in the creation of the Society of Mathematics of São Paulo and was elected head of the department of mathematics of the University of São Paulo in 1968.\n\n"}
{"id": "27906732", "url": "https://en.wikipedia.org/wiki?curid=27906732", "title": "Equivalent latitude", "text": "Equivalent latitude\n\nIn differential geometry, the equivalent latitude is a Lagrangian coordinate .\nIt is often used in atmospheric science,\nparticularly in the study of stratospheric dynamics.\nEach isoline in a map of equivalent latitude follows the flow velocity and encloses the same area as the latitude line of equivalent value, hence \"equivalent latitude.\" \nEquivalent latitude is calculated from potential vorticity, from passive tracer simulations and from actual measurements of atmospheric tracers such as ozone.\n\nThe calculation of equivalent latitude involves creating a monotonic mapping between the values of equivalent latitude and\nthe tracer it is based upon: higher values of the tracer map to higher\nvalues of equivalent latitude.\nA precise method is to assign a\nrepresentative area to each of the tracer measurements, filling the entire globe.\nThus, for a tracer field regularly gridded in longitude and latitude, \ngrid points closer to the pole will take up a smaller area,\nin proportion to the cosine of the latitude.\nNow, rank all the tracer values then form the cumulative sum.\nThe equivalent latitude from the area is given as:\n\nwhere \"A\" is the area enclosed to the South (\"A\" = 0 corresponds to the equivalent South Pole) and \"R\" is the radius of the Earth.\nThis method generates a mapping that is as continuous as the data allows\nas opposed to binning which produces a coarse-grained mapping.\n\n"}
{"id": "20560838", "url": "https://en.wikipedia.org/wiki?curid=20560838", "title": "Equivariant L-function", "text": "Equivariant L-function\n\nIn algebraic number theory, an equivariant Artin L-function is a function associated to a finite Galois extension of global fields created by packaging together the various Artin L-functions associated with the extension. Each extension has many traditional Artin L-functions associated with it, corresponding to the characters of representations of the Galois group. By contrast, each extension has a unique corresponding equivariant L-function.\n\nEquivariant L-functions have become increasingly important as a wide range of conjectures and theorems in number theory have been developed around them. Among these are the Brumer–Stark conjecture, the Coates-Sinnott conjecture, and a recently developed equivariant version of the main conjecture in Iwasawa theory.\n"}
{"id": "723043", "url": "https://en.wikipedia.org/wiki?curid=723043", "title": "Family of sets", "text": "Family of sets\n\nIn set theory and related branches of mathematics, a collection \"F\" of subsets of a given set \"S\" is called a family of subsets of \"S\", or a family of sets over \"S\". More generally, a collection of any sets whatsoever is called a family of sets.\n\nThe term \"collection\" is used here because, in some contexts, a family of sets may be allowed to contain repeated copies of any given member, and in other contexts it may form a proper class rather than a set.\n\n\n\n\nCertain types of objects from other areas of mathematics are equivalent to families of sets, in that they can be described purely as a collection of sets of objects of some type:\n\n\n"}
{"id": "15008875", "url": "https://en.wikipedia.org/wiki?curid=15008875", "title": "Favard operator", "text": "Favard operator\n\nIn functional analysis, a branch of mathematics, the Favard operators are defined by:\n\nwhere formula_2, formula_3. They are named after Jean Favard.\n\nA common generalization is:\n\nwhere formula_5 is a positive sequence that converges to 0. This reduces to the classical Favard operators when formula_6.\n\n"}
{"id": "17441873", "url": "https://en.wikipedia.org/wiki?curid=17441873", "title": "Felsenstein's tree-pruning algorithm", "text": "Felsenstein's tree-pruning algorithm\n\nIn statistical genetics, Felsenstein's tree-pruning algorithm (or Felsenstein's tree-peeling algorithm), attributed to Joseph Felsenstein, is an algorithm for computing the likelihood of an evolutionary tree from nucleic acid sequence data. \n\nThe algorithm is often used as a subroutine in a search for a maximum likelihood estimate for an evolutionary tree. Further, it can be used in a hypothesis test for whether evolutionary rates are constant (by using likelihood ratio tests). It can also be used to provide error estimates for the parameters describing an evolutionary tree.\n"}
{"id": "37232", "url": "https://en.wikipedia.org/wiki?curid=37232", "title": "Fermat's principle", "text": "Fermat's principle\n\nIn optics, Fermat's principle or the principle of least time, named after French mathematician Pierre de Fermat, is the principle that the path taken between two points by a ray of light is the path that can be traversed in the least time. This principle is sometimes taken as the definition of a ray of light. However, this version of the principle is not general; a more modern statement of the principle is that rays of light traverse the path of stationary optical length with respect to variations of the path. In other words, a ray of light prefers the path such that there are other paths, arbitrarily nearby on either side, along which the ray would take almost exactly the same time to traverse.\n\nFermat's principle can be used to describe the properties of light rays reflected off mirrors, refracted through different media, or undergoing total internal reflection. It follows mathematically from Huygens' principle (at the limit of small wavelength). Fermat's text \"Analyse des réfractions\" exploits the technique of adequality to derive Snell's law of refraction and the law of reflection.\n\nFermat's principle has the same form as Hamilton's principle and it is the basis of Hamiltonian optics.\n\nThe time T a point of the electromagnetic wave needs to cover a path between the points A and B is given by:\n\n\"c\" is the speed of light in vacuum, \"ds\" an infinitesimal displacement along the ray, \"v\" = \"ds\"/\"dt\" the speed of light in a medium and \"n\" = \"c\"/\"v\" the refractive index of that medium, formula_2 is the starting time (the wave front is in A), formula_3 is the arrival time at B. The optical path length of a ray from a point A to a point B is defined by:\n\nand it is related to the travel time by \"S\" = \"cT\". The optical path length is a purely geometrical quantity since time is not considered in its calculation. An extremum in the light travel time between two points A and B is equivalent to an extremum of the optical path length between those two points. The historical form proposed by Fermat is incomplete. A complete modern statement of the variational Fermat principle is that In the context of calculus of variations this can be written as\n\nIn general, the refractive index is a scalar field of position in space, that is, formula_6 in 3D euclidean space. Assuming now that light has a component that travels along the \"x\" axis, the path of a light ray may be parametrized as formula_7 and\n\nwhere formula_9. The principle of Fermat can now be written as\n\nwhich has the same form as Hamilton's principle but in which \"x\" takes the role of time in classical mechanics. Function formula_12 is the optical Lagrangian from which the Lagrangian and Hamiltonian (as in Hamiltonian mechanics) formulations of geometrical optics may be derived.\n\nClassically, Fermat's principle can be considered as a mathematical consequence of Huygens' principle. Indeed, of all secondary waves (along all possible paths) the waves with the extremal (stationary) paths contribute most due to constructive interference. Suppose that light waves propagate from A to B by all possible routes AB, unrestricted initially by rules of geometrical or physical optics. The various optical paths AB will vary by amounts greatly in excess of one wavelength, and so the waves arriving at B will have a large range of phases and will tend to interfere destructively. But if there is a shortest route AB, and the optical path varies smoothly through it, then a considerable number of neighboring routes close to AB will have optical paths differing from AB by second-order amounts only and will therefore interfere constructively. Waves along and close to this shortest route will thus dominate and AB will be the route along which the light is seen to travel.\n\nFermat's principle is the main principle of quantum electrodynamics which states that any particle (e.g. a photon or an electron) propagates over all available, unobstructed paths and that the interference, or superposition, of its wavefunction over all those paths at the point of observation gives the probability of detecting the particle at this point. Thus, because the extremal paths (shortest, longest, or stationary) cannot be completely canceled out, they contribute most to this interference. In humans, for example, Fermat's principle can be demonstrated in a situation when a lifeguard has to find the fastest way to traverse both beach and water in order to reach a drowning swimmer. The principle has been tested in studies with ants, in which the ants' nest is on one end of a container and food is on the opposite end, but the ants choose to follow the path of least time, rather than the most direct path.\n\nIn the classic mechanics of waves, Fermat's principle follows from the extremum principle of mechanics (see variational principle).\n\nEuclid, c. 320 BCE in his Catoptrics (on mirrors, including spherical mirrors) and Optics, laid the foundations for reflection, which was repeated by Ptolemy, and then in his more detailed books that have surfaced, Hero of Alexandria (Heron) (c. 60) described the principle of reflection, which stated that a ray of light that goes from point A to point B, suffering any number of reflections on flat mirrors in the same medium, has a smaller path length than any nearby path.\n\nIbn al-Haytham (Alhacen), in his \"Book of Optics\" (1021), expanded the principle to both reflection and refraction, and expressed an early version of the principle of least time. His experiments were based on earlier works on refraction carried out by the Greek scientist Ptolemy.\n\nThe generalized principle of least time in its modern form was stated by Fermat in a letter dated January 1, 1662, to Cureau de la Chambre. It was met with objections by Claude Clerselier in May 1662, an expert in optics and leading spokesman for the Cartesians at the time. Amongst his objections, Clerselier states:\n\"... The principle which you take as the basis for your proof, namely that Nature always acts by using the simplest and shortest paths, is merely a moral, and not a physical one. It is not, and cannot be, the cause of any effect in Nature.\n\nThe original French, from Mahoney, is as follows:\n\"Le principe que vous prenez pour fondement de votre démonstration, à savoir que la nature agit toujours par les voies les plus courtes et les plus simples, n’est qu’un principe moral et non point physique, qui n’est point et qui ne peut être la cause d’aucun effet de la nature.\"\nAlthough Fermat's principle does not hold standing alone, we now know it can be derived from earlier principles such as Huygens' principle.\n\nHistorically, Fermat's principle has served as a guiding principle in the formulation of physical laws with the use of variational calculus (see Principle of least action).\n\n"}
{"id": "2672856", "url": "https://en.wikipedia.org/wiki?curid=2672856", "title": "Floer homology", "text": "Floer homology\n\nIn mathematics, Floer homology is a tool for studying symplectic geometry and low-dimensional topology. Floer homology is a novel invariant that arises as an infinite-dimensional analog of finite-dimensional Morse homology. Andreas Floer introduced the first version of Floer homology, now called Hamiltonian Floer homology, in his proof of the Arnold conjecture in symplectic geometry. Floer also developed a closely related theory for Lagrangian submanifolds of a symplectic manifold. A third construction, also due to Floer, associates homology groups to closed three-dimensional manifolds using the Yang–Mills functional. These constructions and their descendants play a fundamental role in current investigations into the topology of symplectic and contact manifolds as well as (smooth) three- and four-dimensional manifolds.\n\nFloer homology is typically defined by associating to the object of interest an infinite-dimensional manifold and a real valued function on it. In the symplectic version, this is the free loop space of a symplectic manifold with the symplectic action functional. For the (instanton) version for three-manifolds, it is the space of SU(2)-connections on a three-dimensional manifold with the Chern–Simons functional. Loosely speaking, Floer homology is the Morse homology of the function on the infinite-dimensional manifold. A Floer chain complex is formed from the abelian group spanned by the critical points of the function (or possibly certain collections of critical points). The differential of the chain complex is defined by counting the function's gradient flow lines connecting certain pairs of critical points (or collections thereof). Floer homology is the homology of this chain complex.\n\nThe gradient flow line equation, in a situation where Floer's ideas can be successfully applied, is typically a geometrically meaningful and analytically tractable equation. For symplectic Floer homology, the gradient flow equation for a path in the loopspace is (a perturbed version of) the Cauchy–Riemann equation for a map of a cylinder (the total space of the path of loops) to the symplectic manifold of interest; solutions are known as pseudoholomorphic curves. The Gromov compactness theorem is then used to show that the differential is well-defined and squares to zero, so that the Floer homology is defined. For instanton Floer homology, the gradient flow equations is exactly the Yang-Mills equation on the three-manifold crossed with the real line.\n\nSymplectic Floer Homology (SFH) is a homology theory associated to a symplectic manifold and a nondegenerate symplectomorphism of it. If the symplectomorphism is Hamiltonian, the homology arises from studying the symplectic action functional on the (universal cover of the) free loop space of a symplectic manifold. SFH is invariant under Hamiltonian isotopy of the symplectomorphism.\n\nHere, nondegeneracy means that 1 is not an eigenvalue of the derivative of the symplectomorphism at any of its fixed points. This condition implies that the fixed points are isolated. SFH is the homology of the chain complex generated by the fixed points of such a symplectomorphism, where the differential counts certain pseudoholomorphic curves in the product of the real line and the mapping torus of the symplectomorphism. This itself is a symplectic manifold of dimension two greater than the original manifold. For an appropriate choice of almost complex structure, punctured holomorphic curves (of finite energy) in it have cylindrical ends asymptotic to the loops in the mapping torus corresponding to fixed points of the symplectomorphism. A relative index may be defined between pairs of fixed points, and the differential counts the number of holomorphic cylinders with relative index 1.\n\nThe symplectic Floer homology of a Hamiltonian symplectomorphism of a compact manifold is isomorphic to the singular homology of the underlying manifold. Thus, the sum of the Betti numbers of that manifold yields the lower bound predicted by one version of the Arnold conjecture for the number of fixed points for a nondegenerate symplectomorphism. The SFH of a Hamiltonian symplectomorphism also has a pair of pants product that is a deformed cup product equivalent to quantum cohomology. A version of the product also exists for non-exact symplectomorphisms.\n\nFor the cotangent bundle of a manifold M, the Floer homology depends on the choice of Hamiltonian due to its noncompactness. For Hamiltonians that are quadratic at infinity, the Floer homology is the singular homology of the free loop space of M (proofs of various versions of this statement are due to Viterbo, Salamon–Weber, Abbondandolo–Schwarz, and Cohen). There are more complicated operations on the Floer homology of a cotangent bundle that correspond to the string topology operations on the homology of the loop space of the underlying manifold.\n\nThe symplectic version of Floer homology figures in a crucial way in the formulation of the homological mirror symmetry conjecture.\n\nIn 1996 S. Piunikhin, D. Salamon and M. Schwarz summarized the results about the relation between Floer homology and quantum cohomology and formulated as the following.\n\nThe above condition of semi-positive and the compactness of symplectic manifold \"M\" is required for us to obtain Novikov ring and for the definition of both Floer homology and quantum cohomology. The semi-positive condition means that one of the following holds (note that the three cases are not disjoint):\n\nThe quantum cohomology group of symplectic manifold \"M\" can be defined as the tensor products of the ordinary cohomology with Novikov ring Λ, i.e.\n\nThis construction of Floer homology explains the independence on the choice of the almost complex structure on \"M\" and the isomorphism to Floer homology provided from the ideas of Morse theory and pseudoholomorphic curves, where we must recognize the Poincaré duality between homology and cohomology as the background.\n\nThere are several equivalent Floer homologies associated to closed three-manifolds. Each yields three types of homology groups, which fit into an exact triangle. A knot in a three-manifold induces a filtration on the chain complex of each theory, whose chain homotopy type is a knot invariant. (Their homologies satisfy similar formal properties to the combinatorially-defined Khovanov homology.)\n\nThese homologies are closely related to the Donaldson and Seiberg invariants of 4-manifolds, as well as to Taubes's Gromov invariant of symplectic 4-manifolds; the differentials of the corresponding three-manifold homologies to these theories are studied by considering solutions to the relevant differential equations (Yang–Mills, Seiberg–Witten, and Cauchy–Riemann, respectively) on the 3-manifold cross R. The 3-manifold Floer homologies should also be the targets of relative invariants for four-manifolds with boundary, related by gluing constructions to the invariants of a closed 4-manifold obtained by gluing together bounded 3-manifolds along their boundaries. (This is closely related to the notion of a topological quantum field theory.) For Heegaard Floer homology, the 3-manifold homology was defined first, and an invariant for closed 4-manifolds was later defined in terms of it.\n\nThere are also extensions of the 3-manifold homologies to 3-manifolds with boundary: sutured Floer homology and bordered Floer homology . These are related to the invariants for closed 3-manifolds by gluing formulas for the Floer homology of a 3-manifold described as the union along the boundary of two 3-manifolds with boundary.\n\nThe three-manifold Floer homologies also come equipped with a distinguished element of the homology if the three-manifold is equipped with a contact structure. Kronheimer and Mrowka first introduced the contact element in the Seiberg–Witten. Ozsvath and Szabo used constructed it for Heegaard Floer homology using Giroux's relation between contact manifolds and open book decompositions, and it comes for free, as the homology class of the empty set, in embedded contact homology. (Which, unlike the other three, requires a contact homology for its definition. For embedded contact homology see .\n\nThese theories all come equipped with a priori relative gradings; these have been lifted to absolute gradings (by homotopy classes of oriented 2-plane fields) by Kronheimer and Mrowka (for SWF), Gripp and Huang (for HF), and Hutchings (for ECH). Cristofaro-Gardiner has shown that Taubes' isomorphism between ECH and Seiberg-Witten Floer cohomology preserves these absolute gradings.\n\nThis is a three-manifold invariant connected to Donaldson theory introduced by Floer himself. It is obtained using the Chern–Simons functional on the space of connections on a principal SU(2)-bundle over the three-manifold. Its critical points are flat connections and its flow lines are instantons, i.e. anti-self-dual connections on the three-manifold crossed with the real line. Instanton Floer homology may be viewed as a generalization of the Casson invariant because the Euler characteristic of Floer homology agrees with the Casson invariant.\n\nSoon after Floer's introduction of Floer homology, Donaldson realized that cobordisms induce maps. This was the first instance of the structure that came to be known as a Topological Quantum Field Theory.\n\nSeiberg–Witten Floer homology or monopole Floer homology is a homology theory of smooth 3-manifolds (equipped with a spin structure). It may be viewed as the Morse homology of the Chern-Simons-Dirac functional on U(1) connections on the three-manifold. The associated gradient flow equation corresponds to the Seiberg-Witten equations on the 3-manifold crossed with the real line. Equivalently, the generators of the chain complex are translation-invariant solutions to Seiberg–Witten equations (known as monopoles) on the product of a 3-manifold and the real line, and the differential counts solutions to the Seiberg–Witten equations on the product of a three-manifold and the real line, which are asymptotic to invariant solutions at infinity and negative infinity.\n\nOne version of Seiberg-Witten-Floer homology was constructed rigorously in the monograph Monopoles and Three-manifolds by Peter Kronheimer and Tomasz Mrowka, where it is known as monopole Floer homology. Taubes has shown that it is isomorphic to embedded contact homology. Alternate constructions of SWF for rational homology 3-spheres have been given by and ; they are presumed but not known to agree with monopole Floer homology.\n\nHeegaard Floer homology is an invariant due to Peter Ozsváth and Zoltán Szabó of a closed 3-manifold equipped with a spin structure. It is computed using a Heegaard diagram of the space via a construction analogous to Lagrangian Floer homology. announced a proof that Heegaard Floer homology is isomorphic to Seiberg-Witten Floer homology, and announced a proof that the plus-version of Heegaard Floer homology (with reverse orientation) is isomorphic to embedded contact homology.\n\nA knot in a three-manifold induces a filtration on the Heegaard Floer homology groups, and the filtered homotopy type is a powerful knot invariant, called knot Floer homology. It categorifies the Alexander polynomial. Knot Floer homology was defined by and independently by . It is known to detect knot genus. Using grid diagrams for the Heegaard splittings, knot Floer homology was given a combinatorial construction by .\n\nThe Heegaard Floer homology of the double cover of S^3 branched over a knot is related by a spectral sequence to Khovanov homology .\n\nThe \"hat\" version of Heegaard Floer homology was described combinatorially by . The \"plus\" and \"minus\" versions of Heegaard Floer homology, and the related Ozsváth-Szabó four-manifold invariants, can be described combinatorially as well .\n\nEmbedded contact homology, due to Michael Hutchings, is an invariant of 3-manifolds (with a distinguished second homology class, corresponding to the choice of a spin structure in Seiberg–Witten Floer homology) isomorphic (by work of Clifford Taubes) to Seiberg–Witten Floer cohomology and consequently (by work announced by and ) to the plus-version of Heegaard Floer homology (with reverse orientation). It may be seen as an extension of Taubes's Gromov invariant, known to be equivalent to the Seiberg–Witten invariant, from closed symplectic 4-manifolds to certain non-compact symplectic 4-manifolds (namely, a contact three-manifold cross R). Its construction is analogous to symplectic field theory, in that it is generated by certain collections of closed Reeb orbits and its differential counts certain holomorphic curves with ends at certain collections of Reeb orbits. It differs from SFT in technical conditions on the collections of Reeb orbits that generate it—and in not counting all holomorphic curves with Fredholm index 1 with given ends, but only those that also satisfy a topological condition given by the \"ECH index\", which in particular implies that the curves considered are (mainly) embedded.\n\nThe Weinstein conjecture that a contact 3-manifold has a closed Reeb orbit for any contact form holds on any manifold whose ECH is nontrivial, and was proved by Taubes using techniques closely related to ECH; extensions of this work yielded the isomorphism between ECH and SWF. Many constructions in ECH (including its well-definedness) rely upon this isomorphism .\n\nThe contact element of ECH has a particularly nice form: it is the cycle associated to the empty collection of Reeb orbits.\n\nAn analog of embedded contact homology may be defined for mapping tori of symplectomorphisms of a surface (possibly with boundary) and is known as periodic Floer homology, generalizing the symplectic Floer homology of surface symplectomorphisms. More generally, it may be defined with respect to any stable Hamiltonian structure on the 3-manifold; like contact structures, stable Hamiltonian structures define a nonvanishing vector field (the Reeb vector field), and Hutchings and Taubes have proven an analogue of the Weinstein conjecture for them, namely that they always have closed orbits (unless they are mapping tori of a 2-torus).\n\nThe Lagrangian Floer homology of two transversely intersecting Lagrangian submanifolds of a symplectic manifold is the homology of a chain complex generated by the intersection points of the two submanifolds and whose differential counts pseudoholomorphic Whitney discs.\n\nGiven three Lagrangian submanifolds \"L\", \"L\", and \"L\" of a symplectic manifold, there is a product structure on the Lagrangian Floer homology:\n\nwhich is defined by counting holomorphic triangles (that is, holomorphic maps of a triangle whose vertices and edges map to the appropriate intersection points and Lagrangian submanifolds).\n\nPapers on this subject are due to Fukaya, Oh, Ono, and Ohta; the recent work on \"cluster homology\" of Lalonde and Cornea offer a different approach to it. The Floer homology of a pair of Lagrangian submanifolds may not always exist; when it does, it provides an obstruction to isotoping one Lagrangian away from the other using a Hamiltonian isotopy.\n\nSeveral kinds of Floer homology are special cases of Lagrangian Floer homology. The symplectic Floer homology of a symplectomorphism of M can be thought of as a case of Lagrangian Floer homology in which the ambient manifold is M crossed with M and the Lagrangian submanifolds are the diagonal and the graph of the symplectomorphism. The construction of Heegaard Floer homology is based on a variant of Lagrangian Floer homology for totally real submanifolds defined using a Heegaard splitting of a three-manifold. Seidel-Smith and Manolescu constructed a link invariant as a certain case of Lagrangian Floer homology, which conjecturally agrees with Khovanov homology, a combinatorially-defined link invariant.\n\nThe Atiyah–Floer conjecture connects the instanton Floer homology with the Lagrangian intersection Floer homology: Consider a 3-manifold Y with a Heegaard splitting along a surface formula_6. Then the space of flat connections on formula_6 modulo gauge equivalence is a symplectic manifold of dimension 6\"g\" − 6, where \"g\" is the genus of the surface formula_6. In the Heegaard splitting, formula_6 bounds two different 3-manifolds; the space of flat connections modulo gauge equivalence on each 3-manifold with boundary (equivalently, the space of connections on formula_6 that extend over each three manifold) is a Lagrangian submanifold of the space of connections on formula_6. We may thus consider their Lagrangian intersection Floer homology. Alternately, we can consider the Instanton Floer homology of the 3-manifold Y. The Atiyah–Floer conjecture asserts that these two invariants are isomorphic. are working on a program to prove this conjecture.\n\nThe homological mirror symmetry conjecture of Maxim Kontsevich predicts an equality between the Lagrangian Floer homology of Lagrangians in a Calabi–Yau manifold formula_12 and the Ext groups of coherent sheaves on the mirror Calabi–Yau manifold. In this situation, one should not focus on the Floer homology groups but on the Floer chain groups. Similar to the pair-of-pants product, one can construct multi-compositions using pseudo-holomorphic \"n\"-gons. These compositions satisfy the formula_13-relations making the category of all (unobstructed) Lagrangian submanifolds in a symplectic manifold into an formula_13-category, called the Fukaya category.\n\nTo be more precise, one must add additional data to the Lagrangian – a grading and a spin structure. A Lagrangian with a choice of these structures is often called a brane in homage to the underlying physics. The Homological Mirror Symmetry conjecture states there is a type of derived Morita equivalence between the Fukaya category of the Calabi–Yau formula_12 and a dg category underlying the bounded derived category of coherent sheaves of the mirror, and vice versa.\n\nThis is an invariant of contact manifolds and symplectic cobordisms between them, originally due to Yakov Eliashberg, Alexander Givental and Helmut Hofer. The symplectic field theory as well as its subcomplexes, rational symplectic field theory and contact homology, are defined as homologies of differential algebras, which are generated by closed orbits of the Reeb vector field of a chosen contact form. The differential counts certain holomorphic curves in the cylinder over the contact manifold, where the trivial examples are the branched coverings of (trivial) cylinders over closed Reeb orbits. It further includes a linear homology theory, called cylindrical or linearized contact homology (sometimes, by abuse of notation, just contact homology), whose chain groups are vector spaces generated by closed orbits and whose differentials count only holomorphic cylinders. However, cylindrical contact homology is not always defined due to the presence of holomorphic discs and a lack of regularity and transversality results. In situations where cylindrical contact homology makes sense, it may be seen as the (slightly modified) \"Morse homology\" of the action functional on the free loop space, which sends a loop to the integral of the contact form alpha over the loop. Reeb orbits are the critical points of this functional.\n\nSFT also associates a relative invariant of a Legendrian submanifold of a contact manifold known as relative contact homology. Its generators are Reeb chords, which are trajectories of the Reeb vector field beginning and ending on a Lagrangian, and its differential counts certain holomorphic strips in the symplectization of the contact manifold whose ends are asymptotic to given Reeb chords.\n\nIn SFT the contact manifolds can be replaced by mapping tori of symplectic manifolds with symplectomorphisms. While the cylindrical contact homology is well-defined and given by the symplectic Floer homologies of powers of the symplectomorphism, (rational) symplectic field theory and contact homology can be considered as generalized symplectic Floer homologies. In the important case when the symplectomorphism is the time-one map of a time-dependent Hamiltonian, it was however shown that these higher invariants do not contain any further information.\n\nOne conceivable way to construct a Floer homology theory of some object would be to construct a related spectrum whose ordinary homology is the desired Floer homology. Applying other homology theories to such a spectrum could yield other interesting invariants. This strategy was proposed by Ralph Cohen, John Jones, and Graeme Segal, and carried out in certain cases for Seiberg–Witten–Floer homology by and for the symplectic Floer homology of cotangent bundles by Cohen. This approach was the basis of Manolescu's 2013 construction of Pin (2)-equivariant Seiberg-Witten Floer homology, with which he disproved the Triangulation Conjecture for manifolds of dimension 5 and higher.\n\nMany of these Floer homologies have not been completely and rigorously constructed, and many conjectural equivalences have not been proved. Technical difficulties come up in the analysis involved, especially in constructing compactified moduli spaces of pseudoholomorphic curves. Hofer, in collaboration with Kris Wysocki and Eduard Zehnder, has developed new analytic foundations via their theory of polyfolds and a \"general Fredholm theory\". While the polyfold project is not yet fully completed, in some important cases transversality was shown using simpler methods.\n\nFloer homologies are generally difficult to compute explicitly. For instance, the symplectic Floer homology for all surface symplectomorphisms was completed only in 2007. The Heegaard Floer homology has been a success story in this regard: researchers have exploited its algebraic structure to compute it for various classes of 3-manifolds and have found combinatorial algorithms for computation\nof much of the theory. It is also connected to existing invariants and structures and many insights into 3-manifold topology have resulted.\n\n\n\n"}
{"id": "19468696", "url": "https://en.wikipedia.org/wiki?curid=19468696", "title": "Fundamental theorem of calculus", "text": "Fundamental theorem of calculus\n\nThe fundamental theorem of calculus is a theorem that links the concept of differentiating a function with the concept of integrating a function. \n\nThe first part of the theorem, sometimes called the first fundamental theorem of calculus, states that one of the antiderivatives (also called \"indefinite integral\"), say \"F\", of some function \"f\" may be obtained as the integral of \"f\" with a variable bound of integration. This implies the existence of antiderivatives for continuous functions.\n\nConversely, the second part of the theorem, sometimes called the second fundamental theorem of calculus, states that the integral of a function \"f\" over some interval can be computed by using any one, say \"F\", of its infinitely many antiderivatives. This part of the theorem has key practical applications, because explicitly finding the antiderivative of a function by symbolic integration avoids numerical integration to compute integrals. This provides generally a better numerical accuracy.\n\nThe fundamental theorem of calculus relates differentiation and integration, showing that these two operations are essentially inverses of one another. Before the discovery of this theorem, it was not recognized that these two operations were related. Ancient Greek mathematicians knew how to compute area via infinitesimals, an operation that we would now call integration. The origins of differentiation likewise predate the Fundamental Theorem of Calculus by hundreds of years; for example, in the fourteenth century the notions of \"continuity\" of functions and \"motion\" were studied by the Oxford Calculators and other scholars. The historical relevance of the Fundamental Theorem of Calculus is not the ability to calculate these operations, but the realization that the two seemingly distinct operations (calculation of geometric areas, and calculation of velocities) are actually closely related.\n\nThe first published statement and proof of a rudimentary form of the fundamental theorem, strongly geometric in character, was by James Gregory (1638–1675). Isaac Barrow (1630–1677) proved a more generalized version of the theorem, while his student Isaac Newton (1642–1727) completed the development of the surrounding mathematical theory. Gottfried Leibniz (1646–1716) systematized the knowledge into a calculus for infinitesimal quantities and introduced the notation used today.\n\nFor a continuous function whose graph is plotted as a curve, each value of \"x\" has a corresponding area function \"A\"(\"x\"), representing the area beneath the curve between 0 and \"x\". The function \"A\"(\"x\") may not be known, but it is given that it represents the area under the curve.\n\nThe area under the curve between \"x\" and could be computed by finding the area between 0 and then subtracting the area between 0 and \"x\". In other words, the area of this “strip” would be .\n\nThere is another way to \"estimate\" the area of this same strip. As shown in the accompanying figure, \"h\" is multiplied by \"f\"(\"x\") to find the area of a rectangle that is approximately the same size as this strip. So:\n\nIn fact, this estimate becomes a perfect equality if we add the red portion of the \"excess\" area shown in the diagram. So:\n\nRearranging terms:\n\nAs \"h\" approaches 0 in the limit, the last fraction can be shown to go to zero. This is true because the area of the red portion of excess region is less than or equal to the area of the tiny black-bordered rectangle. More precisely,\nwhere formula_5 and formula_6 are points where reaches its maximum and its minimum, respectively, in the interval .\nBy the continuity of , the latter expression tends to zero as does. Therefore, the left-hand side tends to zero as does, which implies\nThis implies . That is, the derivative of the area function \"A\"(\"x\") exists and is the original function \"f\"(\"x\"); so, the area function is simply an antiderivative of the original function. Computing the derivative of a function and “finding the area” under its curve are \"opposite\" operations. This is the crux of the Fundamental Theorem of Calculus.\n\nIntuitively, the theorem simply states that the sum of infinitesimal changes in a quantity over time (or over some other variable) adds up to the net change in the quantity.\n\nImagine for example using a stopwatch to mark-off tiny increments of time as a car travels down a highway. Imagine also looking at the car's speedometer as it travels, so that at every moment you know the velocity of the car. To understand the power of this theorem, imagine also that you are not allowed to look out the window of the car, so that you have no direct evidence of how far the car has traveled.\n\nFor any tiny interval of time in the car, you could calculate how far the car has traveled in that interval by multiplying the current speed of the car times the length of that tiny interval of time. (This is because \"distance\" = \"speed\" formula_8 \"time\".)\n\nNow imagine doing this instant after instant, so that for every tiny interval of time you know how far the car has traveled. In principle, you could then calculate the \"total\" distance traveled in the car (even though you've never looked out the window) by simply summing-up all those tiny distances.\n\nIn other words,\n\nOn the right hand side of this equation, as formula_12 becomes infinitesimally small, the operation of \"summing up\" corresponds to integration. So what we've shown is that the integral of the velocity function can be used to compute how far the car has traveled.\n\nNow remember that the velocity function is simply the derivative of the position function. So what we have really shown is that integrating the velocity simply recovers the original position function. This is the basic idea of the theorem: that \"integration\" and \"differentiation\" are closely related operations, each essentially being the inverse of the other.\n\nIn other words, in terms of one's physical intuition, the theorem simply states that the sum of the changes in a quantity over time (such as \"position\", as calculated by multiplying \"velocity\" times \"time\") adds up to the total net change in the quantity. Or to put this more generally:\nthen the idea that \"distance equals speed times time\" corresponds to the statement\nmeaning that one can recover the original function formula_17 by integrating its derivative, the velocity formula_15, over formula_14.\n\nThere are two parts to the theorem. The first part deals with the derivative of an antiderivative, while the second part deals with the relationship between antiderivatives and definite integrals.\n\nThis part is sometimes referred to as the \"first fundamental theorem of calculus\".\n\nLet \"f\" be a continuous real-valued function defined on a closed interval [\"a\", \"b\"]. Let \"F\" be the function defined, for all \"x\" in [\"a\", \"b\"], by\n\nThen, \"F\" is uniformly continuous on [\"a\", \"b\"], differentiable on the open interval and\n\nfor all \"x\" in (\"a\", \"b\").\n\nThe fundamental theorem is often employed to compute the definite integral of a function formula_22 for which an antiderivative formula_23 is known. Specifically, if formula_22 is a real-valued continuous function on formula_25 and formula_23 is an antiderivative of formula_22 in formula_25 then\n\nThe corollary assumes continuity on the whole interval. This result is strengthened slightly in the following part of the theorem.\n\nThis part is sometimes referred to as the second fundamental theorem of calculus or the Newton–Leibniz axiom.\n\nLet formula_22 be a real-valued function on a closed interval formula_25 and formula_23 an antiderivative of formula_22 in formula_25:\n\nIf formula_22 is Riemann integrable on formula_25 then\n\nThe second part is somewhat stronger than the corollary because it does not assume that formula_22 is continuous.\n\nWhen an antiderivative formula_23 exists, then there are infinitely many antiderivatives for formula_22, obtained by adding an arbitrary constant to formula_23. Also, by the first part of the theorem, antiderivatives of formula_22 always exist when formula_22 is continuous.\n\nFor a given \"f\"(\"t\"), define the function \"F\"(\"x\") as\n\nFor any two numbers \"x\" and \"x\" + Δ\"x\" in [\"a\", \"b\"], we have\nand\n\nSubtracting the two equalities gives\n\nIt can be shown that\nManipulating this equation gives\n\nSubstituting the above into (1) results in\n\nAccording to the mean value theorem for integration, there exists a real number formula_52 such that\n\nTo keep the notation simple, we write just formula_54, but one should keep in mind that, for a given function formula_22, the value of formula_54 depends on formula_57 and on formula_58 but is always confined to the interval formula_59.\nSubstituting the above into (2) we get\n\nDividing both sides by formula_61 gives\n\nTake the limit as formula_61 → 0 on both sides of the equation.\n\nThe expression on the left side of the equation is the definition of the derivative of \"F\" at \"x\".\n\nTo find the other limit, we use the squeeze theorem. The number \"c\" is in the interval [\"x\", \"x\" + Δ\"x\"], so \"x\" ≤ \"c\" ≤ \"x\" + Δ\"x\".\n\nAlso, formula_66 and formula_67\n\nTherefore, according to the squeeze theorem,\n\nSubstituting into (3), we get\n\nThe function \"f\" is continuous at \"c\", so the limit can be taken inside the function. Therefore, we get\nwhich completes the proof.\n\nSuppose \"F\" is an antiderivative of \"f\", with \"f\" continuous on Let\n\nBy the \"first part\" of the theorem, we know \"G\" is also an antiderivative of \"f\". Since \"F' - G' = 0\" the mean value theorem implies that \"F - G\" is a constant function, i. e. there is a number \"c\" such that , for all \"x\" in Letting , we have\n\nwhich means In other words, , and so\n\nThis is a limit proof by Riemann sums.\nLet \"f\" be (Riemann) integrable on the interval and let \"f\" admit an antiderivative \"F\" on Begin with the quantity . Let there be numbers \"x\", ..., \"x\"\nsuch that\n\nIt follows that\n\nNow, we add each \"F\"(\"x\") along with its additive inverse, so that the resulting quantity is equal:\n\nThe above quantity can be written as the following sum:\n\nNext, we employ the mean value theorem. Stated briefly,\n\nLet \"F\" be continuous on the closed interval [\"a\", \"b\"] and differentiable on the open interval (\"a\", \"b\"). Then there exists some \"c\" in (\"a\", \"b\") such that\n\nIt follows that\n\nThe function \"F\" is differentiable on the interval therefore, it is also differentiable and continuous on each interval . According to the mean value theorem (above),\n\nSubstituting the above into (1), we get\n\nThe assumption implies formula_82 Also, formula_83 can be expressed as formula_61 of partition formula_85.\n\nWe are describing the area of a rectangle, with the width times the height, and we are adding the areas together. Each rectangle, by virtue of the mean value theorem, describes an approximation of the curve section it is drawn over. Also formula_87 need not be the same for all values of \"i\", or in other words that the width of the rectangles can differ. What we have to do is approximate the curve with \"n\" rectangles. Now, as the size of the partitions get smaller and \"n\" increases, resulting in more partitions to cover the space, we get closer and closer to the actual area of the curve.\n\nBy taking the limit of the expression as the norm of the partitions approaches zero, we arrive at the Riemann integral. We know that this limit exists because \"f\" was assumed to be integrable. That is, we take the limit as the largest of the partitions approaches zero in size, so that all other partitions are smaller and the number of partitions approaches infinity.\n\nSo, we take the limit on both sides of (2). This gives us\n\nNeither \"F\"(\"b\") nor \"F\"(\"a\") is dependent on formula_89, so the limit on the left side remains \n\nThe expression on the right side of the equation defines the integral over \"f\" from \"a\" to \"b\". Therefore, we obtain\n\nwhich completes the proof.\n\nIt almost looks like the first part of the theorem follows directly from the second. That is, suppose \"G\" is an antiderivative of \"f\". Then by the second theorem, formula_92. Now, suppose formula_93. Then \"F\" has the same derivative as \"G\", and therefore . This argument only works, however, if we already know that \"f\" has an antiderivative, and the only way we know that all continuous functions have antiderivatives is by the first part of the Fundamental Theorem.\nFor example, if then \"f\" has an antiderivative, namely\n\nand there is no simpler expression for this function. It is therefore important not to interpret the second part of the theorem as the definition of the integral. Indeed, there are many functions that are integrable but lack elementary antiderivatives, and discontinuous functions can be integrable but lack any antiderivatives at all. Conversely, many functions that have antiderivatives are not Riemann integrable (see Volterra's function).\n\nAs an example, suppose the following is to be calculated:\n\nHere, formula_96 and we can use formula_97 as the antiderivative. Therefore:\n\nOr, more generally, suppose that\n\nis to be calculated. Here, formula_100 and formula_101 can be used as the antiderivative. Therefore:\n\nOr, equivalently,\n\nAs a theoretical example, the theorem can be used to prove that\n\nSince, \n\nthe result follows from, \n\nWe don't need to assume continuity of \"f\" on the whole interval. Part I of the theorem then says: if \"f\" is any Lebesgue integrable function on and \"x\" is a number in such that \"f\" is continuous at \"x\", then\n\nis differentiable for with We can relax the conditions on \"f\" still further and suppose that it is merely locally integrable. In that case, we can conclude that the function \"F\" is differentiable almost everywhere and almost everywhere. On the real line this statement is equivalent to Lebesgue's differentiation theorem. These results remain true for the Henstock–Kurzweil integral, which allows a larger class of integrable functions .\n\nIn higher dimensions Lebesgue's differentiation theorem generalizes the Fundamental theorem of calculus by stating that for almost every \"x\", the average value of a function \"f\" over a ball of radius \"r\" centered at \"x\" tends to \"f\"(\"x\") as \"r\" tends to 0.\n\nPart II of the theorem is true for any Lebesgue integrable function \"f\", which has an antiderivative \"F\" (not all integrable functions do, though). In other words, if a real function \"F\" on admits a derivative \"f\"(\"x\") at \"every\" point \"x\" of and if this derivative \"f\" is Lebesgue integrable on then\n\nThis result may fail for continuous functions \"F\" that admit a derivative \"f\"(\"x\") at almost every point \"x\", as the example of the Cantor function shows. However, if \"F\" is absolutely continuous, it admits a derivative \"F′\"(\"x\") at almost every point \"x\", and moreover \"F′\" is integrable, with equal to the integral of \"F′\" on Conversely, if \"f\" is any integrable function, then \"F\" as given in the first formula will be absolutely continuous with \"F′\" = \"f\" a.e.\n\nThe conditions of this theorem may again be relaxed by considering the integrals involved as Henstock–Kurzweil integrals. Specifically, if a continuous function \"F\"(\"x\") admits a derivative \"f\"(\"x\") at all but countably many points, then \"f\"(\"x\") is Henstock–Kurzweil integrable and is equal to the integral of \"f\" on The difference here is that the integrability of \"f\" does not need to be assumed. \n\nThe version of Taylor's theorem, which expresses the error term as an integral, can be seen as a generalization of the fundamental theorem.\n\nThere is a version of the theorem for complex functions: suppose \"U\" is an open set in C and is a function that has a holomorphic antiderivative \"F\" on \"U\". Then for every curve the curve integral can be computed as\n\nThe fundamental theorem can be generalized to curve and surface integrals in higher dimensions and on manifolds. One such generalization offered by the calculus of moving surfaces is the time evolution of integrals. The most familiar extensions of the fundamental theorem of calculus in higher dimensions are the divergence theorem and the gradient theorem.\n\nOne of the most powerful generalizations in this direction is Stokes' theorem (sometimes known as the fundamental theorem of multivariable calculus): Let \"M\" be an oriented piecewise smooth manifold of dimension \"n\" and let formula_110 be a smooth compactly supported (\"n\"–1)-form on \"M\". If ∂\"M\" denotes the boundary of \"M\" given its induced orientation, then\n\nHere \"d\" is the exterior derivative, which is defined using the manifold structure only.\n\nThe theorem is often used in situations where \"M\" is an embedded oriented submanifold of some bigger manifold (e.g. R\"\") on which the form formula_110 is defined.\n\n\n\n\n"}
{"id": "436802", "url": "https://en.wikipedia.org/wiki?curid=436802", "title": "Fundamental theorem of poker", "text": "Fundamental theorem of poker\n\nThe fundamental theorem of poker is a principle first articulated by David Sklansky that he believes expresses the essential nature of poker as a game of decision-making in the face of incomplete information. \n\nThe fundamental theorem is stated in common language, but its formulation is based on mathematical reasoning. Each decision that is made in poker can be analyzed in terms of the expected value of the payoff of a decision. The correct decision to make in a given situation is the decision that has the largest expected value. If a player could see all of their opponents' cards, they would always be able to calculate the correct decision with mathematical certainty, and the less they deviate from these correct decisions, the better their expected long-term results. This is certainly true heads-up, but Morton's theorem, in which an opponent's correct decision can benefit a player, may apply in multi-way pots. \n\nIn probabilistic terms, this is an application of the law of total expectation.\n\nSuppose Bob is playing limit Texas hold 'em and is dealt 9♣ 9♠ under the gun before the flop. He calls, and everyone else folds to Carol in the big blind who checks. The flop comes A♣ K♦ 10♦, and Carol bets.\n\nBob now has a decision to make based upon incomplete information. In this particular circumstance, the correct decision is almost certainly to fold. There are too many turn and river cards that could kill his hand. Even if Carol does not have an A or a K, there are 3 cards to a straight and 2 cards to a flush on the flop, and she could easily be on a straight or flush draw. Bob is essentially drawing to 2 outs (another 9), and even if he catches one of these outs, his set may not hold up.\n\nHowever, suppose Bob knew (with 100% certainty) that Carol held 8♦ 7♦. In this case, it would be correct to \"raise\". Even though Carol would still be getting the correct pot odds to call, the best decision for Bob is to raise. Therefore, by folding (or even calling), Bob has played his hand differently from the way he would have played it if he could see his opponent's cards, and so by the Fundamental Theorem of Poker, his opponent has gained. Bob has made a \"mistake\", in the sense that he has played differently from the way he would have played if he knew Carol held 8♦ 7♦, even though this \"mistake\" is almost certainly the best decision given the incomplete information available to him.\n\nThis example also illustrates that one of the most important goals in poker is to induce the opponents to make mistakes. In this particular hand, Carol has practiced deception by employing a semi-bluff — she has bet a hand, hoping Bob will fold, but she still has outs even if he calls or raises. Carol has induced Bob to make a mistake.\n\nThe Fundamental Theorem of Poker applies to all heads-up decisions, but it does not apply to all multi-way decisions. This is because each opponent of a player can make an incorrect decision, but the \"collective decision\" of all the opponents works against the player.\n\nThis type of situation occurs mostly in games with multi-way pots, when a player has a strong hand, but several opponents are chasing with draws or other weaker hands. Also, a good example is a player with a deep stack making a play that favors a short-stacked opponent because he can extract more expected value from the other deep-stacked opponents. Such a situation is sometimes referred to as implicit collusion. \n\nThe Fundamental Theorem of Poker is simply expressed and appears axiomatic, yet its proper application to the countless varieties of circumstances that a poker player may face requires a great deal of knowledge, skill, and experience.\n\n"}
{"id": "41052556", "url": "https://en.wikipedia.org/wiki?curid=41052556", "title": "George Bergman", "text": "George Bergman\n\nGeorge Mark Bergman, born on 22 July 1943 in Brooklyn, New York, is an American mathematician. He attended Stuyvesant High School in New York City and received his Ph.D. from Harvard University in 1968, under the direction of John Tate. The year before he had been appointed Assistant Professor of mathematics at the University of California, Berkeley, where he has taught ever since, being promoted to Associate Professor in 1974 and to Professor in 1978.\n\nHis primary research area is algebra, in particular associative rings, universal algebra, category theory and the construction of counterexamples. Mathematical logic is an additional research area. Bergman officially retired in 2009, but is still teaching. His interests beyond mathematics include subjects as diverse as third-party politics and the works of James Joyce.\n\nHe was designated a member of the Inaugural Class of Fellows of the American Mathematical Society in 2013.\n\n\n"}
{"id": "32890980", "url": "https://en.wikipedia.org/wiki?curid=32890980", "title": "Indifference price", "text": "Indifference price\n\nIn finance, indifference pricing is a method of pricing financial securities with regard to a utility function. The indifference price is also known as the reservation price or private valuation. In particular, the indifference price is the price at which an agent would have the same expected utility level by exercising a financial transaction as by not doing so (with optimal trading otherwise). Typically the indifference price is a pricing range (a bid-ask spread) for a specific agent; this price range is an example of good-deal bounds.\n\nGiven a utility function formula_1 and a claim formula_2 with known payoffs at some terminal time formula_3 let the function formula_4 be defined by\nwhere formula_6 is the initial endowment, formula_7 is the set of all self-financing portfolios at time formula_8 starting with endowment formula_6, and formula_10 is the number of the claim to be purchased (or sold). Then the indifference bid price formula_11 for formula_10 units of formula_2 is the solution of formula_14 and the indifference ask price formula_15 is the solution of formula_16. The indifference price bound is the range formula_17.\n\nConsider a market with a risk free asset formula_18 with formula_19 and formula_20, and a risky asset formula_21 with formula_22 and formula_23 each with probability formula_24. Let your utility function be given by formula_25. To find either the bid or ask indifference price for a single European call option with strike 110, first calculate formula_26.\n\nWhich is maximized when formula_29, therefore formula_30.\n\nNow to find the indifference bid price solve for formula_31\n\nWhich is maximized when formula_34, therefore formula_35.\n\nTherefore formula_36 when formula_37.\n\nSimilarly solve for formula_38 to find the indifference ask price.\n\n\n"}
{"id": "537479", "url": "https://en.wikipedia.org/wiki?curid=537479", "title": "Kane quantum computer", "text": "Kane quantum computer\n\nThe Kane quantum computer is a proposal for a scalable quantum computer proposed by Bruce Kane in 1998, who was then at the University of New South Wales. Often thought of as a hybrid between quantum dot and nuclear magnetic resonance (NMR) quantum computers, the Kane computer is based on an array of individual phosphorus donor atoms embedded in a pure silicon lattice. Both the nuclear spins of the donors and the spins of the donor electrons participate in the computation.\n\nUnlike many quantum computation schemes, the Kane quantum computer is in principle scalable to an arbitrary number of qubits. This is possible because qubits may be individually addressed by electrical means.\n\nThe original proposal calls for phosphorus donors to be placed in an array with a spacing of 20 nm, approximately 20 nm below the surface. An insulating oxide layer is grown on top of the silicon. Metal A gates are deposited on the oxide above each donor, and J gates between adjacent donors.\n\nThe phosphorus donors are isotopically pure P, which have a nuclear spin of 1/2. The silicon substrate is isotopically pure Si which has nuclear spin 0. Using the nuclear spin of the P donors as a method to encode qubits has two major advantages. Firstly, the state has an extremely long decoherence time, perhaps on the order of 10 seconds at millikelvin temperatures. Secondly, the qubits may be manipulated by applying an oscillating magnetic field, as in typical NMR proposals. By altering the voltage on the A gates, it should be possible to alter the Larmor frequency of individual donors. This allows them to be addressed individually, by bringing specific donors into resonance with the applied oscillating magnetic field.\n\nNuclear spins alone will not interact significantly with other nuclear spins 20 nm away. Nuclear spin is useful to perform single-qubit operations, but to make a quantum computer, two-qubit operations are also required. This is the role of electron spin in this design. Under A-gate control, the spin is transferred from the nucleus to the donor electron. Then, a potential is applied to the J gate, drawing adjacent donor electrons into a common region, greatly enhancing the interaction between the neighbouring spins. By controlling the J gate voltage, two-qubit operations are possible.\n\nKane's proposal for readout was to apply an electric field to encourage spin-dependent tunneling of an electron to transform two neutral donors to a D–D state, that is, one where two electrons orbit the same donor. The charge excess is then detected using a single-electron transistor. This method has two major difficulties. Firstly, the D state has strong coupling with the environment and hence a short decoherence time. Secondly and perhaps more importantly, it's not clear that the D state has a sufficiently long lifetime to allow for readout—the electron tunnels into the conduction band.\n\nSince Kane's proposal, under the guidance of Robert Clark and now Michelle Simmons, pursuing realisation of the Kane quantum computer has become the primary quantum computing effort in Australia. Theorists have put forward a number of proposals for improved readout. Experimentally, atomic-precision deposition of phosphorus atoms has been demonstrated, using a scanning tunneling microscope (STM) technique. Detection of the movement of single electrons between small, dense clusters of phosphorus donors has also been achieved. The group remains optimistic that a practical large-scale quantum computer can be built. Other groups believe that the idea needs to be modified.\n"}
{"id": "3963004", "url": "https://en.wikipedia.org/wiki?curid=3963004", "title": "Knaster–Kuratowski–Mazurkiewicz lemma", "text": "Knaster–Kuratowski–Mazurkiewicz lemma\n\nThe Knaster–Kuratowski–Mazurkiewicz lemma is a basic result in mathematical fixed-point theory published in 1929 by Knaster, Kuratowski and Mazurkiewicz.\n\nThe KKM lemma can be proved from Sperner's lemma and can be used to prove the Brouwer fixed-point theorem.\n\nLet formula_1 be a formula_2-dimensional simplex with \"n\" vertices labeled as formula_3. \n\nA KKM covering is defined as a set formula_4 of closed sets such that for any formula_5, the convex hull of the vertices corresponding to formula_6 is covered by formula_7. \n\nThe KKM lemma says that a KKM covering has a non-empty intersection, i.e:\n\nThe case formula_9 may serve as an illustration. In this case the simplex formula_10 is a triangle, whose vertices we can label 1, 2 and 3. We are given three closed sets formula_11 such that:\nThe KKM lemma states that the sets formula_21 have at least one point in common.\nThe lemma is illustrated by the picture on the right, in which set #1 is blue, set #2 is red and set #3 is green. The KKM requirements are satisfied, since:\nThe KKM lemma states that there is a point covered by all three colors simultaneously; such a point is clearly visible in the picture.\n\nDavid Gale proved the following generalization of the KKM lemma.\nSuppose that, instead of one KKM covering, we have \"n\" different KKM coverings: formula_22. Then, there exists a permutation formula_23 of the coverings with a non-empty intersection, i.e:\n\nGale wrote about his lemma: \"A colloquial statement of this result is the red, white and blue lemma which asserts that if each of three people paint a triangle red, white and blue according to the KKM rules, then there will be a point which is in the red set of one person, the white set of another, the blue of the third\".\n\nRavindra Bapat provided an alternative proof of this generalization, based on the permutation variant of Sperner's lemma.\n\nNote: the original KKM lemma follows from the permutation lemma by simply picking \"n\" identical coverings.\n\nA connecting set of a simplex is a connected set that touches all \"n\" faces of the simplex. \nA generalized KKM covering is a covering formula_4 in which no formula_26 contains a connecting set. \n\nAny KKM-covering is a generalized-KKM-covering, since in a KKM covering, no formula_26 even touches all \"n\" faces. However, there are generalized-KKM-coverings that are not KKM-coverings. An example is illustrated at the right. There, the red set touches all three faces, but it does not contain any connecting-set, since no connected component of it touches all three faces.\n\nA theorem of Ravindra Bapat, generalizing Sperner's lemma,\nimplies that the KKM lemma is true for generalized KKM coverings (he proved his theorem for formula_9).\n\nThe connecting-set variant also has a permutation variant, so that both these generalizations can be used simultaneously.\n\nThe KKMS theorem is a generalization of the KKM lemma by Lloyd Shapley. It is useful in economics, especially in cooperative game theory.\n\nWhile a KKM covering contains \"n\" sets, a KKMS covering contains formula_29 sets - indexed by the nonempty subsets of formula_30. For any formula_5, the convex hull of the vertices corresponding to formula_6 should be covered by formula_33. \n\nThe KKMS theorem says that for any KKMS covering, there is a \"balanced collection\" formula_34, such that the intersection of sets indexed by formula_34 is nonempty:\n\nIt remains to explain what a \"balanced collection\" is. A collection formula_34 of subsets of formula_30 is called \"balanced\" if, for each subset formula_39, we can select a weight formula_40, such that, for each element formula_41, the sum of weights of all subsets that contain formula_42 is exactly 1. For example, suppose formula_9. Then:\n\nThe KKMS theorem implies the KKM lemma. Suppose we have a KKM covering formula_26, for formula_46. Construct a KKMS covering formula_47 as follows:\nThe KKM condition on the original covering formula_26 implies the KKMS condition on the new covering formula_47. Therefore, there exists a balanced collection such that the corresponding sets in the new covering have nonempty intersection. But the only possible balanced collection is the collection of all singletons; hence, the original covering has nonempty intersection.\n\nThe KKMS theorem has various proofs.\n\nReny and Holtz proved that the balanced set can also be chosen to be \"partnered\".\n\nOleg R. Musin proved several generalizations of the KKM lemma and KKMS theorem, with boundary conditions on the coverings. The boundary conditions are related to homotopy.\n\n"}
{"id": "150144", "url": "https://en.wikipedia.org/wiki?curid=150144", "title": "List of letters used in mathematics and science", "text": "List of letters used in mathematics and science\n\nLatin and Greek letters are used in mathematics, science, engineering, and other areas where mathematical notation is used as symbols for constants, special functions, and also conventionally for variables representing certain quantities. \n\n\n"}
{"id": "3939419", "url": "https://en.wikipedia.org/wiki?curid=3939419", "title": "MDL Chime", "text": "MDL Chime\n\nMDL \"Chime\" is a free plugin used by web browsers to display the three-dimensional structures of molecules. It is part of the ISIS product line acquired by Symyx Technologies from scientific publisher Elsevier in October 2007. It is based on the RasMol code.\n\nChime is used by a wide range of biochemistry web sites for the visualization of macromolecules. Many of these sites are linked to the \"World Index of Molecular Visualization Resources\" MolVisIndex.Org. Chime was also used until 2006 at the Protein Data Bank to examine structures stored there.\n\nAlthough available in 1996 in both Windows 95 and classic Mac OS versions for both Netscape and Internet Explorer browsers, development of Chime did not follow the move to Mac OS X for the Mac and support for Windows-based browsers other than Internet Explorer was limited (although it works well in Mozilla Firefox). One significant feature added in 1997 was the ability to display spectroscopic data in the form of the IUPAC JCAMP-DX protocols. Apart from this, most updates since then were for the installation package to follow the development of Windows and Internet Explorer.\n\nChime largely has been superseded by Jmol, a non-proprietary open-source Java molecular visualization application/applet that has maintained most Chime command compatibility while adding features.\n\nA feature of Chime which is not yet reproduced with Jmol is the calculation of electrostatic or hydrophobic potential for use in coloring molecular surfaces. Instead, Jmol relies on this data being provided by other calculation packages. Chime involves some level of\ncalculation of these properties.\n\nNow Chime is owned by Accelrys, and has been merged to Discovery Studio.\n\n\n"}
{"id": "31859069", "url": "https://en.wikipedia.org/wiki?curid=31859069", "title": "Metric Structures for Riemannian and Non-Riemannian Spaces", "text": "Metric Structures for Riemannian and Non-Riemannian Spaces\n\nMetric Structures for Riemannian and Non-Riemannian Spaces is a book in geometry by Mikhail Gromov. It was originally published in French in 1981 under the title Structures métriques pour les variétés riemanniennes, by CEDIC (Paris). \n\nThe 1981 edition was edited by Jacques Lafontaine and Pierre Pansu. The English version, considerably expanded, was published in 1999 by Birkhäuser Verlag, with appendices by Pierre Pansu, Stephen Semmes, and Mikhail Katz. The book was well received and has been reprinted several times.\n"}
{"id": "20506173", "url": "https://en.wikipedia.org/wiki?curid=20506173", "title": "Model risk", "text": "Model risk\n\nIn finance, model risk is the risk of loss resulting from using insufficiently accurate models to make decisions, originally and frequently in the context of valuing financial securities. However, model risk is more and more prevalent in activities other than financial securities valuation, such as assigning consumer credit scores, real-time probability prediction of fraudulent credit card transactions, and computing the probability of air flight passenger being a terrorist. Rebonato in 2002 defines model risk as \"the risk of occurrence of a significant difference between the mark-to-model value of a complex and/or illiquid instrument, and the price at which the same instrument is revealed to have traded in the market\".\n\nBurke regards failure to use a model (instead over-relying on expert judgment) as a type of model risk. Derman describes various types of model risk that arise from using a model:\n\n\n\n\nVolatility is the most important input in risk management models and pricing models. Uncertainty on volatility leads to model risk. Derman believes that products whose value depends on a volatility smile are most likely to suffer from model risk. He writes \"I would think it's safe to say that there is no area where model risk is more of an issue than in the modeling of the volatility smile.\"\nAvellaneda & Paras (1995) proposed a systematic way of studying and mitigating model risk resulting from volatility uncertainty.\n\nBuraschi and Corielli formalise the concept of 'time inconsistency' with regards to no-arbitrage models that allow for a perfect fit of the term structure of the interest rates. In these models the current yield curve is an input so that new observations on the yield curve can be used to update the model at regular frequencies. They explore the issue of time-consistent and self-financing strategies in this class of models. Model risk affects all the three main steps of risk management: specification, estimation and implementation.\n\nUncertainty on correlation parameters is another important source of model risk. Cont and Deguest propose a method for computing model risk exposures in multi-asset equity derivatives and show that options which depend on the worst or best performances in a basket (so called rainbow option) are more exposed to model uncertainty than index options.\n\nGennheimer investigates the model risk present in pricing basket default derivatives. He prices these derivatives with various copulas and concludes that \"... unless one is very sure about the dependence structure governing the credit basket, any investors willing to trade basket default products should imperatively compute prices under alternative copula specifications and verify the estimation errors of their simulation to know at least the model risks they run\".\n\nComplexity of a model or a financial contract may be a source of model risk, leading to incorrect identification of its risk factors. This factor was cited as a major source of model risk for mortgage backed securities portfolios during the 2007 crisis.\n\nModel risk does not only exist for complex financial contracts. Frey (2000) presents a study of how market illiquidity is a source of model risk. He writes \"Understanding the robustness of models used for hedging and risk-management purposes with respect to the assumption of perfectly liquid markets is therefore an important issue in the analysis of model risk in general.\"\nConvertible bonds, mortgage-backed securities, and high-yield bonds can often be illiquid and difficult to value. Hedge funds that trade these securities can be exposed to model risk when calculating monthly NAV for its investors.\n\nRantala (2006) mentions that \"In the face of model risk, rather than to base decisions on a single selected 'best' model, the modeller can base his inference on an entire set of models by using model averaging.\"\n\nAnother approach to model risk is the worst-case, or minmax approach, advocated in decision theory by Gilboa and Schmeidler.\nIn this approach one considers a range of models and minimizes the loss encountered in the worst-case scenario. This approach to model risk has been developed by Cont (2006).\n\nTo measure the risk induced by a model, it has to be compared to an alternative model, or a set of alternative benchmark models. The problem is how to choose these benchmark models. In the context of derivative pricing Cont (2006) proposes a quantitative approach to measurement of model risk exposures in derivatives portfolios: first, a set of benchmark models is specified and calibrated to market prices of liquid instruments, then the target portfolio is priced under all benchmark models. A measure of exposure to model risk is then given by the difference between the current portfolio valuation and the worst-case valuation under the benchmark models. Such a measure may be used as a way of determining a reserve for model risk for derivatives portfolios.\n\nKato and Yoshiba discuss qualitative and quantitative ways of controlling model risk. They write \"From a quantitative perspective, in the case of pricing models, we can set up a reserve to allow for the difference in estimations using alternative models. In the case of risk measurement models, scenario analysis can be undertaken for various fluctuation patterns of risk factors, or position limits can be established based on information obtained from scenario analysis.\" Cont (2006) advocates the use of model risk exposure for computing such reserves.\n\n\n\n\nTaleb wrote when describing why most new models that attempted to correct the inadequacies of the Black–Scholes model failed to become accepted:\n\n\"Traders are not fooled by the Black–Scholes–Merton model. The existence of a 'volatility surface' is one such adaptation. But they find it preferable to fudge one parameter, namely volatility, and make it a function of time to expiry and strike price, rather than have to precisely estimate another.\"\n\nHowever, Cherubini and Della Lunga describe the disadavantages of parsimony in the context of volatility and correlation modelling. Using an excessive number of parameters may induce overfitting while choosing a severely specified model may easily induce model misspecification and a systematic failure to represent the future distribution.\n\nFender and Kiff (2004) note that holding complex financial instruments, such as CDOs, \"translates into heightened dependence on these assumptions and, thus, higher model risk. As this risk should be expected to be priced by the market, part of the yield pick-up obtained relative to equally rated single obligor instruments is likely to be a direct reflection of model risk.\"\n\n\n\n"}
{"id": "31187897", "url": "https://en.wikipedia.org/wiki?curid=31187897", "title": "Mumford's compactness theorem", "text": "Mumford's compactness theorem\n\nIn mathematics, Mumford's compactness theorem states that the space of compact Riemann surfaces of fixed genus \"g\" > 1 with no closed geodesics of length less than some fixed \"ε\" > 0 in the Poincaré metric is compact. It was proved by as a consequence of a theorem about the compactness of sets of discrete subgroups of semisimple Lie groups generalizing Mahler's compactness theorem.\n"}
{"id": "45337", "url": "https://en.wikipedia.org/wiki?curid=45337", "title": "Nash equilibrium", "text": "Nash equilibrium\n\nIn game theory, the Nash equilibrium, named after the late mathematician John Forbes Nash Jr., is a proposed solution of a non-cooperative game involving two or more players in which each player is assumed to know the equilibrium strategies of the other players, and no player has anything to gain by changing only their own strategy. \n\nIn terms of game theory, if each player has chosen a strategy, and no player can benefit by changing strategies while the other players keep theirs unchanged, then the current set of strategy choices and their corresponding payoffs constitutes a Nash equilibrium.\n\nStated simply, Alice and Bob are in Nash equilibrium if Alice is making the best decision she can, taking into account Bob's decision while Bob's decision remains unchanged, and Bob is making the best decision he can, taking into account Alice's decision while Alice's decision remains unchanged. Likewise, a group of players are in Nash equilibrium if each one is making the best decision possible, taking into account the decisions of the others in the game as long as the other parties' decisions remain unchanged.\n\nNash showed that there is a Nash equilibrium for every finite game: see further the article on strategy.\n\nGame theorists use the Nash equilibrium concept to analyze the outcome of the strategic interaction of several decision makers. In other words, it provides a way of predicting what will happen if several people or several institutions are making decisions at the same time, and if the outcome for each of them depends on the decisions of the others. The simple insight underlying John Nash's idea is that one cannot predict the result of the choices of multiple decision makers if one analyzes those decisions in isolation. Instead, one must ask what each player would do, \"taking into account\" the decision-making of the others.\n\nNash equilibrium has been used to analyze hostile situations like war and arms races (see prisoner's dilemma), and also how conflict may be mitigated by repeated interaction (see tit-for-tat). It has also been used to study to what extent people with different preferences can cooperate (see battle of the sexes), and whether they will take risks to achieve a cooperative outcome (see stag hunt). It has been used to study the adoption of technical standards, and also the occurrence of bank runs and currency crises (see coordination game). Other applications include traffic flow (see Wardrop's principle), how to organize auctions (see auction theory), the outcome of efforts exerted by multiple parties in the education process, regulatory legislation such as environmental regulations (see tragedy of the Commons), natural resource management, analysing strategies in marketing, and even penalty kicks in football (see matching pennies).\n\nThe Nash equilibrium was named after American mathematician John Forbes Nash, Jr. A version of the Nash equilibrium concept was first known to be used in 1838 by Antoine Augustin Cournot in his theory of oligopoly. In Cournot's theory, firms choose how much output to produce to maximize their own profit. However, the best output for one firm depends on the outputs of others. A Cournot equilibrium occurs when each firm's output maximizes its profits given the output of the other firms, which is a pure-strategy Nash equilibrium. Cournot also introduced the concept of best response dynamics in his analysis of the stability of equilibrium. However, Nash's definition of equilibrium is broader than Cournot's. It is also broader than the definition of a Pareto-efficient equilibrium, since the Nash definition makes no judgements about the optimality of the equilibrium being generated.\n\nThe modern game-theoretic concept of Nash equilibrium is instead defined in terms of mixed strategies, where players choose a probability distribution over possible actions. The concept of the mixed-strategy Nash equilibrium was introduced by John von Neumann and Oskar Morgenstern in their 1944 book \"The Theory of Games and Economic Behavior\". However, their analysis was restricted to the special case of zero-sum games. They showed that a mixed-strategy Nash equilibrium will exist for any zero-sum game with a finite set of actions. The contribution of Nash in his 1951 article \"Non-Cooperative Games\" was to define a mixed-strategy Nash equilibrium for any game with a finite set of actions and prove that at least one (mixed-strategy) Nash equilibrium must exist in such a game. The key to Nash's ability to prove existence far more generally than von Neumann lay in his definition of equilibrium. According to Nash, \"an equilibrium point is an n-tuple such that each player's mixed strategy maximizes his payoff if the strategies of the others are held fixed. Thus each player's strategy is optimal against those of the others.\" Just putting the problem in this framework allowed Nash to employ the Kakutani fixed-point theorem in his 1950 paper, and a variant upon it in his 1951 paper used the Brouwer fixed-point theorem to prove that there had to exist at least one mixed strategy profile that mapped back into itself for finite-player (not necessarily zero-sum) games, namely, a strategy profile that did not call for a shift in strategies that could improve payoffs.\n\nSince the development of the Nash equilibrium concept, game theorists have discovered that it makes misleading predictions (or fails to make a unique prediction) in certain circumstances. They have proposed many related solution concepts (also called 'refinements' of Nash equilibria) designed to overcome perceived flaws in the Nash concept. One particularly important issue is that some Nash equilibria may be based on threats that are not 'credible'. In 1965 Reinhard Selten proposed subgame perfect equilibrium as a refinement that eliminates equilibria which depend on non-credible threats. Other extensions of the Nash equilibrium concept have addressed what happens if a game is repeated, or what happens if a game is played in the absence of complete information. However, subsequent refinements and extensions of the Nash equilibrium concept share the main insight on which Nash's concept rests: all equilibrium concepts analyze what choices will be made when each player takes into account the decision-making of others.\n\nInformally, a strategy profile is a Nash equilibrium if no player can do better by unilaterally changing his or her strategy. To see what this means, imagine that each player is told the strategies of the others. Suppose then that each player asks themselves: \"Knowing the strategies of the other players, and treating the strategies of the other players as set in stone, can I benefit by changing my strategy?\"\n\nIf any player could answer \"Yes\", then that set of strategies is not a Nash equilibrium. But if every player prefers not to switch (or is indifferent between switching and not) then the strategy profile is a Nash equilibrium. Thus, each strategy in a Nash equilibrium is a best response to all other strategies in that equilibrium.\n\nThe Nash equilibrium may sometimes appear non-rational in a third-person perspective. This is because a Nash equilibrium is not necessarily Pareto optimal.\n\nThe Nash equilibrium may also have non-rational consequences in sequential games because players may \"threaten\" each other with non-rational moves. For such games the subgame perfect Nash equilibrium may be more meaningful as a tool of analysis.\n\nLet formula_1 be a game with formula_2 players, where formula_3 is the strategy set for player formula_4, formula_5 is the set of strategy profiles and formula_6 is its payoff function evaluated at formula_7. Let formula_8 be a strategy profile of player formula_4 and formula_10 be a strategy profile of all players except for player formula_4. When each player formula_12 chooses strategy formula_8 resulting in strategy profile formula_14 then player formula_4 obtains payoff formula_16. Note that the payoff depends on the strategy profile chosen, i.e., on the strategy chosen by player formula_4 as well as the strategies chosen by all the other players. A strategy profile formula_18 is a Nash equilibrium (NE) if no unilateral deviation in strategy by any single player is profitable for that player, that is\n\nWhen the inequality above holds strictly (with > instead of ≥) for all players and all feasible alternative strategies, then the equilibrium is classified as a \"strict Nash equilibrium\". If instead, for some player, there is exact equality between formula_20 and some other strategy in the set formula_21, then the equilibrium is classified as a \"weak Nash equilibrium\".\n\nA game can have a pure-strategy or a mixed-strategy Nash equilibrium. (In the latter a pure strategy is chosen stochastically with a fixed probability).\n\nNash proves that if we allow mixed strategies, then every game with a finite number of players in which each player can choose from finitely many pure strategies has at least one Nash equilibrium.\n\nNash equilibrium need not exist if the set of choices is infinite and noncompact. An example is when two players simultaneously name a natural number with the player naming the larger number wins. However, Nash equilibrium exists if the set of choices is compact with continuous payoff. An example (with the equilibrium being a mixture of continuously many pure strategies) is if two players simultaneously pick a real number between 0 and 1 (inclusive) with player one winnings (paid by the second player) equaling square root of the distance between the two numbers.\n\nThe \"coordination game\" is a classic (symmetric) two player, two strategy game, with an example payoff matrix shown to the right. The players should thus coordinate, both adopting strategy A, to receive the highest payoff; i.e., 4. If both players chose strategy B though, there is still a Nash equilibrium. Although each player is awarded less than optimal payoff, neither player has incentive to change strategy due to a reduction in the immediate payoff (from 2 to 1).\n\nA famous example of this type of game was called the stag hunt; in the game two players may choose to hunt a stag or a rabbit, the former providing more meat (4 utility units) than the latter (1 utility unit). The caveat is that the stag must be cooperatively hunted, so if one player attempts to hunt the stag, while the other hunts the rabbit, he will fail in hunting (0 utility units), whereas if they both hunt it they will split the payload (2, 2). The game hence exhibits two equilibria at (stag, stag) and (rabbit, rabbit) and hence the players' optimal strategy depend on their expectation on what the other player may do. If one hunter trusts that the other will hunt the stag, they should hunt the stag; however if they suspect that the other will hunt the rabbit, they should hunt the rabbit. This game was used as an analogy for social cooperation, since much of the benefit that people gain in society depends upon people cooperating and implicitly trusting one another to act in a manner corresponding with cooperation.\n\nAnother example of a coordination game is the setting where two technologies are available to two firms with comparable products, and they have to elect a strategy to become the market standard. If both firms agree on the chosen technology, high sales are expected for both firms. If the firms do not agree on the standard technology, few sales result. Both strategies are Nash equilibria of the game.\n\nDriving on a road against an oncoming car, and having to choose either to swerve on the left or to swerve on the right of the road, is also a coordination game. For example, with payoffs 10 meaning no crash and 0 meaning a crash, the coordination game can be defined with the following payoff matrix:\n\nIn this case there are two pure-strategy Nash equilibria, when both choose to either drive on the left or on the right. If we admit mixed strategies (where a pure strategy is chosen at random, subject to some fixed probability), then there are three Nash equilibria for the same case: two we have seen from the pure-strategy form, where the probabilities are (0%,100%) for player one, (0%, 100%) for player two; and (100%, 0%) for player one, (100%, 0%) for player two respectively. We add another where the probabilities for each player are (50%, 50%).\n\nImagine two prisoners held in separate cells, interrogated simultaneously, and offered deals (lighter jail sentences) for betraying their fellow criminal. They can \"cooperate\" (with the other prisoner) by not snitching, or \"defect\" by betraying the other. However, there is a catch; if both players defect, then they both serve a longer sentence than if neither said anything. Lower jail sentences are interpreted as higher payoffs (shown in the table).\n\nThe prisoner's dilemma has a similar matrix as depicted for the coordination game, but the maximum reward for each player (in this case, a minimum loss of 0) is obtained only when the players' decisions are different. Each player improves their own situation by switching from \"cooperating\" to \"defecting\", given knowledge that the other player's best decision is to \"defect\". The prisoner's dilemma thus has a single Nash equilibrium: both players choosing to defect.\n\nWhat has long made this an interesting case to study is the fact that this scenario is globally inferior to \"both cooperating\". That is, both players would be better off if they both chose to \"cooperate\" instead of both choosing to defect. However, each player could improve their own situation by breaking the mutual cooperation, no matter how the other player possibly (or certainly) changes their decision.\n\nAn application of Nash equilibria is in determining the expected flow of traffic in a network. Consider the graph on the right. If we assume that there are \"cars\" traveling from A to D, what is the expected distribution of traffic in the network?\n\nThis situation can be modeled as a \"game\" where every traveler has a choice of 3 strategies, where each strategy is a route from A to D (either , , or ). The \"payoff\" of each strategy is the travel time of each route. In the graph on the right, a car travelling via experiences travel time of , where is the number of cars traveling on edge . Thus, payoffs for any given strategy depend on the choices of the other players, as is usual. However, the goal, in this case, is to minimize travel time, not maximize it. Equilibrium will occur when the time on all paths is exactly the same. When that happens, no single driver has any incentive to switch routes, since it can only add to their travel time. For the graph on the right, if, for example, 100 cars are travelling from A to D, then equilibrium will occur when 25 drivers travel via , 50 via , and 25 via . Every driver now has a total travel time of 3.75 (to see this, note that a total of 75 cars take the edge, and likewise, 75 cars take the edge).\n\nNotice that this distribution is not, actually, socially optimal. If the 100 cars agreed that 50 travel via and the other 50 through , then travel time for any single car would actually be 3.5, which is less than 3.75. This is also the Nash equilibrium if the path between B and C is removed, which means that adding another possible route can decrease the efficiency of the system, a phenomenon known as Braess's paradox.\n\nThis can be illustrated by a two-player game in which both players simultaneously choose an integer from 0 to 3 and they both win the smaller of the two numbers in points. In addition, if one player chooses a larger number than the other, then they have to give up two points to the other.\n\nThis game has a unique pure-strategy Nash equilibrium: both players choosing 0 (highlighted in light red). Any other strategy can be improved by a player switching their number to one less than that of the other player. In the adjacent table, if the game begins at the green square, it is in player 1's interest to move to the purple square and it is in player 2's interest to move to the blue square. Although it would not fit the definition of a competition game, if the game is modified so that the two players win the named amount if they both choose the same number, and otherwise win nothing, then there are 4 Nash equilibria: (0,0), (1,1), (2,2), and (3,3).\n\nThere is an easy numerical way to identify Nash equilibria on a payoff matrix. It is especially helpful in two-person games where players have more than two strategies. In this case formal analysis may become too long. This rule does not apply to the case where mixed (stochastic) strategies are of interest. The rule goes as follows: if the first payoff number, in the payoff pair of the cell, is the maximum of the column of the cell and if the second number is the maximum of the row of the cell - then the cell represents a Nash equilibrium.\n\nWe can apply this rule to a 3×3 matrix:\n\nUsing the rule, we can very quickly (much faster than with formal analysis) see that the Nash equilibria cells are (B,A), (A,B), and (C,C). Indeed, for cell (B,A) 40 is the maximum of the first column and 25 is the maximum of the second row. For (A,B) 25 is the maximum of the second column and 40 is the maximum of the first row. Same for cell (C,C). For other cells, either one or both of the duplet members are not the maximum of the corresponding rows and columns.\n\nThis said, the actual mechanics of finding equilibrium cells is obvious: find the maximum of a column and check if the second member of the pair is the maximum of the row. If these conditions are met, the cell represents a Nash equilibrium. Check all columns this way to find all NE cells. An N×N matrix may have between 0 and N×N pure-strategy Nash equilibria.\n\nThe concept of stability, useful in the analysis of many kinds of equilibria, can also be applied to Nash equilibria.\n\nA Nash equilibrium for a mixed-strategy game is stable if a small change (specifically, an infinitesimal change) in probabilities for one player leads to a situation where two conditions hold:\n\n\nIf these cases are both met, then a player with the small change in their mixed strategy will return immediately to the Nash equilibrium. The equilibrium is said to be stable. If condition one does not hold then the equilibrium is unstable. If only condition one holds then there are likely to be an infinite number of optimal strategies for the player who changed.\n\nIn the \"driving game\" example above there are both stable and unstable equilibria. The equilibria involving mixed strategies with 100% probabilities are stable. If either player changes their probabilities slightly, they will be both at a disadvantage, and their opponent will have no reason to change their strategy in turn. The (50%,50%) equilibrium is unstable. If either player changes their probabilities, then the other player immediately has a better strategy at either (0%, 100%) or (100%, 0%).\n\nStability is crucial in practical applications of Nash equilibria, since the mixed strategy of each player is not perfectly known, but has to be inferred from statistical distribution of their actions in the game. In this case unstable equilibria are very unlikely to arise in practice, since any minute change in the proportions of each strategy seen will lead to a change in strategy and the breakdown of the equilibrium.\n\nThe Nash equilibrium defines stability only in terms of unilateral deviations. In cooperative games such a concept is not convincing enough. Strong Nash equilibrium allows for deviations by every conceivable coalition. Formally, a strong Nash equilibrium is a Nash equilibrium in which no coalition, taking the actions of its complements as given, can cooperatively deviate in a way that benefits all of its members. However, the strong Nash concept is sometimes perceived as too \"strong\" in that the environment allows for unlimited private communication. In fact, strong Nash equilibrium has to be Pareto efficient. As a result of these requirements, strong Nash is too rare to be useful in many branches of game theory. However, in games such as elections with many more players than possible outcomes, it can be more common than a stable equilibrium.\n\nA refined Nash equilibrium known as coalition-proof Nash equilibrium (CPNE) occurs when players cannot do better even if they are allowed to communicate and make \"self-enforcing\" agreement to deviate. Every correlated strategy supported by iterated strict dominance and on the Pareto frontier is a CPNE. Further, it is possible for a game to have a Nash equilibrium that is resilient against coalitions less than a specified size, k. CPNE is related to the theory of the core.\n\nFinally in the eighties, building with great depth on such ideas Mertens-stable equilibria were introduced as a solution concept. Mertens stable equilibria satisfy both forward induction and backward induction. In a game theory context stable equilibria now usually refer to Mertens stable equilibria.\n\nIf a game has a unique Nash equilibrium and is played among players under certain conditions, then the NE strategy set will be adopted. Sufficient conditions to guarantee that the Nash equilibrium is played are:\n\nExamples of game theory problems in which these conditions are not met:\n\nIn his Ph.D. dissertation, John Nash proposed two interpretations of his equilibrium concept, with the objective of showing how equilibrium points \n\nA second interpretation, that Nash referred to by the mass action interpretation, is less demanding on players: \n\nFor a formal result along these lines, see Kuhn, H. and et al., 1996, \"The Work of John Nash in Game Theory,\" \"Journal of Economic Theory\", 69, 153-185.\n\nDue to the limited conditions in which NE can actually be observed, they are rarely treated as a guide to day-to-day behaviour, or observed in practice in human negotiations. However, as a theoretical concept in economics and evolutionary biology, the NE has explanatory power. The payoff in economics is utility (or sometimes money), and in evolutionary biology is gene transmission; both are the fundamental bottom line of survival. Researchers who apply games theory in these fields claim that strategies failing to maximize these for whatever reason will be competed out of the market or environment, which are ascribed the ability to test all strategies. This conclusion is drawn from the \"stability\" theory above. In these situations the assumption that the strategy observed is actually a NE has often been borne out by research.\n\nThe Nash equilibrium is a superset of the subgame perfect Nash equilibrium. The subgame perfect equilibrium in addition to the Nash equilibrium requires that the strategy also is a Nash equilibrium in every subgame of that game. This eliminates all non-credible threats, that is, strategies that contain non-rational moves in order to make the counter-player change their strategy.\n\nThe image to the right shows a simple sequential game that illustrates the issue with subgame imperfect Nash equilibria. In this game player one chooses left(L) or right(R), which is followed by player two being called upon to be kind (K) or unkind (U) to player one, However, player two only stands to gain from being unkind if player one goes left. If player one goes right the rational player two would de facto be kind to him in that subgame. However, The non-credible threat of being unkind at 2(2) is still part of the blue (L, (U,U)) Nash equilibrium. Therefore, if rational behavior can be expected by both parties the subgame perfect Nash equilibrium may be a more meaningful solution concept when such dynamic inconsistencies arise.\n\nNash's original proof (in his thesis) used Brouwer's fixed-point theorem (e.g., see below for a variant). We give a simpler proof via the Kakutani fixed-point theorem, following Nash's 1950 paper (he credits David Gale with the observation that such a simplification is possible).\n\nTo prove the existence of a Nash equilibrium, let formula_22 be the best response of player i to the strategies of all other players.\n\nHere, formula_24, where formula_25, is a mixed-strategy profile in the set of all mixed strategies and formula_26 is the payoff function for player i. Define a set-valued function formula_27 such that formula_28. The existence of a Nash equilibrium is equivalent to formula_29 having a fixed point.\n\nKakutani's fixed point theorem guarantees the existence of a fixed point if the following four conditions are satisfied.\n\nCondition 1. is satisfied from the fact that formula_34 is a simplex and thus compact. Convexity follows from players' ability to mix strategies. formula_34 is nonempty as long as players have strategies.\n\nCondition 2. and 3. are satisfied by way of Berge's maximum theorem. Because formula_26 is continuous and compact, formula_37 is non-empty and upper hemicontinuous.\n\nCondition 4. is satisfied as a result of mixed strategies. Suppose formula_38, then formula_39. i.e. if two strategies maximize payoffs, then a mix between the two strategies will yield the same payoff.\n\nTherefore, there exists a fixed point in formula_40 and a Nash equilibrium.\n\nWhen Nash made this point to John von Neumann in 1949, von Neumann famously dismissed it with the words, \"That's trivial, you know. That's just a fixed-point theorem.\" (See Nasar, 1998, p. 94.)\n\nWe have a game formula_41 where formula_42 is the number of players and formula_43 is the action set for the players. All of the action sets formula_44 are finite. Let formula_45 denote the set of mixed strategies for the players. The finiteness of the formula_44s ensures the compactness of formula_47.\n\nWe can now define the gain functions. For a mixed strategy formula_48, we let the gain for player formula_4 on action formula_50 be\n\nThe gain function represents the benefit a player gets by unilaterally changing their strategy. We now define formula_52 where\n\nfor formula_54. We see that\n\nNext we define:\n\nIt is easy to see that each formula_57 is a valid mixed strategy in formula_58. It is also easy to check that each formula_57 is a continuous function of formula_60, and hence formula_61 is a continuous function. As the cross product of a finite number of compact convex sets, formula_47 is also compact and convex. Applying the Brouwer fixed point theorem to formula_61 and formula_47 we conclude that So formula_61 has a fixed point in formula_47, call it formula_67. We claim that formula_67 is a Nash equilibrium in formula_69. For this purpose, it suffices to show that\n\nThis simply states that each player gains no benefit by unilaterally changing their strategy, which is exactly the necessary condition for a Nash equilibrium.\n\nNow assume that the gains are not all zero. Therefore, formula_71 and formula_50 such that formula_73. Note then that\n\nSo let\n\nAlso we shall denote formula_76 as the gain vector indexed by actions in formula_44. Since formula_67 is the fixed point we have:\n\nSince formula_80 we have that formula_81 is some positive scaling of the vector formula_82. Now we claim that\n\nTo see this, we first note that if formula_73 then this is true by definition of the gain function. Now assume that formula_85. By our previous statements we have that\n\nand so the left term is zero, giving us that the entire expression is formula_87 as needed.\n\nSo we finally have that\n\nwhere the last inequality follows since formula_81 is a non-zero vector. But this is a clear contradiction, so all the gains must indeed be zero. Therefore, formula_67 is a Nash equilibrium for formula_69 as needed.\n\nIf a player A has a dominant strategy formula_92 then there exists a Nash equilibrium in which A plays formula_92. In the case of two players A and B, there exists a Nash equilibrium in which A plays formula_92 and B plays a best response to formula_92. If formula_92 is a strictly dominant strategy, A plays formula_92 in all Nash equilibria. If both A and B have strictly dominant strategies, there exists a unique Nash equilibrium in which each plays their strictly dominant strategy.\n\nIn games with mixed-strategy Nash equilibria, the probability of a player choosing any particular strategy can be computed by assigning a variable to each strategy that represents a fixed probability for choosing that strategy. In order for a player to be willing to randomize, their expected payoff for each strategy should be the same. In addition, the sum of the probabilities for each strategy of a particular player should be 1. This creates a system of equations from which the probabilities of choosing each strategy can be derived.\n\nIn the matching pennies game, player A loses a point to B if A and B play the same strategy and wins a point from B if they play different strategies. To compute the mixed-strategy Nash equilibrium, assign A the probability \"p\" of playing H and (1−\"p\") of playing T, and assign B the probability \"q\" of playing H and (1−\"q\") of playing T.\n\nThus a mixed-strategy Nash equilibrium, in this game, is for each player to randomly choose H or T with p = 1/2 and q = 1/2.\n\n\n"}
{"id": "1529485", "url": "https://en.wikipedia.org/wiki?curid=1529485", "title": "Neighbourhood (mathematics)", "text": "Neighbourhood (mathematics)\n\nIn topology and related areas of mathematics, a neighbourhood (or neighborhood) is one of the basic concepts in a topological space. It is closely related to the concepts of open set and interior. Intuitively speaking, a neighbourhood of a point is a set of points containing that point where one can move some amount in any direction away from that point without leaving the set.\n\nIf formula_1 is a topological space and formula_2 is a point in formula_1, a neighbourhood of formula_2 is a subset formula_5 of formula_1 that includes an open set formula_7 containing formula_2,\n\nThis is also equivalent to formula_10 being in the interior of formula_5.\n\nNote that the neighbourhood formula_5 need not be an open set itself. If formula_5 is open it is called an . Some mathematicians require that neighbourhoods be open, so it is important to note conventions.\nA set that is a neighbourhood of each of its points is open since it can be expressed as the union of open sets containing each of its points. A rectangle, as illustrated in the figure, is not a neighbourhood of all its points; points on the edges or corners of the rectangle are not contained in any open set that is contained within the rectangle.\n\nThe collection of all neighbourhoods of a point is called the neighbourhood system at the point.\n\nIf formula_14 is a subset of topological space formula_1 then a neighbourhood of formula_14 is a set formula_5 that includes an open set formula_7 containing formula_14. It follows that a set formula_5 is a neighbourhood of formula_14 if and only if it is a neighbourhood of all the points in formula_14. Furthermore, it follows that formula_5 is a neighbourhood of formula_14 iff formula_14 is a subset of the interior of formula_5. The neighbourhood of a point is just a special case of this definition.\n\nIn a metric space formula_27, a set formula_5 is a neighbourhood of a point formula_2 if there exists an open ball with centre formula_2 and radius formula_31, such that\nis contained in formula_5.\n\nformula_5 is called uniform neighbourhood of a set formula_14 if there exists a positive number formula_36 such that for all elements formula_2 of formula_14,\nis contained in formula_5.\n\nFor formula_41 the formula_36-neighbourhood formula_43 of a set formula_14 is the set of all points in formula_1 that are at distance less than formula_36 from formula_14 (or equivalently, formula_14 is the union of all the open balls of radius formula_36 that are centred at a point in formula_14): formula_51\n\nIt directly follows that an formula_36-neighbourhood is a uniform neighbourhood, and that a set is a uniform neighbourhood if and only if it contains an formula_36-neighbourhood for some value of formula_36.\n\nGiven the set of real numbers formula_55 with the usual Euclidean metric and a subset formula_5 defined as\nthen formula_5 is a neighbourhood for the set formula_59 of natural numbers, but is \"not\" a uniform neighbourhood of this set.\n\nThe above definition is useful if the notion of open set is already defined. There is an alternative way to define a topology, by first defining the neighbourhood system, and then open sets as those sets containing a neighbourhood of each of their points.\n\nA neighbourhood system on formula_1 is the assignment of a filter formula_61 (on the set formula_1) to each formula_63 in formula_1, such that\n\nOne can show that both definitions are compatible, i.e. the topology obtained from the neighbourhood system defined using open sets is the original one, and vice versa when starting out from a neighbourhood system.\n\nIn a uniform space formula_76, formula_5 is called a uniform neighbourhood of formula_78 if formula_78 is not close to formula_80, that is there exists no entourage containing formula_78 and formula_80.\n\nA deleted neighbourhood of a point formula_2 (sometimes called a punctured neighbourhood) is a neighbourhood of formula_2, without formula_85. For instance, the interval formula_86 is a neighbourhood of formula_87 in the real line, so the set formula_88 is a deleted neighbourhood of formula_89. Note that a deleted neighbourhood of a given point is not in fact a neighbourhood of the point. The concept of deleted neighbourhood occurs in the definition of the limit of a function.\n\n\n"}
{"id": "46681630", "url": "https://en.wikipedia.org/wiki?curid=46681630", "title": "Ordered set operators", "text": "Ordered set operators\n\nIn mathematical notation, ordered set operators indicate whether an object precedes or succeeds another. These relationship operators are denoted by the unicode symbols U+227A-F, along with symbols located unicode blocks U+228x through U+22Ex.\n\n\n"}
{"id": "48441511", "url": "https://en.wikipedia.org/wiki?curid=48441511", "title": "Overlapping circles grid", "text": "Overlapping circles grid\n\nAn overlapping circles grid is a geometric pattern of repeating, overlapping circles of equal radii in two-dimensional space. Commonly, designs are based on circles centered on triangles (with the simple, two circle form named \"vesica piscis\") or on the square lattice pattern of points.\n\nPatterns of seven overlapping circles appear in historical artefacts from the 7th century BC onwards; they become a frequently used ornament in the Roman Empire period, and survive into medieval artistic traditions both in Islamic art (girih decorations) and in Gothic art. The name \"Flower of Life\" is given to the overlapping circles pattern in New Age publications. \n\nOf special interest is the six petal rosette derived from the \"seven overlapping circles\" pattern, also known as \"Sun of the Alps\" from its frequent use in alpine folk art in the 17th and 18th century.\n\nThe triangular lattice form, with circle radii equal to their separation is called a seven overlapping circles grid. It contains 6 circles intersecting at a point, with a 7th circle centered on that intersection.\n\nOverlapping circles with similar geometrical constructions have been used infrequently in various of the decorative arts since ancient times. The pattern has found a wide range of usage in popular culture, in fashion, jewelry, tattoos and decorative products.\n\nThe oldest known occurrence of the \"overlapping circles\" pattern is dated to the 7th or 6th century BCE, \nfound on the threshold of the palace of Assyrian king Aššur-bāni-apli in Dur Šarrukin (now in the Louvre).\n\nThe design becomes more widespread in the early centuries of the Common Era.\nOne early example are five patterns of 19 overlapping circles drawn on the granite columns at the Temple of Osiris in Abydos, Egypt, and a further five on column opposite the building. They are drawn in red ochre and some are very faint and difficult to distinguish.\nThe patterns are graffiti, and not found in natively Egyptian ornaments. They are mostly dated to the early centuries of the Christian Era \nalthough medieval or even modern (early 20th century) origin cannot be ruled out with certainty, as the drawings are not mentioned in the extensive listings of graffiti at the temple compiled by Margaret Murray in 1904. \n\nSimilar patterns were sometimes used in England as apotropaic marks to keep witches from entering buildings. Consecration crosses indicating points in churches anointed with holy water during a churches dedication also take the form of overlapping circles. \n\nIn Islamic art, the pattern is one of several arrangements of circles (others being used for fourfold or fivefold designs) used to construct grids for Islamic geometric patterns. It is used to design patterns with 6- and 12-pointed stars as well as hexagons in the style called girih. The resulting patterns however characteristically conceal the construction grid, presenting instead a design of interlaced strapwork.\n\nPatterns of seven overlapping circles are found on a Cypro-Archaic I cup of the 8th-7th century BC in Cyprus and Roman mosaics, for example at Herod's palace in the 1st century BC. \nThey are also found in the Hindu temple at Prambanan in Java.\nThe design is found on one of the silver plaques of the Late Roman hoard of Kaiseraugst (discovered 1961).\nIt is later found as an ornament in Gothic architecture, and still later in European folk art of the early modern period. \n\nHigh medieval examples include the Cosmati pavements in Westminster Abbey (13th century).\nLeonardo da Vinci explicitly discussed the mathematical proportions of the design.\n\nThe name \"Flower of Life\" is modern, associated with the New Age movement, and commonly attributed specifically to Drunvalo Melchizedek in his book \"The Ancient Secret of the Flower of Life\" (1999).\n\nThe pattern and modern name have propagated into wide range of usage in popular culture, in fashion, jewelry, tattoos and decorative products.\nThe pattern in quilting has been called diamond wedding ring or \"triangle wedding ring\" to contrast it from the square pattern.\nBesides an occasional use in fashion, it is also used in the decorative arts. For example, the album \"Sempiternal\" (2013) by Bring Me the Horizon uses the 61 overlapping circles grid as the main feature of its album cover, whereas the album \"A Head Full of Dreams\" (2015) by Coldplay features the 19 overlapping circles grid as the central part of its album cover. Teaser posters illustrating the cover art to \"A Head Full of Dreams\" were widely displayed on the London Underground in the last week of October 2015.\n\nThe \"Sun of the Alps\" (Italian \"Sole delle Alpi\") symbol has been used as the emblem of Padanian nationalism in northern Italy since the 1990s. It resembles a pattern often found in that area on buildings. \n\nIn the examples below the pattern has a hexagonal outline, and is further circumscribed.\n\n\nIn the examples below the pattern does not have a hexagonal outline.\n\nMartha Bartfeld, author of geometric art tutorial books, described her independent discovery of the design in 1968. Her original definition said, \"This design consists of circles having a 1-[inch] radius, with each point of intersection serving as a new center. The design can be expanded \"ad infinitum\" depending upon the number of times the odd-numbered points are marked off.\" \n\nThe pattern figure can be drawn by pen and compass, by creating multiple series of interlinking circles of the same diameter touching the previous circle's center. The second circle is centered at any point on the first circle. All following circles are centered on the intersection of two other circles.\n\nThe pattern can be extended outwards in concentric hexagonal rings of circles, as shown. The first row shows rings of circles. The second row shows a three-dimensional interpretation of a set of \"n\"×\"n\"×\"n\" cube of spheres viewed from a diagonal axis. The third row shows the pattern completed with partial circle arcs within a set of completed circles.\n\nExpanding sets have 1, 7, 19, 37, 61, 91, 127, etc. circles, and continuing ever larger hexagonal rings of circles. The number of circles is \"n\"-(\"n\"-1) = 3\"n\"-3\"n\"+1 = 3\"n\"(\"n\"-1)+1.\n\nThese overlapping circles can also be seen as a projection of an \"n\"-unit cube of spheres in 3-dimensional space, viewed on the diagonal axis. There are more spheres than circles because some are overlapping in 2 dimensions.\n\nAnother triangular lattice form is common, with circle separation as the square root of 3 times their radii. Richard Kershner showed in 1939 that no arrangement of circles can cover the plane more efficiently than this hexagonal lattice arrangement.\n\nTwo offset copies of this circle pattern makes a rhombic tiling pattern, while three copies make the original triangular pattern. \n\nThe center lens of the 2-circle figure is called a Vesica piscis, from Euclid. Two circles are also called Villarceau circles as a plane intersection of a torus. The areas inside one circle and outside the other circle is called a lune.\n\nThe 3-circle figure resembles a depiction of borromean rings and is used in 3-set theory Venn diagrams. Its interior makes a unicursal path called a triquetra. The center of the 3-circle figure is called a reuleaux triangle.\n\nSome spherical polyhedra with edges along great circles can be stereographically projected onto the plane as overlapping circles. \nThe 7-circle pattern has also been called an \"Islamic seven-circles pattern\" for its use in Islamic art.\n\nThe square lattice form can be seen with circles that line up horizontally and vertically, while intersecting on their diagonals. The pattern appears slightly different when rotated on its diagonal, also called a \"centered square lattice\" form because it can be seen as two square lattices with each centered on the gaps of the other.\n\nIt is called a Kawung motif in Indonesian batik, and is found on the walls of the 8th century Hindu temple Prambanan in Java.\n\nIt is called a Apsamikkum from ancient Mesopotamian mathematics.\n\n"}
{"id": "47882601", "url": "https://en.wikipedia.org/wiki?curid=47882601", "title": "Patrice Ossona de Mendez", "text": "Patrice Ossona de Mendez\n\nPatrice Ossona de Mendez is a French mathematician specializing in topological graph theory who works as a researcher at the Centre national de la recherche scientifique in Paris. With Pierre Rosenstiehl, he is editor-in-chief of the \"European Journal of Combinatorics\", a position he has held since 2009.\n\nOssona de Mendez was born December 13, 1966, in Paris. He represented France in the International Mathematical Olympiad in 1985, earning a bronze medal there. He studied at the École Normale Supérieure from 1986 until 1990, and completed his Ph.D. in 1994 from the School for Advanced Studies in the Social Sciences. His dissertation, jointly supervised by Rosenstiehl and Hubert de Fraysseix, concerned bipolar orientations of graphs. He has worked at CNRS since 1995, and earned a habilitation in 2009 from the University of Bordeaux 1.\n\nWith Jaroslav Nešetřil he is the author of the book \"Sparsity: Graphs, Structures, and Algorithms\" (Algorithms and Combinatorics 28, Springer, 2012), concerning the properties and applications of different types of sparse graph. This book was included in ACM Computing Reviews\nlist of \"Notable Books and Articles of 2012\".\n\n\n"}
{"id": "37151609", "url": "https://en.wikipedia.org/wiki?curid=37151609", "title": "Pi in the Sky", "text": "Pi in the Sky\n\nPi in the Sky was an experimental, aerial art display where airplanes spelled out pi to decimal 1,000 places in the sky over the San Francisco Bay Area. The display took place on September 12, 2012. It was then displayed again in Austin on March 13, 2014, during the SXSW festival, at which time it was said to be the largest art piece ever displayed in the state of Texas.\n\nThe numbers, each high, were created by a group of five skywriting airplaines, and appeared as a dot matrix. The string of numbers was produced in a large loop in circumference, at an altitude of approximately .\n\nThe aircraft used were 1979 Grumman AA-5B Tigers, small, single-engined planes provided by the company AirSign Aerial Advertising, based in Williston, FL. The numbers were produced by spraying natural, burnt-off canola oil, which dissipated, causing no environmental damage.\n\nThe exhibition began in the skies over San Jose, then continued over Fremont, Hayward, Oakland, Berkeley, San Francisco, San Bruno, San Mateo, Redwood City, Palo Alto, and Mountain View. The planes deliberately flew over the headquarters of NASA Ames, Lawrence Livermore National Laboratory, University of California at Berkeley, Stanford University, Google, Facebook, Twitter, and Apple.\n\nThe 2012 display was part of the 2012 ZERO1 Biennial, was conceived by artist ISHKY, and involved a company called Stamen Design. ZERO1 is an art-technology network based in San Jose. The display was intended to draw attention to their biennial showcase for art and technology.\n\nThe 2014 display was part of an ongoing project, directed by artist ISHKY (Ben Davis), and again involved AirSign Aerial Advertising. The 2014 display quickly gained publicity making it the number 2 top trending hashtag on Twitter during the display and within 24 hours it was shared and viewed a little over six million times.\n\n\n"}
{"id": "54053583", "url": "https://en.wikipedia.org/wiki?curid=54053583", "title": "Quantum economics", "text": "Quantum economics\n\nQuantum economics is an emerging research field which applies methods and ideas from quantum physics to the field of economics. It is motivated by the belief that economic processes such as financial transactions have much in common with quantum processes. It draws on techniques from the related areas of quantum finance and quantum cognition, and can be viewed as a sub-field of what Alexander Wendt and others have called \"quantum social science\".\n\nAn early proponent of this approach was the Pakistani mathematician Asghar Qadir. In his 1978 paper \"Quantum Economics\", he argued that the formalism of quantum mechanics is the best mathematical framework for modeling situations where \"consumer behavior depends on infinitely many factors and that the consumer is not aware of any preference until the matter is brought up.\" He proposed that, like particles in quantum mechanics, \"the individual as an entity ... can be thought of as a point in a Hilbert space.\"\n\nQadir's paper received little attention. However, during the 1990s, workers in the field of quantum cognition indeed showed that many aspects of human decision-making, including those involved in economic decisions, seemed to follow a kind of quantum logic. At the same time, researchers such as economist Martin Shubik, physicist Martin Schaden and social scientist Emmanuel Haven were beginning to use the quantum formalism to model the uncertainty of stock markets.\n\nIn his 2007 book \"Quantum Finance: Path Integrals and Hamiltonians for Options and Interest Rates\", Belal E. Baaquie showed how methods from quantum physics could be applied to things like the pricing of financial options. However he wrote that the ‘’larger question of applying the formalism and insights of (quantum) physics to economics, and which forms a part of the larger subject of econophysics, is left for future research.’’\n\nIn their 2013 book \"Quantum Social Science\", Emmanuel Haven and Andrei Khrennikov extended Baaquie’s work in finance, and showed how quantum techniques could be used to model a number of issues in economics more broadly, such as arbitrage and the reflexivity theory of George Soros.\n\nIn a 2016 paper and book (the latter co-authored with journalist Roman Chlupatý), the mathematician David Orrell proposed a quantum theory of money and value, which states that money has dualistic, quantum properties because of the way that it merges the exact concept of number with the fuzzy concept of value. His 2018 book \"Quantum Economics: The New Science of Money\" described a quantum economics which combined this view of money with the insights of quantum finance and quantum social science.\n\nJust as quantum physics differs in fundamental ways from classical physics, quantum economics differs from neoclassical economics in a number of key respects.\n\nNeoclassical economics is based on expected utility theory, which combines utility theory to model people’s preferences, and probability theory to model expectations under uncertainty. However the field of quantum cognition calls these assumptions into question, since people don’t necessarily have fixed preferences, or base their decisions on probability theory. Many of the findings of behavioral economics are inconsistent with classical logic, but agree with quantum decision theory of the sort assumed in quantum economics.\n\nIn financial applications, neoclassical economics is associated with the efficient market theory. As Haven and Khrennikov show, this condition has come under increasing question since the financial crisis, but can easily be relaxed using a quantum formalism.\n\nNeoclassical economics assumes that people act independently while making economic decisions. Quantum economics notes that financial actors are part of an entangled system, as in quantum game theory.\n\nQuantum economics also stresses the importance of financial transactions and in particular the role of money as an active force in the economy, for example in the way that it binds debtors and creditors. Quantum economics can therefore be viewed as an alternative to neoclassical economics which begins from a different set of assumptions.\n"}
{"id": "41129282", "url": "https://en.wikipedia.org/wiki?curid=41129282", "title": "Quantum illumination", "text": "Quantum illumination\n\nQuantum illumination is a paradigm that uses quantum entanglement beneficially even if the original entanglement is completely destroyed by a lossy and noisy environment.\n\nMany quantum information applications, such as quantum teleportation, quantum error correction, and superdense coding, rely on entanglement. However, entanglement is a fragile quantum property between particles and can be easily destroyed by loss and noise arising from interaction with the environment, leading to quantum decoherence. Entanglement is therefore considered very hard to use in lossy and noisy environment.\n\nLloyd, Shapiro and collaborators showed that even though entanglement itself may not survive, the residual correlation between the two initially entangled systems remains much higher than any initial classical states can provide. This implies that the use of entanglement should not be dismissed in entanglement-breaking scenarios.\n\nQuantum illumination takes advantage of this stronger-than-classical residual correlations between two systems to achieve a performance enhancement over all schemes based on transmitting classical states with comparable power levels. Quantum illumination is particularly useful in extremely lossy and noisy situations.\n\nThe concept of quantum illumination was first introduced by Seth Lloyd and collaborators at MIT in 2008. An experimentally feasible scheme for quantum illumination can be realized using Gaussian states as demonstrated by Jeffrey Shapiro and collaborators from the same institute. \n\nThe basic setup of quantum illumination is target detection. Here the sender prepares two entangled systems, called signal and idler. The idler is retained while the signal is sent to probe the presence of a low-reflectivity object in a region with bright background noise. The reflection from the object is then combined with the retained idler system in a joint quantum measurement providing two possible outcomes: object present or object absent. More precisely, the probing process is repeated many times so that many pairs of signal-idler systems are collected at the receiver for the joint quantum detection.\nThe advantage of the scheme is evident at low energies where the mean number of photons in each signal system is very low (of the order of one photon or less). In this case, at fixed low energy, the probability of success in detecting a target has a remarkable improvement with respect to classical detection schemes, where entanglement is not used and signal systems are prepared in coherent states (technically, there is a 6dB improvement in the error exponent ). A key feature of quantum illumination is that the entanglement between the idler system and the reflected signal system is completely lost in the process. However, the residual quantum correlations between these two systems (idler-reflected signal) remain so strong that they could only be created by the presence of entanglement in the initial systems (idler-signal). Because the reflected signal is quantum-correlated with the retained idler system, it can be distinguished among all the uncorrelated background thermal photons that are also received by the detector. Because of this quantum labeling of the systems, the detection of quantum illumination is very efficient. \nIn 2009, a secure communication scheme based on quantum illumination was proposed. This scheme is a variant of the quantum cryptographic protocols based on continuous variables and two-way quantum communication introduced by Stefano Pirandola, Seth Lloyd and collaborators in 2008. In 2015, an international collaboration coordinated by Stefano Pirandola extended the protocol of quantum illumination to the microwave frequencies, thus providing the first theoretical prototype of quantum radar. In 2017, the optimum receiver design was proposed by Quntao Zhuang, Zheshen Zhang, and Jeffrey Shapiro. Quantum illumination has also been extended to the scenario of target fading.\n\nIn 2013, Lopaeva \"et al.\" exploited photon number correlations, instead of entanglement, in a sub-optimal target detection experiment. To illustrate the benefit of quantum entanglement, in 2013 Zhang \"et al.\" reported a secure communication experiment based on quantum illumination and demonstrated for the first time that entanglement can enable a substantial performance advantage in the presence of quantum decoherence. In 2015, Zhang \"et al.\" applied quantum illumination in sensing and showed that employing entanglement can yield a higher signal-to-noise ratio than the optimal classical scheme can provide, even though the highly lossy and noisy environment completely destroys the initial entanglement. This sensing experiment thus proved the original theoretical proposals of quantum illumination.\n\nPotential applications of quantum illumination include target detection in high background noise environments, but also ultra-sensitive biological imaging and sensing, and secure communication.\n"}
{"id": "35993491", "url": "https://en.wikipedia.org/wiki?curid=35993491", "title": "Rademacher system", "text": "Rademacher system\n\nIn mathematics, in particular in functional analysis, the Rademacher system, named after Hans Rademacher, is an incomplete orthogonal system of functions on the unit interval of the following form:\n\nThe Rademacher system is stochastically independent, and is closely related to the Walsh system. Specifically, the Walsh system can be constructed as a product of Rademacher functions. \n\n"}
{"id": "27997978", "url": "https://en.wikipedia.org/wiki?curid=27997978", "title": "Random-access Turing machine", "text": "Random-access Turing machine\n\nIn computational complexity, a field of computer science, random-access Turing machines are an extension of Turing machines used to speak about small complexity classes, especially for classes using logarithmic time, like DLOGTIME and the Logarithmic Hierarchy.\n\nOn a random-access Turing machine, there is a special \"pointer\" tape of logarithmic space accepting a binary vocabulary. The Turing machine has a special state such that when the binary number on the \"pointer\" tape is 'p', the Turing machine will write on the working tape the \"p\"th symbol of the input.\n\nThis lets the Turing machine read any letter of the input without taking time to move over the entire input. This is mandatory for complexity classes using less than linear time.\n\n"}
{"id": "2686481", "url": "https://en.wikipedia.org/wiki?curid=2686481", "title": "Ring of sets", "text": "Ring of sets\n\nIn mathematics, there are two different notions of a ring of sets, both referring to certain families of sets.\n\nIn order theory, a nonempty family of sets formula_1 is called a ring (of sets) if it is closed under union and intersection. That is, the following two statements are true for all sets formula_2 and formula_3,\n\nIn measure theory, a nonempty family of sets formula_1 is called a ring (of sets) if it is closed under union and relative complement (set-theoretic difference). That is, the following two statements are true for all sets formula_2 and formula_3,\nThis implies that a ring in the measure-theoretic sense always contains the empty set. Furthermore, for all sets formula_2 and formula_3,\nwhich shows that a family of sets closed under relative complement is also closed under intersection, so that a ring in the measure-theoretic sense is also a ring in the order-theoretic sense.\n\nIf \"X\" is any set, then the power set of \"X\" (the family of all subsets of \"X\") forms a ring of sets in either sense.\n\nIf (\"X\",≤) is a partially ordered set, then its upper sets (the subsets of \"X\" with the additional property that if \"x\" belongs to an upper set \"U\" and \"x\" ≤ \"y\", then \"y\" must also belong to \"U\") are closed under both intersections and unions. However, in general it will not be closed under differences of sets.\n\nThe open sets and closed sets of any topological space are closed under both unions and intersections.\n\nOn the real line R, the family of sets consisting of the empty set and all finite unions of intervals of the form <nowiki>(</nowiki>\"a\", \"b\"<nowiki>]</nowiki>, \"a\",\"b\" in R is a ring in the measure-theoretic sense. \n\nIf \"T\" is any transformation defined on a space, then the sets that are mapped into themselves by \"T\" are closed under both unions and intersections.\n\nIf two rings of sets are both defined on the same elements, then the sets that belong to both rings themselves form a ring of sets.\n\nA ring of sets in the order-theoretic sense forms a distributive lattice in which the intersection and union operations correspond to the lattice's meet and join operations, respectively. Conversely, every distributive lattice is isomorphic to a ring of sets; in the case of finite distributive lattices, this is Birkhoff's representation theorem and the sets may be taken as the lower sets of a partially ordered set. \n\nA family of sets closed under union and relative complement is also closed under symmetric difference and intersection. Conversely, every family of sets closed under both symmetric difference and intersection is also closed under union and relative complement. This is due to the identities\nSymmetric difference and intersection together give a ring in the measure-theoretic sense the structure of a boolean ring.\n\nA field of subsets of \"X\" is a ring that contains \"X\" and is closed under relative complement. Every field, and so also every σ-algebra, is a ring of sets in the measure theory sense.\n\nA semi-ring (of sets) is a family of sets formula_20 with the properties\nClearly, every ring (in the measure theory sense) is a semi-ring.\nA semi-field of subsets of \"X\" is a semi-ring that contains \"X\".\n\n"}
{"id": "49221628", "url": "https://en.wikipedia.org/wiki?curid=49221628", "title": "SIAM Journal on Applied Mathematics", "text": "SIAM Journal on Applied Mathematics\n\nThe SIAM Journal on Applied Mathematics is a peer-reviewed academic journal in applied mathematics published by the Society for Industrial and Applied Mathematics (SIAM), with Paul A. Martin as its editor-in-chief. It was founded in 1953 as SIAM's first journal, the \"Journal of the Society for Industrial and Applied Mathematics\", and was given its current name in 1966. In most years since 1999, it has been ranked by SCImago Journal Rank as a second-quartile journal in applied mathematics. Together with \"Communications on Pure and Applied Mathematics\" it has been called \"one of the two greatest American entries in applied math\".\n"}
{"id": "22087585", "url": "https://en.wikipedia.org/wiki?curid=22087585", "title": "Sethi model", "text": "Sethi model\n\nThe Sethi model was developed by Suresh P. Sethi and describes the process of how sales evolve over time in response to advertising. The rate of change in sales depend on three effects: response to advertising that acts positively on the unsold portion of the market, the loss due to forgetting or possibly due to competitive factors that act negatively on the sold portion of the market, and a random effect that can go either way.\n\nSuresh Sethi published his paper \"Deterministic and Stochastic Optimization of a Dynamic Advertising Model\" in 1983. The Sethi model is a modification as well as a stochastic extension of the Vidale-Wolfe advertising model. The model and its competitive extensions have been used extensively in the literature. Moreover, some of these extensions have been also tested empirically.\n\nThe Sethi advertising model or simply the Sethi model provides a sales-advertising dynamics in the form of the following stochastic differential equation:\n\nWhere:\n\nThe rate of change in sales depend on three effects: response to advertising that acts positively on the unsold portion of the market via formula_6, the loss due to forgetting or possibly due to competitive factors that act negatively on the sold portion of the market via formula_7, and a random effect using a diffusion or White noise term that can go either way.\n\n\nSubject to the Sethi model above with the initial market share formula_16, consider the following objective function:\n\nwhere formula_18 denotes the sales revenue corresponding to the total market, i.e., when formula_19, and formula_20 denotes the discount rate.\n\nThe function formula_21 is known as the value function for this problem, and it is shown to be\n\nwhere\n\nThe optimal control for this problem is\n\nwhere\n\nand\n\n\n"}
{"id": "4561248", "url": "https://en.wikipedia.org/wiki?curid=4561248", "title": "Shannon number", "text": "Shannon number\n\nThe Shannon number, named after Claude Shannon, is a conservative lower bound (not an estimate) of the game-tree complexity of chess of 10, based on an average of about 10 possibilities for a pair of moves consisting of a move for White followed by one for Black, and a typical game lasting about 40 such pairs of moves. \n\nShannon showed a calculation for the lower bound of the game-tree complexity of chess, resulting in about 10 possible games, to demonstrate the impracticality of solving chess by brute force, in his 1950 paper \"Programming a Computer for Playing Chess\". (This influential paper introduced the field of computer chess.)\n\nShannon also estimated the number of possible positions, \"of the general order of formula_1, or roughly 10\". This includes some illegal positions (e.g., pawns on the first rank, both kings in check) and excludes legal positions following captures and promotions. Taking these into account, Victor Allis calculated an upper bound of 5×10 for the number of positions, and estimated the true number to be about 10. Recent results improve that estimate, by proving an upper bound of only 2, which is less than 10 and showing an upper bound 2×10 in the absence of promotions.\n\nAllis also estimated the game-tree complexity to be at least 10, \"based on an average branching factor of 35 and an average game length of 80\". As a comparison, the number of atoms in the observable universe, to which it is often compared, is roughly estimated to be 10.\n\nAfter each player has moved 5 times there are 69,352,859,712,417 possible games that could have been played.\n\nAs a comparison to the Shannon number, if chess is analyzed for the number of \"sensible\" games that can be played (not counting ridiculous or obvious game-losing moves such as moving a queen to be immediately captured by a pawn without compensation), then the result is closer to around 10 games. This is based on having a choice of about thirty sensible moves at each ply (half a move), and a game length of 80 ply (40 moves).\n\n"}
{"id": "25173885", "url": "https://en.wikipedia.org/wiki?curid=25173885", "title": "Stochastic computing", "text": "Stochastic computing\n\nStochastic computing is a collection of techniques that represent continuous values by streams of random bits. Complex computations can then be computed by simple bit-wise operations on the streams. Stochastic computing is distinct from the study of randomized algorithms.\n\nSuppose that formula_1 is given, and we wish to compute formula_2. Stochastic computing performs this operation using probability instead of arithmetic.\n\nSpecifically, suppose that there are two random, independent bit streams called \"stochastic number\"s (i.e. Bernoulli processes), where the probability of a one in the first stream is formula_3, and the probability in the second stream is formula_4. We can take the logical AND of the two streams.\nThe probability of a one in the output stream is formula_5. By observing enough output bits and measuring the frequency of ones, it is possible to estimate formula_5 to arbitrary accuracy.\n\nThe operation above converts a fairly complicated computation (multiplication of formula_3 and formula_4) into a series of very simple operations (evaluation of formula_9) on random bits.\n\nMore generally speaking, stochastic computing represents numbers as streams of random bits and reconstructs numbers by calculating frequencies. The computations are performed on the streams and translate complicated operations on formula_3 and formula_4 into simple operations on their stream representations. (Because of the method of reconstruction, devices that perform these operations are sometimes called stochastic averaging processors.) In modern terms, stochastic computing can be viewed as an interpretation of calculations in probabilistic terms, which are then evaluated with a Gibbs sampler. It can also be interpreted as a hybrid analog/digital computer.\n\nStochastic computing was first introduced in a pioneering paper by John von Neumann in 1953. However, the\ntheory could not be fully developed until advances in computing of the 1960s,\n\nmostly through a series of simultaneous and parallel efforts in the US\nand the UK.\nBy the late 1960s, attention turned to the design of\nspecial-purpose hardware to perform stochastic computation. A host\nof these machines were constructed between 1969 and 1974; RASCEL\nis pictured in this article.\n\nDespite the intense interest in the 1960s and 1970s, stochastic\ncomputing ultimately failed to compete with more traditional digital\nlogic, for reasons outlined below. The first (and last)\nInternational Symposium on Stochastic Computing\ntook place in 1978; active research in the area dwindled over the next\nfew years.\n\nAlthough stochastic computing declined as a general method of\ncomputing, it has shown promise in several applications. Research has\ntraditionally focused on certain tasks in machine learning and\ncontrol.\n\nSomewhat recently, interest has turned towards stochastic\ndecoding, which applies stochastic computing to the decoding of error\ncorrecting codes. More recently, stochastic circuits have been successfully used in image processing tasks such as edge detection\n\nAlthough stochastic computing was a historical failure, it may still remain relevant for\nsolving certain problems. To understand when it remains relevant, it is useful to\ncompare stochastic computing with more traditional methods of digital computing.\n\nSuppose we wish to multiply\ntwo numbers each with formula_12 bits of precision.\nUsing the typical long\nmultiplication method, we need to perform\nformula_13 operations. With stochastic computing, we can\nAND together any number of bits and the expected value will always\nbe correct. (However, with a small number of samples the variance will\nrender the actual result highly inaccurate).\n\nMoreover, the underlying operations in a digital multiplier are\nfull adders, whereas a stochastic\ncomputer only requires an AND gate. Additionally,\na digital multiplier would naively require formula_14 input wires,\nwhereas a stochastic multiplier would only require 2 input wires.\n(If the digital multiplier serialized its output, however, it would also\nrequire only 2 input wires.)\n\nAdditionally, stochastic computing is robust against noise; if a few\nbits in a stream are flipped, those errors will have no significant impact\non the solution.\n\nFurthermore, stochastic computing elements can tolerate skew in the arrival time of the inputs.\nCircuits work properly even when the inputs are misaligned temporally. As a result, stochastic\nsystems can be designed to work with inexpensive locally generated clocks instead of using a global clock and \nan expensive clock distribution network.\n\nFinally, stochastic computing provides an estimate of the solution\nthat grows more accurate as we extend the bit stream. In particular,\nit provides a rough estimate very rapidly. This property is usually \nreferred to as \"progressive precision\", which suggests that the precision\nof stochastic numbers (bit streams) increases as computation proceeds.\n\nIt is as if the most significant bits of the number\narrive before its least significant bits; unlike the\nconventional arithmetic circuits where the most\nsignificant bits usually arrive last. In some\niterative systems the partial solutions obtained through progressive precision can provide faster feedback\nthan through traditional computing methods, leading to faster\nconvergence.\n\nStochastic computing is, by its very nature, random. When we examine\na random bit stream and try to reconstruct the underlying value, the effective precision\ncan be measured by the variance of our sample. In the example above, the digital multiplier\ncomputes a number to formula_15 bits of accuracy, so the\nprecision is formula_16. If we are using a random bit\nstream to estimate a number and want the standard deviation of our\nestimate of the solution to be at least formula_16, we\nwould need formula_18 samples. This represents an\nexponential increase in work. In certain applications, however, the\nprogressive precision property of stochastic computing can be exploited\nto compensate this exponential loss.\n\nSecond, stochastic computing requires a method of generating random\nbiased bit streams. In practice, these streams are generated with\npseudo-random number generators. Unfortunately, generating\n(pseudo-)random bits is fairly costly (compared to the expense of,\ne.g., a full adder). Therefore, the gate-level advantage of\nstochastic computing is typically lost.\n\nThird, the analysis of stochastic computing assumes that the bit\nstreams are independent (uncorrelated). If this assumption does not\nhold, stochastic computing can fail dramatically. For instance, if we\ntry to compute formula_19 by multiplying a bit stream for\nformula_3 by itself, the process fails: since formula_21, the stochastic computation would yield formula_22, which is not generally true (unless formula_230 or 1).\nIn systems with feedback, the problem of decorrelation can manifest in\nmore complicated ways. Systems of stochastic processors are prone to\n\"latching\", where feedback between different components can achieve\na deadlocked state.\nA great deal of effort must be spent decorrelating the system to\nattempt to remediate latching.\n\nFourth, although some digital functions have very simple stochastic\ncounterparts (such as the translation between multiplication and the\nAND gate), many do not. Trying to express these functions stochastically\nmay cause various pathologies. For instance, stochastic decoding requires\nthe computation of the function formula_24.\nThere is no single bit operation that can compute this function; the usual solution\ninvolves producing correlated output bits, which, as we have seen above, can cause\na host of problems.\n\nOther functions (such as the averaging operator formula_25) require \neither stream decimation or inflation. Tradeoffs between precision and memory\ncan be challenging.\n\nAlthough stochastic computing has a number of defects when considered\nas a method of general computation, there are certain applications\nthat highlight its strengths. One notable case occurs in the\ndecoding of certain error correcting codes.\n\nIn developments unrelated to stochastic computing, highly effective\nmethods of decoding LDPC codes using\nthe belief propagation algorithm were\ndeveloped. Belief propagation in this context involves iteratively\nreestimating certain parameters using two basic operations\n(essentially, a probabilistic XOR operation and an averaging\noperation).\n\nIn 2003, researchers realized that these two operations could be\nmodeled very simply with stochastic computing.\nMoreover, since the\nbelief propagation algorithm is iterative, stochastic computing provides partial\nsolutions that may lead to faster convergence.\nHardware implementations of stochastic decoders have been built on FPGAs.\n\nThe proponents of these methods argue that the performance of stochastic decoding is\ncompetitive with digital alternatives.\n\nThere are a number of variants of the basic stochastic computing\nparadigm. Further information can be found in the referenced book by\nMars and Poppelbaum.\n\n\"Bundle Processing\" involves sending a fixed number of\nbits instead of a stream. One of the advantages of this approach is\nthat the precision is improved. To see why, suppose we transmit\nformula_26 bits. In regular stochastic computing, we can\nrepresent a precision of roughly formula_27 different\nvalues, because of the variance of the estimate. In bundle\nprocessing, we can represent a precision of formula_28.\nHowever, bundle processing retains the same robustness to error of\nregular stochastic processing.\n\n\"Ergodic Processing\" involves sending a stream of bundles, which\ncaptures the benefits of regular stochastic and bundle processing.\n\n\"Burst Processing\" encodes a number by a higher base increasing\nstream. For instance, we would encode 4.3 with ten decimal digits as\nsince the average value of the preceding stream is 4.3. This\nrepresentation offers various advantages: there is no randomization\nsince the numbers appear in increasing order,\nso the PRNG issues are avoided, but many of the advantages of\nstochastic computing are retained (such as partial estimates of the\nsolution). Additionally, it retains the linear precision of bundle\nand ergodic processing.\n\n"}
{"id": "1462887", "url": "https://en.wikipedia.org/wiki?curid=1462887", "title": "Superconvergence", "text": "Superconvergence\n\nIn numerical analysis, a superconvergent or supraconvergent method is one which converges faster than generally expected (\"superconvergence\" or \"supraconvergence\"). For example, in the Finite Element Method approximation to Poisson's equation in two dimensions, using piecewise linear elements, the average error in the gradient is first order. However under certain conditions it's possible to recover the gradient at certain locations within each element to second order.\n\n"}
{"id": "4708571", "url": "https://en.wikipedia.org/wiki?curid=4708571", "title": "Thomas Banchoff", "text": "Thomas Banchoff\n\nThomas Francis Banchoff (born 1938) is an American mathematician\nspecializing in geometry. He is a professor at Brown University, where he has taught since 1967. He is known for his research in differential geometry in three and four dimensions, for his efforts to develop methods of computer graphics in the early 1990s, and most recently for his pioneering work in methods of undergraduate education utilizing online resources.\n\nBanchoff attended the University of Notre Dame and received his Ph.D from UC Berkeley in 1964, where he was a student of Shiing-Shen Chern. Before going to Brown he taught at Harvard University and the University of Amsterdam. In 2012 he became a fellow of the American Mathematical Society. He was a president of the Mathematical Association of America.\n\n\n\n"}
{"id": "29321051", "url": "https://en.wikipedia.org/wiki?curid=29321051", "title": "Triangular decomposition", "text": "Triangular decomposition\n\nIn computer algebra, a triangular decomposition of a polynomial system is a set of simpler polynomial systems such that a point is a solution of if and only if it is a solution of one of the systems .\n\nWhen the purpose is to describe the solution set of in the algebraic closure of its coefficient field, those simpler systems are regular chains. If the coefficients of the polynomial systems are real numbers, then the real solutions of can be obtained by a triangular decomposition into regular semi-algebraic systems. In both cases, each of these simpler systems has a triangular shape and remarkable properties, which justifies the terminology.\n\nThe Characteristic Set Method is the first factorization-free algorithm, which was proposed for decomposing an algebraic variety into equidimensional components. Moreover, the Author, Wen-Tsun Wu, realized an implementation of this method and reported experimental data in his 1987 pioneer article titled \"A zero structure theorem for polynomial equations solving\". To put this work into context, let us recall what was the common idea of an algebraic set decomposition at the time this article was written.\n\nLet be an algebraically closed field and be a subfield of . A subset is an (affine) algebraic variety over if there exists a polynomial set such that the zero set of equals .\n\nRecall that is said irreducible if for all algebraic varieties the relation implies either or . A first algebraic variety decomposition result is the famous Lasker–Noether theorem which implies the following.\n\nThe varieties in the above Theorem are called the irreducible components of and can be regarded as a natural output for a decomposition algorithm, or, in other words, for an algorithm solving a system of equations in .\n\nIn order to lead to a computer program, this algorithm specification should prescribe how irreducible components are represented. Such an encoding is introduced by Joseph Ritt through the following result.\n\nWe call the set in Ritt's Theorem a Ritt characteristic set of the ideal formula_2. Please refer to regular chain for the notion of a triangular set.\n\nJoseph Ritt described a method for solving polynomial systems based on polynomial factorization over field extensions and computation of characteristic sets of prime ideals.\n\nDeriving a practical implementation of this method, however, was and remains a difficult problem. In the 80's, when the Characteristic set Method was introduced, polynomial factorization was an active research area and certain fundamental questions on this subject were solved recently\n\nNowadays, decomposing an algebraic variety into irreducible components is not essential to process most application problems, since weaker notions of decompositions, less costly to compute, are sufficient.\n\nThe Characteristic Set Method relies on the following variant of Ritt's Theorem.\n\nDifferent concepts and algorithms extended the work of Wen-Tsun Wu. In the early 90's, the notion of a regular chain, introduced independently by Michael Kalkbrener in 1991 in his PhD Thesis and, by Lu Yang and Jingzhong Zhang led to important algorithmic discoveries.\n\nIn Kalkbrener's vision, regular chains are used to represent the generic zeros of the irreducible components of an algebraic variety. In the original work of Yang and Zhang, they are used to decide whether a hypersurface intersects a quasi-variety (given by a regular chain). Regular chains have, in fact, several interesting properties and are the key notion in many algorithms for decomposing systems of algebraic or differential equations.\n\nRegular chains have been investigated in many papers.\n\nThe abundant literature on the subject can be explained by the many equivalent definitions of a regular chain. Actually, the original formulation of Kalkbrener is quite different from that of Yang and Zhang. A bridge between these two notions, the point of view of Kalkbrener and that of Yang and Zhang, appears in Dongming Wang's paper.\n\nThere are various algorithms available for obtaining triangular decomposition of both in the sense of Kalkbrener and in the sense of Lazard and Wen-Tsun Wu. The Lextriangular Algorithm by Daniel Lazard and the Triade Algorithm by Marc Moreno Maza together with the Characteristic Set Method are available in various computer algebra systems, including Axiom and Maple.\n\nLet be a field and be ordered variables. We denote by the corresponding polynomial ring. For , regarded as a system of polynomial equations, there are two notions of a triangular decomposition over the algebraic closure of . The first one is to decompose lazily, by representing only the generic points of the algebraic set in the so-called sense of Kalkbrener.\n\nThe second is to describe explicitly all the points of in the so-called sense of in Lazard and Wen-Tsun Wu.\n\nIn both cases are finitely many regular chains of and formula_8 denotes the radical of the saturated ideal of while denotes the quasi-component of . Please refer to regular chain for definitions of these notions.\n\nAssume from now on that is a real closed field. Consider a semi-algebraic system with polynomials in . There exist finitely many regular semi-algebraic systems such that we have\n\nwhere denotes the points of which solve . The regular semi-algebraic systems form a triangular decomposition of the semi-algebraic system .\n\nDenote the rational number field. In formula_10 with variable ordering formula_11, consider the following polynomial system: \n\nAccording to the Maple code: \nwith(RegularChains):\nR := PolynomialRing([x, y, z]):\nsys := {x^2+y+z-1, x+y^2+z-1, x+y+z^2-1}:\nl := Triangularize(sys, R):\nmap(Equations, l, R);\nOne possible triangular decompositions of the solution set of with using RegularChains library is:\n\n"}
{"id": "54572724", "url": "https://en.wikipedia.org/wiki?curid=54572724", "title": "Workshop on Numerical Ranges and Numerical Radii", "text": "Workshop on Numerical Ranges and Numerical Radii\n\nWorkshop on Numerical Ranges and Numerical Radii (WONRA) is a biennial workshop series on numerical ranges and numerical radii which began in 1992.\nNumerical ranges and numerical radii are useful in the study of matrix and operator theory.\nThese topics have applications in many subjects in pure and applied mathematics, such as\nquadratic forms, Banach spaces, dilation theory, control theory, numerical analysis, quantum information science.\n\nIn the early 1970s, numerical range workshops were organized by Frank Bonsall and John Duncan. More activities were started in early 1990s, including the biennial workshop series, which began in 1992,\nand special issues devoted to this workshop were published.\n\n"}
