{"id": "31474975", "url": "https://en.wikipedia.org/wiki?curid=31474975", "title": "Abstract model theory", "text": "Abstract model theory\n\nIn mathematical logic, abstract model theory is a generalization of model theory which studies the general properties of extensions of first-order logic and their models.\n\nAbstract model theory provides an approach that allows us to step back and study a wide range of logics and their relationships. The starting point for the study of abstract models, which resulted in good examples was Lindström's theorem.\n\nIn 1974 Jon Barwise provided an axiomatization of abstract model theory.\n\n"}
{"id": "5435566", "url": "https://en.wikipedia.org/wiki?curid=5435566", "title": "Action-angle coordinates", "text": "Action-angle coordinates\n\nIn classical mechanics, action-angle coordinates are a set of canonical coordinates useful in solving many integrable systems. The method of action-angles is useful for obtaining the frequencies of oscillatory or rotational motion without solving the equations of motion. Action-angle coordinates are chiefly used when the Hamilton–Jacobi equations are completely separable. (Hence, the Hamiltonian does not depend explicitly on time, i.e., the energy is conserved.) Action-angle variables define an invariant torus, so called because holding the action constant defines the surface of a torus, while the angle variables parameterize the coordinates on the torus.\n\nThe Bohr–Sommerfeld quantization conditions, used to develop quantum mechanics before the advent of wave mechanics, state that the action must be an integral multiple of Planck's constant; similarly, Einstein's insight into EBK quantization and the difficulty of quantizing non-integrable systems was expressed in terms of the invariant tori of action-angle coordinates.\n\nAction-angle coordinates are also useful in perturbation theory of Hamiltonian mechanics, especially in determining adiabatic invariants. One of the earliest results from chaos theory, for the non-linear perturbations of dynamical systems with a small number of degrees of freedom is the KAM theorem, which states that the invariant tori are stable under small perturbations.\n\nThe use of action-angle variables was central to the solution of the Toda lattice, and to the definition of Lax pairs, or more generally, the idea of the isospectral evolution of a system.\n\nAction angles result from a type-2 canonical transformation where the generating function is Hamilton's characteristic function formula_1 (\"not\" Hamilton's principal function formula_2). Since the original Hamiltonian does not depend on time explicitly, the new Hamiltonian formula_3 is merely the old Hamiltonian formula_4 expressed in terms of the new canonical coordinates, which we denote as formula_5 (the action angles, which are the generalized coordinates) and their new generalized momenta formula_6. We will not need to solve here for the generating function formula_7 itself; instead, we will use it merely as a vehicle for relating the new and old canonical coordinates.\n\nRather than defining the action angles formula_5 directly, we define instead their generalized momenta, which resemble the classical action for each original generalized coordinate\n\nwhere the integration path is implicitly given by the constant energy function formula_10. Since the actual motion is not involved in this integration, these generalized momenta formula_11 are constants of the motion, implying that the transformed Hamiltonian formula_12 does not depend on the conjugate generalized coordinates formula_13\n\nwhere the formula_13 are given by the typical equation for a type-2 canonical transformation\n\nHence, the new Hamiltonian formula_17 depends only on the new generalized momenta formula_6.\n\nThe dynamics of the action angles is given by Hamilton's equations\n\nThe right-hand side is a constant of the motion (since all the formula_20's are). Hence, the solution is given by\n\nwhere formula_22 is a constant of integration. In particular, if the original generalized coordinate undergoes an oscillation or rotation of period formula_23, the corresponding action angle formula_13 changes by formula_25.\n\nThese formula_26 are the frequencies of oscillation/rotation for the original generalized coordinates formula_27. To show this, we integrate the net change in the action angle formula_13 over exactly one complete variation (i.e., oscillation or rotation) of its generalized coordinates formula_27\n\nSetting the two expressions for formula_31 equal, we obtain the desired equation\n\nThe action angles formula_5 are an independent set of generalized coordinates. Thus, in the general case, each original generalized coordinate formula_34 can be expressed as a Fourier series in \"all\" the action angles\n\nwhere formula_36 is the Fourier series coefficient. In most practical cases, however, an original generalized coordinate formula_27 will be expressible as a Fourier series in only its own action angles formula_13\n\nThe general procedure has three steps:\n\n\nIn some cases, the frequencies of two different generalized coordinates are identical, i.e., formula_42 for formula_43. In such cases, the motion is called degenerate.\n\nDegenerate motion signals that there are additional general conserved quantities; for example, the frequencies of the Kepler problem are degenerate, corresponding to the conservation of the Laplace–Runge–Lenz vector.\n\nDegenerate motion also signals that the Hamilton–Jacobi equations are completely separable in more than one coordinate system; for example, the Kepler problem is completely separable in both spherical coordinates and parabolic coordinates.\n\n\n"}
{"id": "1374699", "url": "https://en.wikipedia.org/wiki?curid=1374699", "title": "Additive polynomial", "text": "Additive polynomial\n\nIn mathematics, the additive polynomials are an important topic in classical algebraic number theory. \n\nLet \"k\" be a field of characteristic \"p\", with \"p\" a prime number. A polynomial \"P\"(\"x\") with coefficients in \"k\" is called an additive polynomial, or a Frobenius polynomial, if \n\nas polynomials in \"a\" and \"b\". It is equivalent to assume that this equality holds for all \"a\" and \"b\" in some infinite field containing \"k\", such as its algebraic closure. \n\nOccasionally absolutely additive is used for the condition above, and additive is used for the weaker condition that \"P\"(\"a\" + \"b\") = \"P\"(\"a\") + \"P\"(\"b\") for all \"a\" and \"b\" in the field. For infinite fields the conditions are equivalent, but for finite fields they are not, and the weaker condition is the \"wrong\" one and does not behave well. For example, over a field of order \"q\" any multiple \"P\" of \"x\" − \"x\" will satisfy \"P\"(\"a\" + \"b\") = \"P\"(\"a\") + \"P\"(\"b\") for all \"a\" and \"b\" in the field, but will usually not be (absolutely) additive.\n\nThe polynomial \"x\" is additive. Indeed, for any \"a\" and \"b\" in the algebraic closure of \"k\" one has by the binomial theorem\n\nSince \"p\" is prime, for all \"n\" = 1, ..., \"p\"−1 the binomial coefficient formula_3 is divisible by \"p\", which implies that \n\nas polynomials in \"a\" and \"b\".\n\nSimilarly all the polynomials of the form\n\nare additive, where \"n\" is a non-negative integer.\n\nThe definition makes sense even if \"k\" is a field of characteristic zero, but in this case the only additive polynomials are those of the form \"ax\" for some \"a\" in \"k\".\n\nIt is quite easy to prove that any linear combination of polynomials formula_6 with coefficients in \"k\" is also an additive polynomial. An interesting question is whether there are other additive polynomials except these linear combinations. The answer is that these are the only ones.\n\nOne can check that if \"P\"(\"x\") and \"M\"(\"x\") are additive polynomials, then so are \"P\"(\"x\") + \"M\"(\"x\") and \"P\"(\"M\"(\"x\")). These imply that the additive polynomials form a ring under polynomial addition and composition. This ring is denoted \n\nThis ring is not commutative unless \"k\" equals the field formula_8 (see modular arithmetic). Indeed, consider the additive polynomials \"ax\" and \"x\" for a coefficient \"a\" in \"k\". For them to commute under composition, we must have\n\nor \"a\" − \"a\" = 0. This is false for \"a\" not a root of this equation, that is, for \"a\" outside formula_10\n\nLet \"P\"(\"x\") be a polynomial with coefficients in \"k\", and formula_11 be the set of its roots. Assuming that the roots of \"P\"(\"x\") are distinct (that is, \"P\"(\"x\") is separable), then \"P\"(\"x\") is additive if and only if the set formula_12 forms a group with the field addition.\n\n\n"}
{"id": "35117697", "url": "https://en.wikipedia.org/wiki?curid=35117697", "title": "Agranovich–Dynin formula", "text": "Agranovich–Dynin formula\n\nIn mathematics, the Agranovich–Dynin formula is a formula for the index of an elliptic system of differential operators, introduced by \n"}
{"id": "293961", "url": "https://en.wikipedia.org/wiki?curid=293961", "title": "Aleph number", "text": "Aleph number\n\nIn mathematics, and in particular set theory, the aleph numbers are a sequence of numbers used to represent the cardinality (or size) of infinite sets that can be well-ordered. They are named after the symbol used to denote them, the Hebrew letter aleph (formula_1) (though in older mathematics books the letter aleph is often printed upside down by accident, partly because a Monotype matrix for aleph was mistakenly constructed the wrong way up).\n\nThe cardinality of the natural numbers is formula_2 (read \"aleph-naught\" or \"aleph-zero\"; the German term \"aleph-null\" is also sometimes used), the next larger cardinality is aleph-one formula_3, then formula_4 and so on. Continuing in this manner, it is possible to define a cardinal number formula_5 for every ordinal number α, as described below.\n\nThe concept and notation are due to Georg Cantor, who defined the notion of cardinality and realized that infinite sets can have different cardinalities.\n\nThe aleph numbers differ from the infinity (∞) commonly found in algebra and calculus. Alephs measure the sizes of sets; infinity, on the other hand, is commonly defined as an extreme limit of the real number line (applied to a function or sequence that \"diverges to infinity\" or \"increases without bound\"), or an extreme point of the extended real number line.\n\nformula_2 (aleph-naught, also aleph-zero or the German term Aleph-null) is the cardinality of the set of all natural numbers, and is an infinite cardinal. The set of all finite ordinals, called ω or ω (where ω is the lowercase Greek letter omega), has cardinality formula_2. A set has cardinality formula_2 if and only if it is countably infinite, that is, there is a bijection (one-to-one correspondence) between it and the natural numbers. Examples of such sets are\n\n\nThese infinite ordinals: ω, ω+1, ω·2, ω, ω and ε are among the countably infinite sets. For example, the sequence (with ordinality ω·2) of all positive odd integers followed by all positive even integers\n\nis an ordering of the set (with cardinality formula_2) of positive integers.\n\nIf the axiom of countable choice (a weaker version of the axiom of choice) holds, then formula_2 is smaller than any other infinite cardinal.\n\nformula_3 is the cardinality of the set of all countable ordinal numbers, called ω or sometimes Ω. This ω is itself an ordinal number larger than all countable ones, so it is an uncountable set. Therefore, formula_3 is distinct from formula_2. The definition of formula_3 implies (in ZF, Zermelo–Fraenkel set theory \"without\" the axiom of choice) that no cardinal number is between formula_2 and formula_3. If the axiom of choice is used, it can be further proved that the class of cardinal numbers is totally ordered, and thus formula_3 is the second-smallest infinite cardinal number. Using the axiom of choice we can show one of the most useful properties of the set ω: any countable subset of ω has an upper bound in ω. (This follows from the fact that the union of a countable number of countable sets is itself countable, one of the most common applications of the axiom of choice.) This fact is analogous to the situation in formula_2: every finite set of natural numbers has a maximum which is also a natural number, and finite unions of finite sets are finite.\n\nω is actually a useful concept, if somewhat exotic-sounding. An example application is \"closing\" with respect to countable operations; e.g., trying to explicitly describe the σ-algebra generated by an arbitrary collection of subsets (see e. g. Borel hierarchy). This is harder than most explicit descriptions of \"generation\" in algebra (vector spaces, groups, etc.) because in those cases we only have to close with respect to finite operations—sums, products, and the like. The process involves defining, for each countable ordinal, via transfinite induction, a set by \"throwing in\" all possible countable unions and complements, and taking the union of all that over all of ω.\n\nEvery uncountable coanalytic subset of a Polish space formula_19 has\ncardinality formula_3 or formula_21.\n\nThe cardinality of the set of real numbers (cardinality of the continuum) is formula_21. It cannot be determined from ZFC (Zermelo–Fraenkel set theory with the axiom of choice) where this number fits exactly in the aleph number hierarchy, but it follows from ZFC that the continuum hypothesis, CH, is equivalent to the identity\n\nThe CH states that there is no set whose cardinality is strictly between that of the integers and the real numbers. CH is independent of ZFC: it can be neither proven nor disproven within the context of that axiom system (provided that ZFC is consistent). That CH is consistent with ZFC was demonstrated by Kurt Gödel in 1940 when he showed that its negation is not a theorem of ZFC. That it is independent of ZFC was demonstrated by Paul Cohen in 1963 when he showed, conversely, that the CH itself is not a theorem of ZFC by the (then novel) method of forcing. \n\nConventionally the smallest infinite ordinal is denoted ω, and the cardinal number formula_23 is the least upper bound of\n\namong alephs.\n\nAleph-ω is the first uncountable cardinal number that can be demonstrated within Zermelo–Fraenkel set theory \"not\" to be equal to the cardinality of the set of all real numbers; for any positive integer \"n\" we can consistently assume that formula_24, and moreover it is possible to assume formula_21 is as large as we like. We are only forced to avoid setting it to certain special cardinals with cofinality formula_2, meaning there is an unbounded function from formula_2 to it (see Easton's theorem).\n\nTo define formula_5 for arbitrary ordinal number formula_29, we must define the successor cardinal operation, which assigns to any cardinal number ρ the next larger well-ordered cardinal ρ (if the axiom of choice holds, this is the next larger cardinal).\n\nWe can then define the aleph numbers as follows:\n\nand for λ, an infinite limit ordinal,\n\nThe α-th infinite initial ordinal is written formula_30. Its cardinality is written formula_5.\nIn ZFC, the aleph function formula_1 is a bijection from the ordinals to the infinite cardinals.\n\nFor any ordinal α we have\nIn many cases formula_33 is strictly greater than α. For example, for any successor ordinal α this holds. There are, however, some limit ordinals which are fixed points of the omega function, because of the fixed-point lemma for normal functions. The first such is the limit of the sequence\n\nAny weakly inaccessible cardinal is also a fixed point of the aleph function. This can be shown in ZFC as follows. Suppose formula_34 is a weakly inaccessible cardinal. If formula_35 were a successor ordinal, then formula_36 would be a successor cardinal and hence not weakly inaccessible. If formula_35 were a limit ordinal less than formula_38, then its cofinality (and thus the cofinality of formula_36) would be less than formula_40 and so formula_40 would not be regular and thus not weakly inaccessible. Thus formula_42 and consequently formula_43 which makes it a fixed point.\n\nThe cardinality of any infinite ordinal number is an aleph number. Every aleph is the cardinality of some ordinal. The least of these is its initial ordinal. Any set whose cardinality is an aleph is equinumerous with an ordinal and is thus well-orderable.\n\nEach finite set is well-orderable, but does not have an aleph as its cardinality.\n\nThe assumption that the cardinality of each infinite set is an aleph number is equivalent over ZF to the existence of a well-ordering of every set, which in turn is equivalent to the axiom of choice. ZFC set theory, which includes the axiom of choice, implies that every infinite set has an aleph number as its cardinality (i.e. is equinumerous with its initial ordinal), and thus the initial ordinals of the aleph numbers serve as a class of representatives for all possible infinite cardinal numbers.\n\nWhen cardinality is studied in ZF without the axiom of choice, it is no longer possible to prove that each infinite set has some aleph number as its cardinality; the sets whose cardinality is an aleph number are exactly the infinite sets that can be well-ordered. The method of Scott's trick is sometimes used as an alternative way to construct representatives for cardinal numbers in the setting of ZF. For example, one can define card(\"S\") to be the set of sets with the same cardinality as \"S\" of minimum possible rank. This has the property that card(\"S\") = card(\"T\") if and only if \"S\" and \"T\" have the same cardinality. (The set card(\"S\") does not have the same cardinality of \"S\" in general, but all its elements do.)\n\n\n"}
{"id": "44896201", "url": "https://en.wikipedia.org/wiki?curid=44896201", "title": "Ana Caraiani", "text": "Ana Caraiani\n\nAna Caraiani is a Romanian-American mathematician, who is a Royal Society University Research Fellow and Senior Lecturer at Imperial College London. Her research interests include algebraic number theory and the Langlands program.\n\nIn 2001, Caraiani became the first Romanian female competitor in 25 years at the International Mathematical Olympiad, where she won a silver medal. In the following two years, she won two gold medals.\n\nAs an undergraduate student at Princeton University, Caraiani was a two-time Putnam Fellow (the only female competitor at the William Lowell Putnam Mathematical Competition to win more than once) and Elizabeth Lowell Putnam Award winner.\n\nCaraiani graduated summa cum laude from Princeton in 2007, with an undergraduate thesis on Galois representations supervised by Andrew Wiles.\n\nCaraiani did her graduate studies at Harvard University under the supervision of Wiles' student Richard Taylor, earning her Ph.D. in 2012 with a dissertation concerning local-global compatibility in the Langlands correspondence.\n\nAfter spending a year as an L.E. Dickson Instructor at the University of Chicago, she returned to Princeton and the IAS as a Veblen Instructor. In 2016 she was appointed a Bonn Junior Fellow and moved to the Hausdorff Center for Mathematics. She moved to Imperial in 2017.\n\nIn 2007 the Association for Women in Mathematics gave Caraiani their Alice T. Schafer Prize.\n\nIn 2018 she was one of the winners of the Whitehead Prize of the London Mathematical Society.\n\n"}
{"id": "42115167", "url": "https://en.wikipedia.org/wiki?curid=42115167", "title": "Apeirogonal hosohedron", "text": "Apeirogonal hosohedron\n\nIn geometry, an apeirogonal hosohedron or infinite hosohedron is a tiling of the plane consisting of two vertices at infinity. It may be considered an improper regular tiling of the Euclidean plane, with Schläfli symbol {2,∞}.\n\nThe apeirogonal hosohedron is the arithmetic limit of the family of hosohedra {2,\"p\"}, as \"p\" tends to infinity, thereby turning the hosohedron into a Euclidean tiling. All the vertices have then receded to infinity and the digonal faces are no longer defined by closed circuits of finite edges.\n\nSimilarly to the uniform polyhedra and the uniform tilings, eight uniform tilings may be based from the regular apeirogonal tiling. The rectified and cantellated forms are duplicated, and as two times infinity is also infinity, the truncated and omnitruncated forms are also duplicated, therefore reducing the number of unique forms to four: the apeirogonal tiling, the apeirogonal hosohedron, the apeirogonal prism, and the apeirogonal antiprism.\n\n"}
{"id": "18766220", "url": "https://en.wikipedia.org/wiki?curid=18766220", "title": "Bertrand–Diguet–Puiseux theorem", "text": "Bertrand–Diguet–Puiseux theorem\n\nIn the mathematical study of the differential geometry of surfaces, the Bertrand–Diguet–Puiseux theorem expresses the Gaussian curvature of a surface in terms of the circumference of a geodesic circle, or the area of a geodesic disc. The theorem is named for Joseph Bertrand, Victor Puiseux, and Charles François Diguet.\n\nLet \"p\" be a point on a smooth surface \"M\". The geodesic circle of radius \"r\" centered at \"p\" is the set of all points whose geodesic distance from \"p\" is equal to \"r\". Let \"C\"(\"r\") denote the circumference of this circle, and \"A\"(\"r\") denote the area of the disc contained within the circle. The Bertrand–Diguet–Puiseux theorem asserts that\n\nThe theorem is closely related to the Gauss–Bonnet theorem.\n\n"}
{"id": "23335649", "url": "https://en.wikipedia.org/wiki?curid=23335649", "title": "Canonical map", "text": "Canonical map\n\nIn mathematics, a canonical map, also called a natural map, is a map or morphism between objects that arises naturally from the definition or the construction of the objects being mapped against each other. In general it is the map which preserves the widest amount of structure, and it tends to be unique. In the rare cases where latitude in choice remains, the map is either conventionally agreed upon to be the most useful for further analysis, or sometimes simply the most elegant or beautiful known.\n\nA closely related notion is a structure map or structure morphism; the map that comes with the given structure on the object. They are also sometimes called canonical maps.\n\nA canonical isomorphism is a canonical map that is also an isomorphism (i.e., invertible).\n\nIn some contexts, it is necessary to address an issue of \"choices\" of canonical maps or canonical isomorphisms; see prestack for a typical example.\n\n"}
{"id": "293418", "url": "https://en.wikipedia.org/wiki?curid=293418", "title": "Character (mathematics)", "text": "Character (mathematics)\n\nIn mathematics, a character is (most commonly) a special kind of function from a group to a field (such as the complex numbers). There are at least two distinct, but overlapping meanings. Other uses of the word \"character\" are almost always qualified.\n\nA multiplicative character (or linear character, or simply character) on a group \"G\" is a group homomorphism from \"G\" to the multiplicative group of a field , usually the field of complex numbers. If \"G\" is any group, then the set Ch(\"G\") of these morphisms forms an abelian group under pointwise multiplication.\n\nThis group is referred to as the character group of \"G\". Sometimes only \"unitary\" characters are considered (thus the image is in the unit circle); other such homomorphisms are then called \"quasi-characters\". Dirichlet characters can be seen as a special case of this definition.\n\nMultiplicative characters are linearly independent, i.e. if formula_1 are different characters on a group \"G\" then from formula_2 it follows that formula_3.\n\nThe character of a representation \"φ\" of a group \"G\" on a finite-dimensional vector space \"V\" over a field \"F\" is the trace of the representation \"φ\" . In general, the trace is not a group homomorphism, nor does the set of traces form a group. The characters of one-dimensional representations are identical to one-dimensional representations, so the above notion of multiplicative character can be seen as a special case of higher-dimensional characters. The study of representations using characters is called \"character theory\" and one dimensional characters are also called \"linear characters\" within this context.\n\n\n\n"}
{"id": "797238", "url": "https://en.wikipedia.org/wiki?curid=797238", "title": "Clifford–Klein form", "text": "Clifford–Klein form\n\nIn mathematics, a Clifford–Klein form is a double coset space\n\nwhere \"G\" is a reductive Lie group, \"H\" a closed subgroup of \"G\", and Γ a discrete subgroup of G that acts properly discontinuously on the homogeneous space \"G\"/\"H\". A suitable discrete subgroup Γ may or may not exist, for a given \"G\" and \"H\". If Γ exists, there is the question of whether Γ\\\"G\"/\"H\" can be taken to be a compact space, called a compact Clifford–Klein form.\n\nWhen \"H\" is itself compact, classical results show that a compact Clifford–Klein form exists. Otherwise it may not, and there are a number of negative results.\n"}
{"id": "40410426", "url": "https://en.wikipedia.org/wiki?curid=40410426", "title": "Cohn-Vossen's inequality", "text": "Cohn-Vossen's inequality\n\nIn differential geometry, Cohn-Vossen's inequality, named after Stephan Cohn-Vossen, relates the integral of Gaussian curvature of a non-compact surface to the Euler characteristic. It is akin to the Gauss–Bonnet theorem for a compact surface.\n\nA divergent path within a Riemannian manifold is a smooth curve in the manifold that is not contained within any compact subset of the manifold. A complete manifold is one in which every divergent path has infinite length with respect to the Riemannian metric on the manifold. Cohn-Vossen's inequality states that in every complete Riemannian 2-manifold \"S\" with finite total curvature and finite Euler characteristic, we have\n\nwhere \"K\" is the Gaussian curvature, \"dA\" is the element of area, and \"χ\" is the Euler characteristic.\n\n\n\n"}
{"id": "22521356", "url": "https://en.wikipedia.org/wiki?curid=22521356", "title": "Computability in Europe", "text": "Computability in Europe\n\nComputability in Europe (CiE) is an international organization of mathematicians, logicians, computer scientists, philosophers, theoretical physicists and others interested in new developments in computability and in their underlying significance for the real world. CiE aims to widen understanding and appreciation of the importance of the concepts and techniques of computability theory, and to support the development of a vibrant multi-disciplinary community of researchers focused on computability-related topics. CiE positions itself at the interface between applied and fundamental research, prioritising mathematical approaches to computational barriers.\n\nCiE originated as a research network in 2003, became a conference series in 2005, and the \"Association Computability in Europe\" was formed in 2008.\n\nThe \"Association Computability in Europe\" was founded in Athens, Greece in 2008.\nIts founding president (2008 to 2015) was \nProfessor S. Barry Cooper; its current president is Paola Bonizzoni and its current secretary general is Giuseppe Primiero. The Association is promoting the development, particularly in Europe, of computability-related science, ranging over mathematics, computer science, and applications in various natural and engineering sciences such as physics and biology. This also includes the promotion of the study of philosophy and history of computing as it relates to questions of computability.\n\nPast presidents of the Association were S. Barry Cooper (2008-2015) and Dag Normann (2015-2016). The current members of the Council of the Association are\nPablo Arrighi,\nArnold Beckmann,\nPaola Bonizzoni,\nOlivier Bournez,\nLiesbeth De Mol,\nJohann Makowsky,\nFlorin Manea,\nElvira Mayordomo,\nDag Normann,\nGiuseppe Primiero, \nand Martin Ziegler.\n\nCiE is also a major international conference series. \nThe first CiE conference was held in Amsterdam in June 2005, subsequent meetings being in Swansea, Wales (CiE 2006), \nSiena, Italy (CiE 2007), \nAthens, Greece (CiE 2008), \nHeidelberg, Germany (CiE 2009)\nPonta Delgada (Azores), Portugal (CiE 2010),\nSofia, Bulgaria (CiE 2011),\nCambridge, England (CiE 2012),\nMilan, Italy (CiE 2013),\nBudapest, Hungary (CiE 2014), \nBucharest, Romania (CiE 2015),\nand Paris, France (CiE 2016). CiE 2017 will be held in Turku, Finland and CiE 2018 will be held in\nKiel, Germany.\nThe current chair of the Steering Committee of the conference series is Florin Manea; his predecessors were Benedikt Löwe (2005-2013) and Arnold Beckmann (2013-2016).\n\nCiE has editorial responsibility for the Springer book series \"Theory and Applications of Computability\"\nand the journal \"Computability\" published by IOS Press.\n"}
{"id": "30643278", "url": "https://en.wikipedia.org/wiki?curid=30643278", "title": "Convexity in economics", "text": "Convexity in economics\n\nConvexity is an important topic in economics. In the Arrow–Debreu model of general economic equilibrium, agents have convex budget sets and convex preferences: At equilibrium prices, the budget hyperplane supports the best attainable indifference curve. The profit function is the convex conjugate of the cost function. Convex analysis is the standard tool for analyzing textbook economics. Non‑convex phenomena in economics have been studied with nonsmooth analysis, which generalizes convex analysis.\n\nThe economics depends upon the following definitions and results from convex geometry.\n\nA real vector space of two dimensions may be given a Cartesian coordinate system in which every point is identified by a list of two real numbers, called \"coordinates\", which are conventionally denoted by \"x\" and \"y\". Two points in the Cartesian plane can be \"added\" coordinate-wise\nfurther, a point can be \"multiplied\" by each real number \"λ\" coordinate-wise \n\nMore generally, any real vector space of (finite) dimension \"D\" can be viewed as the set of all possible lists of \"D\" real numbers  } together with two operations: vector addition and multiplication by a real number. For finite-dimensional vector spaces, the operations of vector addition and real-number multiplication can each be defined coordinate-wise, following the example of the Cartesian plane.\n\nIn a real vector space, a set is defined to be \"convex\" if, for each pair of its points, every point on the line segment that joins them is covered by the set. For example, a solid cube is convex; however, anything that is hollow or dented, for example, a crescent shape, is non‑convex. Trivially, the empty set is convex.\n\nMore formally, a set \"Q\" is convex if, for all points \"v\" and \"v\" in \"Q\" and for every real number \"λ\" in the unit interval , the point \nis a member of \"Q\".\n\nBy mathematical induction, a set \"Q\" is convex if and only if every convex combination of members of \"Q\" also belongs to \"Q\". By definition, a \"convex combination\" of an indexed subset {\"v\", \"v\", . . . , \"v\"} of a vector space is any weighted average  for some indexed set of non‑negative real numbers {\"λ\"} satisfying the equation  = 1.\n\nThe definition of a convex set implies that the \"intersection\" of two convex sets is a convex set. More generally, the intersection of a family of convex sets is a convex set. \n\nFor every subset \"Q\" of a real vector space, its is the minimal convex set that contains \"Q\". Thus Conv(\"Q\") is the intersection of all the convex sets that cover \"Q\". The convex hull of a set can be equivalently defined to be the set of all convex combinations of points in \"Q\".\n\n\"Supporting hyperplane\" is a concept in geometry. A hyperplane divides a space into two half-spaces. A hyperplane is said to support a set formula_1 in the real \"n\"-space formula_2 if it meets both of the following:\nHere, a closed half-space is the half-space that includes the hyperplane.\n\nThis theorem states that if formula_1 is a closed convex set in formula_6 and formula_7 is a point on the boundary of formula_8 then there exists a supporting hyperplane containing formula_9\n\nThe hyperplane in the theorem may not be unique, as noticed in the second picture on the right. If the closed set formula_1 is not convex, the statement of the theorem is not true at all points on the boundary of formula_8 as illustrated in the third picture on the right.\n\nAn optimal basket of goods occurs where the consumer's convex preference set is supported by the budget constraint, as shown in the diagram. If the preference set is convex, then the consumer's set of optimal decisions is a convex set, for example, a unique optimal basket (or even a line segment of optimal baskets).\n\nFor simplicity, we shall assume that the preferences of a consumer can be described by a utility function that is a continuous function, which implies that the preference sets are closed. (The meanings of \"closed set\" is explained below, in the subsection on optimization applications.)\n\nIf a preference set is non‑convex, then some prices produce a budget supporting two different optimal consumption decisions. For example, we can imagine that, for zoos, a lion costs as much as an eagle, and further that a zoo's budget suffices for one eagle or one lion. We can suppose also that a zoo-keeper views either animal as equally valuable. In this case, the zoo would purchase either one lion or one eagle. Of course, a contemporary zoo-keeper does not want to purchase a half an eagle and a (or a griffin)! Thus, the contemporary zoo-keeper's preferences are non‑convex: The zoo-keeper prefers having either animal to having any strictly convex combination of both.\n\nNon‑convex sets have been incorporated in the theories of general economic equilibria, of market failures, and of public economics. These results are described in graduate-level textbooks in microeconomics, general equilibrium theory, game theory, mathematical economics,\nand applied mathematics (for economists). The Shapley–Folkman lemma results establish that non‑convexities are compatible with approximate equilibria in markets with many consumers; these results also apply to production economies with many small firms.\n\nIn \"oligopolies\" (markets dominated by a few producers), especially in \"monopolies\" (markets dominated by one producer), non‑convexities remain important. Concerns with large producers exploiting market power in fact initiated the literature on non‑convex sets, when Piero Sraffa wrote about on firms with increasing returns to scale in 1926, after which Harold Hotelling wrote about marginal cost pricing in 1938. Both Sraffa and Hotelling illuminated the market power of producers without competitors, clearly stimulating a literature on the supply-side of the economy.\nNon‑convex sets arise also with environmental goods (and other externalities), with information economics, and with stock markets (and other incomplete markets). Such applications continued to motivate economists to study non‑convex sets.\n\nEconomists have increasingly studied non‑convex sets with nonsmooth analysis, which generalizes convex analysis. \"Non‑convexities in [both] production and consumption ... required mathematical tools that went beyond convexity, and further development had to await the invention of non‑smooth calculus\" (for example, Francis Clarke's locally Lipschitz calculus), as described by and , according to . wrote that the \"major methodological innovation in the general equilibrium analysis of firms with pricing rules\" was \"the introduction of the methods of non‑smooth analysis, as a [synthesis] of global analysis (differential topology) and [of] convex analysis.\" According to , \"Non‑smooth analysis extends the local approximation of manifolds by tangent planes [and extends] the analogous approximation of convex sets by tangent cones to sets\" that can be non‑smooth or non‑convex.. Economists have also used algebraic topology.\n\n"}
{"id": "4279403", "url": "https://en.wikipedia.org/wiki?curid=4279403", "title": "Correlation immunity", "text": "Correlation immunity\n\nIn mathematics, the correlation immunity of a Boolean function is a measure of the degree to which its outputs are uncorrelated with some subset of its inputs. Specifically, a Boolean function is said to be correlation-immune \"of order m\" if every subset of \"m\" or fewer variables in formula_1 is statistically independent of the value of formula_2.\n\nA function formula_3 is formula_4-th order correlation immune if for any independent formula_5 binary random variables formula_6, the random variable formula_7 is independent from any random vector formula_8 with formula_9.\n\nWhen used in a stream cipher as a combining function for linear feedback shift registers, a Boolean function with low-order correlation-immunity is more susceptible to a correlation attack than a function with correlation immunity of high order.\n\nSiegenthaler showed that the correlation immunity \"m\" of a Boolean function of algebraic degree \"d\" of \"n\" variables satisfies \"m\" + \"d\" ≤ \"n\"; for a given set of input variables, this means that a high algebraic degree will restrict the maximum possible correlation immunity. Furthermore, if the function is balanced then \"m\" + \"d\" ≤ \"n\" − 1.\n\n"}
{"id": "487354", "url": "https://en.wikipedia.org/wiki?curid=487354", "title": "Cover (telecommunications)", "text": "Cover (telecommunications)\n\nIn telecommunications, cover is the technique of concealing or altering the characteristics of communications patterns for the purpose of denying an unauthorized receiver information that would be of value.\n\nThe purpose of cover is not to make the communication secure, but to make it look like noise, rendering it uninteresting and not worth analysis. Even if an attacker recognizes the communication as interesting, cover makes traffic analysis more difficult since he must crack the cover before he can find out to whom it is addressed.\n\nUsually, the covered communication is also encrypted. In this way, enemies have no idea you sent a message; friends know you sent a message, but don't know what you said; the intended recipient knows what you said. \n\n\"Note:\" \"Cover\" is a process of modulo two addition of a pseudorandom bit stream generated by a cryptographic device with bits from the control message.\n\nSource: from Federal Standard 1037C and from MIL-STD-188\n"}
{"id": "7866313", "url": "https://en.wikipedia.org/wiki?curid=7866313", "title": "Crab (cipher)", "text": "Crab (cipher)\n\nIn cryptography, Crab is a block cipher proposed by Burt Kaliski and Matt Robshaw at the first Fast Software Encryption workshop in 1993. Not really intended for use, Crab was developed to demonstrate how ideas from hash functions could be used to create a fast cipher.\n\nCrab has an unusually large block size of 8192 bits. Its creators suggested using an 80-bit key, but the cipher could use any key size. The authors didn't specify an actual key schedule, only that the key is used to generate two large sets of subkeys: a permutation of the numbers 0 through 255, and an array of 2048 32-bit numbers. The block is divided into 256 32-bit subblocks, which are permuted at the beginning. Then the algorithm makes four passes over the data, each time applying one of four transformations adapted from MD5.\n\nA brief note on the cryptanalysis of Crab is included in Markku-Juhani Saarinen's paper on block ciphers based on SHA-1 and MD5, published at FSE 2003. The author demonstrates a weakness in Crab that permits a distinguisher using no more than a dozen chosen plaintexts, and speculates that this can be converted into a full key-recovery attack using no more than 2 chosen plaintexts. Such an attack would depend on the key schedule used.\n\n"}
{"id": "13245696", "url": "https://en.wikipedia.org/wiki?curid=13245696", "title": "Derek Wanless", "text": "Derek Wanless\n\nSir Derek Wanless (29 September 1947 – 22 May 2012) was an English banker and an adviser to the Labour Party.\nDerek Wanless was born in Newcastle upon Tyne, where he was educated at the Royal Grammar School. From 1967-70, he was an undergraduate at King's College Cambridge, which he attended on a support grant from Westminster Bank (a constituent of the present NatWest Bank). He was an extraordinarily gifted mathematician and graduated as Senior Wrangler in 1970. On graduation he moved into banking, qualifying as a statistician, and attended the Program for Management Development at Harvard. He was a member of the Institute of Statisticians and a Fellow of the Chartered Institute of Bankers, of which he was President in 1999.\n\nHe had joined Westminster Bank, a constituent of the present NatWest Bank in 1967, beginning with a Saturday job before becoming NatWest's Director of Personal Banking from 1986-1988. Then becoming the General Manager for UK Branch Business and UK Financial Services before, in 1992, taking on the role of Group Chief Executive until 1999, when he received a reported pay-off of £3,000,000. It was on Friday 8 October 1999, that BBC News reported that Derek Wanless had been ousted from his position as Chief Executive. Wanless was reportedly forced out by the bank's Non-Executive Directors, who replaced him with Sir David Rowland. Wanless had been criticised by City investors for taking the bank into investment banking, and failing to curtail high costs. As executive responsible for NatWest's card business, he led the team which invented Switch, the UK's debit card scheme. He led the NatWest Group immediately prior to its takeover, by the (then) relatively small Royal Bank of Scotland.\n\nIn 2002 he carried out a review of the future funding of the National Health Service for Gordon Brown, then Chancellor of the Exchequer and in 2007 carried out a further review for the King's Fund.\nHe was a Non-Executive Director of Northern Rock between 2000/2007, where he was Chairman of The Northern Rock's Audit and Risk committees. His position became highly contentious, following the incipient collapse of Northern Rock in September 2007. The Northern Rock's crisis was due to inadequate risk provision, and a 'run on the Bank' was only halted with promises of unlimited UK government support.\n\nSir Derek was heavily criticised regarding his role in the Northern Rock affair by a committee of MPs sitting on the Commons Treasury Select Committee on 16 October 2007. Sir Derek's resignation was accepted by Northern Rock's newly appointed Chairman on 17 November 2007.\nHe died of pancreatic cancer at the age of 64 in 2012.\n\nSir Derek Wanless was a Freeman of the City of London, received a Knighthood in the 2005 New Year Honours and a Doctor of Civil Law, honoris causa from Durham University on 30 June 2005. He received an Honorary Doctorate in Business Administration (Hon DBA) from Sunderland University in July 2007. A further Honorary Doctorate was awarded by Coventry University in November 2007, which prompted a \"Daily Telegraph\" article questioning the value of such awards \nThe House of Commons Select Treasury Committee published its report into the Northern Rock affair on 24 January 2008. Wanless's role as Chairman of the Risk Committee, was criticised in the report. The report's conclusion is appended below, and the full report may be found as referenced.\n\n"}
{"id": "19721986", "url": "https://en.wikipedia.org/wiki?curid=19721986", "title": "Directed graph", "text": "Directed graph\n\nIn mathematics, and more specifically in graph theory, a directed graph (or digraph) is a graph that is a set of vertices connected by edges, where the edges have a direction associated with them.\n\nIn formal terms, a directed graph is an ordered pair where\n\nIt differs from an ordinary or undirected graph, in that the latter is defined in terms of unordered pairs of vertices, which are usually called \"edges\", \"arcs\", or \"lines\".\n\nThe aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arrows (namely, they allow the arrows set to be a multiset). More specifically, these entities are addressed as directed multigraphs (or multidigraphs).<br>\nOn the other hand, the aforementioned definition allows a directed graph to have loops (that is, arrows that connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops.\nMore specifically, directed graphs without loops are addressed as simple directed graphs, while directed graphs with loops are addressed as \"loop-digraphs\" (see section Types of directed graphs).\n\n\n\nAn arrow is considered to be directed \"from\" \"x\" \"to\" \"y\"; \"y\" is called the \"head\" and \"x\" is called the \"tail\" of the arrow; \"y\" is said to be a \"direct successor\" of \"x\" and \"x\" is said to be a \"direct predecessor\" of \"y\". If a path leads from \"x\" to \"y\", then \"y\" is said to be a \"successor\" of \"x\" and \"reachable\" from \"x\", and \"x\" is said to be a \"predecessor\" of \"y\". The arrow is called the \"inverted arrow\" of .\n\nThe adjacency matrix of a multidigraph with loops is the integer-valued matrix with rows and columns corresponding to the vertices, where a nondiagonal entry \"a\" is the number of arrows from vertex \"i\" to vertex \"j\", and the diagonal entry \"a\" is the number of loops at vertex \"i\". The adjacency matrix of a directed graph is unique up to identical permutation of rows and columns.\n\nAnother matrix representation for a directed graph is its incidence matrix.\n\nSee direction for more definitions.\n\nFor a vertex, the number of head ends adjacent to a vertex is called the \"indegree\" of the vertex and the number of tail ends adjacent to a vertex is its \"outdegree\" (called \"branching factor\" in trees).\n\nLet and . The indegree of \"v\" is denoted deg(\"v\") and its outdegree is denoted deg(\"v\").\n\nA vertex with is called a \"source\", as it is the origin of each of its outcoming arrows. Similarly, a vertex with is called a \"sink\", since it is the end of each of its incoming arrows.\n\nIf a vertex is neither a \"source\" nor a \"sink\", it is called an \"internal\". \n\nThe \"degree sum formula\" states that, for a directed graph,\n\nIf for every vertex , , the graph is called a \"balanced directed graph\".\n\nThe degree sequence of a directed graph is the list of its indegree and outdegree pairs; for the above example we have degree sequence ((2, 0), (2, 2), (0, 2), (1, 1)). The degree sequence is a directed graph invariant so isomorphic directed graphs have the same degree sequence. However, the degree sequence does not, in general, uniquely identify a directed graph; in some cases, non-isomorphic digraphs have the same degree sequence.\n\nThe directed graph realization problem is the problem of finding a directed graph with the degree sequence a given sequence of positive integer pairs. (Trailing pairs of zeros may be ignored since they are trivially realized by adding an appropriate number of isolated vertices to the directed graph.) A sequence which is the degree sequence of some directed graph, i.e. for which the directed graph realization problem has a solution, is called a directed graphic or directed graphical sequence. This problem can either be solved by the Kleitman–Wang algorithm or by the Fulkerson–Chen–Anstee theorem.\n\nA directed graph is \"weakly connected\" (or just \"connected\") if the undirected \"underlying graph\" obtained by replacing all directed edges of the graph with undirected edges is a connected graph. A directed graph is \"strongly connected\" or \"strong\" if it contains a directed path from \"x\" to \"y\" and a directed path from \"y\" to \"x\" for every pair of vertices }. The \"strong components\" are the maximal strongly connected subgraphs.\n\n\n"}
{"id": "43239696", "url": "https://en.wikipedia.org/wiki?curid=43239696", "title": "Discipline-based education research", "text": "Discipline-based education research\n\nDiscipline-based education research (DBER) is an interdisciplinary research enterprise that \"investigates learning and teaching in a discipline [normally from the STEM fields] from a perspective that reflects the discipline's priorities, worldview, knowledge, and practices.\"\n\n\n"}
{"id": "2767626", "url": "https://en.wikipedia.org/wiki?curid=2767626", "title": "Five Equations That Changed the World", "text": "Five Equations That Changed the World\n\nFive Equations That Changed the World: The Power and Poetry of Mathematics is a book by Michael Guillen, published in 1995.\nIt is divided into five chapters that talk about five different equations in physics and the people who have developed them.\nThe scientists and their equations are:\n\nThe book is a light study in science and history, portraying the preludes to and times and settings of discoveries that have been the basis of further development, including space travel, flight and nuclear power. Each chapter of the book is divided into sections titled Veni, Vidi, Vici.\n\nThe reviews of the book have been mixed. \"Publishers Weekly\" called it \"wholly accessible, beautifully written\", \"Kirkus Reviews\" wrote that it is a \"crowd-pleasing kind of book designed to make the science as palatable as possible\", and Frank Mahnke wrote that Guillen \"has a nice touch for the history of mathematics and physics and their impact on the world\". However, in contrast, Charles Stephens panned \"the superficiality of the author's treatment of scientific ideas\", and the editors of \"The Capital Times\" called the book a \"miserable failure\" at its goal of helping the public appreciate the beauty of mathematics.\n\n"}
{"id": "19535600", "url": "https://en.wikipedia.org/wiki?curid=19535600", "title": "HMMER", "text": "HMMER\n\nHMMER is a free and commonly used software package for sequence analysis written by Sean Eddy. Its general usage is to identify homologous protein or nucleotide sequences, and to perform sequence alignments. It detects homology by comparing a profile-HMM to either a single sequence or a database of sequences. Sequences that score significantly better to the profile-HMM compared to a null model are considered to be homologous to the sequences that were used to construct the profile-HMM. Profile-HMMs are constructed from a multiple sequence alignment in the HMMER package using the \"hmmbuild\" program. The profile-HMM implementation used in the HMMER software was based on the work of Krogh and colleagues. HMMER is a console utility ported to every major operating system, including different versions of Linux, Windows, and Mac OS.\n\nHMMER is the core utility that protein family databases such as Pfam and InterPro are based upon. Some other bioinformatics tools such as UGENE also use HMMER.\n\nHMMER3 also makes extensive use of vector instructions for increasing computational speed. This work is based upon earlier publication showing a significant acceleration of the Smith-Waterman algorithm for aligning two sequences.\n\nA profile HMM is a variant of an HMM relating specifically to biological sequences. Profile HMMs turn a multiple sequence alignment into a position-specific scoring system, which can be used to align sequences and search databases for remotely homologous sequences. They capitalise on the fact that certain positions in a sequence alignment tend to have biases in which residues are most likely to occur, and are likely to differ in their probability of containing an insertion or a deletion. Capturing this information gives them a better ability to detect true homologs than traditional BLAST-based approaches, which penalise substitutions, insertions and deletions equally, regardless of where in an alignment they occur.\n\nProfile HMMs center around a linear set of match (M) states, with one state corresponding to each consensus column in a sequence alignment. Each M state emits a single residue (amino acid or nucleotide). The probability of emitting a particular residue is determined largely by the frequency at which that residue has been observed in that column of the alignment, but also incorporates prior information on patterns of residues that tend to co-occur in the same columns of sequence alignments. This string of match states emitting amino acids at particular frequencies are analogous to position specific score matrices or weight matrices.\n\nA profile HMM takes this modelling of sequence alignments further by modelling insertions and deletions, using I and D states, respectively. D states do not emit a residue, while I states do emit a residue. Multiple I states can occur consecutively, corresponding to multiple residues between consensus columns in an alignment. M, I and D states are connected by state transition probabilities, which also vary by position in the sequence alignment, to reflect the different frequencies of insertions and deletions across sequence alignments.\n\nThe HMMER2 and HMMER3 releases used an architecture for building profile HMMs called the Plan 7 architecture, named after the seven states captured by the model. In addition to the three major states (M, I and D), six additional states capture non-homologous flanking sequence in the alignment. These 6 states collectively are important for controlling how sequences are aligned to the model e.g. whether a sequence can have multiple consecutive hits to the same model (in the case of sequences with multiple instances of the same domain).\n\nThe HMMER package consists of a collection of programs for performing functions using profile hidden Markov models. The programs include:\n\n\n\n\nThe package contains numerous other specialised functions.\n\nIn addition to the software package, the HMMER search function is available in the form of a web server. The service facilitates searches across a range of databases, including sequence databases such as UniProt, SwissProt, and the Protein Data Bank, and HMM databases such as Pfam, TIGRFAMs and SUPERFAMILY. The four search types phmmer, hmmsearch, hmmscan and jackhmmer are supported (see Programs). The search function accepts single sequences as well as sequence alignments or profile HMMs.\n\nThe search results are accompanied by a report on the taxonomic breakdown, and the domain organisation of the hits. Search results can then be filtered according to either parameter.\n\nThe web service is currently run out of the European Bioinformatics Institute (EBI) in the United Kingdom, while development of the algorithm is still performed by Sean Eddy's team in the United States. Major reasons for relocating the web service were to leverage the computing infrastructure at the EBI, and to cross-link HMMER searches with relevant databases that are also maintained by the EBI.\n\nThe latest stable release of HMMER is version 3.0. HMMER3 is complete rewrite of the earlier HMMER2 package, with the aim of improving the speed of profile-HMM searches. Major changes are outlined below:\n\nA major aim of the HMMER3 project, started in 2004 was to improve the speed of HMMER searches. While profile HMM-based homology searches were more accurate than BLAST-based approaches, their slower speed limited their applicability. The main performance gain is due to a heuristic filter that finds high-scoring un-gapped matches within database sequences to a query profile. This heuristic results in a computation time comparable to BLAST with little impact on accuracy. Further gains in performance are due to a log-likelihood model that requires no calibration for estimating E-values, and allows the more accurate forward scores to be used for computing the significance of a homologous sequence.\n\nHMMER still lags behind BLAST in speed of DNA-based searches, however DNA-based searches can be tuned, such that an improvement in speed comes at the expense of accuracy.\n\nThe major advance in speed was made possible by the development of an approach for calculating the significance of results integrated over a range of possible alignments. In discovering remote homologs, alignments between query and hit proteins are often very uncertain. While most sequence alignment tools calculate match scores using only the best scoring alignment, HMMER3 calculates match scores by integrating across all possible alignments, to account for uncertainty in which alignment is best. HMMER sequence alignments are accompanied by posterior probability annotations, indicating which portions of the alignment have been assigned high confidence and which are more uncertain.\n\nA major improvement in HMMER3 was the inclusion of DNA/DNA comparison tools. HMMER2 only had functionality to compare protein sequences.\n\nWhile HMMER2 could perform glocal alignment (align a complete model to a subsequence of the target) and global alignment (align a complete model to a complete target sequence) as well as local alignment, HMMER3 only performs local alignment. This restriction is due to the difficulty in calculating the significance of hits when performing glocal/global alignments using the new algorithm.\n\n\nSeveral implementations of profile HMM methods and related position-specific scoring matrix methods are available. Some are listed below:\n\n"}
{"id": "39521086", "url": "https://en.wikipedia.org/wiki?curid=39521086", "title": "Half-carry flag", "text": "Half-carry flag\n\nA half-carry flag (also known as an auxiliary flag or decimal adjust flag) is a condition flag bit in the status register of many CPU families, such as the Intel 8080, Zilog Z80, the x86, and the Atmel AVR series, among others. It indicates when a carry or borrow has been generated out of the least significant four bits of the accumulator register following the execution of an arithmetic instruction. It is primarily used in decimal (BCD) arithmetic instructions.\n\nNormally, a processor that utilizes binary arithmetic (which includes almost all modern CPUs) will add two 8-bit byte values according to the rules of simple binary addition. For example, adding 25 and 48 produces 6D. However, for binary-coded decimal (BCD) values, where each 4-bit nibble represents a decimal digit, addition is more complicated. For example, adding the decimal value 25 and 48, which are encoded as the BCD values 25 and 48, the binary addition of the two values produces 6D. Since the lower nibble of this value is a non-decimal digit (D), it must be adjusted by adding 06 to produce the correct BCD result of 73, which represents the decimal value 73.\n\nLikewise, adding the BCD values 39 and 48 produces 81. This result does not have a non-decimal low nibble, but it does cause a carry out of the least significant digit (lower four bits) into the most significant digit (upper four bits). This is indicated by the CPU setting the half-carry flag. This value must also be corrected, by adding 06 to 81 to produce a corrected BCD result of 87.\n\nFinally, if an addition results in a non-decimal high digit, then 60 must be added to the value to produce the correct BCD result. For example, adding 72 and 73 produces E5. Since the most significant digit of this sum is non-decimal (E), adding 60 to it produces a corrected BCD result of 145. (Note that the leading 1 digit is actually a carry bit.)\n\nSummarizing, if the result of a binary addition contains a non-decimal low digit or causes the half-carry flag to be set, the result must be corrected by adding 06 to it; if the result contains a non-decimal high digit, the result must be further corrected by adding 60 to produce the correct final BCD value.\n\n"}
{"id": "19088928", "url": "https://en.wikipedia.org/wiki?curid=19088928", "title": "Helly metric", "text": "Helly metric\n\nIn game theory, the Helly metric is used to assess the distance between two strategies. It is named for Eduard Helly.\n\nConsider a game formula_1, between player I and II. Here, formula_2 and formula_3 are the sets of pure strategies for players I and II respectively; and formula_4 is the payoff function.\n\n(in other words, if player I plays formula_5 and player II plays formula_6, then player I pays formula_7 to player II).\n\nThe Helly metric formula_8 is defined as\n\nThe metric so defined is symmetric, reflexive, and satisfies the triangle inequality.\n\nThe Helly metric measures distances between strategies, not in terms of the differences between the strategies themselves, but in terms of the consequences of the strategies. Two strategies are distant if their payoffs are different. Note that formula_10 does not imply formula_11 but it does imply that the \"consequences\" of formula_12 and formula_13 are identical; and indeed this induces an equivalence relation.\n\nIf one stipulates that formula_10 implies formula_11 then the topology so induced is called the natural topology.\n\nThe metric on the space of player II's strategies is analogous:\n\nNote that formula_17 thus defines \"two\" Helly metrics: one for each player's strategy space.\n\nNotation (definition of an formula_18-net). A set formula_19 is an formula_18-net in the space formula_21 with metric formula_22 if for any formula_23 there exists formula_24 with formula_25.\n\nA metric space formula_26 is conditionally compact if for any formula_27 there exists a \"finite\" formula_18-net in formula_26.\n\nA game that is conditionally compact in the Helly metric has an formula_18-optimal strategy for any formula_27.\n\nIf the space of strategies for one player is conditionally compact, then the space of strategies for the other player is conditionally compact (in their Helly metric).\n\nN. N. Vorob'ev 1977. \"Game theory lectures for economists and systems scientists\". Springer-Verlag (translated by S. Kotz).\n"}
{"id": "14943332", "url": "https://en.wikipedia.org/wiki?curid=14943332", "title": "Hiroshima Mathematical Journal", "text": "Hiroshima Mathematical Journal\n\nThe Hiroshima Mathematical Journal is an open-access mathematics journal that continues the \"Journal of Science of the Hiroshima University, Series A\" (1930–1960) and \"Journal of Science of the Hiroshima University, Series A - I\" (1961–1970). The journal contains original research papers in pure and applied mathematics. Each annual volume has had three issues since 1974.\n\n"}
{"id": "54400069", "url": "https://en.wikipedia.org/wiki?curid=54400069", "title": "Holmes–Thompson volume", "text": "Holmes–Thompson volume\n\nIn geometry of normed spaces, the Holmes–Thompson volume is a notion of volume that allows to compare sets contained in different normed spaces (of the same dimension). It was introduced by Raymond D. Holmes and Anthony Charles Thompson.\n\nThe Holmes–Thompson volume formula_1 of a measurable set formula_2 in a normed space formula_3 is defined as the 2\"n\"-dimensional measure of the product set formula_4 where formula_5 is the dual unit ball of formula_6 (the unit ball of the dual norm formula_7).\n\nThe Holmes–Thompson volume can be defined without coordinates: if formula_8 is a measurable set in an \"n\"-dimensional real normed space formula_9 then its Holmes–Thompson volume is defined as the absolute value of the integral of the volume form formula_10 over the set formula_11,\n\nwhere formula_13 is the standard symplectic form on the vector space formula_14 and formula_15 is the dual unit ball of formula_16.\n\nThis definition is consistent with the previous one, because if each vector formula_17 is given linear coordinates formula_18 and each covector formula_19 is given the dual coordinates formula_20 (so that formula_21), then the standard symplectic form is formula_22, and the volume form is\n\nwhose integral over the set formula_24 is just the usual volume of the set in the coordinate space formula_25.\n\nMore generally, the Holmes–Thompson volume of a measurable set formula_26 in a Finsler manifold formula_27 can be defined as\n\nwhere formula_29 and formula_30 is the standard symplectic form on the cotangent bundle formula_31. Holmes–Thompson's definition of volume is appropriate for establishing links between the total volume of a manifold and the length of the geodesics (shortest curves) contained in it (such as systolic inequalities and filling volumes) because, according to Liouville's theorem, the geodesic flow preserves the symplectic volume of sets in the cotangent bundle.\n\nIf formula_32 is a region in coordinate space formula_33, then the tangent and cotangent spaces at each point formula_34 can both be identified with formula_33. The Finsler metric is a continuous function formula_36 that yields a (possibly asymmetric) norm formula_37 for each point formula_34. The Holmes–Thompson volume of a subset can be computed as\n\nwhere for each point formula_34, the set formula_41 is the dual unit ball of formula_42 (the unit ball of the dual norm formula_43), the bars formula_44 denote the usual volume of a subset in coordinate space, and formula_45 is the product of all coordinate differentials formula_46.\n\nThis formula follows, again, from the fact that the -form formula_47 is equal (up to a sign) to the product of the differentials of all formula_48 coordinates formula_49 and their dual coordinates formula_50. The Holmes–Thompson volume of is then equal to the usual volume of the subset formula_51 of formula_52.\n\nIf formula_26 is a simple region in a Finsler manifold (that is, a region homeomorphic to a ball, with convex boundary and a unique geodesic along formula_26 joining each pair of points of formula_26), then its Holmes–Thompson volume can be computed in terms of the path-length distance (along formula_26) between the boundary points of formula_26 using Santaló's formula, which in turn is based on the fact that the geodesic flow on the cotangent bundle is Hamiltonian.\n\nThe original authors used a different normalization for Holmes–Thompson volume. They divided the value given here by the volume of the Euclidean \"n\"-ball, to make Holmes–Thompson volume coincide with the product measure in the standard Euclidean space formula_58. This article does not follow that convention.\n\nIf the Holmes–Thompson volume in normed spaces (or Finsler manifolds) is normalized, then it never exceeds the Hausdorff measure. This is a consequence of the Blaschke-Santaló inequality. The equality holds if and only if the space is Euclidean (or a Riemannian manifold).\n"}
{"id": "28192978", "url": "https://en.wikipedia.org/wiki?curid=28192978", "title": "Major index", "text": "Major index\n\nIn mathematics (and particularly in combinatorics), the major index of a permutation is the sum of the positions of the descents of the permutation. In symbols, the major index of the permutation \"w\" is\n\nFor example, if \"w\" is given in one-line notation by \"w\" = 351624 (that is, \"w\" is the permutation of {1, 2, 3, 4, 5, 6} such that \"w\"(1) = 3, \"w\"(2) = 5, etc.) then \"w\" has descents at positions 2 (from 5 to 1) and 4 (from 6 to 2) and so maj(\"w\") = 2 + 4 = 6.\n\nThis statistic is named after Major Percy Alexander MacMahon who showed in 1913 that the distribution of the major index on all permutations of a fixed length is the same as the distribution of inversions. That is, the number of permutations of length \"n\" with \"k\" inversions is the same as the number of permutations of length \"n\" with major index equal to \"k\". (These numbers are known as \"Mahonian numbers\", also in honor of MacMahon.) In fact, a stronger result is true: the number of permutations of length \"n\" with major index \"k\" and \"i\" inversions is the same as the number of permutations of length \"n\" with major index \"i\" and \"k\" inversions, that is, the two statistics are equidistributed. For example, the number of permutations of length 4 with given major index and number of inversions is given in the table below.\n"}
{"id": "735426", "url": "https://en.wikipedia.org/wiki?curid=735426", "title": "Matroid embedding", "text": "Matroid embedding\n\nIn combinatorics, a matroid embedding is a set system (F, \"E\"), where F is a collection of \"feasible sets\", that satisfies the following properties:\n\nMatroid embedding was introduced by to characterize problems that can be optimized by a greedy algorithm.\n"}
{"id": "11904406", "url": "https://en.wikipedia.org/wiki?curid=11904406", "title": "Mazur's lemma", "text": "Mazur's lemma\n\nIn mathematics, Mazur's lemma is a result in the theory of Banach spaces. It shows that any weakly convergent sequence in a Banach space has a sequence of convex combinations of its members that converges strongly to the same limit, and is used in the proof of Tonelli's theorem.\n\nLet (\"X\", || ||) be a Banach space and let (\"u\") be a sequence in \"X\" that converges weakly to some \"u\" in \"X\":\n\nThat is, for every continuous linear functional \"f\" in \"X\", the continuous dual space of \"X\",\n\nThen there exists a function \"N\" : N → N and a sequence of sets of real numbers\n\nsuch that \"α\"(\"n\") ≥ 0 and\n\nsuch that the sequence (\"v\") defined by the convex combination\n\nconverges strongly in \"X\" to \"u\", i.e.\n"}
{"id": "53733761", "url": "https://en.wikipedia.org/wiki?curid=53733761", "title": "Minerva Cordero", "text": "Minerva Cordero\n\nMinerva Cordero is a Puerto Rican mathematician, and a professor of mathematics at the University of Texas at Arlington. She is also the university's associate dean of academic affairs.\n\nCordero was born in Bayamón, Puerto Rico. Her mother, whose schooling stopped after the fifth grade, made education a top priority in the family home. She told her children \"the best thing I can give you is an education.\" Cordero and her siblings would do their homework together and discussed what they learned in school each day. Cordero said, \"We learned each other's subjects\". Wanting to go to college, Cordero bought herself an SAT preparation book in high school and studied for the exam. Her SAT exam scores are the highest scores for her high school, Miguel Melendez Munoz High School.\n\nCordero attended the Universidad de Puerto Rico and received her B.S. degree in 1981. She applied for and was granted a National Science Foundation Minority Graduate Fellowship. She applied to graduate schools in the United States and was accepted by the University of California Berkeley. Cordero graduated from Berkeley in 1983 with a M.S. in Mathematics. She continued her studies at the University of Iowa, and obtained her PhD in 1989.\n\nAfter earning her PhD, she worked as an Associate and Assistant Professor at Texas Tech University until 2011, when she joined the faculty at Arlington. She studies finite geometry. Cordero served as the Mathematical Association of America's Governor-at-Large for Minority Interests from 2008 to 2011. Her most cited work is \"A survey of finite semifields\". She was the Principal Investigator for a $2.85 million National Science Foundation grant awarded to the University of Texas Arlington in 2009 for a project that places graduate students in Arlington public schools to improve math teaching. \n\nIn 1994, Cordero received the New Faculty Award at Texas Tech University. In 1995, she was awarded Professor of the Year by the student chapter of the Mathematical Association of America at Texas Tech University. In 2009 she was among nine faculty members to receive the Board of Regents' Outstanding Teaching Awards at the University of Texas Arlington. Dr. Cordero was recognized as Ford’s 2016 \"Legendary Woman\"\n"}
{"id": "25809225", "url": "https://en.wikipedia.org/wiki?curid=25809225", "title": "Multi-level technique", "text": "Multi-level technique\n\nIn mathematics, the multi-level technique is a technique used to solve the graph partitioning problem.\n\nThe idea of the multi-level technique is to reduce the magnitude of a graph by merging vertices together, compute a partition on this reduced graph, and finally project this partition on the original graph.\n\nIn the first phase the magnitude of the graph is reduced by merging vertices. The merging of vertices is done iteratively: of a graph a new coarser graph is created and of this new coarser graph an even more coarse graph is created. This is done until a certain small magnitude is reached. Thus graphs with different magnitudes are induced.\n\nIn the second phase a partition of the graph with the smallest magnitude – the coarsest graph – is computed.\n\nIn the third and last phase, the computed partition is iteratively projected back to the original graph. In each iteration a refinement heuristic is applied. The merging of vertices induces a map between vertices of a graph and vertices of its coarser graph which is used for the back projection. A rebalancing to insure the size of the partition may be needed since vertices not belonging to the same partition may be merged.\n\nThe multi-level technique has shown to significantly improve the results, in terms of both quality and running time. Especially when used on heuristics considering the graph only locally, as the multi-level technique constitutes a more global view on the graph.\n"}
{"id": "4003614", "url": "https://en.wikipedia.org/wiki?curid=4003614", "title": "Multiscale modeling", "text": "Multiscale modeling\n\nIn engineering, mathematics, physics, chemistry, bioinformatics, computational biology, meteorology and computer science, multiscale modeling or multiscale mathematics is the field of solving problems which have important features at multiple scales of time and/or space. Important problems include multiscale modeling of fluids, solids, polymers, proteins, nucleic acids as well as various physical and chemical phenomena (like adsorption, chemical reactions, diffusion).\n\nHorstemeyer 2009, 2012 presented a historical review of the different disciplines (solid mechanics, numerical methods, mathematics, physics, and materials science) for solid materials related to multiscale materials modeling.\n\nThe aforementioned DOE multiscale modeling efforts were hierarchical in nature. The first concurrent multiscale model occurred when Michael Ortiz (Caltech) took the molecular dynamics code, Dynamo, (developed by Mike Baskes at Sandia National Labs) and with his students embedded it into a finite element code for the first time. Martin Karplus, Michael Levitt, Arieh Warshel 2013 were awarded a Nobel Prize in Chemistry for the development of a multiscale model method using both classical and quantum mechanical theory which were used to model large complex chemical systems and reactions.\n\nIn physics and chemistry, multiscale modeling is aimed to calculation of material properties or system behavior on one level using information or models from different levels. On each level particular approaches are used for description of a system. The following levels are usually distinguished: level of quantum mechanical models (information about electrons is included), level of molecular dynamics models (information about individual atoms is included), coarse-grained models (information about atoms and/or groups of atoms is included), mesoscale or nano level (information about large groups of atoms and/or molecule positions is included), level of continuum models, level of device models. Each level addresses a phenomenon over a specific window of length and time. Multiscale modeling is particularly important in integrated computational materials engineering since it allows the prediction of material properties or system behavior based on knowledge of the process-structure-property relationships.\n\nIn operations research, multiscale modeling addresses challenges for decision makers which come from multiscale phenomena across organizational, temporal and spatial scales. This theory fuses decision theory and multiscale mathematics and is referred to as multiscale decision-making. Multiscale decision-making draws upon the analogies between physical systems and complex man-made systems.\n\nIn meteorology, multiscale modeling is the modeling of interaction between weather systems of different spatial and temporal scales that produces the weather that we experience. The most challenging task is to model the way through which the weather systems interact as models cannot see beyond the limit of the model grid size. In other words, to run an atmospheric model that is having a grid size (very small ~ ) which can see each possible cloud structure for the whole globe is computationally very expensive. On the other hand, a computationally feasible Global climate model (GCM), with grid size ~ , cannot see the smaller cloud systems. So we need to come to a balance point so that the model becomes computationally feasible and at the same time we do not lose much information, with the help of making some rational guesses, a process called Parametrization.\n\nBesides the many specific applications, one area of research is methods for the accurate and efficient solution of multiscale modeling problems. The primary areas of mathematical and algorithmic development include:\n\n\n\n"}
{"id": "48572227", "url": "https://en.wikipedia.org/wiki?curid=48572227", "title": "Nataša Šešum", "text": "Nataša Šešum\n\nNataša Šešum is a Professor of mathematics at Rutgers University, specializing in partial differential equations and geometric flow.\n\nŠešum earned her Ph.D. in 2004 from the Massachusetts Institute of Technology under the supervision of Gang Tian. Her dissertation was \"Limiting Behavior of Ricci Flows\".\n\nŠešum was an invited speaker at the International Congress of Mathematicians in 2014.\nIn 2015 she was elected as a fellow of the American Mathematical Society.\n\n \n"}
{"id": "39726151", "url": "https://en.wikipedia.org/wiki?curid=39726151", "title": "Negative hypergeometric distribution", "text": "Negative hypergeometric distribution\n\n=\\frac}{N \\choose K}.\n</math>\n\nTherefore, a random variable follows the negative hypergeometric distribution if its probability mass function (pmf) is given by\n\nformula_1\n\nwhere\nBy design the probabilities sum up to 1. However, in case we want show it explicitly we have:\n\nformula_7\n\nwhere we have used that,\n\nformula_8\n\nwhich can be derived using the binomial identity, formula_9, and the Chu–Vandermonde identity, formula_10, which holds for any complex-values formula_11 and formula_12 and any non-negative integer formula_5. \n\nThe relationship formula_14 can also be found by examination of the coefficient of formula_15 in the expansion of formula_16, using Newton's binomial series.\n\nWhen counting the number formula_5 of successes before formula_4 failures, the expected number of successes is formula_19 and can be derived as follows. \n\nformula_20\n"}
{"id": "3121852", "url": "https://en.wikipedia.org/wiki?curid=3121852", "title": "Order dimension", "text": "Order dimension\n\nIn mathematics, the dimension of a partially ordered set (poset) is the smallest number of total orders the intersection of which gives rise to the partial order.\nThis concept is also sometimes called the order dimension or the Dushnik–Miller dimension of the partial order.\n\nThe dimension of a poset \"P\" is the least integer \"t\" for which there exists a family \n\nof linear extensions of \"P\" so that, for every \"x\" and \"y\" in \"P\", \"x\" precedes \"y\" in \"P\" if and only if it precedes \"y\" in each of the linear extensions. That is,\n\nAn alternative definition of order dimension is as the minimal number of total orders such that \"P\" embeds to the product of these total orders for the componentwise ordering, in which formula_3 if and only if formula_4 for all \"i\" (, ).\n\nA family formula_1 of linear orders on \"X\" is called a realizer of a poset \"P\" = (\"X\", <) if \n\nwhich is to say that for any \"x\" and \"y\" in \"X\",\n\"x\" < \"y\" precisely when \"x\" < \"y\", \"x\" < \"y\", ..., and \"x\" < \"y\".\nThus, an equivalent definition of the dimension of a poset \"P\" is \"the least cardinality of a realizer of \"P\".\"\n\nIt can be shown that any nonempty family \"R\" of linear extensions is a realizer of a finite partially ordered set \"P\" if and only if, for every critical pair (\"x\",\"y\") of \"P\", \"y\" < \"x\" for some order\n< in \"R\".\n\nLet \"n\" be a positive integer, and let \"P\" be the partial order on the elements \"a\" and \"b\" (for 1 ≤ \"i\" ≤ \"n\") in which \"a\" ≤ \"b\" whenever \"i\" ≠ \"j\", but no other pairs are comparable. In particular, \"a\" and \"b\" are incomparable in \"P\"; \"P\" can be viewed as an oriented form of a crown graph. The illustration shows an ordering of this type for \"n\" = 4.\n\nThen, for each \"i\", any realizer must contain a linear order that begins with all the \"a\" except \"a\" (in some order), then includes \"b\", then \"a\", and ends with all the remaining \"b\". This is so because if there were a realizer that didn't include such an order, then the intersection of that realizer's orders would have \"a\" preceding \"b\", which would contradict the incomparability of \"a\" and \"b\" in \"P\". And conversely, any family of linear orders that includes one order of this type for each \"i\" has \"P\" as its intersection. Thus, \"P\" has dimension exactly \"n\". In fact, \"P\" is known as the \"standard example\" of a poset of dimension \"n\", and is usually denoted by \"S\".\n\nThe partial orders with order dimension two may be characterized as the partial orders whose comparability graph is the complement of the comparability graph of a different partial order . That is, \"P\" is a partial order with order dimension two if and only if there exists a partial order \"Q\" on the same set of elements, such that every pair \"x\", \"y\" of distinct elements is comparable in exactly one of these two partial orders. If \"P\" is realized by two linear extensions, then partial order \"Q\" complementary to \"P\" may be realized by reversing one of the two linear extensions. Therefore, the comparability graphs of the partial orders of dimension two are exactly the permutation graphs, graphs that are both themselves comparability graphs and complementary to comparability graphs.\n\nThe partial orders of order dimension two include the series-parallel partial orders . They are exactly the partial orders whose Hasse diagrams have dominance drawings, which can be obtained by using the positions in the two permutations of a realizer as Cartesian coordinates.\n\nIt is possible to determine in polynomial time whether a given finite partially ordered set has order dimension at most two, for instance, by testing whether the comparability graph of the partial order is a permutation graph. However, for any \"k\" ≥ 3, it is NP-complete to test whether the order dimension is at most \"k\" .\n\nThe incidence poset of any undirected graph \"G\" has the vertices and edges of \"G\" as its elements; in this poset, \"x\" ≤ \"y\" if either \"x\" = \"y\" or \"x\" is a vertex, \"y\" is an edge, and \"x\" is an endpoint of \"y\". Certain kinds of graphs may be characterized by the order dimensions of their incidence posets: a graph is a path graph if and only if the order dimension of its incidence poset is at most two, and according to Schnyder's theorem it is a planar graph if and only if the order dimension of its incidence poset is at most three .\n\nFor a complete graph on \"n\" vertices, the order dimension of the incidence poset is formula_7 . It follows that all simple \"n\"-vertex graphs have incidence posets with order dimension formula_8.\n\nA generalization of dimension is the notion of \"k\"-dimension (written formula_9) which is the minimal number of chains of length at most \"k\" in whose product the partial order can be embedded. In particular, the 2-dimension of an order can be seen as the size of the smallest set such that the order embeds in the containment order on this set.\n\n\n"}
{"id": "37939813", "url": "https://en.wikipedia.org/wiki?curid=37939813", "title": "PBR theorem", "text": "PBR theorem\n\nThe PBR theorem is a theorem about the physical reality of quantum states due to Matthew Pusey, Jonathan Barrett, and Terry Rudolph, named after the initial letters of their surnames.\n\nThe theorem was first published as an arXiv preprint, with a subsequent version published in \"Nature Physics\". The theorem states that either the quantum state corresponds to a physically real object and is not merely a statistical tool, or else all quantum states, including non-entangled ones, can communicate by action at a distance. This preliminary result has been referred to as Pusey's theorem or the PBR theorem, and has been cited by theoretical physicist Antony Valentini as \"the most important general theorem relating to the foundations of quantum mechanics since Bell's theorem\". A revised version was released on 7 May 2012.\n\n"}
{"id": "3808674", "url": "https://en.wikipedia.org/wiki?curid=3808674", "title": "Plotkin bound", "text": "Plotkin bound\n\nIn the mathematics of coding theory, the Plotkin bound, named after Morris Plotkin, is a limit (or bound) on the maximum possible number of codewords in binary codes of given length \"n\" and given minimum distance \"d\".\n\nA code is considered \"binary\" if the codewords use symbols from the binary alphabet formula_1. In particular, if all codewords have a fixed length \"n\",\nthen the binary code has length \"n\". Equivalently, in this case the codewords can be considered elements of vector space formula_2 over the finite field formula_3. Let formula_4 be the minimum \ndistance of formula_5, i.e. \nwhere formula_7 is the Hamming distance between formula_8 and formula_9. The expression formula_10 represents the maximum number of possible codewords in a binary code of length formula_11 and minimum distance formula_4. The Plotkin bound places a limit on this expression.\n\nTheorem (Plotkin bound):\n\ni) If formula_4 is even and formula_14, then\n\nii) If formula_4 is odd and formula_17, then\n\niii) If formula_4 is even, then\n\niv) If formula_4 is odd, then\n\nwhere formula_23 denotes the floor function.\n\nLet formula_7 be the Hamming distance of formula_8 and formula_9, and formula_27 be the number of elements in formula_5 (thus, formula_27 is equal to formula_10). The bound is proved by bounding the quantity formula_31 in two different ways.\n\nOn the one hand, there are formula_27 choices for formula_8 and for each such choice, there are formula_34 choices for formula_9. Since by definition formula_36 for all formula_8 and formula_9 (formula_39), it follows that\n\nOn the other hand, let formula_41 be an formula_42 matrix whose rows are the elements of formula_5. Let formula_44 be the number of zeros contained in the formula_45'th column of formula_41. This means that the formula_45'th column contains formula_48 ones. Each choice of a zero and a one in the same column contributes exactly formula_49 (because formula_50) to the sum formula_51 and therefore\n\nThe quantity on the right is maximized if and only if formula_53 holds for all formula_45 (at this point of the proof we ignore the fact, that the formula_44 are integers), then\n\nCombining the upper and lower bounds for formula_57 that we have just derived,\n\nwhich given that formula_59 is equivalent to\n\nSince formula_27 is even, it follows that\n\nThis completes the proof of the bound.\n\n"}
{"id": "1236666", "url": "https://en.wikipedia.org/wiki?curid=1236666", "title": "Pointed space", "text": "Pointed space\n\nIn mathematics, a pointed space is a topological space with a distinguished point, the basepoint. The distinguished point is just simply one particular point, picked out from the space, and given a name, such as \"x\", that remains unchanged during subsequent discussion, and is kept track of during all operations.\n\nMaps of pointed spaces (based maps) are continuous maps preserving basepoints, i.e., a map \"f\" between a pointed space \"X\" with basepoint \"x\" and a pointed space \"Y\" with basepoint \"y\" is a based map if it is continuous with respect to the topologies of \"X\" and \"Y\" and if \"f\"(\"x\") = \"y\". This is usually denoted\nPointed spaces are important in algebraic topology, particularly in homotopy theory, where many constructions, such as the fundamental group, depend on a choice of basepoint.\n\nThe pointed set concept is less important; it is anyway the case of a pointed discrete space.\n\nPointed spaces are often taken as a special case of the relative topology, where the subset is a single point. Thus, much of homotopy theory is usually developed on pointed spaces, and then moved to relative topologies in algebraic topology.\n\nThe class of all pointed spaces forms a category Top with basepoint preserving continuous maps as morphisms. Another way to think about this category is as the comma category, ({•} ↓ Top) where {•} is any one point space and Top is the category of topological spaces. (This is also called a coslice category denoted {•}/Top.) Objects in this category are continuous maps {•} → \"X\". Such morphisms can be thought of as picking out a basepoint in \"X\". Morphisms in ({•} ↓ Top) are morphisms in Top for which the following diagram commutes:\n\nIt is easy to see that commutativity of the diagram is equivalent to the condition that \"f\" preserves basepoints.\n\nAs a pointed space, {•} is a zero object in Top, while it is only a terminal object in Top.\n\nThere is a forgetful functor Top → Top which \"forgets\" which point is the basepoint. This functor has a left adjoint which assigns to each topological space \"X\" the disjoint union of \"X\" and a one-point space {•} whose single element is taken to be the basepoint.\n\n\n\n"}
{"id": "1618671", "url": "https://en.wikipedia.org/wiki?curid=1618671", "title": "Quadrature (mathematics)", "text": "Quadrature (mathematics)\n\nIn mathematics, quadrature is a historical term which means the process of determining area. This term is still used nowadays in the context of differential equations, where \"solving an equation by quadrature\" means expressing its solution in terms of integrals.\n\nQuadrature problems served as one of the main sources of problems in the development of calculus, and introduce important topics in mathematical analysis.\n\nMathematicians of ancient Greece, according to the Pythagorean doctrine, understood determination of area of a figure as the process of geometrically constructing a square having the same area (\"squaring\"), thus the name \"quadrature\" for this process. The Greek geometers were not always successful (see quadrature of the circle), but they did carry out quadratures of some figures whose sides were not simply line segments, such as the lunes of Hippocrates and the quadrature of the parabola. By Greek tradition, these constructions had to be performed using only a compass and straightedge.\n\nFor a quadrature of a rectangle with the sides \"a\" and \"b\" it is necessary to construct a square with the side formula_1 (the geometric mean of \"a\" and \"b\"). For this purpose it is possible to use the following: if one draws the circle with diameter made from joining line segments of lengths \"a\" and \"b\", then the height (\"BH\" in the diagram) of the line segment drawn perpendicular to the diameter, from the point of their connection to the point where it crosses the circle, equals the geometric mean of \"a\" and \"b\". A similar geometrical construction solves the problems of quadrature of a parallelogram and of a triangle.\nProblems of quadrature for curvilinear figures are much more difficult. The quadrature of the circle with compass and straightedge was proved in the 19th century to be impossible. Nevertheless, for some figures (for example a lune of Hippocrates) a quadrature can be performed. The quadratures of the surface of a sphere and a parabola segment discovered by Archimedes became the highest achievement of analysis in antiquity.\nFor the proof of these results, Archimedes used the method of exhaustion of Eudoxus.\n\nIn medieval Europe, quadrature meant the calculation of area by any method. Most often the method of indivisibles was used; it was less rigorous than the geometric constructions of the Greeks, but it was simpler and more powerful. With its help, Galileo Galilei and Gilles de Roberval found the area of a cycloid arch, Grégoire de Saint-Vincent investigated the area under a hyperbola (\"Opus Geometricum\", 1647), and Alphonse Antonio de Sarasa, de Saint-Vincent's pupil and commentator, noted the relation of this area to logarithms.\n\nJohn Wallis algebrised this method; he wrote in his \"Arithmetica Infinitorum\" (1656) some series which are equivalent to what is now called the definite integral, and he calculated their values. Isaac Barrow and James Gregory made further progress: quadratures for some algebraic curves and spirals. Christiaan Huygens successfully performed a quadrature of the surface area of some solids of revolution.\n\nThe quadrature of the hyperbola by Saint-Vincent and de Sarasa provided a new function, the natural logarithm, of critical importance. With the invention of integral calculus came a universal method for area calculation. In response, the term \"quadrature\" has become traditional, and instead the modern phrase \"finding the area\" is more commonly used for what is technically the \"computation of a univariate definite integral\".\n\n\n"}
{"id": "9421365", "url": "https://en.wikipedia.org/wiki?curid=9421365", "title": "Rhombitriheptagonal tiling", "text": "Rhombitriheptagonal tiling\n\nIn geometry, the rhombitriheptagonal tiling is a semiregular tiling of the \nhyperbolic plane. At each vertex of the tiling there is one triangle and one heptagon, alternating between two squares. The tiling has Schläfli symbol rr{7, 3}. It can be seen as constructed as a rectified triheptagonal tiling, r{7,3}, as well as an expanded heptagonal tiling or expanded order-7 triangular tiling.\n\nThe dual tiling is called a \"deltoidal triheptagonal tiling\", and consists of congruent kites. It is formed by overlaying an order-3 heptagonal tiling and an order-7 triangular tiling.\n\nFrom a Wythoff construction there are eight hyperbolic uniform tilings that can be based from the regular heptagonal tiling. \n\nDrawing the tiles colored as red on the original faces, yellow at the original vertices, and blue along the original edges, there are 8 forms.\nThis tiling is topologically related as a part of sequence of cantellated polyhedra with vertex figure (3.4.n.4), and continues as tilings of the hyperbolic plane. These vertex-transitive figures have (*n32) reflectional symmetry.\n\n\n\n"}
{"id": "25852", "url": "https://en.wikipedia.org/wiki?curid=25852", "title": "Rice's theorem", "text": "Rice's theorem\n\nIn computability theory, Rice's theorem states that all non-trivial, semantic properties of programs are undecidable. A semantic property is one about the program's behavior (for instance, does the program terminate for all inputs), unlike a syntactic property (for instance, does the program contain an if-then-else statement). A property is \"non-trivial\" if it is neither true for every computable function, nor false for every computable function.\n\nRice's theorem can also be put in terms of functions: for any non-trivial property of partial functions, no general and effective method can decide whether an algorithm computes a partial function with that property. Here, a property of partial functions is called \"trivial\" if it holds for all partial computable functions or for none, and an effective decision method is called \"general\" if it decides correctly for every algorithm.\nThe theorem is named after Henry Gordon Rice, who proved it in his doctoral dissertation of 1951 at Syracuse University. It is also known as the Rice–Myhill–Shapiro theorem after Rice, John Myhill, and Norman Shapiro.\n\nAnother way of stating Rice's theorem that is more useful in computability theory follows.\n\nLet \"S\" be a set of languages that is nontrivial, meaning\nThen, it is undecidable to determine whether the language recognized by an arbitrary Turing machine lies in \"S\".\n\nIn practice, this means that there is no machine that can always decide whether the language of a given Turing machine has a particular nontrivial property. Special cases include the undecidability of whether a Turing machine accepts a particular string, whether a Turing machine recognizes a particular recognizable language, and whether the language recognized by a Turing machine could be recognized by a nontrivial simpler machine, such as a finite automaton.\n\nIt is important to note that Rice's theorem does not say anything about those properties of machines or programs that are not also properties of functions and languages. For example, whether a machine runs for more than 100 steps on some input is a decidable property, even though it is non-trivial. Implementing exactly the same language, two different machines might require a different number of steps to recognize the same input. Similarly, whether a machine has more than 5 states is a decidable property of the machine, as the number of states can simply be counted. Where a property is of the kind that either of the two machines may or may not have it, while still implementing exactly the same language, the property is of the machines and not of the language, and Rice's Theorem does not apply.\n\nUsing Rogers' characterization of acceptable programming systems, Rice's Theorem may essentially be generalized from Turing machines to most computer programming languages: there exists no automatic method that decides with generality non-trivial questions on the behavior of computer programs.\n\nAs an example, consider the following variant of the halting problem. Let \"P\" be the following property of partial functions F of one argument: \"P\"(F) means that F is defined for the argument '1'. It is obviously non-trivial, since there are partial functions that are defined at 1, and others that are undefined at 1. The \"1-halting problem\" is the problem of deciding of any algorithm whether it defines a function with this property,\ni.e., whether the algorithm halts on input 1. By Rice's theorem, the 1-halting problem is undecidable. Similarly the question of whether a Turing machine \"T\" terminates on an initially empty tape (rather than with an initial word \"w\" given as second argument in addition to a description of \"T\", as in the full halting problem) is still undecidable.\n\nLet formula_1 be an admissible numbering of the computable functions; a map from the natural numbers to the class formula_2 of unary (partial) computable functions.\nDenote by formula_3 the th (partial) computable function.\n\nWe identify each \"property\" that a computable function may have with the subset of formula_2 consisting of the functions with that property.\nThus given a set formula_5, a computable function formula_6 has property formula_7 if and only if formula_8. For each property formula_5 there is an associated decision problem formula_10 of determining, given \"e\", whether formula_8.\n\nRice's theorem states that the decision problem formula_10 is decidable (also called recursive or computable) if and only if formula_13 or formula_14.\n\nAccording to Rice's theorem, if there is at least one computable function in a particular class \"C\" of computable functions and another computable function not in \"C\" then the problem of deciding whether a particular program computes a function in \"C\" is undecidable. For example, Rice's theorem shows that each of the following sets of computable functions is undecidable:\n\nA corollary to Kleene's recursion theorem states that for every Gödel numbering formula_1 of the computable functions and every computable function formula_16, there is an index formula_17 such that formula_18 returns formula_19. (In the following, we say that formula_20 \"returns\" formula_21 if either formula_22, or both formula_20 and formula_21 are undefined.) Intuitively, formula_6 is a quine, a function that returns its own source code (Gödel number), except that rather than returning it directly, formula_6 passes its Gödel number to formula_27 and returns the result.\n\nLet formula_7 be a set of computable functions such that formula_29. Then there are computable functions formula_30 and formula_31. Suppose that the set of indices formula_32 such that formula_33 is decidable; then, there exists a function formula_16 that returns formula_35 if formula_33, and formula_37 otherwise. By the corollary to the recursion theorem, there is an index formula_17 such that formula_18 returns formula_19. But then, if formula_8, then formula_6 is the same function as formula_43, and therefore formula_44; and if formula_44, then formula_6 is formula_47, and therefore formula_8. In both cases, we have a contradiction.\n\nSuppose, for concreteness, that we have an algorithm for examining a program \"p\" and determining infallibly whether \"p\" is an implementation of the squaring function, which takes an integer \"d\" and returns \"d\". The proof works just as well if we have an algorithm for deciding any other nontrivial property of program behavior (i.e a semantic and non-trivial property), and is given in general below.\n\nThe claim is that we can convert our algorithm for identifying squaring programs into one that identifies functions that halt. We will describe an algorithm that takes inputs \"a\" and \"i\" and determines whether program \"a\" halts when given input \"i\".\n\nThe algorithm for deciding this is conceptually simple: it constructs (the description of) a new program \"t\" taking an argument \"n\", which (1) first executes program \"a\" on input \"i\" (both \"a\" and \"i\" being hard-coded into the definition of \"t\"), and (2) then returns the square of \"n\". If \"a\"(\"i\") runs forever, then \"t\" never gets to step (2), regardless of \"n\". Then clearly, \"t\" is a function for computing squares if and only if step (1) terminates. Since we've assumed that we can infallibly identify programs for computing squares, we can determine whether \"t\", which depends on \"a\" and \"i\", is such a program, and that for every \"a\" and \"i\"; thus we have obtained a program that decides whether program \"a\" halts on input \"i\". Note that our halting-decision algorithm never executes \"t\", but only passes its description to the squaring-identification program, which by assumption always terminates; since the construction of the description of \"t\" can also be done in a way that always terminates, the halting-decision cannot fail to halt either.\n\nThis method doesn't depend specifically on being able to recognize functions that compute squares; as long as \"some\" program can do what we're trying to recognize, we can add a call to \"a\" to obtain our \"t\". We could have had a method for recognizing programs for computing square roots, or programs for computing the monthly payroll, or programs that halt when given the input \"Abraxas\"; in each case, we would be able to solve the halting problem similarly.\n\nFor the formal proof, algorithms are presumed to define partial functions over strings and are themselves represented by strings. The partial function computed by the algorithm represented by a string \"a\" is denoted F. This proof proceeds by reductio ad absurdum: we assume that there is a non-trivial property that is decided by an algorithm, and then show that it follows that we can decide the halting problem, which is not possible, and therefore a contradiction.\n\nLet us now assume that \"P\"(\"a\") is an algorithm that decides some non-trivial property of F. Without loss of\ngenerality we may assume that \"P\"(\"no-halt\") = \"no\", with \"no-halt\" being the representation of an algorithm that never halts. If this is not true, then this holds for the negation of the property. Since \"P\" decides a non-trivial property, it follows that there is a string \"b\" that represents an algorithm and \"P\"(\"b\") = \"yes\". We can then define an algorithm \"H\"(\"a\", \"i\") as follows:\n\nWe can now show that \"H\" decides the halting problem:\n\n\nSince the halting problem is known to be undecidable, this is a contradiction and the assumption that there is an algorithm \"P\"(\"a\") that decides a non-trivial property for the function represented by \"a\" must be false.\n\nRice's theorem can be succinctly stated in terms of index sets:\n\nwhere formula_54 is the set of natural numbers, including zero.\n\nOne can regard Rice's theorem as asserting the impossibility of effectively deciding for any \"recursively enumerable\" set\nwhether it has a certain nontrivial property.\nIn this section, we give an analogue of Rice's theorem for recursive sets\",\" instead of recursively enumerable sets.\nRoughly speaking, the analogue says that if one can effectively determine for every \"recursive\" set whether it has a certain property,\nthen only finitely many integers determine whether a recursive set has the property.\nThis result is analogous to the original theorem of Rice, because both results assert that a property is \"decidable\"\nonly if one can determine whether a set has that property by examining \"for at most finitely many formula_55\"\n(for no formula_55, for the original theorem), if formula_55 belongs to the set.\n\nLet formula_58 be a class (called a \"simple game\" and thought of as a property) of recursive sets.\nIf formula_59 is a recursive set, then for some formula_17, computable function formula_6\nis the characteristic function of formula_59. We call formula_17 a characteristic index for formula_59.\nLet's say the class formula_58 is \"computable\" if there is an algorithm (computable function) that decides\nfor any nonnegative integer formula_17 (not necessarily a characteristic index),\n\nA set formula_72 \"extends\" a string formula_73 of 0's and 1's\nif for every formula_74 (the length of formula_73),\nthe formula_76th element of formula_73 is 1 if formula_78; and is 0 otherwise.\nFor example, formula_79 extends the string formula_80.\nA string formula_73 is \"winning determining\" if every recursive set extending formula_73 belongs to formula_58.\nA string formula_73 is \"losing determining\" if no recursive set extending formula_73 belongs to formula_58.\n\nWe can now state the following analogue of Rice's theorem\n(Kreisel, Lacombe, and Shoenfield, 1959, Kumabe and Mihara, 2008):\n\nA class formula_58 of recursive sets is computable\nif and only if there are a recursively enumerable set formula_88 of losing determining strings\nand a recursively enumerable set formula_89 of winning determining strings such that\nevery recursive set extends a string in formula_90.\n\nThis result has been applied to foundational problems in computational social choice (more broadly, algorithmic game theory).\nFor instance, Kumabe and Mihara (2008, 2008)\napply this result to an investigation of the Nakamura numbers for simple games in cooperative game theory and social choice theory.\n\n\n"}
{"id": "14031635", "url": "https://en.wikipedia.org/wiki?curid=14031635", "title": "Rook polynomial", "text": "Rook polynomial\n\nIn combinatorial mathematics, a rook polynomial is a generating polynomial of the number of ways to place non-attacking rooks on a board that looks like a checkerboard; that is, no two rooks may be in the same row or column. The board is any subset of the squares of a rectangular board with \"m\" rows and \"n\" columns; we think of it as the squares in which one is allowed to put a rook. The board is the ordinary chessboard if all squares are allowed and \"m\" = \"n\" = 8 and a chessboard of any size if all squares are allowed and \"m\" = \"n\". The coefficient of \"x\" in the rook polynomial \"R\"(\"x\") is the number of ways \"k\" rooks, none of which attacks another, can be arranged in the squares of \"B\". The rooks are arranged in such a way that there is no pair of rooks in the same row or column. In this sense, an arrangement is the positioning of rooks on a static, immovable board; the arrangement will not be different if the board is rotated or reflected while keeping the squares stationary. The polynomial also remains the same if rows are interchanged or columns are interchanged.\n\nThe term \"rook polynomial\" was coined by John Riordan.\nDespite the name's derivation from chess, the impetus for studying rook polynomials is their connection with counting permutations (or partial permutations) with restricted positions. A board \"B\" that is a subset of the \"n\" × \"n\" chessboard corresponds to permutations of \"n\" objects, which we may take to be the numbers 1, 2, ..., \"n\", such that the number \"a\" in the \"j\"-th position in the permutation must be the column number of an allowed square in row \"j\" of \"B\". Famous examples include the number of ways to place \"n\" non-attacking rooks on:\n\nInterest in rook placements arises in pure and applied combinatorics, group theory, number theory, and statistical physics. The particular value of rook polynomials comes from the utility of the generating function approach, and also from the fact that the zeroes of the rook polynomial of a board provide valuable information about its coefficients, i.e., the number of non-attacking placements of \"k\" rooks.\n\nThe rook polynomial \"R\"(\"x\") of a board \"B\" is the generating function for the numbers of arrangements of non-attacking rooks:\n\nwhere \"r\" is the number of ways to place \"k\" non-attacking rooks on the board. Despite the notation, this is a finite sum, since the board is finite so there is a maximum number of non-attacking rooks it can hold; indeed, there cannot be more rooks than the smaller of the number of rows and columns in the board.\n\nThe first few rook polynomials on square \"n\" × \"n\" boards are (with \"R\" = \"R\"):\n\nIn words, this means that on a 1 × 1 board, 1 rook can be arranged in 1 way, and zero rooks can also be arranged in 1 way (empty board); on a complete 2 × 2 board, 2 rooks can be arranged in 2 ways (on the diagonals), 1 rook can be arranged in 4 ways, and zero rooks can be arranged in 1 way; and so forth for larger boards.\n\nFor complete \"m\" × \"n\" rectangular boards \"B\" we write \"R\" := \"R\" . The smaller of \"m\" and \"n\" can be taken as an upper limit for \"k\", since obviously \"r\" = 0 if \"k\" > min(\"m\", \"n\"). This is also shown in the formula for \"R\"(\"x\").\n\nThe rook polynomial of a rectangular chessboard is closely related to the generalized Laguerre polynomial \"L\"(\"x\") by the identity\n\nA rook polynomial is a special case of one kind of matching polynomial, which is the generating function of the number of \"k\"-edge matchings in a graph.\n\nThe rook polynomial \"R\"(\"x\") corresponds to the complete bipartite graph \"K\" . The rook polynomial of a general board \"B\" ⊆ \"B\" corresponds to the bipartite graph with left vertices \"v\", \"v\", ..., \"v\" and right vertices \"w\", \"w\", ..., \"w\" and an edge \"v\"\"w\" whenever the square (\"i\", \"j\") is allowed, i.e., belongs to \"B\". Thus, the theory of rook polynomials is, in a sense, contained in that of matching polynomials.\n\nWe deduce an important fact about the coefficients \"r\", which we recall given the number of non-attacking placements of \"k\" rooks in \"B\": these numbers are unimodal, i.e., they increase to a maximum and then decrease. This follows (by a standard argument) from the theorem of Heilmann and Lieb about the zeroes of a matching polynomial (a different one from that which corresponds to a rook polynomial, but equivalent to it under a change of variables), which implies that all the zeroes of a rook polynomial are negative real numbers.\n\nFor incomplete square \"n\" × \"n\" boards, (i.e. rooks are not allowed to be played on some arbitrary subset of the board's squares) computing the number of ways to place \"n\" rooks on the board is equivalent to computing the permanent of a 0–1 matrix.\n\nA precursor to the rook polynomial is the classic \"Eight rooks problem\" by H. E. Dudeney in which he shows that the maximum number of non-attacking rooks on a chessboard is eight by placing them on one of the main diagonals (Fig. 1). The question asked is: \"In how many ways can eight rooks be placed on an 8 × 8 chessboard so that neither of them attacks the other?\" The answer is: \"Obviously there must be a rook in every row and every column. Starting with the bottom row, it is clear that the first rook can be put on any one of eight different squares (Fig. 1). Wherever it is placed, there is the option of seven squares for the second rook in the second row. Then there are six squares from which to select the third row, five in the fourth, and so on. Therefore the number of different ways must be 8 × 7 × 6 × 5 × 4 × 3 × 2 × 1 = 40,320\" (that is, 8<nowiki>!</nowiki>, where \"!\" is factorial).\n\nThe same result can be obtained in a slightly different way. Let us endow each rook with a positional number, corresponding to the number of its rank, and assign it a name that corresponds to the name of its file. Thus, rook a1 has position 1 and name \"a\", rook b2 has position 2 and name \"b\", etc. Then let us order the rooks into an ordered list (sequence) by their positions. The diagram on Fig. 1 will then transform in the sequence (a,b,c,d,e,f,g,h). Placing any rook on another file would involve moving the rook that hitherto occupied the second file to the file, vacated by the first rook. For instance, if rook a1 is moved to \"b\" file, rook b2 must be moved to \"a\" file, and now they will become rook b1 and rook a2. The new sequence will become (b,a,c,d,e,f,g,h). In combinatorics, this operation is termed permutation, and the sequences, obtained as a result of the permutation, are permutations of the given sequence. The total number of permutations, containing 8 elements from a sequence of 8 elements is 8! (factorial of 8).\n\nTo assess the effect of the imposed limitation \"rooks must not attack each other\", let us consider the problem without such limitation. In how many ways can eight rooks be placed on an 8 × 8 chessboard? This will be the total number of combinations of 8 rooks on 64 squares:\n\nThus, the limitation \"rooks must not attack each other\" reduces the total number of allowable positions from combinations to permutations which is a factor of about 109,776.\n\nA number of problems from different spheres of human activity can be reduced to the rook problem by giving them a \"rook formulation\". As an example: A company must employ \"n\" workers on \"n\" different jobs and each job must be carried out only by one worker. In how many ways can this appointment be done?\n\nLet us put the workers on the ranks of the \"n\" × \"n\" chessboard, and the jobs − on the files. If worker \"i\" is appointed to job \"j\", a rook is placed on the square where rank \"i\" crosses file \"j\". Since each job is carried out only by one worker and each worker is appointed to only one job, all files and ranks will contain only one rook as a result of the arrangement of \"n\" rooks on the board, that is, the rooks do not attack each other.\n\nThe classical rooks problem immediately gives the value of \"r\", the coefficient in front of the highest order term of the rook polynomial. Indeed, its result is that 8 non-attacking rooks can be arranged on an 8 × 8 chessboard in \"r\" = 8! = 40320 ways.\n\nLet us generalize this problem by considering an \"m\" × \"n\" board, that is, a board with \"m\" ranks (rows) and \"n\" files (columns). The problem becomes: In how many ways can one arrange \"k\" rooks on an \"m\" × \"n\" board in such a way that they do not attack each other?\n\nIt is clear that for the problem to be solvable, \"k\" must be less or equal to the smaller of the numbers \"m\" and \"n\"; otherwise one cannot avoid placing a pair of rooks on a rank or on a file. Let this condition be fulfilled. Then the arrangement of rooks can be carried out in two steps. First, choose the set of \"k\" ranks on which to place the rooks. Since the number of ranks is \"m\", of which \"k\" must be chosen, this choice can be done in formula_5 ways. Similarly, the set of \"k\" files on which to place the rooks can be chosen in formula_6 ways. Because the choice of files does not depend on the choice of ranks, according to the products rule there are formula_7 ways to choose the square on which to place the rook.\n\nHowever, the task is not yet finished because \"k\" ranks and \"k\" files intersect in \"k\" squares. By deleting unused ranks and files and compacting the remaining ranks and files together, one obtains a new board of \"k\" ranks and \"k\" files. It was already shown that on such board \"k\" rooks can be arranged in \"k\"! ways (so that they do not attack each other). Therefore, the total number of possible non-attacking rooks arrangements is:\n\nFor instance, 3 rooks can be placed on a conventional chessboard (8 × 8) in formula_9 ways. For \"k\" = \"m\" = \"n\", the above formula gives \"r\" = \"n\"! that corresponds to the result obtained for the classical rooks problem.\n\nThe rook polynomial with explicit coefficients is now:\n\nIf the limitation \"rooks must not attack each other\" is removed, one must choose any \"k\" squares from \"m\" × \"n\" squares. This can be done in:\n\nIf the \"k\" rooks differ in some way from each other, e.g., they are labelled or numbered, all the results obtained so far must be multiplied by \"k\"!, the number of permutations of \"k\" rooks.\n\nAs a further complication to the rooks problem, let us require that rooks not only be non-attacking but also symmetrically arranged on the board. Depending on the type of symmetry, this is equivalent to rotating or reflecting the board. \nSymmetric arrangements lead to many problems, depending on the symmetry condition.\n\nThe simplest of those arrangements is when rooks are symmetric about the centre of the board. Let us designate with \"G\" the number of arrangements in which \"n\" rooks are placed on a board with \"n\" ranks and \"n\" files. Now let us make the board to contain 2\"n\" ranks and 2\"n\" files. A rook on the first file can be placed on any of the 2\"n\" squares of that file. According to the symmetry condition, placement of this rook defines the placement of the rook that stands on the last file − it must be arranged symmetrically to the first rook about the board centre. Let us remove the first and the last files and the ranks that are occupied by rooks (since the number of ranks is even, the removed rooks cannot stand on the same rank). This will give a board of 2\"n\" − 2 files and 2\"n\" − 2 ranks. It is clear that to each symmetric arrangement of rooks on the new board corresponds a symmetric arrangement of rooks on the original board. Therefore, \"G\" = 2\"nG\" (the factor 2\"n\" in this expression comes from the possibility for the first rook to occupy any of the 2\"n\" squares on the first file). By iterating the above formula one reaches to the case of a 2 × 2 board, on which there are 2 symmetric arrangements (on the diagonals). As a result of this iteration, the final expression is \"G\" = 2\"n\"! For the usual chessboard (8 × 8), \"G\" = 2 × 4! = 16 × 24 = 384 centrally symmetric arrangements of 8 rooks. One such arrangement is shown in Fig. 2.\n\nFor odd-sized boards (containing 2\"n\" + 1 ranks and 2\"n\" + 1 files) there is always a square that does not have its symmetric double − this is the central square of the board. There must always be a rook placed on this square. Removing the central file and rank, one obtains a symmetric arrangement of 2\"n\" rooks on a 2\"n\" × 2\"n\" board. Therefore, for such board, once again \"G\" = \"G\" = 2\"n\"!\n\nA little more complicated problem is to find the number of non-attacking arrangements that do not change upon 90° rotation of the board. Let the board has 4\"n\" files and 4\"n\" ranks, and the number of rooks is also 4\"n\". In this case, the rook that is on the first file can occupy any square on this file, except the corner squares (a rook cannot be on a corner square because after a 90° rotation there would 2 rooks that attack each other). There are another 3 rooks that correspond to that rook and they stand, respectively, on the last rank, the last file, and the first rank (they are obtained from the first rook by 90°, 180°, and 270° rotations). Removing the files and ranks of those rooks, one obtains the rook arrangements for a (4\"n\" − 4) × (4\"n\" − 4) board with the required symmetry. Thus, the following recurrence relation is obtained: \"R\" = (4\"n\" − 2)\"R\", where \"R\" is the number of arrangements for a \"n\" × \"n\" board. Iterating, it follows that \"R\" = 2\"n\"(2\"n\" − 1)(2\"n\" − 3)...1. The number of arrangements for a (4\"n\" + 1) × (4\"n\" + 1) board is the same as that for a 4\"n\" × 4\"n\" board; this is because on a (4\"n\" + 1) × (4\"n\" + 1) board, one rook must necessarily stand in the centre and thus the central rank and file can be removed. Therefore \"R\" = \"R\". For the traditional chessboard (\"n\" = 2), \"R\" = 4 × 3 × 1 = 12 possible arrangements with rotational symmetry.\n\nFor (4\"n\" + 2) × (4\"n\" + 2) and (4\"n\" + 3) × (4\"n\" + 3) boards, the number of solutions is zero. Two cases are possible for each rook: either it stands in the centre or it doesn't stand in the centre. In the second case, this rook is included in the rook quartet that exchanges squares on turning the board at 90°. Therefore, the total number of rooks must be either 4\"n\" (when there is no central square on the board) or 4\"n\" + 1. This proves that \"R\" = \"R\" = 0.\n\nThe number of arrangements of \"n\" non-attacking rooks symmetric to one of the diagonals (for determinacy, the diagonal corresponding to a1–h8 on the chessboard) on a \"n\" × \"n\" board is given by the telephone numbers defined by the recurrence \"Q\" = \"Q\" + (\"n\" − 1)\"Q\". This recurrence is derived in the following way. Note that the rook on the first file either stands on the bottom corner square or it stands on another square. In the first case, removal of the first file and the first rank leads to the symmetric arrangement \"n\" − 1 rooks on a (\"n\" − 1) × (\"n\" − 1) board. The number of such arrangements is \"Q\". In the second case, for the original rook there is another rook, symmetric to the first one about the chosen diagonal. Removing the files and ranks of those rooks leads to a symmetric arrangement \"n\" − 2 rooks on a (\"n\" − 2) × (\"n\" − 2) board. Since the number of such arrangements is \"Q\" and the rook can be put on the \"n\" − 1 square of the first file, there are (\"n\" − 1)\"Q\" ways for doing this, which immediately gives the above recurrence. The number of diagonal-symmetric arrangements is then given by the expression:\n\nThis expression is derived by partitioning all rook arrangements in classes; in class \"s\" are those arrangements in which \"s\" pairs of rooks do not stand on the diagonal. In exactly the same way, it can be shown that the number of \"n\"-rook arrangements on a \"n\" × \"n\" board, such that they do not attack each other and are symmetric to both diagonals is given by the recurrence equations \"B\" = 2\"B\" + (2\"n\" − 2)\"B\" and \"B\" = \"B\".\n\nA different type of generalization is that in which rook arrangements that are obtained from each other by symmetries of the board are counted as one. For instance, if rotating the board by 90 degrees is allowed as a symmetry, then any arrangement obtained by a rotation of 90, 180, or 270 degrees is considered to be \"the same\" as the original pattern, even though these arrangements are counted separately in the original problem where the board is fixed. For such problems, Dudeney observes: \"How many ways there are if mere reversals and reflections are not counted as different has not yet been determined; it is a difficult problem.\" The problem reduces to that of counting symmetric arrangements via Burnside's lemma.\n"}
{"id": "2293999", "url": "https://en.wikipedia.org/wiki?curid=2293999", "title": "Sequence transformation", "text": "Sequence transformation\n\nIn mathematics, a sequence transformation is an operator acting on a given space of sequences (a sequence space). Sequence transformations include linear mappings such as convolution with another sequence, and resummation of a sequence and, more generally, are commonly used for series acceleration, that is, for improving the rate of convergence of a slowly convergent sequence or series. Sequence transformations are also commonly used to compute the antilimit of a divergent series numerically, and are used in conjunction with extrapolation methods.\n\nClassical examples for sequence transformations include the binomial transform, Möbius transform, Stirling transform and others.\n\nFor a given sequence \n\nthe transformed sequence is \n\nwhere the members of the transformed sequence are usually computed from some finite number of members of the original sequence, i.e.\n\nfor some formula_4 which often depends on formula_5 (cf. e.g. Binomial transform). In the simplest case, the formula_6 and the formula_7 are real or complex numbers. More generally, they may be elements of some vector space or algebra. \n\nIn the context of acceleration of convergence, the transformed sequence is said to converge faster than the original sequence if \n\nwhere formula_9 is the limit of formula_10, assumed to be convergent. In this case, convergence acceleration is obtained. If the original sequence is divergent, the sequence transformation acts as extrapolation method to the antilimit formula_9.\n\nIf the mapping formula_12 is linear in each of its arguments, i.e., for\n\nfor some constants formula_14 (which may depend on \"n\"), the sequence transformation formula_15 is called a linear sequence transformation. Sequence transformations that are not linear are called nonlinear sequence transformations.\n\nSimplest examples of (linear) sequence transformations include shifting all elements, formula_16 (resp. = 0 if \"n\" + \"k\" < 0) for a fixed \"k\", and scalar multiplication of the sequence.\n\nA little less trivial generalization would be the discrete convolution with a fixed sequence. A particularly basic form is the difference operator, which is convolution with the sequence formula_17 and is a discrete analog of the derivative. The binomial transform is another linear transformation of a still more general type.\n\nAn example of a nonlinear sequence transformation is Aitken's delta-squared process, used to improve the rate of convergence of a slowly convergent sequence. An extended form of this is the Shanks transformation. The Möbius transform is also a nonlinear transformation, only possible for integer sequences.\n\n\n\n"}
{"id": "22509875", "url": "https://en.wikipedia.org/wiki?curid=22509875", "title": "Simulation algorithms for atomic DEVS", "text": "Simulation algorithms for atomic DEVS\n\nGiven an atomic DEVS model, simulation algorithms are methods to generate the model's legal behaviors which are trajectories not to reach to illegal states. (see Behavior of DEVS). [Zeigler84] originally introduced the algorithms that handle time variables related to \"lifespan\" formula_1 and \"elapsed time\" formula_2 by introducing two other time variables, \"last event time\", formula_3, and \"next event time\" formula_4 with the following relations: \nformula_5\n\nand\n\nformula_6\n\nwhere formula_7 denotes the \"current time\". And the \"remaining time\",\n\nformula_9, apparently formula_10.\n\nSince the behavior of a given atomic DEVS model can be defined in two different views depending on the total state and the external transition function (refer to Behavior of DEVS), the simulation algorithms are also introduced in two different views as below.\n\nRegardless of two different views of total states, algorithms for initialization and internal transition cases are commonly defined as below.\n\nAs addressed in Behavior of Atomic DEVS, when DEVS receives an input event, right calling formula_24, the last event time,formula_11 is set by the current time,formula_14, thus the elapsed timeformula_27 becomes zero because formula_28.\n\nNotice that as addressed in Behavior of Atomic DEVS, depending on the value of formula_36 return by formula_37, last event time,formula_11, and next event time,formula_12,consequently, elapsed time, formula_27, and lifespanformula_12, are updated (if formula_42) or preserved (if formula_43).\n\n\n"}
{"id": "7266141", "url": "https://en.wikipedia.org/wiki?curid=7266141", "title": "Strongly positive bilinear form", "text": "Strongly positive bilinear form\n\nA bilinear form, \"a\"(•,•) whose arguments are elements of normed vector space \"V\" is a strongly positive bilinear form if and only if there exists a constant, \"c\">0, such that\n\nfor all formula_2 where formula_3 is the norm on \"V\".\n"}
{"id": "6524226", "url": "https://en.wikipedia.org/wiki?curid=6524226", "title": "Structural cohesion", "text": "Structural cohesion\n\nStructural cohesion is the sociological conception of a useful formal definition and measure of cohesion in social groups. It is defined as the minimal number of actors in a social network that need to be removed to disconnect the group. It is thus identical to the question of the node connectivity of a given graph. The vertex-cut version of Menger's theorem also proves that the disconnection number is equivalent to a maximally sized group with a network in which every pair of persons has at least this number of separate paths between them. It is also useful to know that k-cohesive graphs (or k-components) are always a subgraph of a k-core, although a k-core is not always k-cohesive. A k-core is simply a subgraph in which all nodes have at least k neighbors but it need not even be connected. The boundaries of structural endogamy in a kinship group are a special case of structural cohesion.\n\nCohesive.blocking is the R program for computing structural cohesion according to the Moody-White (2003) algorithm. This wiki site provides numerous examples and a tutorial for use with R.\n\nSome illustrative examples are presented in the gallery below:\n\nPerceived Cohesion Scale (PCS) is a six item scale that is used to measure structural cohesion in groups. In 1990, Bollen and Hoyle used the PCS and applied it to a study of large groups which were used to assess the psychometric qualities of their scale.\n\n"}
{"id": "44098050", "url": "https://en.wikipedia.org/wiki?curid=44098050", "title": "Symmetry of diatomic molecules", "text": "Symmetry of diatomic molecules\n\nMolecular symmetry in physics and chemistry describes the symmetry present in molecules and the classification of molecules according to their symmetry. Molecular symmetry is a fundamental concept in the application of Quantum Mechanics in physics and chemistry, for example it can be used to predict or explain many of a molecule's properties, such as its dipole moment and its allowed spectroscopic transitions (based on selection rules), without doing the exact rigorous calculations (which, in some cases, may not even be possible). Group theory is the predominant framework for analyzing molecular symmetry.\n\nAmong all the molecular symmetries, diatomic molecules show some distinct features and they are relatively easier to analyze.\n\nThe physical laws governing a system is generally written as a relation (equations, differential equations, integral equations etc.). An operation on the ingredients of this relation, which keeps the form of the relations invariant is called a symmetry transformation or a symmetry of the system.\nSymmetry is a fundamentally important concept in quantum mechanics. It can predict conserved quantities and provide quantum numbers. It can predict degeneracies of eigenstates and gives insights about the matrix elements of the Hamiltonian without calculating them. Rather than looking into individual symmetries, it is sometimes more convenient to look into the general relations between the symmetries. It turns out that Group theory is the most efficient way of doing this.\n\nA \"group\" is a mathematical structure (usually denoted in the form (\"G\",*)) consisting of a set \"G\" and a binary operation formula_1 (sometimes loosely called 'multiplication'), satisfying the following properties:\n\nThe set of all symmetry transformations of a Hamiltonian has the structure of a group, with group multiplication equivalent to applying the transformations one after the other. The group elements can be represented as matrices, so that the group operation becomes the ordinary matrix multiplication. In quantum mechanics, the evolution of an arbitrary superposition of states are given by unitary operators, so each of the elements of the symmetry groups are unitary operators. Now any unitary operator can be expressed as the exponential of some Hermitian operator . So, the corresponding Hermitian operators are the 'generators' of the symmetry group. These unitary transformations act on the Hamiltonian operator in some Hilbert space in a way that the Hamiltonian remains invariant under the transformations. In other words, the symmetry operators commute with the Hamiltonian. If formula_11 represents the unitary symmetry operator and acts on the Hamiltonian formula_12, then;\n\nThese operators have the above-mentioned properties of a group: \nSo, by the symmetry of a system, we mean a set of operators, each of which commutes with the Hamiltonian, and they form a symmetry group. This group may be Abelian or Non-Abelian. Depending upon which one it is, the properties of the system changes (for example, if the group is Abelian, there would be no degeneracy). Corresponding to every different kind of symmetry in a system, we can find a symmetry group associated with it.\n\nIt follows that the generator formula_13 of the symmetry group also commutes with the Hamiltonian. Now, it follows that:\n\nSome specific examples can be systems having rotational, translational invariance etc.. For a rotationally invariant system, The symmetry group of the Hamiltonian is the general rotation group. Now, if (say) the system is invariant about any rotation about Z-axis (i.e., the system has axial symmetry), then the symmetry group of the Hamiltonian is the group of rotation about the symmetry axis. Now, this group is generated by the Z-component of the orbital angular momentum, formula_14 (general group element formula_15). Thus, formula_14 commutes with formula_12 for this system and Z-component of the angular momentum is conserved. Similarly, translation symmetry gives rise to conservation of linear momentum, inversion symmetry gives rise to parity conservation and so on.\n\nA molecule at equilibrium in a certain electronic state usually has some geometrical symmetry.This symmetry is described by a certain point group which consists of operations (called symmetry operations) that produce a spatial orientation of the molecule that is indistinguishable from the starting configuration. There are five types of point group symmetry operation: identity, rotation, reflection, inversion and improper rotation or rotation-reflection. Common to all symmetry operations is that the geometrical center-point of the molecule does not change its position; hence the name point group. One can determine the elements of the point group for a particular molecule by considering the geometrical symmetry of its molecular model. However, when one uses a point group, the elements are not to be interpreted in the same way. Instead the elements rotate and/or reflect the vibronic (vibration-electronic) coordinates and these elements commute with the vibronic Hamiltonian. The point group is used to classify by symmetry the vibronic eigenstates. The symmetry classification of the rotational levels, the eigenstates of the full (rovibronic nuclear spin) Hamiltonian, requires the use of the appropriate permutation-inversion group as introduced by Longuet-Higgins. See the Section \"Inversion symmetry and nuclear permutation symmetry\" below, and Link \n. The elements of permutation-inversion groups commute with the full molecular Hamiltonian. In addition to point groups, there exists another kind of group important in crystallography, where translation in 3-D also needs to be taken care of. They are known as space groups.\n\nThe five basic symmetry operations mentioned above are:\nIt is to be noted that all other symmetry present in a specific molecule are a combination of these 5 operations.\n\nThe Schoenflies (or Schönflies) notation, named after the German mathematician Arthur Moritz Schoenflies, is one of two conventions commonly used to describe point groups. This notation is used in spectroscopy and is used here to specify a molecular point group.\n\nThere are two point groups for diatomic molecules: formula_22 for heteronuclear diatomics, and formula_22 for homonuclear diatomics.\nThe group formula_22, contains rotations formula_26 through any angle formula_27 about the axis of symmetry and an infinite number of reflections formula_18 through the planes containing the inter-nuclear axis (or the vertical axis, that is reason of the subscript '\"v\"').In the group formula_22 all planes of symmetry are equivalent, so that all reflections formula_18 form a single class with a continuous series of elements; the axis of symmetry is bilateral, so that there is a continuous series of classes, each containing two elements formula_31. Note that this group is Non-abelian and there exists an infinite number of irreducible representations in the group. The character table of the group is as follows:\n\nIn addition to axial reflection symmetry, homonuclear diatomic molecules are symmetric with respect to inversion or reflection through any axis in the plane passing through the point of symmetry and perpendicular to the inter-nuclear axis. The classes of the group formula_18 can be obtained from those of the group formula_22 using the relation between the two groups: formula_35. Like formula_22, formula_18 is non-Abelian and there are an infinite number of irreducible representations in the group.The character table of this group is as follows:\n\nUnlike a single atom, the Hamiltonian of a diatomic molecule doesn't commute with formula_38. So the quantum number formula_39 is no longer a good quantum number. The internuclear axis chooses a specific direction in space and the potential is no longer spherically symmetric. Instead, formula_38 and formula_38 commutes with the Hamiltonian formula_12 (taking the arbitrary internuclear axis as the \"Z\" axis). But formula_43 do not commute with formula_12 due to the fact that the electronic Hamiltonian of a diatomic molecule is invariant under rotations about the internuclear line (the \"Z\" axis), but not under rotations about the \"X\" or \"Y\" axes. Again, formula_38 and formula_38 act on a different Hilbert space, so they commute with formula_12 in this case also. The electronic Hamiltonian for a diatomic molecule is also invariant under reflections in all planes containing the internuclear line. The (\"X-Z\") plane is such a plane, and reflection of the coordinates of the electrons in this plane corresponds to the operation formula_48. If formula_38 is the operator that performs this reflection, then formula_50. So the Complete Set of Commuting Operators (CSCO) for a general heteronuclear diatomic molecule is formula_51; where formula_52 is an operator that inverts only one of the two spatial co-ordinates (\"x or y). \"\n\nIn the special case of a homonuclear diatomic molecule, there is an extra symmetry since in addition to the axis of symmetry provided by the internuclear axis, there is a centre of symmetry at the midpoint of the distance between the two nuclei (the symmetry discussed in this paragraph only depends on the two nuclear charges being the same. The two nuclei can therefore have different mass, that is they can be two isotopes of the same species such as the proton and the deuteron, or formula_38 and formula_38, and so on). Choosing this point as the origin of the coordinates, the Hamiltonian is invariant under an inversion of the coordinates of all electrons with respect to that origin, namely in the operation formula_55. Thus the parity operator formula_56. Thus the CSCO for a homonuclear diatomic molecule is formula_57.\n\nMolecular term symbol is a shorthand expression of the group representation and angular momenta that characterize the state of a molecule. It is the equivalent of the term symbol for the atomic case. We already know the CSCO of the most general diatomic molecule. So, the good quantum numbers can sufficiently describe the state of the diatomic molecule. Here, the symmetry is explicitly stated in the nomenclature.\n\nHere, the system is not spherically symmetric. So, formula_58, and the state cannot be depicted in terms of formula_39 as an eigenstate of the Hamiltonian is not an eigenstate of formula_18 anymore (in contrast to the atomic term symbol, where the states were written as formula_61). But, as formula_62, the eigenvalues corresponding to formula_38 can still be used. If,\n\nformula_64\n\nwhere formula_65 is the absolute value (in a.u.) of the projection of the total electronic angular momentum on the internuclear axis; formula_66 can be used as a term symbol. By analogy with the spectroscopic notation S, P, D, F, ... used for atoms, it is customary to associate code letters with the values of formula_66 according to the correspondence:\nFor the individual electrons, the notation and the correspondence used are:\n\nformula_68 and\n\nAgain, formula_50, and in addition: formula_70 [as formula_71]. It follows immediately that if formula_72 the action of the operator formula_38 on an eigenstate corresponding to the eigenvalue formula_74 of formula_14 converts this state into another one corresponding to the eigenvalue formula_76, and that both eigenstates have the same energy. The electronic terms such that formula_72 (that is, the terms formula_78) are thus doubly degenerate, each value of the energy corresponding to two states which differ by the direction of the projection of the orbital angular momentum along the molecular axis. This twofold degeneracy is actually only approximate and it is possible to show that the interaction between the electronic and rotational motions leads to a splitting of the terms with formula_72 into two nearby levels, which is called formula_66-doubling.\n\nformula_81 corresponds to the formula_82 states. These states are non-degenerate, so that the states of a formula_82 term can only be multiplied by a constant in a reflection through a plane containing the molecular axis. When formula_81, simultaneous eigenfunctions of formula_12,formula_14 and formula_14 can be constructed. Since formula_88, the eigenfunctions of formula_14 have eigenvalues formula_90. So to completely specify formula_82 states of diatomic molecules, formula_38 states, which is left unchanged upon reflection in a plane containing the nuclei, needs to be distinguished from formula_38 states, for which it changes sign in performing that operation.\n\nHomonuclear diatomic molecules have a center of symmetry at their midpoint. Choosing this point as the origin of the coordinates, the electronic Hamiltonian is invariant under the point group operation i of inversion of the coordinates of all electrons at that origin. This operation is not the parity operation P (or E*); the parity operation involves the inversion of nuclear and electronic spatial coordinates at the molecular center of mass. Electronic states are either even, i.e. remain unchanged by the operation i, or they are odd, i.e. changed in sign by i. The former are denoted by the subscript g and are called gerade, while the latter are denoted by the subscript u and are called ungerade. The subscripts g or u are therefore added to the term symbol, so that for homonuclear diatomic molecules we have formula_94 electronic states. A homonuclear diatomic molecule has four non-degenerate formula_82 electronic states: formula_96. Vibronic states are classified according to the irreducible representations of the appropriate point group.\n\nThe complete Hamiltonian of a diatomic molecule (as for all molecules) commutes with the parity operation P or E* and rovibronic energy levels (usually called rotational levels) can be given the parity symmetry label + or -. The complete Hamiltonian of a homonuclear diatomic molecule also commutes with the operation\nof permuting (or exchanging) the coordinates of the two (identical) nuclei and rotational levels \ngain the additional label s or a depending on whether the total wavefunction is\nunchanged (symmetric) or changed in sign (antisymmetric) by the permutation operation. Thus, the rotational levels of heteronuclear diatomic molecules are labelled + or -, whereas those of homonuclear diatomic\nmolecules are labelled +s, +a, -s or -a. The rovibronic nuclear spin states are classified using the appropriate permutation-inversion group.\n\nThe complete Hamiltonian of a homonuclear diatomic molecule (as for all centro-symmetric molecules)\ndoes not commute with the point group inversion operation i because of the effect of the nuclear hyperfine Hamiltonian. The nuclear hyperfine Hamiltonian can mix the rotational levels of g and u vibronic states (called ortho-para mixing) and give\nrise to ortho-para transitions\n\nIf S denotes the resultant of the individual electron spins, formula_97 are the eigenvalues of S and as in the case of atoms, each electronic term of the molecule is also characterised by the value of S. If spin-orbit coupling is neglected, there is a degeneracy of order formula_98 associated with each formula_99 for a given formula_66. Just as for atoms, the quantity formula_98 is called the multiplicity of the term and.is written as a (left) superscript, so that the term symbol is written as formula_102. For example, the symbol formula_103denotes a term such that formula_104 and formula_105. It is worth noting that the ground state (often labelled by the symbol formula_106) of most diatomic molecules is such that formula_107 and exhibits maximum symmetry. Thus, in most cases it is a formula_108 state (written as formula_109, excited states are written with formula_110 in front) for a heteronuclear molecule and a formula_111 state (written as formula_112) for a homonuclear molecule.\n\nSpin–orbit coupling lifts the degeneracy of the electronic states. This is because the \"z\"-component of spin interacts with the \"z\"-component of the orbital angular momentum, generating a total electronic angular momentum along the molecule axis J. This is characterized by the quantum number formula_18, where formula_114. Again, positive and negative values of formula_18 are degenerate, so the pairs (\"M\", \"M\") and (−\"M\", −\"M\") are degenerate. These pairs are grouped together with the quantum number formula_116, which is defined as the sum of the pair of values (\"M\", \"M\") for which \"M\" is positive: formula_117\n\nSo, the overall molecular term symbol for the most general diatomic molecule is given by:\n\nformula_118\n\nwhere\n\nThe electronic terms or potential curves formula_121 of a diatomic molecule depend only on the internuclear distance formula_122, and it is important to investigate the behaviour of these potential curves as R varies.It is of considerable interest to examine the intersection of the curves representing the different terms.\n\nLet formula_123 and formula_123 two different electronic potential curves. If they intersect at some point, then the functions formula_123 and formula_123 will have neighbouring values near this point. To decide whether such an intersection can occur, it is convenient to put the problem as follows. Suppose at some internuclear distance formula_127 the values formula_128 and formula_128 are close, but distinct (as shown in the figure). Then it is to be examined whether or formula_123 and formula_123 can be made to intersect by the modification formula_132. The energies formula_133 and formula_134 are eigenvalues of the Hamiltonian formula_135. The corresponding orthonormal electronic eigenstates will be denoted by formula_136 and formula_137 and are assumed to be real.\nThe Hamiltonian now becomes formula_138, where formula_139 is the small perturbation operator (though it is a degenerate case, so ordinary method of perturbation won't work). setting formula_140, it can be deduced that in order for formula_123 and formula_123 to be equal at the point formula_143 the following two conditions are required to be fulfilled:\n\nHowever, we have at our disposal only one arbitrary parameter formula_144 giving the perturbation formula_145. Hence the\n\ntwo conditions involving more than one parameter cannot in general be simultaneously satisfied (the initial assumption that formula_136 and formula_137 real, implies that formula_148 is also real). So, two case can arise: \nThus, in a diatomic molecule, only terms of different symmetry can intersect, while the intersection of terms of like symmetry is forbidden. This is, in general, true for any case in quantum mechanics where the Hamiltonian contains some parameter and its eigenvalues are consequently functions of that parameter. This general rule is known as von Neumann - Wigner non-crossing rule. \nThis general symmetry principle has important consequences is molecular spectra.\nIn fact, in the applications of valence bond method in case of diatomic molecules, three main correspondence between the atomic and the molecular orbitals are taken care of:\nThus, von Neumann-Wigner non-crossing rule also acts as a starting point for valence bond theory.\n\nSymmetry in diatomic molecules manifests itself directly by influencing the molecular spectra of the molecule. The effect of symmetry on different types of spectra in diatomic molecules are:\n\nIn the electric dipole approximation the transition amplitude for emission or absorption of radiation can be shown to be proportional to the vibronic matrix element of the component of the electric dipole operator formula_174 along the molecular axis. This is the permanent electric dipole moment.\nIn homonuclear diatomic molecules, the permanent electric dipole moment vanishes and there is no pure rotation spectrum.\nHeteronuclear diatomic molecules possess a permanent electric dipole moment and exhibit spectra corresponding to rotational transitions, without change in the vibronic state. For formula_175, the selection rules for a rotational transition are: formula_176. For formula_177, the selection rules become: formula_178.This is due to the fact that although the photon absorbed or emitted carries one unit of angular momentum, the nuclear rotation can change, with no change in formula_179, if the electronic angular momentum makes an equal and opposite change. Symmetry considerations require that the electric dipole moment of a diatomic molecule is directed along the internuclear line, and this leads to the additional selection rule formula_180.The pure rotational spectrum of a diatomic molecule consists of lines in the far infra-red or the microwave region, the frequencies of these lines given by:\n\nformula_181; where formula_182, and formula_183\n\nThe transition matrix elements for pure vibrational transition are formula_184, where formula_185 is the dipole moment of the diatomic molecule in the electronic state formula_186. Because the dipole moment depends on the bond length formula_187, its variation with displacement of the nuclei from equilibrium can be expressed as: formula_188\n\nThe analysis of formula_189 using variational method starts assuming these forms. Again, this is only one possible combination of states. There can be other combination of states also, for example, the electron is in an excited state of the hydrogen atom. The corresponding Hamiltonian of the system is:\n\nformula_190\n\nClearly, using the states formula_191 and formula_192 as basis will introduce off-diagonal elements in the Hamiltonian. Here, because of the relative simplicity of the formula_189 ion, the matrix elements can actually be calculated. The electronic Hamiltonian of formula_189 commutes with the point group inversion symmetry operation i. Using its symmetry properties, we can relate the diagonal and off-diagonal elements of the Hamiltonian as:\n\nWhere, formula_197is the ground-state energy of the hydrogen atom.\n\nAgain,formula_198\n\nformula_199\n\nwhere the last step follows from the fact that formula_200 and from the symmetry of the system, the value of the integrals are same.\n\nNow the off-diagonal terms:\n\nformula_201\n\nformula_202\n\nby inserting a complete set of states formula_203 in the last term. formula_204 is called the 'overlap integral'\n\nAnd,\n\nformula_205\n\nformula_206 (as the wave functions are real)\n\nSo, formula_207\nBecause formula_208 as well as formula_208, the linear combination of formula_191 andformula_192 that diagonalizes the Hamiltonian is formula_212 (after normalization). Now as formula_213iformula_214 for formula_189, the states formula_216 are also eigenstates of i. It turns out that formula_217 and formula_218 are the eigenstates of i with eigenvalues +1 and -1 (in other words, the wave functions formula_219 and formula_220 are gerade (symmetric) and ungerade (unsymmetric), respectively). The corresponding expectation value of the energies are formula_221. \n\nFrom the graph, we see that only formula_38 has a minimum corresponding to a separation of 1.3 Å and a total energy formula_223, which is less than the initial energy of the system, formula_224. Thus, only the gerade state stabilizes the ion with a binding energy of formula_225. As a result, the ground state of formula_189 is formula_227 and this state formula_228 is called a bonding molecular orbital.\n\nThus, symmetry plays an explicit role in the formation of formula_189.\n\n\n\n"}
{"id": "15575410", "url": "https://en.wikipedia.org/wiki?curid=15575410", "title": "Two-dimensional space", "text": "Two-dimensional space\n\nTwo-dimensional space (also known as bi-dimensional space) is a geometric setting in which two values (called parameters) are required to determine the position of an element (i.e., point). In Mathematics, it is commonly represented by the symbol . For a generalization of the concept, see dimension.\n\nTwo-dimensional space can be seen as a projection of the physical universe onto a plane. Usually, it is thought of as a Euclidean space and the two dimensions are called length and width.\n\nBooks I through IV and VI of Euclid's Elements dealt with two-dimensional geometry, developing such notions as similarity of shapes, the Pythagorean theorem (Proposition 47), equality of angles and areas, parallelism, the sum of the angles in a triangle, and the three cases in which triangles are \"equal\" (have the same area), among many other topics.\n\nLater, the plane was described in a so-called \"Cartesian coordinate system\", a coordinate system that specifies each point uniquely in a plane by a pair of numerical \"coordinates\", which are the signed distances from the point to two fixed perpendicular directed lines, measured in the same unit of length. Each reference line is called a \"coordinate axis\" or just \"axis\" of the system, and the point where they meet is its \"origin\", usually at ordered pair (0, 0). The coordinates can also be defined as the positions of the perpendicular projections of the point onto the two axes, expressed as signed distances from the origin.\n\nThe idea of this system was developed in 1637 in writings by Descartes and independently by Pierre de Fermat, although Fermat also worked in three dimensions, and did not publish the discovery. Both authors used a single axis in their treatments and have a variable length measured in reference to this axis. The concept of using a pair of axes was introduced later, after Descartes' \"La Géométrie\" was translated into Latin in 1649 by Frans van Schooten and his students. These commentators introduced several concepts while trying to clarify the ideas contained in Descartes' work.\n\nLater, the plane was thought of as a field, where any two points could be multiplied and, except for 0, divided. This was known as the complex plane. The complex plane is sometimes called the Argand plane because it is used in Argand diagrams. These are named after Jean-Robert Argand (1768–1822), although they were first described by Danish-Norwegian land surveyor and mathematician Caspar Wessel (1745–1818). Argand diagrams are frequently used to plot the positions of the poles and zeroes of a function in the complex plane.\n\nIn mathematics, analytic geometry (also called Cartesian geometry) describes every point in two-dimensional space by means of two coordinates. Two perpendicular coordinate axes are given which cross each other at the origin. They are usually labeled \"x\" and \"y\". Relative to these axes, the position of any point in two-dimensional space is given by an ordered pair of real numbers, each number giving the distance of that point from the origin measured along the given axis, which is equal to the distance of that point from the other axis.\n\nAnother widely used coordinate system is the polar coordinate system, which specifies a point in terms of its distance from the origin and its angle relative to a rightward reference ray.\n\nIn two dimensions, there are infinitely many polytopes: the polygons. The first few regular ones are shown below:\n\nThe Schläfli symbol {p} represents a regular \"p\"-gon.\n\nThe regular henagon {1} and regular digon {2} can be considered degenerate regular polygons. They can exist nondegenerately in non-Euclidean spaces like on a 2-sphere or a 2-torus.\n\nThere exist infinitely many non-convex regular polytopes in two dimensions, whose Schläfli symbols consist of rational numbers {n/m}. They are called star polygons and share the same vertex arrangements of the convex regular polygons.\n\nIn general, for any natural number n, there are n-pointed non-convex regular polygonal stars with Schläfli symbols {\"n\"/\"m\"} for all \"m\" such that \"m\" < \"n\"/2 (strictly speaking {\"n\"/\"m\"} = {\"n\"/(\"n\" − \"m\")}) and \"m\" and \"n\" are coprime.\n\nThe hypersphere in 2 dimensions is a circle, sometimes called a 1-sphere (\"S\") because it is a one-dimensional manifold. In a Euclidean plane, it has the length 2π\"r\" and the area of its interior is\nwhere formula_2 is the radius.\n\nThere are an infinitude of other curved shapes in two dimensions, notably including the conic sections: the ellipse, the parabola, and the hyperbola.\n\nAnother mathematical way of viewing two-dimensional space is found in linear algebra, where the idea of independence is crucial. The plane has two dimensions because the length of a rectangle is independent of its width. In the technical language of linear algebra, the plane is two-dimensional because every point in the plane can be described by a linear combination of two independent vectors.\n\nThe dot product of two vectors and is defined as:\n\nA vector can be pictured as an arrow. Its magnitude is its length, and its direction is the direction the arrow points. The magnitude of a vector A is denoted by formula_4. In this viewpoint, the dot product of two Euclidean vectors A and B is defined by\nwhere θ is the angle between A and B.\n\nThe dot product of a vector A by itself is\nwhich gives\nthe formula for the Euclidean length of the vector.\n\nIn a rectangular coordinate system, the gradient is given by\n\nFor some scalar field \"f\" : \"U\" ⊆ R → R, the line integral along a piecewise smooth curve \"C\" ⊂ \"U\" is defined as\nwhere r: [a, b] → \"C\" is an arbitrary bijective parametrization of the curve \"C\" such that r(\"a\") and r(\"b\") give the endpoints of \"C\" and formula_10.\n\nFor a vector field F : \"U\" ⊆ R → R, the line integral along a piecewise smooth curve \"C\" ⊂ \"U\", in the direction of r, is defined as\n\nwhere · is the dot product and r: [a, b] → \"C\" is a bijective parametrization of the curve \"C\" such that r(\"a\") and r(\"b\") give the endpoints of \"C\".\n\nA double integral refers to an integral within a region \"D\" in R of a function formula_12 and is usually written as:\n\nThe fundamental theorem of line integrals says that a line integral through a gradient field can be evaluated by evaluating the original scalar field at the endpoints of the curve.\n\nLet formula_14. Then\n\nLet \"C\" be a positively oriented, piecewise smooth, simple closed curve in a plane, and let \"D\" be the region bounded by \"C\". If \"L\" and \"M\" are functions of (\"x\", \"y\") defined on an open region containing \"D\" and have continuous partial derivatives there, then\n\nwhere the path of integration along C is counterclockwise.\n\nIn topology, the plane is characterized as being the unique contractible 2-manifold.\n\nIts dimension is characterized by the fact that removing a point from the plane leaves a space that is connected, but not simply connected.\n\nIn graph theory, a planar graph is a graph that can be embedded in the plane, i.e., it can be drawn on the plane in such a way that its edges intersect only at their endpoints. In other words, it can be drawn in such a way that no edges cross each other. Such a drawing is called a \"plane graph\" or \"planar embedding of the graph\". A plane graph can be defined as a planar graph with a mapping from every node to a point on a plane, and from every edge to a plane curve on that plane, such that the extreme points of each curve are the points mapped from its end nodes, and all curves are disjoint except on their extreme points.\n\n"}
{"id": "35100531", "url": "https://en.wikipedia.org/wiki?curid=35100531", "title": "Virtual Cell", "text": "Virtual Cell\n\nVirtual Cell (VCell) is an open-source software platform for modeling and simulation of living organisms, primarily cells. It has been designed to be a tool for a wide range of scientists, from experimental cell biologists to theoretical biophysicists.\n\nThe primary mode of operation is the definition of a model consisting of compartments, species and chemical reactions, and reaction rates that are functions of concentrations. Given initial concentrations of species, the VCell can calculate how these concentrations change over time. \n\nModels can range from the simple to the highly complex, and can represent a mixture of experimental data and purely theoretical assumptions.\n\nUsers access Virtual Cell as a distributed application over the Internet. The web-based Java interface allows users to build complex models in biologically relevant terms: compartment dimensions and shape, molecular characteristics, and interaction parameters. VCell converts the biological description into an equivalent mathematical system of differential equations. Users can switch back-and-forth between the schematic biological view and the mathematical view in the common graphical interface. Indeed, if users desire, they can manipulate the mathematical description directly, bypassing the schematic view. VCell allows users a choice of numerical solvers to translate the mathematical description into software code which is executed to perform the simulations. The results can be displayed on-line, or they can be downloaded to the user's computer in a wide variety of export formats. The Virtual Cell license allows free access to all members of the scientific community.\n\nVCell supports the following features:\n\n\nVCell allows users integrated access to a variety of sources to help build and annotate models: \n\n\nThe Virtual Cell is being developed at the Center for Cell Analysis and Modeling at the University of Connecticut Health Center. The team is primarily funded through research grants through the National Institutes of Health.\n\n"}
{"id": "37842037", "url": "https://en.wikipedia.org/wiki?curid=37842037", "title": "WIRIS", "text": "WIRIS\n\nWIRIS is a set of proprietary HTML-based JavaScript tools which can author and edit mathematical formulas, execute mathematical problems and show mathematical graphics on the Cartesian coordinate system. WIRIS equation editor is a native browser application, with a light server-side, that supports both MathML and LaTeX.\n"}
