{"id": "2070023", "url": "https://en.wikipedia.org/wiki?curid=2070023", "title": "156 (number)", "text": "156 (number)\n\n156 (one hundred [and] fifty-six) is the natural number, following 155 and preceding 157.\n\n156 is an abundant number, a pronic number, a dodecagonal number, a refactorable number and a Harshad number.\n\n156 is a repdigit in base 5 (1111), and also in bases 25, 38, 51, 77, and 155.\n\n\n\n\n156 is also:\n\n\n"}
{"id": "362203", "url": "https://en.wikipedia.org/wiki?curid=362203", "title": "23 (number)", "text": "23 (number)\n\n23 (twenty-three) is the natural number following 22 and preceding 24.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "566866", "url": "https://en.wikipedia.org/wiki?curid=566866", "title": "880 (number)", "text": "880 (number)\n\n880 (eight hundred [and] eighty) is the natural number following 879 and preceding 881.\n\nIt is the number of 4-by-4 magic squares. It is a Harshad number.\n\n880 is the frequency in hertz of the musical note A5.\n\n880 is also:\n"}
{"id": "52825568", "url": "https://en.wikipedia.org/wiki?curid=52825568", "title": "Askar Dzhumadildayev", "text": "Askar Dzhumadildayev\n\nAskar Dzhumadildayev (; born 25 February 1956) is a Kazakh mathematician, doctor of physics and mathematics, professor, Full Member of the Kazakhstan National Academy of Science. He was also member Supreme Council of Kazakh SSR and Republic of Kazakhstan.\n\nAskar Serkululy Dzhumadilyavev was born on 25 April 1956 in Shieli, Kyzylorda Region, Kazakhstan. He was the member of the 51st IMO Jury.\n\n1977 – M.A. in Mathematics (Moscow State University)\n1981 – Ph.D. in Mathematics (Steklov Institute of Mathematics)\n1988 – 2nd Ph.D. in Mathematics (Steklov Institute of Mathematics)\n1990 – Professor of Kazakh State University\n1995 – Corresponding Member of the National Kazakh Academy of Sciences\n2004 – Full Member of the National Kazakh Academy of Sciences\n\n\n\n1983 – Prize of Republic Counsel for Science and Technology\n1993–1995 – Grants of American Mathematical Society,International Science Foundation (Soros Foundation) INTAS (International association for the Promotion of Cooperation with Scientists from former USSR)\n1995–1996 – Alexander von Humboldt Fellowship\n1999–2004 – Grant of Swedish Royal Academy of Sciences\n1999 – Grant of JSPS (Japan Soc. Promotion of Sciences)\n2000–2003 – Grant of INTAS\n2000–2004 – Kazakh State Fellowship for distinguished scholars\n2007, 2016 – Grant of Kazakh Ministry of Education \"Best professor of Higher School\"\n2011–2012 – Kazakh State Fellowship for distinguished scholars\n2011 – State Prize of the Republic of Kazakhstan in science and technology\n2012 – International Khwarizmi Award (Islamic Republic of Iran)\n\n"}
{"id": "1981917", "url": "https://en.wikipedia.org/wiki?curid=1981917", "title": "Bundle gerbe", "text": "Bundle gerbe\n\nIn mathematics, a bundle gerbe is a geometrical model of certain 1-gerbes with connection, or equivalently of a 2-class in Deligne cohomology.\n\nformula_1-principal bundles over a space formula_2 (see circle bundle) are geometrical realizations of 1-classes in Deligne cohomology which consist of 1-form connections) and 2-form curvatures. The topology of a formula_1 bundle is classified by its Chern class, which is an element of formula_4, the second integral cohomology of formula_2.\n\nGerbes, or more precisely 1-gerbes, are abstract descriptions of Deligne 2-classes, which each define an element of formula_6, the third integral cohomology of \"M\".\n\nHistorically the most popular construction of a gerbe is a category-theoretic model featured in Giraud's theory of gerbes, which are roughly sheaves of groupoids over \"M\".\n\nIn 1994 Murray introduced bundle gerbes, which are geometric realizations of 1-gerbes.\nFor many purposes these are more suitable for calculations than Giraud's realization, because their construction is entirely within the framework of classical geometry. In fact, as their name suggests, they are fiber bundles. This notion was extended to higher gerbes the following year.\n\nIn Twisted K-theory and the K-theory of Bundle Gerbes the authors defined modules of bundle gerbes and used this to define a K-theory for bundle gerbes. They then showed that this K-theory is isomorphic to Rosenberg's twisted K-theory, and provides an analysis-free construction.\n\nIn addition they defined a notion of twisted Chern character which is a characteristic class for an element of twisted K-theory. The twisted Chern character is a differential form that represents a class in the twisted cohomology with respect to the nilpotent operator\n\nwhere formula_8 is the ordinary exterior derivative and the \"twist\" formula_9 is a 3-form. This construction was extended to equivariant K-theory and to holomorphic K-theory by Mathai and Stevenson.\n\nBundle gerbes have also appeared in the context of conformal field theories. Gawedzki and Reis have interpreted the Wess-Zumino term in the Wess-Zumino-Witten model (WZW) of string propagation on a group manifold as the connection of a bundle gerbe. Urs Schreiber, Christoph Schweigert and Konrad Waldorf have used this construction to extend WZW models to unoriented surfaces and, more generally, the global Kalb-Ramond coupling to unoriented strings.\n\nMore details can be found at the n-Category Café:\n\n\n"}
{"id": "3879", "url": "https://en.wikipedia.org/wiki?curid=3879", "title": "Business statistics", "text": "Business statistics\n\n\"Business statistics is the science of good decision making in the face of uncertainty and is used in many disciplines such as financial analysis, econometrics, auditing, production and operations including services improvement and marketing research\".\n\nThese sources feature regular repetitive publication of series of data. This makes the topic of time series especially important for business statistics. It is also a branch of applied statistics working mostly on data collected as a by-product of doing business or by government agencies. It provides knowledge and skills to interpret and use statistical techniques in a variety of business applications.\n\nA typical business statistics course is intended for business majors, and covers statistical study, descriptive statistics (collection, description, analysis, and summary of data), probability, and the binomial and normal distributions, test of hypotheses and confidence intervals, linear regression, and correlation.\n\n\n"}
{"id": "35808199", "url": "https://en.wikipedia.org/wiki?curid=35808199", "title": "Canonizant", "text": "Canonizant\n\nIn mathematical invariant theory, the canonizant or canonisant is a covariant of forms related to a canonical form for them.\n\nThe canonizant of a binary form of degree 2\"n\" – 1 is a covariant of degree \"n\" and order \"n\", given by the catalecticant of the penultimate emanant, which is the determinant of the \"n\" by \"n\" Hankel matrix with entries \"a\"\"x\" + \"a\"\"y\" for 0 ≤ \"i\",\"j\" < \"n\".\n"}
{"id": "2941952", "url": "https://en.wikipedia.org/wiki?curid=2941952", "title": "Carus Mathematical Monographs", "text": "Carus Mathematical Monographs\n\nThe Carus Mathematical Monographs is a monograph series published by the Mathematical Association of America. Books in this series are intended to appeal to a wide range of readers in mathematics and science.\n\nWhile the books are intended to cover nontrivial material, the emphasis is on exposition and clear communication rather than novel results and a systematic Bourbaki-style presentation. The webpage for the series states:\n\nThe exposition of mathematical subjects that the monographs contain are set forth in a manner comprehensible not only to teachers and students specializing in mathematics, but also to scientific workers in other fields. More generally, the monographs are intended for the wide circle of thoughtful people familiar with basic graduate or advanced undergraduate mathematics encountered in the study of mathematics itself or in the context of related disciplines who wish to extend their knowledge without prolonged and critical study of the mathematical journals and treatises.\n\nMany of the books in the series have become classics in the genre of general mathematical exposition.\n\n\n\n"}
{"id": "1467815", "url": "https://en.wikipedia.org/wiki?curid=1467815", "title": "Computational indistinguishability", "text": "Computational indistinguishability\n\nIn computational complexity and cryptography, two families of distributions are computationally indistinguishable if no efficient algorithm can tell the difference between them except with small probability.\n\nLet formula_1 and formula_2 be two distribution ensembles indexed by a security parameter \"n\" (which usually refers to the length of the input); we say they are computationally indistinguishable if for any non-uniform probabilistic polynomial time algorithm \"A\", the following quantity is a negligible function in \"n\":\n\ndenoted formula_4. In other words, every efficient algorithm \"A\"'s behavior does not significantly change when given samples according to \"D\" or \"E\" in the limit as formula_5. Another interpretation of computational indistinguishability, is that polynomial-time algorithms actively trying to distinguish between the two ensembles cannot do so: that any such algorithm will only perform negligibly better than if one were to just guess.\n\nImplicit in the definition is the condition that the algorithm, formula_6, must decide based on a single sample from one of the distributions. One might conceive of a situation in which the algorithm trying to distinguish between two distributions, could access as many samples as it needed. Hence two ensembles that cannot be distinguished by polynomial-time algorithms looking at multiple samples are deemed indistinguishable by polynomial-time sampling. If the polynomial-time algorithm can generate samples in polynomial time, or has access to a random oracle that generates samples for it, then indistinguishability by polynomial-time sampling is equivalent to computational indistinguishability.\n\n"}
{"id": "31255067", "url": "https://en.wikipedia.org/wiki?curid=31255067", "title": "Criss-cross algorithm", "text": "Criss-cross algorithm\n\nIn mathematical optimization, the criss-cross algorithm is any of a family of algorithms for linear programming. Variants of the criss-cross algorithm also solve more general problems with linear inequality constraints and nonlinear objective functions; there are criss-cross algorithms for linear-fractional programming problems, quadratic-programming problems, and linear complementarity problems.\n\nLike the simplex algorithm of George B. Dantzig, the criss-cross algorithm is not a polynomial-time algorithm for linear programming. Both algorithms visit all 2 corners of a (perturbed) cube in dimension \"D\", the Klee–Minty cube (after Victor Klee and George J. Minty), in the worst case. However, when it is started at a random corner, the criss-cross algorithm on average visits only \"D\" additional corners. Thus, for the three-dimensional cube, the algorithm visits all 8 corners in the worst case and exactly 3 additional corners on average.\n\nThe criss-cross algorithm was published independently by Tamás Terlaky and by Zhe-Min Wang; related algorithms appeared in unpublished reports by other authors.\n\nIn linear programming, the criss-cross algorithm pivots between a sequence of bases but differs from the simplex algorithm of George Dantzig. The simplex algorithm first finds a (primal-) feasible basis by solving a \"\"phase-one\" problem\"; in \"phase two\", the simplex algorithm pivots between a sequence of basic \"feasible \"solutions so that the objective function is non-decreasing with each pivot, terminating when with an optimal solution (also finally finding a \"dual feasible\" solution).\n\nThe criss-cross algorithm is simpler than the simplex algorithm, because the criss-cross algorithm only has one phase. Its pivoting rules are similar to the least-index pivoting rule of Bland. Bland's rule uses only signs of coefficients rather than their (real-number) order when deciding eligible pivots. Bland's rule selects an entering variables by comparing values of reduced costs, using the real-number ordering of the eligible pivots. Unlike Bland's rule, the criss-cross algorithm is \"purely combinatorial\", selecting an entering variable and a leaving variable by considering only the signs of coefficients rather than their real-number ordering. The criss-cross algorithm has been applied to furnish constructive proofs of basic results in real linear algebra, such as the lemma of Farkas.\n\nWhile most simplex variants are monotonic in the objective (strictly in the non-degenerate case), most variants of the criss-cross algorithm lack a monotone merit function which can be a disadvantage in practice.\n\nThe criss-cross algorithm works on a standard pivot tableau (or on-the-fly calculated parts of a tableau, if implemented like the revised simplex method). In a general step, if the tableau is primal or dual infeasible, it selects one of the infeasible rows / columns as the pivot row / column using an index selection rule. An important property is that the selection is made on the union of the infeasible indices and the standard version of the algorithm does not distinguish column and row indices (that is, the column indices basic in the rows). If a row is selected then the algorithm uses the index selection rule to identify a position to a dual type pivot, while if a column is selected then it uses the index selection rule to find a row position and carries out a primal type pivot.\n\nThe time complexity of an algorithm counts the number of arithmetic operations sufficient for the algorithm to solve the problem. For example, Gaussian elimination requires on the order of\" D\" operations, and so it is said to have polynomial time-complexity, because its complexity is bounded by a cubic polynomial. There are examples of algorithms that do not have polynomial-time complexity. For example, a generalization of Gaussian elimination called Buchberger's algorithm has for its complexity an exponential function of the problem data (the degree of the polynomials and the number of variables of the multivariate polynomials). Because exponential functions eventually grow much faster than polynomial functions, an exponential complexity implies that an algorithm has slow performance on large problems.\n\nSeveral algorithms for linear programming—Khachiyan's ellipsoidal algorithm, Karmarkar's projective algorithm, and central-path algorithms—have polynomial time-complexity (in the worst case and thus on average). The ellipsoidal and projective algorithms were published before the criss-cross algorithm.\n\nHowever, like the simplex algorithm of Dantzig, the criss-cross algorithm is \"not\" a polynomial-time algorithm for linear programming. Terlaky's criss-cross algorithm visits all the 2 corners of a (perturbed) cube in dimension \"D\", according to a paper of Roos; Roos's paper modifies the Klee–Minty construction of a cube on which the simplex algorithm takes 2 steps. Like the simplex algorithm, the criss-cross algorithm visits all 8 corners of the three-dimensional cube in the worst case.\n\nWhen it is initialized at a random corner of the cube, the criss-cross algorithm visits only \"D\" additional corners, however, according to a 1994 paper by Fukuda and Namiki. Trivially, the simplex algorithm takes on average \"D\" steps for a cube. Like the simplex algorithm, the criss-cross algorithm visits exactly 3 additional corners of the three-dimensional cube on average.\n\nThe criss-cross algorithm has been extended to solve more general problems than linear programming problems.\n\nThere are variants of the criss-cross algorithm for linear programming, for quadratic programming, and for the linear-complementarity problem with \"sufficient matrices\"; conversely, for linear complementarity problems, the criss-cross algorithm terminates finitely only if the matrix is a sufficient matrix. A sufficient matrix is a generalization both of a positive-definite matrix and of a P-matrix, whose principal minors are each positive. The criss-cross algorithm has been adapted also for linear-fractional programming.\n\nThe criss-cross algorithm was used in an algorithm for enumerating all the vertices of a polytope, which was published by David Avis and Komei Fukuda in 1992. Avis and Fukuda presented an algorithm which finds the \"v\" vertices of a polyhedron defined by a nondegenerate system of \"n\" linear inequalities in \"D\" dimensions (or, dually, the \"v\" facets of the convex hull of \"n\" points in \"D\" dimensions, where each facet contains exactly \"D\" given points) in time O(\"nDv\") and O(\"nD\") space.\n\nThe criss-cross algorithm is often studied using the theory of oriented matroids (OMs), which is a combinatorial abstraction of linear-optimization theory. Indeed, Bland's pivoting rule was based on his previous papers on oriented-matroid theory. However, Bland's rule exhibits cycling on some oriented-matroid linear-programming problems. The first purely combinatorial algorithm for linear programming was devised by Michael J. Todd. Todd's algorithm was developed not only for linear-programming in the setting of oriented matroids, but also for quadratic-programming problems and linear-complementarity problems. Todd's algorithm is complicated even to state, unfortunately, and its finite-convergence proofs are somewhat complicated.\n\nThe criss-cross algorithm and its proof of finite termination can be simply stated and readily extend the setting of oriented matroids. The algorithm can be further simplified for \"linear feasibility problems\", that is for linear systems with nonnegative variables; these problems can be formulated for oriented matroids. The criss-cross algorithm has been adapted for problems that are more complicated than linear programming: There are oriented-matroid variants also for the quadratic-programming problem and for the linear-complementarity problem.\n\nThe criss-cross algorithm is a simply stated algorithm for linear programming. It was the second fully combinatorial algorithm for linear programming. The partially combinatorial simplex algorithm of Bland cycles on some (nonrealizable) oriented matroids. The first fully combinatorial algorithm was published by Todd, and it is also like the simplex algorithm in that it preserves feasibility after the first feasible basis is generated; however, Todd's rule is complicated. The criss-cross algorithm is not a simplex-like algorithm, because it need not maintain feasibility. The criss-cross algorithm does not have polynomial time-complexity, however.\n\nResearchers have extended the criss-cross algorithm for many optimization-problems, including linear-fractional programming. The criss-cross algorithm can solve quadratic programming problems and linear complementarity problems, even in the setting of oriented matroids. Even when generalized, the criss-cross algorithm remains simply stated.\n\n\n\n"}
{"id": "910234", "url": "https://en.wikipedia.org/wiki?curid=910234", "title": "Cut-elimination theorem", "text": "Cut-elimination theorem\n\nThe cut-elimination theorem (or Gentzen's \"Hauptsatz\") is the central result establishing the significance of the sequent calculus. It was originally proved by Gerhard Gentzen in his landmark 1934 paper \"Investigations in Logical Deduction\" for the systems LJ and LK formalising intuitionistic and classical logic respectively. The cut-elimination theorem states that any judgement that possesses a proof in the sequent calculus making use of the cut rule also possesses a cut-free proof, that is, a proof that does not make use of the cut rule.\n\nA sequent is a logical expression relating multiple formulas, in the form , which is to be read as proves , and (as glossed by Gentzen) should be understood as equivalent to the truth-function \"If (formula_1 and formula_2 and formula_3 …) then (formula_4 or formula_5 or formula_6 …).\" Note that the left-hand side (LHS) is a conjunction (and) and the RHS is a disjunction (or). \n\nThe LHS may have arbitrarily many or few formulae; when the LHS is empty, the RHS is a tautology. In LK, the RHS may also have any number of formulae—if it has none, the LHS is a contradiction, whereas in LJ the RHS may only have one formula or none: here we see that allowing more than one formula in the RHS is equivalent, in the presence of the right contraction rule, to the admissibility of the law of the excluded middle. However, the sequent calculus is a fairly expressive framework, and there have been sequent calculi for intuitionistic logic proposed that allow many formulae in the RHS. From Jean-Yves Girard's logic LC it is easy to obtain a rather natural formalisation of classical logic where the RHS contains at most one formula; it is the interplay of the logical and structural rules that is the key here.\n\n\"Cut\" is a rule in the normal statement of the sequent calculus, and equivalent to a variety of rules in other proof theories, which, given\n\nand \n\nallows one to infer\n\nThat is, it \"cuts\" the occurrences of the formula formula_7 out of the inferential relation. \nThe cut-elimination theorem states that (for a given system) any sequent provable using the rule Cut can be proved without use of this rule.\n\nFor sequent calculi that have only one formula in the RHS, the \"Cut\" rule reads, given\n\nand \n\nallows one to infer\n\nIf we think of formula_8 as a theorem, then cut-elimination in this case simply says that a lemma formula_7 used to prove this theorem can be inlined. Whenever the theorem's proof mentions lemma formula_7, we can substitute the occurrences for the proof of formula_7. Consequently, the cut rule is admissible.\n\nFor systems formulated in the sequent calculus, analytic proofs are those proofs that do not use Cut. Typically such a proof will be longer, of course, and not necessarily trivially so. In his essay \"Don't Eliminate Cut!\" George Boolos demonstrated that there was a derivation that could be completed in a page using cut, but whose analytic proof could not be completed in the lifespan of the universe.\n\nThe theorem has many, rich consequences:\n\nCut elimination is one of the most powerful tools for proving interpolation theorems. The possibility of carrying out proof search based on resolution, the essential insight leading to the Prolog programming language, depends upon the admissibility of Cut in the appropriate system.\n\nFor proof systems based on higher-order typed lambda calculus through a Curry–Howard isomorphism, cut elimination algorithms correspond to the strong normalization property (every proof term reduces in a finite number of steps into a normal form).\n\n\n\n"}
{"id": "591359", "url": "https://en.wikipedia.org/wiki?curid=591359", "title": "Dialetheism", "text": "Dialetheism\n\nDialetheism (di-alethe-ism is greek for two-truth-(belief in)) is the view that there are statements which are both true and false. More precisely, it is the belief that there can be a true statement whose negation is also true. Such statements are called \"true contradictions\", \"dialetheia\", or nondualisms.\n\nDialetheism is not a system of formal logic; instead, it is a thesis about truth that influences the construction of a formal logic, often based on pre-existing systems. Introducing dialetheism has various consequences, depending on the theory into which it is introduced. A common mistake resulting from this is to reject dialetheism on the basis that, in traditional systems of logic (e.g., classical logic and intuitionistic logic), every statement becomes false if a contradiction is true; this means that such systems become trivial when dialetheism is included as an axiom. Other logical systems, however, do not explode in this manner when contradictions are introduced; such contradiction-tolerant systems are known as paraconsistent logics. Dialetheists who do not want to allow that every statement is true are free to favour these over traditional, explosive logics.\n\nGraham Priest defines dialetheism as the view that there are true contradictions. Jc Beall is another advocate; his position differs from Priest's in advocating constructive (methodological) deflationism regarding the truth predicate.\n\nThe Liar's paradox and Russell's paradox deal with self-contradictory statements in classical logic and naïve set theory, respectively. Contradictions are problematic in these theories because they cause the theories to explode—if a contradiction is true, then every proposition is true. The classical way to solve this problem is to ban contradictory statements, to revise the axioms of the logic so that self-contradictory statements do not appear. Dialetheists, on the other hand, respond to this problem by accepting the contradictions as true. Dialetheism allows for the unrestricted axiom of comprehension in set theory, claiming that any resulting contradiction is a theorem.\n\nAmbiguous situations may cause humans to affirm both a proposition and its negation. For example, if John stands in the doorway to a room, it may seem reasonable both to affirm that \"John is in the room\" and to affirm that \"John is not in the room\".\n\nCritics argue that this merely reflects an ambiguity in our language rather than a dialetheic quality in our thoughts; if we replace the given statement with one that is less ambiguous (such as \"John is halfway in the room\" or \"John is in the doorway\"), the contradiction disappears. The statements appeared contradictory only because of a syntactic play; here, the actual meaning of \"being in the room\" is not the same in both instances, and thus each sentence is not the exact logical negation of the other: therefore, they are not necessarily contradictory.\n\nThe Jain philosophical doctrine of anekantavada—non-one-sidedness—states that all statements are true in some sense and false in another. Some interpret this as saying that dialetheia not only exist but are ubiquitous. Technically, however, a \"logical contradiction\" is a proposition that is true and false in the \"same\" sense; a proposition which is true in one sense and false in another does not constitute a logical contradiction. (For example, although in one sense a man cannot both be a \"father\" and \"celibate\"—leaving aside such cases as a celibate man adopting a child or a man fathering a child and only later adopting celibacy—there is no contradiction for a man to be a \"spiritual\" father and also celibate; the sense of the word father is different here. In another example, although at the same time George W. Bush cannot both be President and not be President, he was President from 2001-2009, but was not President before 2001 or after 2009, so in different times he was both President and not President.)\n\nThe Buddhist logic system named Catuṣkoṭi similarly implies that a statement and its negation may possibly co-exist.\n\nGraham Priest argues in \"Beyond the Limits of Thought\" that dialetheia arise at the borders of expressibility, in a number of philosophical contexts other than formal semantics.\n\nIn classical logics, taking a contradiction formula_1 (see List of logic symbols) as a premise (that is, taking as a premise the truth of both formula_2 and formula_3), allows us to prove any statement formula_4. Indeed, since formula_2 is true, the statement formula_6 is true (by generalization). Taking formula_6 together with formula_3 is a disjunctive syllogism from which we can conclude formula_4. (This is often called the \"principle of explosion\", since the truth of a contradiction is imagined to make the number of theorems in a system \"explode\".)\n\nThe proponents of dialetheism mainly advocate its ability to avoid problems faced by other more orthodox resolutions as a consequence of their appeals to hierarchies. According to Graham Priest, \"the whole point of the dialetheic solution to the semantic paradoxes is to get rid of the distinction between object language and meta-language\". Another possibility is to utilize dialetheism along with a paraconsistent logic to resurrect the program of logicism advocated for by Frege and Russell. This even allows one to prove the truth of otherwise unprovable theorems such as the well-ordering theorem and the falsity of others such as the continuum hypothesis.\n\nThere are also dialetheic solutions to the sorites paradox.\n\nOne criticism of dialetheism is that it fails to capture a crucial feature about negation, known as absoluteness of disagreement.\n\nImagine John's utterance of \"P\". Sally's typical way of disagreeing with John is a consequent utterance of ¬\"P\". Yet, if we accept dialetheism, Sally's so uttering does not prevent her from also accepting \"P\"; after all, \"P\" may be a dialetheia and therefore it and its negation are both true. The absoluteness of disagreement is lost.\n\nA response is that disagreement can be displayed by uttering \"¬\"P\" and, furthermore, \"P\" is not a dialetheia\". However, the most obvious codification of \"\"P\" is not a dialetheia\" is ¬(\"P\" & ¬\"P\"). But what if \"this itself\" is a dialetheia as well? One dialetheist response is to offer a distinction between assertion and rejection. This distinction might be hashed out in terms of the traditional distinction between logical qualities, or as a distinction between two illocutionary speech acts: assertion and rejection. Another criticism is that dialetheism cannot describe logical consequences, once we believe in the relevance of logical consequences, because of its inability to describe hierarchies.\n\n\n\n"}
{"id": "20755852", "url": "https://en.wikipedia.org/wiki?curid=20755852", "title": "Educational Studies in Mathematics", "text": "Educational Studies in Mathematics\n\nEducational Studies in Mathematics is a peer-reviewed scientific journal within the field of mathematics education. Founded by Hans Freudenthal, it first appeared in 1968. Published by Springer, the journal normally appears in 3 annual volumes, each consisting of 3 issues. The journal is paginated by volume.\n\nAccording to the official description of the journal, it \"emphasizes high-level articles that go beyond local or national interest\", and a typical article deals with \"didactical, methodological and pedagogical subjects, rather than with specific programs for teaching mathematics\".\n\nThe journal was listed in ISI and received an impact factor (of 0.549) for the first time in 2012.\n\n\n"}
{"id": "57110772", "url": "https://en.wikipedia.org/wiki?curid=57110772", "title": "Eugene Isaacson", "text": "Eugene Isaacson\n\nEugene Isaacson (1919–2008), was a US mathematician who pioneered modern numerical analysis. He was a mathematics and physics graduate of City College in New York, he then entered the graduate program in mathematics at New York University under the supervision of Kurt Otto Friedrichs, gaining a PhD on water waves on sloping beaches in 1949. His academic career was then spent at the Courant Institute until his retirement.\n\nDespite an initial interest in topology, Isaacson worked for most of his career in applied and computational mathematics and is best known for his work on the numerical solution of differential equations. His book with Herbert Keller Analysis of Numerical Methods was a leading textbook at the time.\n\nHe served as editor for \"Mathematics of Computation\" and the \"SIAM Journal on Numerical Analysis\".\n\nA special issue of Mathematics of Computation was published in 1989 to celebrate his 70th birthday. The contributors included his sons David and Eli Isaacson, also mathematicians, who wrote a paper together for this volume. The paper is dedicated to their father and their mother Muriel \"for making this collaboration possible\".\n"}
{"id": "41069703", "url": "https://en.wikipedia.org/wiki?curid=41069703", "title": "Eugenius Nulty", "text": "Eugenius Nulty\n\nEugenius Nulty (1790 – July 3, 1871) was an Irish born American mathematician of the 19th century. He served on the faculty of Dickinson College from 1814 to 1816, and later taught and tutored prominent Philadelphians, including the brothers Mathew Carey Lea and Henry Charles Lea.\n\nAfter arriving in the United States from his native Ireland, Nulty quickly became ensconced as a member of the new nation’s small intelligentsia. Contemporaries described him as “brilliant”.\n\nIn 1814, Nulty became a professor of mathematics at Dickinson College, where he remained for two years. In 1816 he moved to Philadelphia at the invitation of The Philadelphia Life Insurance Company and the Pennsylvania Company, who each recruited Nulty as one of the first U.S. actuarial scientists. His new countrymen also called Nulty to assist with mathematics for the U.S. Office of Coast Survey.\n\nIn 1817, Nulty was elected a member of the American Philosophical Society. In 1823, the University of Pennsylvania awarded Nulty an honorary A.M. He was elected an Associate Fellow of the American Academy of Arts and Sciences 1832. Nulty was also a correspondent of mathematician, chemist and natural philosopher Robert M. Patterson.\n\nNulty contributed to the defunct \"Mathematical Diary\", one of the 3 earliest learned mathematical journals published in the U.S. His \"Elements of Geometry, theoretical and practical\" Philadelphia: J. Wetham (1836) was one of the first two or three original geometries published in the United States and is still over 150 years later available from multiple publishers in historical reprints.\n\nIn 1840, P.J. Walker, director of the National Institute for the Promotion of Science, called Nulty \"unsurpassed at home or abroad\" in pure mathematics.\n"}
{"id": "36903485", "url": "https://en.wikipedia.org/wiki?curid=36903485", "title": "Fractal canopy", "text": "Fractal canopy\n\nIn geometry, fractal canopies are one of the easiest-to-create types of fractals. They are created by splitting a line segment into two smaller segments at the end, and then splitting the two smaller segments and as well, and so on, infinitely.\n\nA fractal canopy must have the following three properties:\n\n\n"}
{"id": "22850636", "url": "https://en.wikipedia.org/wiki?curid=22850636", "title": "Generalized trigonometry", "text": "Generalized trigonometry\n\nOrdinary trigonometry studies triangles in the Euclidean plane R. There are a number of ways of defining the ordinary Euclidean geometric trigonometric functions on real numbers: right-angled triangle definitions, unit-circle definitions, series definitions, definitions via differential equations, definitions using functional equations. Generalizations of trigonometric functions are often developed by starting with one of the above methods and adapting it to a situation other than the real numbers of Euclidean geometry. Generally, trigonometry can be the study of triples of points in any kind of geometry or space. A triangle is the polygon with the smallest number of vertices, so one direction to generalize is to study higher-dimensional analogs of angles and polygons: solid angles and polytopes such as tetrahedrons and n-simplices.\n\n\n\n\n\n\n\n\n\n"}
{"id": "37761264", "url": "https://en.wikipedia.org/wiki?curid=37761264", "title": "Grothendieck–Teichmüller group", "text": "Grothendieck–Teichmüller group\n\nIn mathematics, the Grothendieck–Teichmüller group \"GT\" is a group closely related to (and possibly equal to) the absolute Galois group of the rational numbers. It was introduced by and named after Alexander Grothendieck and Oswald Teichmüller, based on Grothendieck's suggestion in his Esquisse d'un Programme to study the absolute Galois group of the rationals by relating it to its action on the Teichmüller tower of Teichmüller groupoids \"T\", the fundamental groupoids of moduli stacks of genus \"g\" curves with \"n\" points removed. There are several minor variations of the group: a discrete version, a pro-\"l\" version, a \"k\"-pro-unipotent version, and a profinite version; the first three versions were defined by Drinfeld, and the version most often used is the profinite version.\n\n"}
{"id": "30709197", "url": "https://en.wikipedia.org/wiki?curid=30709197", "title": "Grundlagen der Mathematik", "text": "Grundlagen der Mathematik\n\nGrundlagen der Mathematik (English: \"Foundations of Mathematics\") is a two-volume work by David Hilbert and Paul Bernays. Originally published in 1934 and 1939, it presents fundamental mathematical ideas and introduced second-order arithmetic.\n\n\n\n\n"}
{"id": "14334415", "url": "https://en.wikipedia.org/wiki?curid=14334415", "title": "Grzegorczyk hierarchy", "text": "Grzegorczyk hierarchy\n\nThe Grzegorczyk hierarchy (pronounced: ), named after the Polish logician Andrzej Grzegorczyk, is a hierarchy of functions used in computability theory (Wagner and Wechsung 1986:43). Every function in the Grzegorczyk hierarchy is a primitive recursive function, and every primitive recursive function appears in the hierarchy at some level. The hierarchy deals with the rate at which the values of the functions grow; intuitively, functions in lower level of the hierarchy grow slower than functions in the higher levels. \n\nFirst we introduce an infinite set of functions, denoted \"E\" for some natural number \"i\". We define formula_1 and formula_2. I.e., \"E\" is the addition function, and \"E\" is a unary function which squares its argument and adds two. Then, for each \"n\" greater than 1, we define formula_3, i.e. the \"x\"-th iterate of formula_4 evaluated at 2.\n\nFrom these functions we define the Grzegorczyk hierarchy. formula_5, the \"n\"-th set in the hierarchy, contains the following functions:\n\nIn other words, formula_5 is the closure of set formula_16 with respect to function composition and limited recursion (as defined above).\n\nThese sets clearly form the hierarchy\nbecause they are closures over the formula_18's and formula_19.\n\nThey are strict subsets (Rose 1984; Gakwaya 1997). In other words\nbecause the hyper operation formula_21 is in formula_5 but not in formula_23.\n\n\nNotably, both the function formula_29 and the characteristic function of the predicate formula_30 from the Kleene normal form theorem are definable in a way such that they lie at level formula_24 of the Grzegorczyk hierarchy. This implies in particular that every recursively enumerable set is enumerable by some formula_24-function.\n\nThe definition of formula_5 is the same as that of the primitive recursive functions, , except that recursion is \"limited\" (formula_10 for some \"j\" in formula_5) and the functions formula_36 are explicitly included in formula_5. Thus the Grzegorczyk hierarchy can be seen as a way to \"limit\" the power of primitive recursion to different levels.\n\nIt is clear from this fact that all functions in any level of the Grzegorczyk hierarchy are primitive recursive functions (i.e. formula_38) and thus:\n\nIt can also be shown that all primitive recursive functions are in some level of the hierarchy (Rose 1984; Gakwaya 1997), thus\nand the sets formula_41 partition the set of primitive recursive functions, .\n\nThe Grzegorczyk hierarchy can be extended to transfinite ordinals. Such extensions define a fast-growing hierarchy. To do this, the generating functions formula_42 must be recursively defined for limit ordinals (note they have already been recursively defined for successor ordinals by the relation formula_43). If there is a standard way of defining a \"fundamental sequence\" formula_44, whose limit ordinal is formula_45, then the generating functions can be defined formula_46. However, this definition depends upon a standard way of defining the fundamental sequence. Rose (1984) suggests a standard way for all ordinals α < ε.\n\nThe original extension was due to Martin Löb and Stan S. Wainer (1970) and is sometimes called the Löb–Wainer hierarchy.\n\n\n"}
{"id": "33194896", "url": "https://en.wikipedia.org/wiki?curid=33194896", "title": "Harish-Chandra's Schwartz space", "text": "Harish-Chandra's Schwartz space\n\nIn mathematical abstract harmonic analysis, Harish-Chandra's Schwartz space is a space of functions on a semisimple Lie group whose derivatives are rapidly decreasing, studied by . It is an analogue of the Schwartz space on a real vector space, and is used to define the space of tempered distributions on a semisimple Lie group.\n\nThe definition of the Schwartz space uses Harish-Chandra's Ξ function and his \"σ\" function. The \"σ\" function is defined by\nfor \"x\"=\"k\" exp \"X\" with \"k\" in \"K\" and \"X\" in \"p\" for a Cartan decomposition \"G\" = \"K\" exp \"p\" of the Lie group \"G\", where ||\"X\"|| is a \"K\"-invariant Euclidean norm on \"p\", usually chosen to be the Killing form. .\n\nThe Schwartz space on \"G\" consists roughly of the functions all of whose derivatives are rapidly decreasing compared to \"Ξ\". More precisely, if \"G\" is connected then the Schwartz space consists of all smooth functions \"f\" on \"G\" such that \nis bounded, where \"D\" is a product of left-invariant and right-invariant differential operators on \"G\" .\n\n"}
{"id": "5352569", "url": "https://en.wikipedia.org/wiki?curid=5352569", "title": "Harish-Chandra isomorphism", "text": "Harish-Chandra isomorphism\n\nIn mathematics, the Harish-Chandra isomorphism, introduced by ,\nis an isomorphism of commutative rings constructed in the theory of Lie algebras. The isomorphism maps the center \"Z\"(\"U\"(\"g\")) of the universal enveloping algebra \"U\"(\"g\") of a reductive Lie algebra \"g\" to the elements \"S\"(\"h\") of the symmetric algebra \"S\"(\"h\") of a Cartan subalgebra \"h\" that are invariant under the Weyl group \"W\".\n\nLet \"n\" be the rank of \"g\", which is the dimension of the Cartan subalgebra \"h\". H. S. M. Coxeter observed that \"S\"(\"h\") is a polynomial algebra in \"n\" variables (see Chevalley–Shephard–Todd theorem for a more general statement). Therefore, the center of the universal enveloping algebra of a reductive Lie algebra is a polynomial algebra. The degrees of the generators are the degrees of the fundamental invariants given in the following table.\nFor example, the center of the universal enveloping algebra of \"G\" is a polynomial algebra on generators of degrees 2 and 6.\n\n\nLet \"g\" be a semisimple Lie algebra, \"h\" its Cartan subalgebra and λ, μ ∈ \"h\"* be two elements of the weight space and assume that a set of positive roots Φ have been fixed. Let \"V\", resp. \"V\" be highest weight modules with highest weight λ, resp. μ.\n\nThe \"g\"-modules \"V\" and \"V\" are representations of the universal enveloping algebra \"U\"(\"g\") and its center acts on the modules by scalar multiplication (this follows from the fact that the modules are generated by a highest weight vector). So, for \"v\" in \"V\" and \"x\" in \"Z\"(\"U\"(\"g\")),\nand similarly for \"V\".\n\nThe functions formula_2 are homomorphims to scalars called \"central characters\".\n\nFor any λ, μ ∈ \"h\"*, the characters formula_3 if and only if λ+δ and μ+δ are on the same orbit of the Weyl group of \"h\"*, where δ is the half-sum of the positive roots.\n\nAnother closely related formulation is that the Harish-Chandra homomorphism from the center of the universal enveloping algebra \"Z\"(\"U\"(\"g\")) to \"S\"(\"h\") (the elements of the symmetric algebra of the Cartan subalgebra fixed by the Weyl group) is an isomorphism.\n\nThe theorem may be used to obtain a simple algebraic proof of Weyl's character formula for finite-dimensional representations.\n\nFurther, it is a necessary condition for the existence of a nonzero homomorphism of some highest weight modules (a homomorphism of such modules preserves central character). A simple consequence is that for Verma modules or generalized Verma modules \"V\" with highest weight λ, there exist only finitely many weights μ such that a nonzero homomorphism \"V\" → \"V\" exists.\n\n\n"}
{"id": "6095407", "url": "https://en.wikipedia.org/wiki?curid=6095407", "title": "Herta Freitag", "text": "Herta Freitag\n\nHerta Freitag (December 6, 1908 – January 25, 2000) was an Austrian-American mathematician, a professor of mathematics at Hollins College, known for her work on the Fibonacci numbers.\nShe was born as Herta Taussig in Vienna, Austria. She earned a master's degree from the University of Vienna in 1934 and took a teaching position at the university. However, her father (the editor of \"Die Neue Freie Presse\") had publicly opposed the Nazis, so in 1938 she and her parents emigrated to England, taking a job as a maid because the English immigration laws prevented her from entering the country as a teacher. In 1944 she, her brother (the conductor Walter Taussig) and her mother moved to the United States (her father having died a year earlier), and began teaching mathematics again at the Greer School in upstate New York.\n\nShe earned a second master's degree in 1948 from Columbia University, and a doctorate from Columbia in 1953. Meanwhile, in 1948, she had joined the faculty at Hollins, where she eventually became a full professor and department chair. In 1962 she served as a section president for the Mathematical Association of America, the first woman in her section to do so. She retired in 1971, but returned to teaching again in 1979 after the death of her husband, Arthur Freitag, whom she had married in 1950.\n\nAfter her retirement, she became a frequent contributor to the \"Fibonacci Quarterly\", and the journal honored her in 1996 by dedicating an issue to her on the occasion of her 89th birthday (89 being a Fibonacci number).\n"}
{"id": "38039504", "url": "https://en.wikipedia.org/wiki?curid=38039504", "title": "Hochster–Roberts theorem", "text": "Hochster–Roberts theorem\n\nIn algebra, the Hochster–Roberts theorem, introduced by , \nstates that rings of invariants of linearly reductive groups acting on regular rings are Cohen–Macaulay.\n\nIn other words,\n\nIn characteristic \"p\">0, there are examples of groups that are reductive (or even finite) acting on polynomial rings whose rings of invariants are not Cohen–Macaulay.\n\n"}
{"id": "1285375", "url": "https://en.wikipedia.org/wiki?curid=1285375", "title": "Hyperbolic metric space", "text": "Hyperbolic metric space\n\nIn mathematics, a hyperbolic metric space is a metric space satisfying certain metric relations (depending quantitatively on a nonnegative real number δ) between points. The definition, introduced by Mikhael Gromov, generalizes the metric properties of classical hyperbolic geometry and of trees. Hyperbolicity is a large-scale property, and is very useful to the study of certain infinite groups called (Gromov-)hyperbolic groups.\n\nIn this paragraph we give various definitions of a formula_1-hyperbolic space. A metric space is said to be (Gromov-) hyperbolic if it is formula_1-hyperbolic for some formula_3.\n\nLet formula_4 be a metric space. The Gromov product of two points formula_5 with respect to a third one formula_6 is defined by the formula:\n\nGromov's definition of a hyperbolic metric space is then as follows: formula_8 is formula_1-hyperbolic if and only if all formula_10 satisfy the \"four-point condition\"\n\nNote that if this condition is satisfied for all formula_12 and one fixed base point formula_13, then it is satisified for all formula_14 with a constant formula_15. Thus the hyperbolicity condition only needs to be verified for one fixed base point; for this reason, the subscript for the base point is often dropped from the Gromov product.\n\nUp to changing formula_1 by a constant multiple, there is an equivalent geometric definition involving triangles when the metric space formula_8 is \"geodesic\", i.e. any two points formula_18 are end points of a geodesic segment formula_19 (an isometric image of a compact subinterval formula_20 of the reals). Note that the definition via Gromov products does not require the space to be geodesic.\n\nLet formula_21. A geodesic triangle with vertices formula_22 is the union of three geodesic segments formula_23 (where formula_24 denotes a segment with endpoints formula_25 and formula_26).\n\nIf for any point formula_27 there is a point in formula_28 at distance less than formula_1 of formula_30, and similarly for points on the other edges, and formula_31 then the triangle is said to be \"formula_1-slim\" .\n\nA definition of a formula_1-hyperbolic space is then a geodesic metric space all of whose geodesic triangles are formula_1-slim. This definition is generally credited to Eliyahu Rips.\n\nAnother definition can be given using the notion of a formula_35-approximate center of a geodesic triangle: this is a point which is at distance at most formula_35 of any edge of the triangle (an \"approximate\" version of the incenter). A space is formula_1-hyperbolic if every geodesic triangle has a formula_1-center.\n\nThese two definitions of a formula_1-hyperbolic space using geodesic triangles are not exactly equivalent, but there exists formula_40 such that a formula_1-hyperbolic space in the first sense is formula_42-hyperbolic in the second, and vice versa. Thus the notion of an hyperbolic space is independent of the chosen definition.\n\nThe hyperbolic plane is hyperbolic: in fact the incircle of a geodesic triangle is the circle of largest diameter contained in the triangle and every geodesic triangle lies in the interior of an ideal triangle, all of which are isometric with incircles of diameter 2 log 3. Note that in this case the Gromov product also has a simple interpretation in terms of the incircle of a geodesic triangle. In fact the quantity is just the hyperbolic distance from to either of the points of contact of the incircle with the adjacent sides: for from the diagram , so that \n\nThe Euclidean plane is not hyperbolic, for example because of the existence of homotheties.\n\nTwo \"degenerate\" examples of hyperbolic spaces are spaces with bounded diameter (for example finite or compact spaces) and the real line.\n\nMetric trees and more generally real trees are the simplest interesting examples of hyperbolic spaces as they are 0-hyperbolic (i.e. all triangles are tripods).\n\nThe 1-skeleton of the triangulation by Euclidean equilateral triangles is not hyperbolic (it is in fact quasi-isometric to the Euclidean plane). A triangulation of the plane formula_43 has an hyperbolic 1-skeleton if every vertex has degree 7 or more.\n\nThe two-dimensional grid is not hyperbolic (it is quasi-isometric to the Euclidean plane). It is the Cayley graph of the fundamental group of the torus; the Cayley graphs of the fundamental groups of a surface of higher genus is hyperbolic (it is in fact quasi-isometric to the hyperbolic plane).\n\nThe hyperbolic plane (and more generally any Hadamard manifolds of sectional curvature formula_44) is formula_45-hyperbolic. If we scale the Riemannian metric by a factor formula_46 then the distances are multiplied by formula_47 and thus we get a space that is formula_48-hyperbolic. Since the curvature is multiplied by formula_49 we see that in this example \"the more (negatively) curved the space is, the more hyperbolic it is (measured by its hyperbolicity constant formula_1)\".\n\nSimilar examples are CAT spaces of negative curvature. With respect to curvature and hyperbolicity it should be noted however that while curvature is a property that is essentially local, hyperbolicity is a large-scale property which does not see local (i.e. happening in a bounded region) metric phenomena. For example, the union of an hyperbolic space with a compact space with any metric extending the original ones remains hyperbolic.\n\nOne way to precise the meaning of \"large scale\" is to require invariance under quasi-isometry. This is true of hyperbolicity.\n\nThe constant formula_54 depends on formula_1 and on the multiplicative and additive constants for the quasi-isometry.\n\nThe definition of an hyperbolic space in terms of the Gromov product can be seen as saying that the metric relations between any four points are the same as they would be in a tree, up to the additive constant formula_1. More generally the following property shows that any finite subset of an hyperbolic space looks like a finite tree.\n\nThe constant formula_35 can be taken to be formula_71 with formula_72 and this is optimal.\n\nIn an hyperbolic space formula_8 we have the following property:\n\nInformally this means that the circumference of a \"circle\" of radius formula_80 grows exponentially with formula_80. This is reminiscent of the isoperimetric problem in the Euclidean plane. Here is a more specific statement to this effect.\n\nHere the area of a 2-complex is the number of 2-cells and the length of a 1-complex is the number of 1-cells. The statement above is a linear isoperimetric inequality ; it turns out that having such an isoperimetric inequality characterises Gromov-hyperbolic spaces. Linear isoperimetric inequalities were inspired by the small cancellation conditions from combinatorial group theory.\n\nA subspace formula_51 of a geodesic metric space formula_8 is said to be quasiconvex if there is a constant formula_35 such that any geodesic in formula_78 between two points of formula_51 stays within distance formula_35 of formula_51.\n\nAll asymptotic cones of an hyperbolic space are real trees. This property characterises hyperbolic spaces.\n\nGeneralising the construction of the ends of a simplicial tree there is a natural notion of boundary at infinity for hyperbolic spaces, which has proven very useful for analysing group actions.\n\nIn this paragraph formula_8 is a geodesic metric space which is hyperbolic.\n\nA sequence formula_99 is said to \"converge to infinity\" if for some (or any) point formula_25 we have that formula_101 as both formula_102 and formula_30 go to infinity. Two sequences formula_104 converging to infinity are considered equivalent when formula_105 (for some or any formula_25). The \"boundary\" of formula_8 is the set of equivalence classes of sequences which converge to infinity, which is denoted formula_108.\n\nIf formula_109 are two points on the boundary then their Gromov product is defined to be:\n\nwhich is finite and does not depend on formula_111. One can then define a topology on formula_108 using the functions formula_113. This topology on formula_108 is metrisable and there is a distinguished family of metrics defined using the Gromov product.\n\nLet formula_115 be two quasi-isometric embeddings of formula_116 into formula_8 (\"quasi-geodesic rays\"). They are considered equivalent if and only if the function formula_118 is bounded on formula_116. If the space formula_8 is proper then the set of all such embeddings modulo equivalence with its natural topology is homeomorphic to formula_108 as defined above.\n\nA similar realisation is to fix a basepoint and consider only quasi-geodesic rays originating from this point. In case formula_8 is geodesic and proper one can also restrict to genuine geodesic rays.\n\nWhen formula_123 is a simplicial regular tree the boundary is just the space of ends, which is a Cantor set. Fixing a point formula_124 yields a natural distance on formula_125: two points represented by rays formula_115 originating at formula_78 are at distance formula_128.\n\nWhen formula_8 is the unit disk, i.e. the Poincaré disk model for the hyperbolic plane, the hyperbolic metric on the disk is\n\nand the Gromov boundary can be identified with the unit circle.\n\nThe boundary of formula_102-dimensional hyperbolic space is homeomorphic to the formula_132-dimensional sphere and the metrics are similar to the one above.\n\nIf formula_8 is proper then its boundary is homeomorphic to the space of Busemann functions on formula_8 modulo translations.\n\nA quasi-isometry between two hyperbolic spaces formula_135 induces a homeomorphism between the boundaries.\n\nIn particular the group of isometries of formula_8 acts by homeomorphisms on formula_108. This action can be used to classify isometries according to their dynamical behaviour on the boundary, generalising that for trees and classical hyperbolic spaces. Let formula_138 be an isometry of formula_8, then one of the following cases occur:\n\n\nSubsets of the theory of hyperbolic groups can be used to give more examples of hyperbolic spaces, for instance the Cayley graph of a small cancellation group. It is also known that the Cayley graphs of certain models of random groups (which is in effect a randomly-generated infinite regular graph) tend to be hyperbolic very often.\n\nIt can be difficult and interesting to prove that certain spaces are hyperbolic. For example, the following hyperbolicity results have led to new phenomena being discovered for the groups acting on them.\n\n\n\n"}
{"id": "581005", "url": "https://en.wikipedia.org/wiki?curid=581005", "title": "Implicit function theorem", "text": "Implicit function theorem\n\nIn mathematics, more specifically in multivariable calculus, the implicit function theorem is a tool that allows relations to be converted to functions of several real variables. It does so by representing the relation as the graph of a function. There may not be a single function whose graph can represent the entire relation, but there may be such a function on a restriction of the domain of the relation. The implicit function theorem gives a sufficient condition to ensure that there is such a function.\n\nMore precisely, given a system of equations (often abbreviated into ), the theorem states that, under a mild condition on the partial derivatives (with respect to the s) at a point, the variables are differentiable functions of the in some neighborhood of the point. As these functions can generally not be expressed in closed form, they are \"implicitly\" defined by the equations, and this motivated the name of the theorem.\n\nIn other words, under a mild condition on the partial derivatives, the set of zeros of a system of equations is locally the graph of a function.\n\nAugustin-Louis Cauchy (1789–1857) is credited with the first rigorous form of the implicit function theorem. Ulisse Dini (1845–1918) generalized the real-variable version of the implicit function theorem to the context of functions of any number of real variables.\n\nIf we define the function formula_1, then the equation \"f\"(\"x\", \"y\") = 1 cuts out the unit circle as the level set {(\"x\", \"y\")| \"f\"(\"x\", \"y\") = 1}. There is no way to represent the unit circle as the graph of a function of one variable \"y\" = \"g\"(\"x\") because for each choice of \"x\" ∈ (−1, 1), there are two choices of \"y\", namely formula_2.\n\nHowever, it is possible to represent \"part\" of the circle as the graph of a function of one variable. If we let formula_3 for −1 ≤ \"x\" ≤ 1, then the graph of formula_4 provides the upper half of the circle. Similarly, if formula_5, then the graph of formula_6 gives the lower half of the circle.\n\nThe purpose of the implicit function theorem is to tell us the existence of functions like formula_7 and formula_8, even in situations where we cannot write down explicit formulas. It guarantees that formula_7 and formula_8 are differentiable, and it even works in situations where we do not have a formula for \"f\"(\"x\", \"y\").\n\nLet \"f\" : R → R be a continuously differentiable function. We think of R as the Cartesian product R × R, and we write a point of this product as (x, y) = (\"x\", ..., \"x\", \"y\", ..., \"y\"). Starting from the given function \"f\", our goal is to construct a function \"g\": R → R whose graph (x, \"g\"(x)) is precisely the set of all (x, y) such that \"f\"(x, y) = \"0\".\n\nAs noted above, this may not always be possible. We will therefore fix a point (a, b) = (\"a\", ..., \"a\", \"b\", ..., \"b\") which satisfies \"f\"(a, b) = 0, and we will ask for a \"g\" that works near the point (a, b). In other words, we want an open set \"U\" of R containing a, an open set \"V\" of R containing b, and a function \"g\" : \"U\" → \"V\" such that the graph of \"g\" satisfies the relation \"f\" = 0 on \"U\" × \"V\", and that no other points within \"U\" × \"V\" do so. In symbols,\n\nTo state the implicit function theorem, we need the Jacobian matrix of \"f\", which is the matrix of the partial derivatives of \"f\". Abbreviating (\"a\", ..., \"a\", \"b\", ..., \"b\") to (a, b), the Jacobian matrix is\n\nwhere \"X\" is the matrix of partial derivatives in the variables \"x\" and \"Y\" is the matrix of partial derivatives in the variables \"y\". The implicit function theorem says that if \"Y\" is an invertible matrix, then there are \"U\", \"V\", and \"g\" as desired. Writing all the hypotheses together gives the following statement.\n\nLet \"f\": R → R be a continuously differentiable function, and let R have coordinates (x, y). Fix a point (a, b) = (\"a\", ..., \"a\", \"b\", ..., \"b\") with \"f\"(a, b) = 0, where 0 ∈ R is the zero vector. If the Jacobian matrix (this is the right-hand panel of the Jacobian matrix shown in the previous section) is invertible, then there exists an open set \"U\" of R containing a such that there exists a unique continuously differentiable function \"g\": \"U\" → R such that\nand\n\nMoreover, the partial derivatives of \"g\" in \"U\" are given by the matrix product\n\nIf, moreover, \"f\" is analytic or continuously differentiable \"k\" times in a neighborhood of (a, b), then one may choose \"U\" in order that the same holds true for \"g\" inside \"U\". In the analytic case, this is called the analytic implicit function theorem.\n\nLet us go back to the example of the unit circle. In this case \"n\" = \"m\" = 1 and formula_16. The matrix of partial derivatives is just a 1 × 2 matrix, given by\n\nThus, here, the \"Y\" in the statement of the theorem is just the number 2\"b\"; the linear map defined by it is invertible iff \"b\" ≠ 0. By the implicit function theorem we see that we can locally write the circle in the form \"y\" = \"g\"(\"x\") for all points where \"y\" ≠ 0. For (±1, 0) we run into trouble, as noted before. The implicit function theorem may still be applied to these two points, by writing \"x\" as a function of \"y\", that is, formula_18; now the graph of the function will be formula_19, since where \"b = 0\" we have \"a = 1\", and the conditions to locally express the function in this form are satisfied.\n\nThe implicit derivative of \"y\" with respect to \"x\", and that of \"x\" with respect to \"y\", can be found by totally differentiating the implicit function formula_20 and equating to 0:\n\ngiving \n\nand\n\nSuppose we have an \"m\"-dimensional space, parametrised by a set of coordinates formula_24. We can introduce a new coordinate system formula_25 by supplying m functions formula_26. These functions allow us to calculate the new coordinates formula_25 of a point, given the point's old coordinates formula_24 using formula_29. One might want to verify if the opposite is possible: given coordinates formula_25, can we 'go back' and calculate the same point's original coordinates formula_24? The implicit function theorem will provide an answer to this question. The (new and old) coordinates formula_32 are related by \"f\" = 0, with\nNow the Jacobian matrix of \"f\" at a certain point (\"a\", \"b\") [ where formula_34 ] is given by \nwhere I denotes the \"m\" × \"m\" identity matrix, and \"J\" is the \"m\" × \"m\" matrix of partial derivatives, evaluated at (\"a\", \"b\"). (In the above, these blocks were denoted by X and Y. As it happens, in this particular application of the theorem, neither matrix depends on \"a\".) The implicit function theorem now states that we can locally express formula_24 as a function of formula_25 if \"J\" is invertible. Demanding \"J\" is invertible is equivalent to det \"J\" ≠ 0, thus we see that we can go back from the primed to the unprimed coordinates if the determinant of the Jacobian \"J\" is non-zero. This statement is also known as the inverse function theorem.\n\nAs a simple application of the above, consider the plane, parametrised by polar coordinates (\"R\", θ). We can go to a new coordinate system (cartesian coordinates) by defining functions \"x\"(\"R\", θ) = \"R\" cos(θ) and \"y\"(\"R\", θ) = \"R\" sin(θ). This makes it possible given any point (\"R\", θ) to find corresponding cartesian coordinates (\"x\", \"y\"). When can we go back and convert cartesian into polar coordinates? By the previous example, it is sufficient to have det \"J\" ≠ 0, with \nSince det \"J\" = \"R\", conversion back to polar coordinates is possible if \"R\" ≠ 0. So it remains to check the case \"R\" = 0. It is easy to see that in case \"R\" = 0, our coordinate transformation is not invertible: at the origin, the value of θ is not well-defined.\n\nBased on the inverse function theorem in Banach spaces, it is possible to extend the implicit function theorem to Banach space valued mappings.\n\nLet \"X\", \"Y\", \"Z\" be Banach spaces. Let the mapping \"f\" : \"X\" × \"Y\" → \"Z\" be continuously Fréchet differentiable. If formula_39, formula_40, and formula_41 is a Banach space isomorphism from \"Y\" onto \"Z\", then there exist neighbourhoods \"U\" of \"x\" and \"V\" of \"y\" and a Fréchet differentiable function \"g\" : \"U\" → \"V\" such that \"f\"(\"x\", \"g\"(\"x\")) = 0 and \"f\"(\"x\", \"y\") = 0 if and only if \"y\" = \"g\"(\"x\"), for all formula_42.\n\nVarious forms of the implicit function theorem exist for the case when the function \"f\" is not differentiable. It is standard that it holds in one dimension. The following more general form was proven by Kumagai based on an observation by Jittorntrum.\n\nConsider a continuous function formula_43 such that formula_44. If there exist open neighbourhoods formula_45 and formula_46 of \"x\" and \"y\", respectively, such that, for all \"y\" in \"B\", formula_47 is locally one-to-one then there exist open neighbourhoods formula_48 and formula_49 of \"x\" and \"y\", such that, for all formula_50, the equation\n\"f\"(\"x\", \"y\") = 0 has a unique solution\nwhere \"g\" is a continuous function from \"B\" into \"A\".\n\n"}
{"id": "31789393", "url": "https://en.wikipedia.org/wiki?curid=31789393", "title": "Langlands–Shahidi method", "text": "Langlands–Shahidi method\n\nIn mathematics, the Langlands–Shahidi method provides the means to define automorphic L-functions in many cases that arise with connected reductive groups over a number field. This includes Rankin–Selberg products for cuspidal automorphic representations of general linear groups. The method develops the theory of the local coefficient, which links to the global theory via Eisenstein series. The resulting \"L\"-functions satisfy a number of analytic properties, including an important functional equation.\n\nThe setting is in the generality of a connected quasi-split reductive group \"G\", together with a Levi subgroup \"M\", defined over a local field \"F\". For example, if \"G\" = \"G\" is a classical group of rank \"l\", its maximal Levi subgroups are of the form GL(\"m\") × \"G\", where \"G\" is a classical group of rank \"n\" and of the same type as \"G\", \"l\" = \"m\" + \"n\". F. Shahidi develops the theory of the local coefficient for irreducible generic representations of \"M(F)\". The local coefficient is defined by means of the uniqueness property of Whittaker models paired with the theory of intertwining operators for representations obtained by parabolic induction from generic representations.\n\nThe global intertwining operator appearing in the functional equation of Langlands' theory of Eisenstein series can be decomposed as a product of local intertwining operators. When \"M\" is a maximal Levi subgroup, local coefficients arise from Fourier coefficients of appropriately chosen Eisenstein series and satisfy a crude functional equation involving a product of partial \"L\"-functions.\n\nAn induction step refines the crude functional equation of a globally generic cuspidal automorphic representation formula_1 to individual functional equations of partial \"L\"-functions and γ-factors:\n\nThe details are technical: \"s\" a complex variable, \"S\" a finite set of places (of the underlying global field) with formula_3 unramified for \"v\" outside of \"S\", and formula_4 is the adjoint action of \"M\" on the complex Lie algebra of a specific subgroup of the Langlands dual group of \"G\". When \"G\" is the special linear group SL(2), and \"M\" = \"T\" is the maximal torus of diagonal matrices, then π is a Größencharakter and the corresponding γ-factors are the local factors of Tate's thesis.\n\nThe γ-factors are uniquely characterized by their role in the functional equation and a list of local properties, including multiplicativity with respect to parabolic induction. They satisfy a relationship involving Artin L-functions and Artin root numbers when \"v\" gives an archimedean local field or when \"v\" is non-archimedean and formula_3 is a constituent of an unramified principal series representation of \"M(F)\". Local \"L\"-functions and root numbers εformula_6 are then defined at every place, including formula_7, by means of Langlands classification for \"p\"-adic groups. The functional equation takes the form\n\nwhere formula_9 and formula_10 are the completed global \"L\"-function and root number.\n\n\nA full list of Langlands–Shahidi L-functions depends on the quasi-split group \"G\" and maximal Levi subgroup \"M\". More specifically, the decomposition of the adjoint action formula_4 can be classified using Dynkin diagrams. A first study of automorphic \"L\"-functions via the theory of Eisenstein Series can be found in Langlands' Euler Products, under the assumption that the automorphic representations are everywhere unramified. What the Langlands–Shahidi method provides is the definition of \"L\"-functions and root numbers with no other condition on the representation of \"M\" other than requiring the existence of a Whittaker model.\n\nGlobal \"L\"-functions are said to be nice if they satisfy:\n\n\nLanglands–Shahidi \"L\"-functions satisfy the functional equation. Progress towards boundedness in vertical strips was made by S. S. Gelbart and F. Shahidi. And, after incorporating twists by highly ramified characters, Langlands–Shahidi \"L\"-functions do become entire.\n\nAnother result is the non-vanishing of \"L\"-functions. For Rankin–Selberg products of general linear groups it states that formula_20 is non-zero for every real number \"t\".\n\nHere, formula_22 is obtained by unitary parabolic induction from \n"}
{"id": "31978226", "url": "https://en.wikipedia.org/wiki?curid=31978226", "title": "Life-time of correlation", "text": "Life-time of correlation\n\nThe life-time of correlation measures the timespan over which there is appreciable autocorrelation or cross correlation in stochastic processes.\n\nThe correlation coefficient \"ρ\", expressed as an autocorrelation function or cross-correlation function, depends on the lag-time between the times being considered. Typically such functions, \"ρ\"(\"t\"), decay to zero with increasing lag-time, but they can assume values across all levels of correlations: strong and weak, and positive and negative as in the table.\n\nThe life-time of a correlation is defined as the length of time when the correlation coefficient is at the strong level. The durability of correlation is determined by signal (the strong level of correlation is separated from weak and negative levels). The mean life-time of correlation could measure how the durability of correlation depends on the window width size (the window is the length of time series used to calculate correlation).\n"}
{"id": "505253", "url": "https://en.wikipedia.org/wiki?curid=505253", "title": "List of regular polytopes and compounds", "text": "List of regular polytopes and compounds\n\nThis page lists the regular polytopes and regular polytope compounds in Euclidean, spherical and hyperbolic spaces.\n\nThe Schläfli symbol describes every regular tessellation of an \"n\"-sphere, Euclidean and hyperbolic spaces. A Schläfli symbol describing an n-polytope equivalently describes a tessellation of an (\"n\"−1)-sphere. In addition, the symmetry of a regular polytope or tessellation is expressed as a Coxeter group, which Coxeter expressed identically to the Schläfli symbol, except delimiting by square brackets, a notation that is called Coxeter notation. Another related symbol is the Coxeter-Dynkin diagram which represents a symmetry group with no rings, and the represents regular polytope or tessellation with a ring on the first node. For example, the cube has Schläfli symbol {4,3}, and with its octahedral symmetry, [4,3] or , it is represented by Coxeter diagram .\n\nThe regular polytopes are grouped by dimension and subgrouped by convex, nonconvex and infinite forms. Nonconvex forms use the same vertices as the convex forms, but have intersecting facets. Infinite forms tessellate a one-lower-dimensional Euclidean space.\n\nInfinite forms can be extended to tessellate a hyperbolic space. Hyperbolic space is like normal space at a small scale, but parallel lines diverge at a distance. This allows vertex figures to have negative angle defects, like making a vertex with seven equilateral triangles and allowing it to lie flat. It cannot be done in a regular plane, but can be at the right scale of a hyperbolic plane.\n\nA more general definition of regular polytopes which do not have simple Schläfli symbols includes regular skew polytopes and regular skew apeirotopes with nonplanar facets or vertex figures.\n\nThis table shows a summary of regular polytope counts by dimension.\n\nThere are no Euclidean regular star tessellations in any number of dimensions.\n\nA one-dimensional polytope or 1-polytope is a closed line segment, bounded by its two endpoints. A 1-polytope is regular by definition and is represented by Schläfli symbol { }, or a Coxeter diagram with a single ringed node, . Norman Johnson calls it a \"dion\" and gives it the Schläfli symbol { }.\n\nAlthough trivial as a polytope, it appears as the edges of polygons and other higher dimensional polytopes. It is used in the definition of uniform prisms like Schläfli symbol { }×{p}, or Coxeter diagram as a Cartesian product of a line segment and a regular polygon.\n\nThe two-dimensional polytopes are called polygons. Regular polygons are equilateral and cyclic. A p-gonal regular polygon is represented by Schläfli symbol {p}.\n\nUsually only convex polygons are considered regular, but star polygons, like the pentagram, can also be considered regular. They use the same vertices as the convex forms, but connect in an alternate connectivity which passes around the circle more than once to complete.\n\nStar polygons should be called \"nonconvex\" rather than \"concave\" because the intersecting edges do not generate new vertices and all the vertices exist on a circle boundary.\n\nThe Schläfli symbol {p} represents a regular \"p\"-gon.\n\nThe regular digon {2} can be considered to be a degenerate regular polygon. It can be realized non-degenerately in some non-Euclidean spaces, such as on the surface of a sphere or torus.\n\nThere exist infinitely many regular star polytopes in two dimensions, whose Schläfli symbols consist of rational numbers {\"n\"/\"m\"}. They are called star polygons and share the same vertex arrangements of the convex regular polygons.\n\nIn general, for any natural number \"n\", there are n-pointed star regular polygonal stars with Schläfli symbols {\"n\"/\"m\"} for all m such that \"m\" < \"n\"/2 (strictly speaking {\"n\"/\"m\"}={\"n\"/(\"n\"−\"m\")}) and \"m\" and \"n\" are coprime (and as such, all stellations of a polygon with a prime number of sides will be regular stars). Cases where \"m\" and \"n\" are not coprime are called compound polygons.\n\nIn 3-dimensional space, a regular skew polygon is called an \"antiprismatic polygon\", with the vertex arrangement of an antiprism, and a subset of edges, zig-zagging between top and bottom polygons.\nIn 4-dimensions a regular skew polygon can have vertices on a Clifford torus and related by a Clifford displacement. Unlike antiprismatic skew polygons, skew polygons on double rotations can include an odd-number of sides.\n\nThey can be seen in the Petrie polygons of the convex regular 4-polytopes, seen as regular plane polygons in the perimeter of Coxeter plane projection:\n\nIn three dimensions, polytopes are called polyhedra:\n\nA regular polyhedron with Schläfli symbol {p,q}, Coxeter diagrams , has a regular face type {p}, and regular vertex figure {q}.\n\nA vertex figure (of a polyhedron) is a polygon, seen by connecting those vertices which are one edge away from a given vertex. For regular polyhedra, this vertex figure is always a regular (and planar) polygon.\n\nExistence of a regular polyhedron {p,q} is constrained by an inequality, related to the vertex figure's angle defect:\n\nBy enumerating the permutations, we find 5 convex forms, 4 star forms and 3 plane tilings, all with polygons {p} and {q} limited to: {3}, {4}, {5}, {5/2}, and {6}.\n\nBeyond Euclidean space, there is an infinite set of regular hyperbolic tilings.\n\nThe convex regular polyhedra are called the 5 Platonic solids. The vertex figure is given with each vertex count. All these polyhedra have an Euler characteristic (χ) of 2.\n\nIn spherical geometry, regular spherical polyhedra (tilings of the sphere) exist that would otherwise be degenerate as polytopes. These are the hosohedra {2,n} and their dual dihedra {n,2}. Coxeter calls these cases \"improper\" tessellations.\n\nThe first few cases (n from 2 to 6) are listed below.\n\nStar-dihedra and hosohedra {\"p\"/\"q\",2} and {2,\"p\"/\"q\"} also exist for any star polygon {\"p\"/\"q\"}.\n\nThe regular star polyhedra are called the Kepler–Poinsot polyhedra and there are four of them, based on the vertex arrangements of the dodecahedron {5,3} and icosahedron {3,5}:\n\nAs spherical tilings, these star forms overlap the sphere multiple times, called its \"density\", being 3 or 7 for these forms. The tiling images show a single spherical polygon face in yellow.\nThere are infinitely many \"failed\" star polyhedra. These are also spherical tilings with star polygons in their Schläfli symbols, but they do not cover a sphere finitely many times. Some examples are {5/2,4}, {5/2,9}, {7/2,3}, {5/2,5/2}, {7/2,7/3}, {4,5/2}, and {3,7/3}.\n\nRegular skew polyhedra are generalizations to the set of regular polyhedron which include the possibility of nonplanar vertex figures.\n\nFor 4-dimensional skew polyhedra, Coxeter offered a modified Schläfli symbol {l,m|n} for these figures, with {l,m} implying the vertex figure, \"m\" l-gons around a vertex, and \"n\"-gonal holes. Their vertex figures are skew polygons, zig-zagging between two planes.\n\nThe regular skew polyhedra, represented by {l,m|n}, follow this equation:\n\nFour of them can be seen in 4-dimensions as a subset of faces of four regular 4-polytopes, sharing the same vertex arrangement and edge arrangement:\n\nRegular 4-polytopes with Schläfli symbol formula_4 have cells of type formula_5, faces of type formula_6, edge figures\nformula_7, and vertex figures formula_8.\n\nThe existence of a regular 4-polytope formula_4 is constrained by the existence of the regular polyhedra formula_10. A suggested name for 4-polytopes is \"polychoron\".\n\nEach will exist in a space dependent upon this expression:\n\nThese constraints allow for 21 forms: 6 are convex, 10 are nonconvex, \"one\" is a Euclidean 3-space honeycomb, and 4 are hyperbolic honeycombs.\n\nThe Euler characteristic formula_15 for convex 4-polytopes is zero:\nformula_16\n\nThe 6 convex regular 4-polytopes are shown in the table below. All these 4-polytopes have an Euler characteristic (χ) of 0.\n\nDi-4-topes and hoso-4-topes exist as regular tessellations of the 3-sphere.\n\nRegular di-4-topes (2 facets) include: {3,3,2}, {3,4,2}, {4,3,2}, {5,3,2}, {3,5,2}, {p,2,2}, and their hoso-4-tope duals (2 vertices): {2,3,3}, {2,4,3}, {2,3,4}, {2,3,5}, {2,5,3}, {2,2,\"p\"}. 4-polytopes of the form {2,\"p\",2} are the same as {2,2,\"p\"}. There are also the cases {\"p\",2,\"q\"} which have dihedral cells and hosohedral vertex figures.\n\nThere are ten regular star 4-polytopes, which are called the Schläfli–Hess 4-polytopes. Their vertices are based on the convex 120-cell \"{5,3,3}\" and 600-cell \"{3,3,5}\".\n\nLudwig Schläfli found four of them and skipped the last six because he would not allow forms that failed the Euler characteristic on cells or vertex figures (for zero-hole tori: F+V−E=2). Edmund Hess (1843–1903) completed the full list of ten in his German book \"Einleitung in die Lehre von der Kugelteilung mit besonderer Berücksichtigung ihrer Anwendung auf die Theorie der Gleichflächigen und der gleicheckigen Polyeder\" (1883).\n\nThere are 4 unique edge arrangements and 7 unique face arrangements from these 10 regular star 4-polytopes, shown as orthogonal projections:\nThere are 4 \"failed\" potential regular star 4-polytopes permutations: {3,5/2,3}, {4,3,5/2}, {5/2,3,4}, {5/2,3,5/2}. Their cells and vertex figures exist, but they do not cover a hypersphere with a finite number of repetitions.\n\nIn five dimensions, a regular polytope can be named as\nformula_17 where formula_4 is the 4-face type, formula_5 is the cell type, formula_6 is the face type, and formula_21 is the face figure, formula_22 is the edge figure, and formula_23 is the vertex figure.\n\nA regular 5-polytope formula_17 exists only if formula_4 and formula_23 are regular 4-polytopes.\n\nThe space it fits in is based on the expression:\n\nEnumeration of these constraints produce \"3\" convex polytopes, \"zero\" nonconvex polytopes, \"3\" 4-space tessellations, and \"5\" hyperbolic 4-space tessellations. There are no non-convex regular polytopes in five dimensions or higher.\n\nIn dimensions 5 and higher, there are only three kinds of convex regular polytopes.\n\nThere are also improper cases where some numbers in the Schläfli symbol are 2. For example, {p,q,r...2} is an improper regular spherical polytope whenever {p,q,r...} is a regular spherical polytope, and {2...p,q,r} is an improper regular spherical polytope whenever {...p,q,r} is a regular spherical polytope. Such polytopes may also be used as facets, yielding forms such as {p,q...2...y,z}.\n\nThere are no non-convex regular polytopes in five dimensions or higher.\n\nA projective regular (\"n\"+1)-polytope exists when an original regular \"n\"-spherical tessellation, {p,q...}, is centrally symmetric. Such a polytope is named hemi-{p,q...}, and contain half as many elements. Coxeter gives a symbol {p,q...}/2, while McMullen writes {p,q...} with \"h\" as the coxeter number.\n\nEven-sided regular polygons have hemi-\"2n\"-gon projective polygons, {2p}/2.\n\nThere are 4 regular projective polyhedra related to 4 of 5 Platonic solids.\n\nThe hemi-cube and hemi-octahedron generalize as hemi-\"n\"-cubes and hemi-\"n\"-orthoplexes in any dimensions.\n\nIn 4-dimensions 5 of 6 convex regular 4-polytopes generate projective 4-polytopes. The 3 special cases are hemi-24-cell, hemi-600-cell, and hemi-120-cell.\n\nThere are only 2 convex regular projective hemi-polytopes in dimensions 5 or higher.\n\nAn apeirotope or infinite polytope is a polytope which has infinitely many facets. An \"n\"-apeirotope is an infinite \"n\"-polytope: a 2-apeirotope or apeirotope, is an infinite polygon, a 3-apeirotope, or apeirohedron, is an infinite polyhedron, etc.\n\nThere are two main geometric classes of apeirotope:\n\nThe straight apeirogon is a regular tessellation of the line, subdviding it into infinitely many equal segments. It has infinitely many vertices and edges. Its Schläfli symbol is {∞}, and Coxeter diagram .\n\nApeirogons in the hyperbolic plane, most notably the \"regular apeirogon\", {∞}, can have a curvature just like finite polygons of the Euclidean plane, with the vertices circumscribed by horocycles or hypercycles rather than circles.\n\nRegular apeirogons that are scaled to converge at infinity have the symbol {∞} and exist on horocycles, while more generally they can exist on hypercycles.\n\nAbove are two regular hyperbolic apeirogons in the Poincaré disk model, the right one shows perpendicular reflection lines of divergent fundamental domains, separated by length λ.\n\nA skew apeirogon in two dimensions forms a zig-zag line in the plane. If the zig-zag is even and symmetrical, then the apeirogon is regular.\n\nSkew apeirogons can be constructed in any number of dimensions. In three dimensions, a regular skew apeirogon traces out a helical spiral and may be either left- or right-handed.\n\nThere are three regular tessellations of the plane. All three have an Euler characteristic (χ) of 0.\nThere are two improper regular tilings: {∞,2}, an apeirogonal dihedron, made from two apeirogons, each filling half the plane; and secondly, its dual, {2,∞}, an apeirogonal hosohedron, seen as an infinite set of parallel lines.\n\nThere are no regular plane tilings of star polygons. There are many enumerations that fit in the plane (1/\"p\" + 1/\"q\" = 1/2), like {8/3,8}, {10/3,5}, {5/2,10}, {12/5,12}, etc., but none repeat periodically.\n\nTessellations of hyperbolic 2-space are \"hyperbolic tilings\". There are infinitely many regular tilings in H. As stated above, every positive integer pair {\"p\",\"q\"} such that 1/\"p\" + 1/\"q\" < 1/2 gives a hyperbolic tiling. In fact, for the general Schwarz triangle (\"p\", \"q\", \"r\") the same holds true for 1/\"p\" + 1/\"q\" + 1/\"r\" < 1.\n\nThere are a number of different ways to display the hyperbolic plane, including the Poincaré disc model which maps the plane into a circle, as shown below. It should be recognized that all of the polygon faces in the tilings below are equal-sized and only appear to get smaller near the edges due to the projection applied, very similar to the effect of a camera fisheye lens.\n\nThere are infinitely many flat regular 3-apeirotopes (apeirohedra) as regular tilings of the hyperbolic plane, of the form {p,q}, with p+q<pq/2. (previously listed above as tessellations)\n\nA sampling:\nThere are 2 infinite forms of hyperbolic tilings whose faces or vertex figures are star polygons: {\"m\"/2, \"m\"} and their duals {\"m\", \"m\"/2} with \"m\" = 7, 9, 11, ... The {\"m\"/2, \"m\"} tilings are stellations of the {\"m\", 3} tilings while the {\"m\", \"m\"/2} dual tilings are facetings of the {3, \"m\"} tilings and greatenings of the {\"m\", 3} tilings.\n\nThe patterns {\"m\"/2, \"m\"} and {\"m\", \"m\"/2} continue for odd \"m\" < 7 as polyhedra: when \"m\" = 5, we obtain the small stellated dodecahedron and great dodecahedron, and when \"m\" = 3, the case degenerates to a tetrahedron. The other two Kepler–Poinsot polyhedra (the great stellated dodecahedron and great icosahedron) do not have regular hyperbolic tiling analogues. If \"m\" is even, depending on how we choose to define {\"m\"/2}, we can either obtain degenerate double covers of other tilings or compound tilings.\n\nThere are three regular skew apeirohedra in Euclidean 3-space, with regular skew polygon vertex figures. They share the same vertex arrangement and edge arrangement of 3 convex uniform honeycombs.\nThere are thirty regular apeirohedra in Euclidean 3-space. These include those listed above, as well as 8 other \"pure\" apeirohedra, all related to the cubic honeycomb, {4,3,4}, with others having skew polygon faces: {6,6}, {4,6}, {6,4}, {∞,3}, {∞,3}, {∞,4}, {∞,4}, {∞,6}, and {∞,6}.\n\nThere are 31 regular skew apeirohedra in hyperbolic 3-space:\n\nThere is only one non-degenerate regular tessellation of 3-space (\"honeycombs\"), {4, 3, 4}:\n\nThere are six improper regular tessellations, pairs based on the three regular Euclidean tilings. Their cells and vertex figures are all regular hosohedra {2,n}, dihedra, {n,2}, and Euclidean tilings. These improper regular tilings are constructionally related to prismatic uniform honeycombs by truncation operations. They are higher-dimensional analogues of the order-2 apeirogonal tiling and apeirogonal hosohedron.\nThere are ten flat regular honeycombs of hyperbolic 3-space: (previously listed above as tessellations)\nTessellations of hyperbolic 3-space can be called \"hyperbolic honeycombs\". There are 15 hyperbolic honeycombs in H, 4 compact and 11 paracompact.\n\nThere are also 11 paracompact H honeycombs (those with infinite (Euclidean) cells and/or vertex figures): {3,3,6}, {6,3,3}, {3,4,4}, {4,4,3}, {3,6,3}, {4,3,6}, {6,3,4}, {4,4,4}, {5,3,6}, {6,3,5}, and {6,3,6}.\n\nNoncompact solutions exist as Lorentzian Coxeter groups, and can be visualized with open domains in hyperbolic space (the fundamental tetrahedron having some parts inaccessible beyond infinity). All honeycombs which are not shown in the set of tables below and do not have 2 in their Schläfli symbol are noncompact.\nThere are no regular hyperbolic star-honeycombs in H: all forms with a regular star polyhedron as cell, vertex figure or both end up being spherical.\n\nThere are three kinds of infinite regular tessellations (honeycombs) that can tessellate Euclidean four-dimensional space:\n\nThere are also the two improper cases {4,3,4,2} and {2,4,3,4}.\n\nThere are three flat regular honeycombs of Euclidean 4-space: \n\nThere are seven flat regular convex honeycombs of hyperbolic 4-space:\n\nThere are four flat regular star honeycombs of hyperbolic 4-space:\n\nThere are seven convex regular honeycombs and four star-honeycombs in H space. Five convex ones are compact, and two are paracompact.\n\nFive compact regular honeycombs in H:\nThe two paracompact regular H honeycombs are: {3,4,3,4}, {4,3,4,3}.\n\nNoncompact solutions exist as Lorentzian Coxeter groups, and can be visualized with open domains in hyperbolic space (the fundamental 5-cell having some parts inaccessible beyond infinity). All honeycombs which are not shown in the set of tables below and do not have 2 in their Schläfli symbol are noncompact.\nThere are four regular star-honeycombs in H space:\nThere is only one flat regular honeycomb of Euclidean 5-space: (previously listed above as tessellations)\n\nThere are five flat regular regular honeycombs of hyperbolic 5-space, all paracompact: (previously listed above as tessellations)\n\nThe hypercubic honeycomb is the only family of regular honeycomb that can tessellate each dimension, five or higher, formed by hypercube facets, four around every ridge.\n\nIn E, there are also the improper cases {4,3,3,4,2}, {2,4,3,3,4}, {3,3,4,3,2}, {2,3,3,4,3}, {3,4,3,3,2}, and {2,3,4,3,3}. In E, {4,3,4,2} and {2,4,3,4} are always improper Euclidean tessellations.\n\nThere are 5 regular honeycombs in H, all paracompact, which include infinite (Euclidean) facets or vertex figures: {3,4,3,3,3}, {3,3,4,3,3}, {3,3,3,4,3}, {3,4,3,3,4}, and {4,3,3,4,3}.\n\nThere are no compact regular tessellations of hyperbolic space of dimension 5 or higher and no paracompact regular tessellations in hyperbolic space of dimension 6 or higher.\n\nSince there are no regular star \"n\"-polytopes for \"n\" ≥ 5, that could be potential cells or vertex figures, there are no more hyperbolic star honeycombs in H for \"n\" ≥ 5.\n\nThere are no regular compact or paracompact tessellations of hyperbolic space of dimension 6 or higher. However, any Schläfli symbol of the form {p,q,r,s...} not covered above (p,q,r,s... natural numbers above 2, or infinity) will form a noncompact tessellation of hyperbolic \"n\"-space.\n\nFor any natural number n, there are n-pointed star regular polygonal stars with Schläfli symbols {n/m} for all m such that m < n/2 (strictly speaking {n/m}={n/(n−m)}) and m and n are coprime. When m and n are not coprime, the star polygon obtained will be a regular polygon with \"n\"/\"m\" sides. A new figure is obtained by rotating these regular \"n\"/\"m\"-gons one vertex to the left on the original polygon until the number of vertices rotated equals \"n\"/\"m\" minus one, and combining these figures. An extreme case of this is where \"n\"/\"m\" is 2, producing a figure consisting of \"n\"/2 straight line segments; this is called a degenerate star polygon.\n\nIn other cases where \"n\" and \"m\" have a common factor, a star polygon for a lower \"n\" is obtained, and rotated versions can be combined. These figures are called star figures, improper star polygons or compound polygons. The same notation {\"n\"/\"m\"} is often used for them, although authorities such as Grünbaum (1994) regard (with some justification) the form \"k\"{\"n\"} as being more correct, where usually \"k\" = \"m\".\n\nA further complication comes when we compound two or more star polygons, as for example two pentagrams, differing by a rotation of 36°, inscribed in a decagon. This is correctly written in the form \"k\"{\"n\"/\"m\"}, as 2{5/2}, rather than the commonly used {10/4}.\n\nCoxeter's extended notation for compounds is of the form \"c\"{\"m\",\"n\"...}[\"d\"{\"p\",\"q\"...}]\"e\"{\"s\",\"t\"...}, indicating that \"d\" distinct {\"p\",\"q\"...}'s together cover the vertices of {\"m\",\"n\"...} \"c\" times and the facets of {\"s\",\"t\"...} \"e\" times. If no regular {\"m\",\"n\"...} exists, the first part of the notation is removed, leaving [\"d\"{\"p\",\"q\"...}]\"e\"{\"s\",\"t\"...}; the opposite holds if no regular {\"s\",\"t\"...} exists. The dual of \"c\"{\"m\",\"n\"...}[\"d\"{\"p\",\"q\"...}]\"e\"{\"s\",\"t\"...} is \"e\"{\"t\",\"s\"...}[\"d\"{\"q\",\"p\"...}]\"c\"{\"n\",\"m\"...}. If \"c\" or \"e\" are 1, they may be omitted. For compound polygons, this notation reduces to {\"nk\"}[\"k\"{\"n\"/\"m\"}]{\"nk\"}: for example, the hexagram may be written thus as {6}[2{3}]{6}.\n\nRegular skew polygons also create compounds, seen in the edges of prismatic compound of antiprisms, for instance:\n\nA regular polyhedron compound can be defined as a compound which, like a regular polyhedron, is vertex-transitive, edge-transitive, and face-transitive. With this definition there are 5 regular compounds.\n\nCoxeter's notation for regular compounds is given in the table above, incorporating Schläfli symbols. The material inside the square brackets, [\"d\"{\"p\",\"q\"}], denotes the components of the compound: \"d\" separate {\"p\",\"q\"}'s. The material \"before\" the square brackets denotes the vertex arrangement of the compound: \"c\"{\"m\",\"n\"}[\"d\"{\"p\",\"q\"}] is a compound of \"d\" {\"p\",\"q\"}'s sharing the vertices of an {\"m\",\"n\"} counted \"c\" times. The material \"after\" the square brackets denotes the facet arrangement of the compound: [\"d\"{\"p\",\"q\"}]\"e\"{\"s\",\"t\"} is a compound of \"d\" {\"p\",\"q\"}'s sharing the faces of {\"s\",\"t\"} counted \"e\" times. These may be combined: thus \"c\"{\"m\",\"n\"}[\"d\"{\"p\",\"q\"}]\"e\"{\"s\",\"t\"} is a compound of \"d\" {\"p\",\"q\"}'s sharing the vertices of {\"m\",\"n\"} counted \"c\" times \"and\" the faces of {\"s\",\"t\"} counted \"e\" times. This notation can be generalised to compounds in any number of dimensions.\n\nThere are eighteen two-parameter families of regular compound tessellations of the Euclidean plane. In the hyperbolic plane, five one-parameter families and seventeen isolated cases are known, but the completeness of this listing has not yet been proven.\n\nThe Euclidean and hyperbolic compound families 2 {\"p\",\"p\"} (4 ≤ \"p\" ≤ ∞, \"p\" an integer) are analogous to the spherical stella octangula, 2 {3,3}.\n\nThere are thirty-two regular compounds of regular 4-polytopes, which Coxeter lists in his book \"Regular Polytopes\":\n\nThere are two different compounds of 75 tesseracts: one shares the vertices of a 120-cell, while the other shares the vertices of a 600-cell. It immediately follows therefore that the corresponding dual compounds of 75 16-cells are also different.\n\nThere are also fourteen \"partially regular\" compounds, that are either vertex-transitive or cell-transitive but not both. The seven vertex-transitive partially regular compounds are the duals of the seven cell-transitive partially regular compounds.\n\nAlthough the 5-cell and 24-cell are both self-dual, their dual compounds (the compound of two 5-cells and compound of two 24-cells) are not considered to be regular, unlike the compound of two tetrahedra and the various dual polygon compounds, because they are neither vertex-regular nor cell-regular: they are not facetings or stellations of any regular 4-polytope.\n\nThe only regular Euclidean compound honeycombs are an infinite family of compounds of cubic honeycombs, all sharing vertices and faces with another cubic honeycomb. This compound can have any number of cubic honeycombs. The Coxeter notation is {4,3,4}[\"d\"{4,3,4}]{4,3,4}.\n\nThere are no regular compounds in five or six dimensions. There are three known seven-dimensional compounds (16, 240, or 480 7-simplexes), and six known eight-dimensional ones (16, 240, or 480 8-cubes or 8-orthoplexes). There is also one compound of \"n\"-simplexes in \"n\"-dimensional space provided that \"n\" is one less than a power of two, and also two compounds (one of \"n\"-cubes and a dual one of \"n\"-orthoplexes) in \"n\"-dimensional space if \"n\" is a power of two.\n\nThe Coxeter notation for these compounds are (using α = {3}, β = {3,4}, γ = {4,3}:\n\n\nThe general cases (where \"n\" = 2 and \"d\" = 2, \"k\" = 2, 3, 4, ...):\n\n\nA known family of regular Euclidean compound honeycombs in five or more dimensions is an infinite family of compounds of hypercubic honeycombs, all sharing vertices and faces with another hypercubic honeycomb. This compound can have any number of hypercubic honeycombs. The Coxeter notation is δ[\"d\"δ]δ where δ = {∞} when \"n\" = 2 and {4,3,4} when \"n\" ≥ 3.\n\nThe abstract polytopes arose out of an attempt to study polytopes apart from the geometrical space they are embedded in. They include the tessellations of spherical, Euclidean and hyperbolic space, tessellations of other manifolds, and many other objects that do not have a well-defined topology, but instead may be characterised by their \"local\" topology. There are infinitely many in every dimension. See this atlas for a sample. Some notable examples of abstract regular polytopes that do not appear elsewhere in this list are the 11-cell, {3,5,3}, and the 57-cell, {5,3,5}, which have regular projective polyhedra as cells and vertex figures.\n\nThe elements of an abstract polyhedron are its body (the maximal element), its faces, edges, vertices and the \"null polytope\" or empty set. These abstract elements can be mapped into ordinary space or \"realised\" as geometrical figures. Some abstract polyhedra have well-formed or \"faithful\" realisations, others do not. A \"flag\" is a connected set of elements of each dimension - for a polyhedron that is the body, a face, an edge of the face, a vertex of the edge, and the null polytope. An abstract polytope is said to be \"regular\" if its combinatorial symmetries are transitive on its flags - that is to say, that any flag can be mapped onto any other under a symmetry of the polyhedron. Abstract regular polytopes remain an active area of research.\n\nFive such regular abstract polyhedra, which can not be realised faithfully, were identified by H. S. M. Coxeter in his book \"Regular Polytopes\" (1977) and again by J. M. Wills in his paper \"The combinatorially regular polyhedra of index 2\" (1987). They are all topologically equivalent to toroids. Their construction, by arranging \"n\" faces around each vertex, can be repeated indefinitely as tilings of the hyperbolic plane. In the diagrams below, the hyperbolic tiling images have colors corresponding to those of the polyhedra images.\n\nThese occur as dual pairs as follows:\n\n\n"}
{"id": "25141867", "url": "https://en.wikipedia.org/wiki?curid=25141867", "title": "Mandelbulb", "text": "Mandelbulb\n\nThe Mandelbulb is a three-dimensional fractal, constructed by Daniel White and Paul Nylander using spherical coordinates in 2009.\n\nA canonical 3-dimensional Mandelbrot set does not exist, since there is no 3-dimensional analogue of the 2-dimensional space of complex numbers. It is possible to construct Mandelbrot sets in 4 dimensions using quaternions and bicomplex numbers. \n\nWhite and Nylander's formula for the \"\"n\"th power\" of the vector formula_1 in is\n\nwhere <br>\nformula_3, <br>\nformula_4, and <br> \nformula_5. <br>\n\nThe Mandelbulb is then defined as the set of those formula_6 in for which the orbit of formula_7 under the iteration formula_8 is bounded. For \"n\" > 3, the result is a 3-dimensional bulb-like structure with fractal surface detail and a number of \"lobes\" depending on \"n\". Many of their graphic renderings use \"n\" = 8. However, the equations can be simplified into rational polynomials when n is odd. For example, in the case \"n\" = 3, the third power can be simplified into the more elegant form:\n\nThe Mandelbulb given by the formula above is actually one in a family of fractals given by parameters (p,q) given by:\nSince p and q do not necessarily have to equal n for the identity |v|=|v| to hold. More general fractals can be found by setting\n\nfor functions f and g.\n\nOther formulae come from identities which parametrise the sum of squares to give a power of the sum of squares such as:\nwhich we can think of as a way to square a triplet of numbers so that the modulus is squared. So this gives, for example:\nor various other permutations. This 'quadratic' formula can be applied several times to get many power-2 formulae.\n\nOther formulae come from identities which parametrise the sum of squares to give a power of the sum of squares such as:\nwhich we can think of as a way to cube a triplet of numbers so that the modulus is cubed. So this gives:\nor other permutations.\n\nfor example. This reduces to the complex fractal formula_20 when z=0 and formula_21 when y=0.\n\nThere are several ways to combine two such `cubic` transforms to get a power-9 transform which has slightly more structure.\n\nAnother way to create Mandelbulbs with cubic symmetry is by taking the complex iteration formula formula_22 for some integer m and adding terms to make it symmetrical in 3 dimensions but keeping the cross-sections to be the same 2 dimensional fractal. (The 4 comes from the fact that formula_23.) For example, take the case of formula_24. In two dimensions where formula_25 this is:\n\nThis can be then extended to three dimensions to give:\n\nfor arbitrary constants A,B,C and D which give different Mandelbulbs (usually set to 0). The case formula_31 gives a Mandelbulb most similar to the first example where n=9. A more pleasing result for the fifth power is got basing it on the formula: formula_32.\nThis fractal has cross-sections of the power 9 Mandelbrot fractal. It has 32 small bulbs sprouting from the main sphere. It is defined by, for example:\n\nThese formula can be written in a shorter way:\nand equivalently for the other coordinates.\n\nA perfect spherical formula can be defined as a formula:\nwhere\nwhere f,g and h are nth power rational trinomials and n is an integer. The cubic fractal above is an example.\n\n\n\n"}
{"id": "7849795", "url": "https://en.wikipedia.org/wiki?curid=7849795", "title": "Mercy (cipher)", "text": "Mercy (cipher)\n\nIn cryptography, Mercy is a tweakable block cipher designed by Paul Crowley for disk encryption.\n\nThe block size is 4096 bits—unusually large for a block cipher, but a standard disk sector size. Mercy uses a 128-bit secret key, along with a 128-bit non-secret tweak for each block. In disk encryption, the sector number would be used as a tweak. Mercy uses a 6-round Feistel network structure with partial key whitening. The round function uses a key-dependent state machine which borrows some structure from the stream cipher WAKE, with key-dependent S-boxes based on the Nyberg S-boxes also used in AES.\n\nScott Fluhrer has discovered a differential attack that works against the full 6 rounds of Mercy. This attack can even be extended to a seven-round variant.\n"}
{"id": "2395424", "url": "https://en.wikipedia.org/wiki?curid=2395424", "title": "Mex (mathematics)", "text": "Mex (mathematics)\n\nIn mathematics, the mex of a subset of a well-ordered set is the smallest value from the whole set that does not belong to the subset. That is, it is the minimum value of the complement set. The name \"mex\" is shorthand for \"\"m\"inimum \"ex\"cluded\" value.\n\nBeyond sets, subclasses of well-ordered classes have minimum excluded values. Minimum excluded values of subclasses of the ordinal numbers are used in combinatorial game theory to assign nim-values to impartial games.\nAccording to the Sprague–Grundy theorem, the nim-value of a game position is the minimum excluded value of the class of values of the positions that can be reached in a single move from the given position.\n\nMinimum excluded values are also used in graph theory, in greedy coloring algorithms. These algorithms typically choose an ordering of the vertices of a graph and choose a numbering of the available vertex colors. They then consider the vertices in order, for each vertex choosing its color to be the minimum excluded value of the set of colors already assigned to its neighbors.\n\nThe following examples all assume that the given set is a subset of the class of ordinal numbers:\n\nwhere is the limit ordinal for the natural numbers.\n\nIn the Sprague–Grundy theory the minimum excluded ordinal is used to determine the nimber of a normal-play impartial game. In such a game, either player has the same moves in each position and the last player to move wins. The nimber is equal to 0 for a game that is lost immediately by the first player, and is equal to the mex of the nimbers of all possible next positions for any other game.\n\nFor example, in a one-pile version of Nim, the game starts with a pile of stones, and the player to move may take any positive number of stones. If is zero stones, the nimber is 0 because the mex of the empty set of legal moves is the nimber 0. If is 1 stone, the player to move will leave 0 stones, and , gives the nimber for this case. If is 2 stones, the player to move can leave 0 or 1 stones, giving the nimber 2 as the mex of the nimbers . In general, the player to move with a pile of stones can leave anywhere from 0 to stones; the mex of the nimbers is always the nimber . The first player wins in Nim if and only if the nimber is not zero, so from this analysis we can conclude that the first player wins if and only if the starting number of stones in a one-pile game of Nim is not zero; the winning move is to take all the stones.\n\nIf we change the game so that the player to move can take up to 3 stones only, then with stones, the successor states have nimbers , giving a mex of 0. Since the nimber for 4 stones is 0, the first player loses. The second player's strategy is to respond to whatever move the first player makes by taking the rest of the stones. For stones, the nimbers of the successor states of 2, 3, and 4 stones are the nimbers 2, 3, and 0 (as we just calculated); the mex of the set of nimbers is the nimber 1, so starting with 5 stones in this game is a win for the first player.\n\nSee nimbers for more details on the meaning of nimber values.\n"}
{"id": "1709372", "url": "https://en.wikipedia.org/wiki?curid=1709372", "title": "Michael Garey", "text": "Michael Garey\n\nMichael Randolph Garey is a computer science researcher, and co-author (with David S. Johnson) of \"Computers and Intractability: A Guide to the Theory of NP-completeness\". He and Johnson received the 1979 Lanchester Prize from the Operations Research Society of America for the book. Garey earned his PhD in computer science in 1970 from the University of Wisconsin–Madison. He was employed by AT&T Bell Laboratories in the Mathematical Sciences Research Center from 1970 until his retirement in 1999. For his last 11 years with the organization, he served as its director. His technical specialties included discrete algorithms and computational complexity, approximation algorithms, scheduling theory, and graph theory. From 1978 until 1981 he served as Editor-in-Chief of The Journal of the Association for Computing Machinery. In 1995, Garey was inducted as a Fellow of the Association for Computing Machinery.\n\n"}
{"id": "439082", "url": "https://en.wikipedia.org/wiki?curid=439082", "title": "Moving frame", "text": "Moving frame\n\nIn mathematics, a moving frame is a flexible generalization of the notion of an ordered basis of a vector space often used to study the extrinsic differential geometry of smooth manifolds embedded in a homogeneous space.\n\nIn lay terms, a frame of reference is a system of measuring rods used by an observer to measure the surrounding space by providing coordinates. A moving frame is then a frame of reference which moves with the observer along a trajectory (a curve). The method of the moving frame, in this simple example, seeks to produce a \"preferred\" moving frame out of the kinematic properties of the observer. In a geometrical setting, this problem was solved in the mid 19th century by Jean Frédéric Frenet and Joseph Alfred Serret. The Frenet–Serret frame is a moving frame defined on a curve which can be constructed purely from the velocity and acceleration of the curve.\n\nThe Frenet–Serret frame plays a key role in the differential geometry of curves, ultimately leading to a more or less complete classification of smooth curves in Euclidean space up to congruence. The Frenet–Serret formulas show that there is a pair of functions defined on the curve, the torsion and curvature, which are obtained by differentiating the frame, and which describe completely how the frame evolves in time along the curve. A key feature of the general method is that a preferred moving frame, provided it can be found, gives a complete kinematic description of the curve.\nIn the late 19th century, Gaston Darboux studied the problem of constructing a preferred moving frame on a surface in Euclidean space instead of a curve, the Darboux frame (or the \"trièdre mobile\" as it was then called). It turned out to be impossible in general to construct such a frame, and that there were integrability conditions which needed to be satisfied first.\n\nLater, moving frames were developed extensively by Élie Cartan and others in the study of submanifolds of more general homogeneous spaces (such as projective space). In this setting, a frame carries the geometric idea of a basis of a vector space over to other sorts of geometrical spaces (Klein geometries). Some examples of frames are:\n\n\nIn each of these examples, the collection of all frames is homogeneous in a certain sense. In the case of linear frames, for instance, any two frames are related by an element of the general linear group. Projective frames are related by the projective linear group. This homogeneity, or symmetry, of the class of frames captures the geometrical features of the linear, affine, Euclidean, or projective landscape. A moving frame, in these circumstances, is just that: a frame which varies from point to point.\n\nFormally, a frame on a homogeneous space \"G\"/\"H\" consists of a point in the tautological bundle \"G\" → \"G\"/\"H\". A moving frame is a section of this bundle. It is \"moving\" in the sense that as the point of the base varies, the frame in the fibre changes by an element of the symmetry group \"G\". A moving frame on a submanifold \"M\" of \"G\"/\"H\" is a section of the pullback of the tautological bundle to \"M\". Intrinsically a moving frame can be defined on a principal bundle \"P\" over a manifold. In this case, a moving frame is given by a \"G\"-equivariant mapping φ : \"P\" → \"G\", thus \"framing\" the manifold by elements of the Lie group \"G\".\n\nAlthough there is a substantial formal difference between extrinsic and intrinsic moving frames, they are both alike in the sense that a moving frame is always given by a mapping into \"G\". The strategy in Cartan's method of moving frames, as outlined briefly in Cartan's equivalence method, is to find a \"natural moving frame\" on the manifold and then to take its Darboux derivative, in other words pullback the Maurer-Cartan form of \"G\" to \"M\" (or \"P\"), and thus obtain a complete set of structural invariants for the manifold.\n\n formulated the general definition of a moving frame and the method of the moving frame, as elaborated by . The elements of the theory are\n\n\nThe following axioms are then assumed to hold between these elements:\n\n\nOf interest to the method are parameterized submanifolds of \"X\". The considerations are largely local, so the parameter domain is taken to be an open subset of R. Slightly different techniques apply depending on whether one is interested in the submanifold along with its parameterization, or the submanifold up to reparameterization.\n\nThe most commonly encountered case of a moving frame is for the bundle of tangent frames (also called the \"frame bundle\") of a manifold. In this case, a moving tangent frame on a manifold \"M\" consists of a collection of vector fields \"e\", \"e\", ..., \"e\" forming a basis of the tangent space at each point of an open set \"U\" ⊂ \"M\".\n\nIf formula_2 is a coordinate system on \"U\", then each vector field \"e\" can be expressed as a linear combination of the coordinate vector fields formula_3:formula_4where each formula_5 is a function on \"U\". These can be seen as the components of a matrix formula_6. This matrix is useful for finding the coordinate expression of the dual coframe, as explained in the next section.\n\nA moving frame determines a dual frame or coframe of the cotangent bundle over \"U\", which is sometimes also called a moving frame. This is a \"n\"-tuple of smooth \"1\"-forms\n\nwhich are linearly independent at each point \"q\" in \"U\". Conversely, given such a coframe, there is a unique moving frame \"e\", \"e\", ..., \"e\" which is dual to it, i.e., satisfies the duality relation \"θ\"(\"e\") = \"δ\", where \"δ\" is the Kronecker delta function on \"U\".\n\nIf formula_2 is a coordinate system on \"U\", as in the preceding section, then each covector field \"θ\" can be expressed as a linear combination of the coordinate covector fields formula_8:formula_9where each formula_10 is a function on \"U.\" Since formula_11, the two coordinate expressions above combine to yield formula_12; in terms of matrices, this just says that formula_6 and formula_14 are inverses of each other.\n\nMoving frames are important in general relativity, where there is no privileged way of extending a choice of frame at an event \"p\" (a point in spacetime, which is a manifold of dimension four) to nearby points, and so a choice must be made. In contrast in special relativity, \"M\" is taken to be a vector space \"V\" (of dimension four). In that case a frame at a point \"p\" can be translated from \"p\" to any other point \"q\" in a well-defined way. Broadly speaking, a moving frame corresponds to an observer, and the distinguished frames in special relativity represent inertial observers.\n\nIn relativity and in Riemannian geometry, the most useful kind of moving frames are the orthogonal and orthonormal frames, that is, frames consisting of orthogonal (unit) vectors at each point. At a given point \"p\" a general frame may be made orthonormal by orthonormalization; in fact this can be done smoothly, so that the existence of a moving frame implies the existence of a moving orthonormal frame.\n\nA moving frame always exists \"locally\", i.e., in some neighbourhood \"U\" of any point \"p\" in \"M\"; however, the existence of a moving frame globally on \"M\" requires topological conditions. For example when \"M\" is a circle, or more generally a torus, such frames exist; but not when \"M\" is a 2-sphere. A manifold that does have a global moving frame is called \"parallelizable\". Note for example how the unit directions of latitude and longitude on the Earth's surface break down as a moving frame at the north and south poles.\n\nThe method of moving frames of Élie Cartan is based on taking a moving frame that is adapted to the particular problem being studied. For example, given a curve in space, the first three derivative vectors of the curve can in general define a frame at a point of it (cf. torsion tensor for a quantitative description – it is assumed here that the torsion is not zero). In fact, in the method of moving frames, one more often works with coframes rather than frames. More generally, moving frames may be viewed as sections of principal bundles over open sets \"U\". The general Cartan method exploits this abstraction using the notion of a Cartan connection.\n\nIn many cases, it is impossible to define a single frame of reference that valid globally. To overcome this, frames are commonly pieced together to form an atlas, thus arriving at the notion of a local frame. In addition, it is often desirable to endow these atlases with a smooth structure, so that the resulting frame fields are differentiable.\n\nAlthough this article constructs the frame fields as a coordinate system on the tangent bundle of a manifold, the general ideas move over easily to the concept of a vector bundle, which is a manifold endowed with a vector space at each point, that vector space being arbitrary, and not in general related to the tangent bundle.\n\nAircraft maneuvers can be expressed in terms of the moving frame (Aircraft principal axes) when described by the pilot.\n\n\n"}
{"id": "33230639", "url": "https://en.wikipedia.org/wiki?curid=33230639", "title": "Multicast-broadcast single-frequency network", "text": "Multicast-broadcast single-frequency network\n\nMultimedia Broadcast multicast service Single Frequency Network (MBSFN) is a communication channel defined in the fourth-generation cellular networking standard called Long Term Evolution (LTE). The transmission mode is intended as a further improvement of the efficiency of the enhanced Multimedia Broadcast Multicast Service (eMBMS) service, which can deliver services such as mobile TV using the LTE infrastructure, and is expected to compete with dedicated mobile/handheld TV broadcast systems such as DVB-H and DVB-SH. This enables network operators to offer mobile TV without the need for additional expensive licensed spectrum and without requiring new infrastructure and end-user devices.\n\nThe eMBMS service can offer many more TV programs in a specific radio frequency spectrum as compared to traditional terrestrial TV broadcasting, since it is based on the principles of Interactive Multicast, where TV content only is transmitted in where there currently are viewers. The eMBMS service also provides better system spectral efficiency than video-on-demand over traditional cellular unicasting services, since in eMBMS, each TV program is only transmitted once in each cell, even if there are several viewers of that program in the same cell. The MBSFN transmission mode further improves the spectral efficiency, since it is based on the principles of Dynamic single frequency networks (DSFN). This implies that it dynamically forms single-frequency networks (SFNs), i.e. groups of adjacent base stations that send the same signal simultaneously on the same frequency sub-carriers, when there are mobile TV viewers of the same TV program content in the adjacent cells. The LTE OFDMA downlink modulation and multiple access scheme eliminates self-interference caused by the SFN:s. Efficient TV transmission using similar combinations of Interactive multicast (IP Multicast) and DSFN has also been suggested for the DVB-T2 and DVB-H systems.\n\nMBMS and mobile TV was a failure in 3G systems, and was offered by very few mobile operators, partly because of its limited peak bit rates and capacity, not allowing standard TV video quality, something that LTE with eMBMS does not suffer from.\n\nLTE's Enhanced Multimedia Broadcast Multicast Services (E-MBMS) provides transport features for sending the same content information to all the users in a cell (broadcast) or to a given set of users (subscribers) in a cell (multicast) using a subset of the available radio resources with the remaining available to support transmissions towards a particular user (so-called unicast services). It must not be confused with IP-level broadcast or multicast, which offer no sharing of resources on the radio access level. In E-MBMS it is possible to either use a single eNode-B or multiple eNode-Bs for transmission to multiple UEs. MBSFN is the definition for the latter.\n\nMBSFN is a transmission mode which exploits LTE's OFDM radio interface to send multicast or broadcast data as a multicell transmission over a synchronized single-frequency network (SFN). The transmissions from the multiple cells are sufficiently tightly synchronized for each to arrive at the UE within the OFDM Cyclic Prefix (CP) so as to avoid Inter-Symbol Interference (ISI). In effect, this makes the MBSFN transmission appear to a UE as a transmission from a single large cell, dramatically increasing the Signal-to-Interference Ratio (SIR) due to the absence of inter-cell interference.\n\nCommercial deployment of E-MBMS (and therefore MBSFN) features is expected to start in 2013 as an upgrade of existing LTE networks. Lowell McAdam, CEO of Verizon, stated in his CES 2013 keynote that he hopes to have LTE-Broadcast available to live-broadcast the Super Bowl 2014 over its network. On a more general note, he identified live events as the ideal use case for LTE-Broadcast.\n\n"}
{"id": "19211790", "url": "https://en.wikipedia.org/wiki?curid=19211790", "title": "Multiplicity (mathematics)", "text": "Multiplicity (mathematics)\n\nIn mathematics, the multiplicity of a member of a multiset is the number of times it appears in the multiset. For example, the number of times a given polynomial equation has a root at a given point is the multiplicity of that root.\n\nThe notion of multiplicity is important to be able to count correctly without specifying exceptions (for example, \"double roots\" counted twice). Hence the expression, \"counted with multiplicity\".\n\nIf multiplicity is ignored, this may be emphasized by counting the number of distinct elements, as in \"the number of distinct roots\". However, whenever a set (as opposed to multiset) is formed, multiplicity is automatically ignored, without requiring use of the term \"distinct\".\n\nIn the prime factorization, for example,\n\nthe multiplicity of the prime factor 2 is 2, while the multiplicity of each of the prime factors 3 and 5 is 1. Thus, 60 has four prime factors allowing for multiplicities, but only three distinct prime factors.\n\nLet \"F\" be a field and \"p\"(\"x\") be a polynomial in one variable and coefficients in \"F\". An element \"a\" ∈ \"F\" is a root of multiplicity \"k\" of \"p\"(\"x\") if there is a polynomial \"s\"(\"x\") such that \"s\"(\"a\") ≠ 0 and \"p\"(\"x\") = (\"x\" − \"a\")\"s\"(\"x\"). If \"k\" = 1, then \"a\" is called a simple root. If \"k\" ≥ 2, then \"a\" is called a multiple root.\n\nFor instance, the polynomial \"p\"(\"x\") = \"x\" + 2\"x\" − 7\"x\" + 4 has 1 and −4 as roots, and can be written as \"p\"(\"x\") = (\"x\" + 4)(\"x\" − 1). This means that 1 is a root of multiplicity 2, and −4 is a 'simple' root (of multiplicity 1). The multiplicity of a root is the number of occurrences of this root in the complete factorization of the polynomial, by means of the fundamental theorem of algebra.\n\nIf \"a\" is a root of multiplicity \"k\" of a polynomial, then it is a root of multiplicity \"k\" – 1 of its derivative.\nThe discriminant of a polynomial is zero if and only if the polynomial has a multiple root.\n\nThe graph of a polynomial function \"y\" = \"f\"(\"x\") intersects the \"x\"-axis at the real roots of the polynomial. The graph is tangent to this axis at the multiple roots of \"f\" and not tangent at the simple roots. The graph crosses the \"x\"-axis at roots of odd multiplicity and bounces off (not goes through) the \"x\"-axis at roots of even multiplicity.\n\nA non-zero polynomial function is always non-negative if and only if all its roots have an even multiplicity and there exists \"x\" such that .\n\nIn algebraic geometry, the intersection of two sub-varieties of an algebraic variety is a finite union of irreducible varieties. To each component of such an intersection is attached an intersection multiplicity. This notion is local in the sense that it may be defined by looking at what occurs in a neighborhood of any generic point of this component. It follows that without loss of generality, we may consider, in order to define the intersection multiplicity, the intersection of two affines varieties (sub-varieties of an affine space).\n\nThus, given two affine varieties \"V\" and \"V\", let us consider an irreducible component \"W\" of the intersection of \"V\" and \"V\". Let \"d\" be the dimension of \"W\", and \"P\" be any generic point of \"W\". The intersection of \"W\" with \"d\" hyperplanes in general position passing through \"P\" has an irreducible component that is reduced to the single point \"P\". Therefore, the local ring at this component of the coordinate ring of the intersection has only one prime ideal, and is therefore an Artinian ring. This ring is thus a finite dimensional vector space over the ground field. Its dimension is the intersection multiplicity of \"V\" and \"V\" at \"W\".\n\nThis definition allows us to state Bézout's theorem and its generalizations precisely.\n\nThis definition generalizes the multiplicity of a root of a polynomial in the following way. The roots of a polynomial \"f\" are points on the affine line, which are the components of the algebraic set defined by the polynomial. The coordinate ring of this affine set is formula_1 where \"K\" is an algebraically closed field containing the coefficients of \"f\". If formula_2 is the factorization of \"f\", then the local ring of \"R\" at the prime ideal formula_3 is formula_4 This is a vector space over \"K\", which has the multiplicity formula_5 of the root as a dimension.\n\nThis definition of intersection multiplicity, which is essentially due to Jean-Pierre Serre in his book \"Local Algebra\", works only for the set theoretic components (also called \"isolated components\") of the intersection, not for the embedded components. Theories have been developed for handling the embedded case (see Intersection theory for details).\n\nLet \"z\" be a root of a holomorphic function \"f\", and let \"n\" be the least positive integer such that, the \"n\" derivative of \"f\" evaluated at \"z\" differs from zero. Then the power series of \"f\" about \"z\" begins with the \"n\" term, and \"f\" is said to have a root of multiplicity (or “order”) \"n\". If \"n\" = 1, the root is called a simple root.\n\nWe can also define the multiplicity of the zeroes and poles of a meromorphic function thus: If we have a meromorphic function \"f\" = \"g\"/\"h\", take the Taylor expansions of \"g\" and \"h\" about a point \"z\", and find the first non-zero term in each (denote the order of the terms \"m\" and \"n\" respectively). if \"m\" = \"n\", then the point has non-zero value. If \"m\" > \"n\", then the point is a zero of multiplicity \"m\" − \"n\". If \"m\" < \"n\", then the point has a pole of multiplicity \"n\" − \"m\".\n\n"}
{"id": "23110101", "url": "https://en.wikipedia.org/wiki?curid=23110101", "title": "Near sets", "text": "Near sets\n\nIn mathematics, near sets are either spatially close or descriptively close. Spatially close sets have nonempty intersection. In other words, spatially close sets are not disjoint sets, since they always have at least one element in common. Descriptively close sets contain elements that have matching descriptions. Such sets can be either disjoint or non-disjoint sets. Spatially near sets are also descriptively near sets.\n\nThe underlying assumption with descriptively close sets is that such sets contain elements that have location and measurable features such as colour and frequency of occurrence. The description of the element of a set is defined by a feature vector. Comparison of feature vectors provides a basis for measuring the closeness of descriptively near sets. Near set theory provides a formal basis for the observation, comparison, and classification of elements in sets based on their closeness, either spatially or descriptively. Near sets offer a framework for solving problems based on human perception that arise in areas such as image processing, computer vision as well as engineering and science problems.\n\nNear sets have a variety of applications in areas such as topology, pattern detection and classification, abstract algebra, mathematics in computer science, and solving a variety of problems based on human perception that arise in areas such as image analysis, image processing, face recognition, ethology, as well as engineering and science problems. From the beginning, descriptively near sets have proved to be useful in applications of topology, and visual pattern recognition , spanning a broad spectrum of applications that include camouflage detection, micropaleontology, handwriting forgery detection, biomedical image analysis, content-based image retrieval, population dynamics, quotient topology, textile design, visual merchandising, and topological psychology.\n\nAs an illustration of the degree of descriptive nearness between two sets, consider an example of the Henry colour model for varying degrees of nearness\nbetween sets of picture elements in pictures (see, \"e.g.\", §4.3). The two pairs of ovals in Fig. 1 and Fig. 2 contain coloured segments. Each segment in the figures corresponds to an equivalence class where all pixels in the class have similar descriptions, \"i.e.\", picture elements with similar colours. The ovals in Fig.1 are closer to each other descriptively than the ovals in Fig. 2.\n\nIt has been observed that the simple concept of \"nearness\" unifies various concepts of topological structures inasmuch as the category Near of all nearness spaces and nearness preserving maps contains categories sTop (symmetric topological spaces and continuous maps), Prox (proximity spaces and formula_1-maps), Unif (uniform spaces and uniformly continuous maps) and Cont (contiguity spaces and contiguity maps) as embedded full subcategories. The categories formula_2 and formula_3 are shown to be full supercategories of various well-known categories, including the category formula_4 of symmetric topological spaces and continuous maps, and the category formula_5 of extended metric spaces and nonexpansive maps. The notation formula_6 reads \"category\" formula_7 \"is embedded in category\" formula_8. The categories formula_9 and formula_10 are supercategories for a variety of familiar categories shown in Fig. 3. Let formula_2 denote the category of all formula_12-approach nearness spaces and contractions, and let formula_9 denote the category of all formula_12-approach merotopic spaces and contractions.\n\nAmong these familiar categories is formula_4, the symmetric form of formula_16 (see category of topological spaces), the category with objects that are topological spaces and morphisms that are continuous maps between them. formula_17 with objects that are extended metric spaces is a subcategory of formula_18 (having objects formula_12-approach spaces and contractions) (see also). Let formula_20 be extended pseudometrics on nonempty sets formula_21, respectively. The map formula_22 is a contraction if and only if formula_23 is a contraction. For nonempty subsets formula_24 , the distance function formula_25 is defined by\n\nThus formula_27AP is embedded as a full subcategory in formula_2 by the functor formula_29 defined by formula_30 and formula_31. Then formula_22 is a contraction if and only if formula_23 is a contraction. Thus formula_34 is embedded as a full subcategory in formula_2 by the functor formula_29 defined by formula_30 and formula_38 Since the category formula_5 of extended metric spaces and nonexpansive maps is a full subcategory of formula_34, therefore, formula_2 is also a full supercategory of formula_5. The category formula_2 is a topological construct.\n\nThe notions of near and far in mathematics can be traced back to works by Johann Benedict Listing and Felix Hausdorff. The related notions of resemblance and similarity can be traced back to J.H. Poincaré, who introduced sets of similar sensations (nascent tolerance classes) to represent the results of G.T. Fechner's sensation sensitivity experiments and a framework for the study of resemblance in representative spaces as models of what he termed physical continua. The elements of a physical continuum (pc) are sets of sensations. The notion of a pc and various representative spaces (tactile, visual, motor spaces) were introduced by Poincaré in an 1894 article on the mathematical continuum, an 1895 article on space and geometry and a compendious 1902 book on science and hypothesis followed by a number of elaborations, \"e.g.\". The 1893 and 1895 articles on continua (Pt. 1, ch. II) as well as representative spaces and geometry (Pt. 2, ch IV) are included as chapters in. Later, F. Riesz introduced the concept of proximity or nearness of pairs of sets at the International Congress of Mathematicians (ICM) in 1908.\n\nDuring the 1960s, E.C. Zeeman introduced tolerance spaces in modelling visual perception. A.B. Sossinsky observed in 1986 that the main idea underlying tolerance space theory comes from Poincaré, especially. In 2002, Z. Pawlak and J. Peters considered an informal approach to the perception of the nearness of physical objects such as snowflakes that was not limited to spatial nearness. In 2006, a formal approach to the descriptive nearness of objects was considered by J. Peters, A. Skowron and J. Stepaniuk in the context of proximity spaces. In 2007, descriptively near sets were introduced by J. Peters followed by the introduction of tolerance near sets. Recently, the study of descriptively near sets has led to algebraic, topological and proximity space foundations of such sets.\n\nThe adjective \"near\" in the context of near sets is used to denote the fact that observed feature value differences of distinct objects are small enough to be\nconsidered indistinguishable, \"i.e.\", within some tolerance.\n\nThe exact idea of closeness or 'resemblance' or of 'being within tolerance' is universal enough to appear, quite naturally, in almost any mathematical setting\n(see, \"e.g.\",). It is especially natural in mathematical applications: practical problems, more often than not, deal with approximate input data and only require viable results with a tolerable level of error.\n\nThe words \"near\" and \"far\" are used in daily life and it was an incisive suggestion of F. Riesz that these intuitive concepts be made rigorous. He introduced the concept of nearness of pairs of sets at the ICM in Rome in 1908. This concept is useful in simplifying teaching calculus and advanced calculus. For example, the passage from an intuitive definition of continuity of a function at a point to its rigorous epsilon-delta definition is sometime difficult for teachers to explain and for students to understand. Intuitively, continuity can be explained using nearness language, \"i.e.\", a function formula_44 is continuous at a point formula_45, provided points formula_46 near formula_45 go into points formula_48 near formula_49. Using Riesz's idea, this definition can be made more precise and its contrapositive is the familiar definition.\n\nFrom a spatial point of view, nearness (a.k.a. proximity) is considered a generalization of set intersection. For disjoint sets, a form of nearness set intersection is defined in terms of a set of objects (extracted from disjoint sets) that have similar features within some\ntolerance (see, \"e.g.\", §3 in). For example, the ovals in Fig. 1 are considered near each other, since these ovals contain pairs of classes that display similar (visually indistinguishable) colours.\n\nLet formula_50 denote a metric topological space that is endowed with one or more proximity relations and let formula_51 denote the collection of all subsets of formula_50. The collection formula_51 is called the power set of formula_50.\n\nThere are many ways to define Efremovič proximities on topological spaces (discrete proximity, standard proximity, metric proximity, Čech proximity, Alexandroff proximity, and Freudenthal proximity), For details, see § 2, pp. 93–94 in.\nThe focus here is on \"standard proximity\" on a topological space. For formula_55, formula_56 is near formula_57 (denoted by formula_58), provided their closures share a common point.\n\nThe \"closure\" of a subset formula_59 (denoted by formula_60) is the usual Kuratowski closure of a set, introduced in § 4, p. 20, is defined by\n\n\"i.e.\" formula_60 is the set of all points formula_63 in formula_50 that are close to formula_56 (formula_66 is the Hausdorff distance (see § 22, p. 128, in) between formula_63 and the set formula_56 and formula_69 (standard distance)). A \"standard\" proximity relation is defined by\n\nWhenever sets formula_56 and formula_57 have no points in common, the sets are \"far\"from each other (denoted formula_73).\n\nThe following EF-proximity space axioms are given by Jurij Michailov Smirnov based on what Vadim Arsenyevič Efremovič introduced during the first half of the 1930s. Let formula_74.\n\n\nThe pair formula_93 is called an EF-proximity space. In this context, a space is a set with some added structure. With a proximity space formula_50, the structure of formula_50 is induced by the EF-proximity relation formula_1. In a proximity space formula_50, the closure of formula_56 in formula_50 coincides with the intersection of all closed sets that contain formula_56.\n\n\nLet the set formula_50 be represented by the points inside the rectangular region in Fig. 5. Also, let formula_106 be any two non-intersection subsets (\"i.e.\" subsets spatially far from each other) in formula_50, as shown in Fig. 5. Let formula_108 (complement of the set formula_90). Then from the EF-axiom, observe the following:\n\nDescriptively near sets were introduced as a means of solving classification and pattern recognition problems arising from disjoint sets that resemble each other. Recently, the connections between near sets in EF-spaces and near sets in descriptive EF-proximity spaces have been explored in.\n\nAgain, let formula_50 be a metric topological space and let formula_112 a set of probe functions that represent features of each formula_103. The assumption made here is formula_50 contains non-abstract points that have measurable features such as gradient orientation. A non-abstract point has a location and features that can be measured (see § 3 in ).\n\nA \"probe function\" formula_115 represents a feature of a sample point in formula_50. The mapping formula_117 is defined by formula_118, where formula_119 is an n-dimensional real Euclidean vector space. formula_120 is a feature vector for formula_63, which provides a description of formula_103. For example, this leads to a proximal view of sets of picture points in digital images.\n\nTo obtain a descriptive proximity relation (denoted by formula_123), one first chooses a set of probe functions. Let formula_124 be a mapping on a subset of formula_51 into a subset of formula_126. For example, let formula_24 and formula_128 denote sets of descriptions of points in formula_106, respectively. That is,\n\nThe expression formula_131 reads formula_56 \"is descriptively near\" formula_57. Similarly, formula_134 reads formula_56 \"is descriptively far from\" formula_57. The descriptive proximity of formula_56 and formula_57 is defined by\n\nThe \"descriptive intersection\" formula_140 of formula_56 and formula_57 is defined by\n\nThat is, formula_144 is in formula_145, provided formula_146 for some formula_147. Observe that formula_56 and formula_57 can be disjoint and yet formula_145 can be nonempty.\nThe descriptive proximity relation formula_123 is defined by\n\nWhenever sets formula_56 and formula_57 have no points with matching descriptions, the sets are \"descriptively far\" from each other \n(denoted by formula_155).\n\nThe binary relation formula_123 is a \"descriptive EF-proximity\", provided the following axioms are satisfied for formula_157.\n\n\nThe pair formula_179 is called a descriptive proximity space.\n\nA \"relator\" is a nonvoid family of relations formula_180 on a nonempty set formula_50. The pair formula_182 (also denoted formula_183) is called a relator space. Relator spaces are natural generalizations of ordered sets and uniform spaces}. With the introduction of a family of proximity relations formula_184 on formula_50, we obtain a proximal relator space formula_186. For simplicity, we consider only two proximity relations, namely, the Efremovič proximity formula_1 and the descriptive proximity formula_123 in defining the \"descriptive relator\" formula_189. The pair formula_190 is called a \"proximal relator space \". In this work, formula_50 denotes a metric topological space that is endowed with the relations in a proximal relator. With the introduction of formula_190, the traditional closure of a subset (\"e.g.\", ) can be compared with the more recent descriptive closure of a subset.\n\nIn a proximal relator space formula_50, the \"descriptive closure of a set\" formula_56 (denoted by formula_195) is defined by\n\nThat is, formula_103 is in the descriptive closure of formula_56, provided the closure of formula_120 and the closure of formula_200 have at least one element in common.\n\n\n\n\n\nIn a proximal relator space, EF-proximity formula_1 leads to the following results for descriptive proximity formula_123.\n\n\n\nformula_230\n\nformula_236\n\nIn a pseudometric proximal relator space formula_50, the neighbourhood of a point formula_103 (denoted by formula_240), for formula_241, is defined by\n\nThe interior of a set formula_56 (denoted by formula_244) and boundary of formula_56 (denoted by formula_246) in a proximal relator space formula_50 are defined by\n\nA set formula_56 has a \"natural strong inclusion\" in a set formula_57 associated with formula_1} (denoted by formula_253), provided formula_254, \"i.e.\", formula_255 (formula_56 is far from the complement of formula_257). Correspondingly, a set formula_56 has a \"descriptive strong inclusion\" in a set formula_57 associated with formula_123 (denoted by formula_261), provided formula_262, \"i.e.\", formula_263 (formula_264 is far from the complement of formula_257).\n\nLet formula_266 be a descriptive formula_1-neighbourhood relation defined by\n\nThat is, formula_261, provided the description of each formula_270 is contained in the set of descriptions of the points formula_271. Now observe that any formula_106 in the proximal relator space formula_50 such that formula_155 have disjoint formula_123-neighbourhoods, \"i.e.\",\n\n\nA consideration of strong containment of a nonempty set in another set leads to the study of hit-and-miss topologies and the Wijsman topology.\n\nLet formula_12 be a real number greater than zero. In the study of sets that are proximally near within some tolerance, the set of proximity relations formula_189 is augmented with a pseudometric tolerance proximity relation (denoted by formula_281) defined by\n\nLet formula_283. In other words, a nonempty set equipped with the proximal relator formula_284 has underlying structure provided by the proximal relator formula_189 and provides a basis for the study of tolerance near sets in formula_50 that are near within some tolerance. Sets formula_106 in a descriptive pseudometric proximal relator space formula_288 are tolerance near sets (\"i.e.\", formula_289), provided\n\nRelations with the same formal properties as similarity relations of sensations considered by Poincaré are nowadays, after Zeeman, called \"tolerance relations\". A \"tolerance formula_291 on a set formula_292\" is a relation formula_293 that is reflexive and symmetric. In algebra, the term \"tolerance relation\" is also used in a narrow sense to denote reflexive and symmetric relations defined on universes of algebras that are also compatible with operations of a given algebra, \"i.e.\", they are generalizations of congruence relations (see \"e.g.\",). In referring to such relations, the term \"algebraic tolerance\" or the term \"algebraic tolerance relation\" is used.\nTransitive tolerance relations are equivalence relations. A set formula_292 together with a tolerance formula_291 is called a \"tolerance space\" (denoted formula_296). A set formula_297 is a \"formula_291-preclass\" (or briefly \"preclass\" when formula_291 is understood) if and only if for any formula_300, formula_301.\n\nThe family of all preclasses of a tolerance space is naturally ordered by set inclusion and preclasses that are maximal with respect to set inclusion are called \"formula_291-classes\" or just \"classes\", when formula_291 is understood. The family of all classes of the space formula_296 is particularly interesting and is denoted by formula_305. The family formula_305 is a covering of formula_292.\n\nThe work on similarity by Poincaré and Zeeman presage the introduction of near sets and research on similarity relations, \"e.g.\". In science and engineering, tolerance near sets are a practical application of the study of sets that are near within some tolerance. A tolerance formula_308 is directly related to the idea of closeness or resemblance (\"i.e.\", being within some tolerance) in comparing objects.\nBy way of application of Poincaré's approach in defining visual spaces and Zeeman's approach to tolerance relations, the basic idea is to compare objects such as image patches in the interior of digital images.\n\nSimple Example\n\nThe following simple example demonstrates the construction of tolerance classes from real data. Consider the 20 objects in the table below with formula_309.\n\nLet a tolerance relation be defined as\n\nThen, setting formula_311 gives the following tolerance classes:\n\nObserve that each object in a tolerance class satisfies the condition formula_313, and that almost all of the objects appear in more than one class. Moreover, there would be twenty classes if the indiscernibility relation was used since there are no two objects with matching descriptions.\n\nImage Processing Example\n\nThe following example provides an example based on digital images. Let a subimage be defined as a small subset of pixels belonging to a digital image such that the pixels contained in the subimage form a square. Then, let the sets formula_314 and formula_315 respectively represent the subimages obtained from two different images, and let formula_316. Finally, let the description of an object be given by the Green component in the RGB color model. The next step is to find all the tolerance classes using the tolerance relation defined in the previous example. Using this information, tolerance classes can be formed containing objects that have similar (within some small formula_12) values for the Green component in the RGB colour model. Furthermore, images that are near (similar) to each other should have tolerance classes divided among both images (instead of a tolerance classes contained solely in one of the images). For example, the figure accompanying this example shows a subset of the tolerance classes obtained from two leaf images. In this figure, each tolerance class is assigned a separate colour. As can be seen, the two leaves share similar tolerance classes. This example highlights a need to measure the degree of nearness of two sets.\n\nLet formula_318 denote a particular descriptive pseudometric EF-proximal relator space equipped with the proximity relation formula_281 and with nonempty subsets formula_320 and with the tolerance relation formula_321 defined in terms of a set of probes formula_322 and with formula_323, where\n\nFurther, assume formula_325 and let formula_326 denote the family of all classes in the space formula_327.\n\nLet formula_328. The distance formula_329 is defined by\n\nwhere\n\nThe details concerning formula_332 are given in. The idea behind formula_332 is that sets that are similar should have a similar number of objects in each tolerance class. Thus, for each tolerance class obtained from the covering of formula_334, formula_332 counts the number of objects that belong to formula_50 and formula_315 and takes the ratio (as a proper fraction) of their cardinalities. Furthermore, each ratio is weighted by the total size of the tolerance class (thus giving importance to the larger classes) and the final result is normalized by dividing by the sum of all the cardinalities. The range of formula_332 is in the interval [0,1], where a value of 1 is obtained if the sets are equivalent (based on object descriptions) and a value of 0 is obtained if they have no descriptions in common.\n\nAs an example of the degree of nearness between two sets, consider figure below in which each image consists of two sets of objects, formula_50 and formula_315. Each colour in the figures corresponds to a set where all the objects in the class share the same description. The idea behind formula_332 is that the nearness of sets in a perceptual system is based on the cardinality of tolerance classes that they share. Thus, the sets in left side of the figure are closer (more near) to each other in terms of their descriptions than the sets in right side of the figure.\n\nThe Near set Evaluation and Recognition (NEAR) system, is a system developed to demonstrate practical applications of near set theory to the problems of image segmentation evaluation and image correspondence. It was motivated by a need for a freely available software tool that can provide results for research and to generate interest in near set theory. The system implements a Multiple Document Interface (MDI) where each separate processing task is performed in its own child frame. The objects (in the near set sense) in this system are subimages of the images being processed and the probe functions (features) are image processing functions defined on the subimages. The system was written in C++ and was designed to facilitate the addition of new processing tasks and probe functions. Currently, the system performs six major tasks, namely, displaying equivalence and tolerance classes for an image, performing segmentation evaluation, measuring the nearness of two images, performing Content Based Image Retrieval (CBIR), and displaying the output of processing an image using a specific probe function.\n\nThe Proximity System is an application developed to demonstrate descriptive-based topological approaches to nearness and proximity within the context of digital image analysis. The Proximity System grew out of the work of S. Naimpally and J. Peters on Topological Spaces. The Proximity System was written in Java and is intended to run in two different operating environments, namely on Android smartphones and tablets, as well as desktop platforms running the Java Virtual Machine. With respect to the desktop environment, the Proximity System is a cross-platform Java application for Windows, OSX, and Linux systems, which has been tested on Windows 7 and Debian Linux using the Sun Java 6 Runtime. In terms of the implementation of the theoretical approaches, both the Android and the desktop based applications use the same back-end libraries to perform the description-based calculations, where the only differences are the user interface and the Android version has less available features due to restrictions on system resources.\n\n"}
{"id": "45334947", "url": "https://en.wikipedia.org/wiki?curid=45334947", "title": "Newton–Okounkov body", "text": "Newton–Okounkov body\n\nIn algebraic geometry, a Newton–Okounkov body, also called an Okounkov body, is a convex body in Euclidean space associated to a divisor (or more generally a linear system) on a variety. The convex geometry of a Newton–Okounkov body encodes (asymptotic) information about the geometry of the variety and the divisor. It is a large generalization of the notion of the Newton polytope of a projective toric variety.\n\nIt was introduced (in passing) by Andrei Okounkov in his papers in the late 1990s and early 2000s. Okounkov’s construction relies on an earlier result of Askold Khovanskii on semigroups of lattice points. Later Okounkov’s construction was generalized and systematically developed in the papers of Robert Lazarsfeld and Mircea Mustață as well as Kiumars Kaveh and Khovanskii.\n\nBeside Newton polytopes of toric varieties, several polytopes appearing in representation theory (such as the Gelfand–Zetlin polytopes and the string polytopes of Peter Littelmann and Arkady Berenstein–Andrei Zelevinsky) can be realized as special cases of Newton–Okounkov bodies.\n\n\n"}
{"id": "1625306", "url": "https://en.wikipedia.org/wiki?curid=1625306", "title": "Novum Organum", "text": "Novum Organum\n\nThe Novum Organum, fully Novum Organum Scientiarum ('new instrument of science'), is a philosophical work by Francis Bacon, written in Latin and published in 1620. The title is a reference to Aristotle's work \"Organon\", which was his treatise on logic and syllogism. In \"Novum Organum\", Bacon details a new system of logic he believes to be superior to the old ways of syllogism. This is now known as the Baconian method.\n\nFor Bacon, finding the essence of a thing was a simple process of reduction, and the use of inductive reasoning. In finding the cause of a 'phenomenal nature' such as heat, one must list all of the situations where heat is found. Then another list should be drawn up, listing situations that are similar to those of the first list except for the lack of heat. A third table lists situations where heat can vary. The 'form nature', or cause, of heat must be that which is common to all instances in the first table, is lacking from all instances of the second table and varies by degree in instances of the third table.\n\nThe title page of \"Novum Organum\" depicts a galleon passing between the mythical Pillars of Hercules that stand either side of the Strait of Gibraltar, marking the exit from the well-charted waters of the Mediterranean into the Atlantic Ocean. The Pillars, as the boundary of the Mediterranean, have been smashed through by Iberian sailors, opening a new world for exploration. Bacon hopes that empirical investigation will, similarly, smash the old scientific ideas and lead to greater understanding of the world and heavens. This title page was liberally copied from Andrés García de Céspedes's \"Regimiento de Navegación\", published in 1606.\n\nThe Latin tag across the bottom – \"\" – is taken from the Old Testament (Daniel 12:4). It means: \"Many will travel and knowledge will be increased\".\n\nBacon's work was instrumental in the historical development of the scientific method. His technique bears a resemblance to the modern formulation of the scientific method in the sense that it is centered on experimental research. Bacon's emphasis on the use of artificial experiments to provide additional observances of a phenomenon is one reason that he is often considered \"the Father of the Experimental Philosophy\" (for example famously by Voltaire). On the other hand, modern scientific method does not follow Bacon's methods in its details, but more in the spirit of being methodical and experimental, and so his position in this regard can be disputed. Importantly though, Bacon set the scene for science to develop various methodologies, because he made the case against older Aristotelian approaches to science, arguing that method was needed because of the natural biases and weaknesses of the human mind, including the natural bias it has to seek metaphysical explanations which are not based on real observations.\n\nBacon begins the work with a rejection of pure \"a priori\" deduction as a means of discovering truth in natural philosophy. Of his philosophy, he states:Now my plan is as easy to describe as it is difficult to effect. For it is to establish degrees of certainty, take care of the sense by a kind of reduction, but to reject for the most part the work of the mind that follows upon sense; in fact I mean to open up and lay down a new and certain pathway from the perceptions of the senses themselves to the mind.\n\nThe emphasis on beginning with observation pervades the entire work. In fact, it is in the idea that natural philosophy must begin with the senses that we find the revolutionary part of Bacon's philosophy, and its consequent philosophical method, eliminative induction, is one of Bacon's most lasting contributions to science and philosophy.\n\n\"Novum organum\" was actually published as part of a much larger work, \"Instauratio magna\"—'the great restoration'. Originally intending \"Instauratio magna\" to contain six parts (of which \"Novum organum\" constituted the second), Bacon did not come close to completing this series, as parts V and VI were never written at all. \"Novum organum\", written in Latin and consisting of two books of aphorisms, was included in the volume that Bacon published in 1620; however, it was also unfinished, as Bacon promised several additions to its content which ultimately remained unprinted.\n\nBacon titled this first book \"\" ('Aphorisms Concerning the Interpretation of Nature, and the Kingdom of Man').\n\nIn the first book of aphorisms, Bacon criticizes the current state of natural philosophy. The object of his assault consists largely in the syllogism, a method that he believes to be completely inadequate in comparison to what Bacon calls \"true \"Induction\":\n\nIn many of his aphorisms, Bacon reiterates the importance of inductive reasoning. Induction, methodologically opposed to deduction, entails beginning with particular cases observed by the senses and then attempting to discover the general axioms from those observations. In other words, induction presupposes nothing. Deduction, on the other hand, begins with general axioms, or first principles, by which the truth of particular cases is extrapolated. Bacon emphasises the strength of the gradual process that is inherent in induction:\n\nAfter many similar aphoristic reiterations of these important concepts, Bacon presents his famous Idols.\n\n\"Novum organum\", as suggested by its name, is focused just as much on a rejection of received doctrine as it is on a forward-looking progression. In Bacon's Idols are found his most critical examination of man-made impediments which mislead the mind's objective reasoning. They appear in previous works but were never fully fleshed out until their formulation in \"Novum organum\":\n\n\"Idols of the Tribe are rooted in human nature itself and in the very tribe or race of men. For people falsely claim that human sense is the measure of things, whereas in fact all perceptions of sense and mind are built to the scale of man and not the universe.\" (Aphorism 41.)\n\nBacon includes in this idol the predilection of the human imagination to presuppose otherwise unsubstantiated regularities in nature. An example might be the common historical astronomical assumption that planets move in perfect circles.\n\nThese \"belong to the particular individual. For everyone has (besides vagaries of human nature in general) his own special cave or den which scatters and discolours the light of nature. Now this comes either of his own unique and singular nature; or his education and association with others, or the books he reads and the several authorities of those whom he cultivates and admires, or the different impressions as they meet in the soul, be the soul possessed and prejudiced, or steady and settled, or the like; so that the human spirit (as it is allotted to particular individuals) is evidently a variable thing, all muddled, and so to speak a creature of chance...\" (Aphorism 42).\n\nThis type of idol stems from the particular life experiences of the individual. Variable educations can lead the individual to a preference for specific concepts or methods, which then corrupt their subsequent philosophies. Bacon himself gives the example of Aristotle, \"who made his natural philosophy a mere slave to his logic\". (Aphorism 54.)\n\nThese are \"derived as if from the mutual agreement and association of the human race, which I call Idols of the Market on account of men's commerce and partnerships. For men associate through conversation, but words are applied according to the capacity of ordinary people. Therefore shoddy and inept application of words lays siege to the intellect in wondrous ways\" (Aphorism 43).\n\nBacon considered these \"the greatest nuisances of them all\" (Aphorism 59). Because humans reason through the use of words they are particularly dangerous, because the received definitions of words, which are often falsely derived, can cause confusion. He outlines two subsets of this kind of idol and provides examples (Aphorism 60). \n\n\"Lastly, there are the Idols which have misguided into men's souls from the dogmas of the philosophers and misguided laws of demonstration as well; I call these Idols of the Theatre, for in my eyes the philosophies received and discovered are so many stories made up and acted out stories which have created sham worlds worth of the stage.\" (Aphorism 44.)\n\nThese idols manifest themselves in the unwise acceptance of certain philosophical dogmas, namely Aristotle's sophistical natural philosophy (named specifically in Aphorism 63) which was corrupted by his passion for logic, and Plato's superstitious philosophy, which relied too heavily on theological principles.\n\nAfter enumerating the shortcomings of the current and past natural philosophies, Bacon can now present his own philosophy and methods.\nBacon retains the Aristotelian causes, but redefines them in interesting ways. While traditionally the final cause was held as most important among the four (material, formal, efficient, and final), Bacon claims that it is the least helpful and in some cases actually detrimental to the sciences (aph. 2). For Bacon, it is the formal cause which is both the most illusive and most valuable, although each of the causes provides certain practical devices. By forms and formal causes, Bacon means the universal laws of nature. To these Bacon attaches an almost occult like power:\n\nBut he who knows forms grasps the unity of nature beneath the surface of materials which are very unlike. Thus is he able to identify and bring about things that have never been done before, things of the kind which neither the vicissitudes of nature, nor hard experimenting, nor pure accident could ever have actualised, or human thought dreamed of. And thus from the discovery of the forms flows true speculation and unrestricted operation (aphorism 3)\n\nIn this second book, Bacon offers an example of the process that of what he calls true induction. In this example, Bacon attempts to grasp the form of heat.\n\nThe first step he takes is the surveying of all known instances where the nature of heat appears to exist. To this compilation of observational data Bacon gives the name \"Table of Essence and Presence.\" The next table, the \"Table of Absence in Proximity\", is essentially the opposite—a compilation of all the instances in which the nature of heat is not present. Because these are so numerous, Bacon enumerates only the most relevant cases. Lastly, Bacon attempts to categorise the instances of the nature of heat into various degrees of intensity in his \"Table of Degrees.\" The aim of this final table is to eliminate certain instances of heat which might be said to be the form of heat, and thus get closer to an approximation of the true form of heat. Such elimination occurs through comparison. For example, the observation that both a fire and boiling water are instances of heat allows us to exclude light as the true form of heat, because light is present in the case of the fire but not in the case of the boiling water. Through this comparative analysis, Bacon intends to eventually extrapolate the true form of heat, although it is clear that such a goal is only gradually approachable by degrees. Indeed, the hypothesis that is derived from this eliminative induction, which Bacon names \"The First Vintage\", is only the starting point from which additional empirical evidence and experimental analysis can refine our conception of a formal cause.\n\nThe \"Baconian method\" does not end at the \"First Vintage\". Bacon described numerous classes of Instances with Special Powers, cases in which the phenomena one is attempting to explain is particularly relevant. These instances, of which Bacon describes 27 in \"Novum Organum\", aid and accelerate the process of induction. They are \"labour-saving devices or shortcuts intended to accelerate or make more rigorous the search for forms by providing logical reinforcement to induction.\"\n\nAside from the First Vintage and the Instances with Special Powers, Bacon enumerates additional \"aids to the intellect\" which presumably are the next steps in his \"method.\" In Aphorism 21 of Book II, Bacon lays out the subsequent series of steps in proper induction: including \"Supports to Induction\", \"Rectification of Induction\", \"Varying the Inquiry according to the Nature of the Subject\", \"Natures with Special Powers\", \"Ends of Inquiry\", \"Bringing Things down to Practice\", \"Preparatives to Inquiry\" and \"Ascending and Descending Scale of Axioms.\" \nThese additional aids, however, were never explained beyond their initial limited appearance in \"Novum Organum\". It is likely that Bacon intended them to be included in later parts of \"Instauratio magna\" and simply never got to writing about them.\n\nAs mentioned above, this second book of \"Novum organum\" was far from complete and indeed was only a small part of a massive, also unfinished work, the \"Instauratio magna.\"\n\nBacon is often studied through a comparison to his contemporary René Descartes. Both thinkers were, in a sense, some of the first to question the philosophical authority of the ancient Greeks. Bacon and Descartes both believed that a critique of preexisting natural philosophy was necessary, but their respective critiques proposed radically different approaches to natural philosophy. Two over-lapping movements developed; \"one was rational and theoretical in approach and was headed by Rene Descartes; the other was practical and empirical and was led by Francis Bacon.\" They were both profoundly concerned with the extent to which humans can come to knowledge, and yet their methods of doing so projected diverging paths.\n\nOn the one hand, Descartes begins with a doubt of anything which cannot be known with absolute certainty and includes in this realm of doubt the impressions of sense perception, and thus, \"all sciences of corporal things, such as physics and astronomy.\" He thus attempts to provide a metaphysical principle (this becomes the Cogito) which cannot be doubted, on which further truths must be deduced. In this method of deduction, the philosopher begins by examining the most general axioms (such as the \"Cogito\"), and then proceeds to determine the truth about particulars from an understanding of those general axioms.\n\nConversely, Bacon endorsed the opposite method of Induction, in which the particulars are first examined, and only then is there a gradual ascent to the most general axioms. While Descartes doubts the ability of the senses to provide us with accurate information, Bacon doubts the ability of the mind to deduce truths by itself as it is subjected to so many intellectual obfuscations, Bacon's \"Idols.\" In his first aphorism of \"New organum\", Bacon states:\n\n\"Man, the servant and interpreter of nature, does and understands only as much as he has observed, by fact or mental activity, concerning the order of nature; beyond that he has neither knowledge nor power.\"\n\nSo, in a basic sense the central difference between the philosophical methods of Descartes and those of Bacon can be reduced to an argument between deductive and inductive reasoning and whether to trust or doubt the senses. However, there is another profound difference between the two thinkers' positions on the accessibility of Truth. Descartes professed to be aiming at absolute Truth. It is questionable whether Bacon believed such a Truth can be achieved. In his opening remarks, he proposes \"to establish progressive stages of certainty.\" For Bacon, a measure of truth was its power to allow predictions of natural phenomena (although Bacon's forms come close to what we might call \"Truth,\" because they are universal, immutable laws of nature).\n\nAn interesting characteristic of Bacon's apparently scientific tract was that, although he amassed an overwhelming body of empirical data, he did not make any original discoveries. Indeed, that was never his intention, and such an evaluation of Bacon's legacy may wrongfully lead to an unjust comparison with Newton. Bacon never claimed to have brilliantly revealed new unshakable truths about nature—in fact, he believed that such an endeavour is not the work of single minds but that of whole generations by gradual degrees toward reliable knowledge.\n\nIn many ways, Bacon's contribution to the advancement of human knowledge lies not in the fruit of his scientific research but in the reinterpretation of the methods of natural philosophy. His innovation is summarised in \"The Oxford Francis Bacon\":Before Bacon where else does one find a meticulously articulated view of natural philosophy as an enterprise of instruments and experiment, and enterprise designed to restrain discursive reason and make good the defects of the senses? Where else in the literature before Bacon does one come across a stripped-down natural-historical programme of such enormous scope and scrupulous precision, and designed to serve as the basis for a complete reconstruction of human knowledge which would generate new, vastly productive sciences through a form of eliminative induction supported by various other procedures including deduction? Where else does one find a concept of scientific research which implies an institutional framework of such proportions that it required generations of permanent state funding to sustain it? And all this accompanied by a thorough, searching, and devastating attack on ancient and not-so-ancient philosophies, and by a provisional natural philosophy anticipating the results of the new philosophy?\"\n\n"}
{"id": "19651210", "url": "https://en.wikipedia.org/wiki?curid=19651210", "title": "Ontological maximalism", "text": "Ontological maximalism\n\nIn philosophy, ontological maximalism is a preference for largest possible universe, i.e. anything which could exist does exist.\n\n"}
{"id": "502042", "url": "https://en.wikipedia.org/wiki?curid=502042", "title": "Poisson summation formula", "text": "Poisson summation formula\n\nIn mathematics, the Poisson summation formula is an equation that relates the Fourier series coefficients of the periodic summation of a function to values of the function's continuous Fourier transform. Consequently, the periodic summation of a function is completely defined by discrete samples of the original function's Fourier transform. And conversely, the periodic summation of a function's Fourier transform is completely defined by discrete samples of the original function. The Poisson summation formula was discovered by Siméon Denis Poisson and is sometimes called Poisson resummation.\n\nFor appropriate functions formula_1  the Poisson summation formula may be stated as:\n\nWith the substitution, formula_4  and the Fourier transform property,  formula_5  (for formula_6),   becomes:\n\nWith another definition,  formula_7  and the transform property  formula_8  becomes a periodic summation (with period formula_9) and its equivalent Fourier series:\n\nSimilarly, the periodic summation of a function's Fourier transform has this Fourier series equivalent:\n\nwhere T represents the time interval at which a function formula_10 is sampled, and formula_11 is the rate of samples/sec.\n\n\nThese equations can be interpreted in the language of distributions (; ) for a function formula_2 whose derivatives are all rapidly decreasing (see Schwartz function). Using the Dirac comb distribution and its Fourier series:\n\nIn other words, the periodization of a Dirac delta formula_19,\nresulting in a Dirac comb, corresponds to the discretization of its spectrum which is constantly one.\nHence, this again is a Dirac comb but with reciprocal increments.\n\nSimilarly:\n\nWe can also prove that holds in the sense that if formula_22, then the right-hand side is the (possibly divergent) Fourier series of the left-hand side. This proof may be found in either or . It follows from the dominated convergence theorem that formula_23 exists and is finite for almost every formula_24. And furthermore it follows that formula_25 is integrable on the interval formula_26. The right-hand side of has the form of a Fourier series. So it is sufficient to show that the Fourier series coefficients of formula_23 are formula_28. Proceeding from the definition of the Fourier coefficients we have:\n\nThe Poisson summation formula can also be proved quite conceptually using the compatibility of Pontryagin duality with short exact sequences such as\n\n holds provided formula_10 is a continuous integrable function which satisfies\nfor some formula_35 and every formula_24 (; ). Note that such formula_10 is uniformly continuous, this together with the decay assumption on formula_38, show that the series defining formula_25 converges uniformly to a continuous function.   holds in the strong sense that both sides converge uniformly and absolutely to the same limit .\n\nThe Fourier series on the right-hand side of is then understood as a (conditionally convergent) limit of symmetric partial sums.\n\nAs shown above, holds under the much less restrictive assumption that formula_10 is in formula_43, but then it is necessary to interpret it in the sense that the right-hand side is the (possibly divergent) Fourier series of formula_23 . In this case, one may extend the region where equality holds by considering summability methods such as Cesàro summability. When interpreting convergence in this way holds under the less restrictive conditions that formula_45 is integrable and 0 is a point of continuity of formula_46. However may fail to hold even when both formula_47 and formula_48 are integrable and continuous, and the sums converge absolutely .\n\nIn partial differential equations, the Poisson summation formula provides a rigorous justification for the fundamental solution of the heat equation with absorbing rectangular boundary by the method of images. Here the heat kernel on formula_49 is known, and that of a rectangle is determined by taking the periodization. The Poisson summation formula similarly provides a connection between Fourier analysis on Euclidean spaces and on the tori of the corresponding dimensions . In one dimension, the resulting solution is called a theta function.\n\nIn the statistical study of time-series, if formula_50 is a function of time, then looking only at its values at equally spaced points of time is called \"sampling.\" In applications, typically the function formula_50 is band-limited, meaning that there is some cutoff frequency formula_52 such that the Fourier transform is zero for frequencies exceeding the cutoff: formula_53 for formula_54. For band-limited functions, choosing the sampling rate formula_55 guarantees that no information is lost: since formula_56 can be reconstructed from these sampled values, then, by Fourier inversion, so can formula_50. This leads to the Nyquist–Shannon sampling theorem .\n\nComputationally, the Poisson summation formula is useful since a slowly converging summation in real space is guaranteed to be converted into a quickly converging equivalent summation in Fourier space. (A broad function in real space becomes a narrow function in Fourier space and vice versa.) This is the essential idea behind Ewald summation.\n\nThe Poisson summation formula may be used to derive Landau's asymptotic formula for the number of lattice points in a large Euclidean sphere. It can also be used to show that if an integrable function, formula_2 and formula_59 both have compact support then formula_60  .\n\nIn number theory, Poisson summation can also be used to derive a variety of functional equations including the functional equation for the Riemann zeta function.\n\nOne important such use of Poisson summation concerns theta functions: periodic summations of Gaussians . Put formula_61, for formula_62 a complex number in the upper half plane, and define the theta function:\n\nformula_63\n\nThe relation between formula_64 and formula_65 turns out to be important for number theory, since this kind of relation is one of the defining properties of a modular form. By choosing formula_66 in the second version of the Poisson summation formula (with formula_67), and using the fact that formula_68, one gets immediately\n\nformula_69\n\nby putting formula_70.\n\nIt follows from this that formula_71 has a simple transformation property under formula_72 and this can be used to prove Jacobi's formula for the number of different ways to express an integer as the sum of eight perfect squares.\n\n proved an upper bound on the density of sphere packings using the Poisson summation formula, which subsequently led to a proof of optimal sphere packings in dimension 8 and 24.\n\nThe Poisson summation formula holds in Euclidean space of arbitrary dimension. Let formula_73 be the lattice in formula_74 consisting of points with integer coordinates; formula_73 is the character group, or Pontryagin dual, of formula_74. For a function formula_2 in formula_78, consider the series given by summing the translates of formula_2 by elements of formula_73:\n\nTheorem For formula_2 in formula_78, the above series converges pointwise almost everywhere, and thus defines a periodic function Pƒ on formula_73. Pƒ lies in formula_85 with ||Pƒ|| ≤ ||ƒ||. Moreover, for all formula_86 in formula_73, Pƒ̂(ν) (Fourier transform on formula_73) equals formula_89 (Fourier transform on formula_74).\n\nWhen formula_2 is in addition continuous, and both formula_2 and formula_93 decay sufficiently fast at infinity, then one can \"invert\" the domain back to formula_74 and make a stronger statement. More precisely, if\n\nfor some \"C\", δ > 0, then\n\nwhere both series converge absolutely and uniformly on Λ. When \"d\" = 1 and \"x\" = 0, this gives the formula given in the first section above.\n\nMore generally, a version of the statement holds if Λ is replaced by a more general lattice in formula_74. The \"dual lattice\" Λ′ can be defined as a subset of the dual vector space or alternatively by Pontryagin duality. Then the statement is that the sum of delta-functions at each point of Λ, and at each point of Λ′, are again Fourier transforms as distributions, subject to correct normalization.\n\nThis is applied in the theory of theta functions, and is a possible method in geometry of numbers. In fact in more recent work on counting lattice points in regions it is routinely used − summing the indicator function of a region \"D\" over lattice points is exactly the question, so that the LHS of the summation formula is what is sought and the RHS something that can be attacked by mathematical analysis.\n\nFurther generalisation to locally compact abelian groups is required in number theory. In non-commutative harmonic analysis, the idea is taken even further in the Selberg trace formula, but takes on a much deeper character.\n\nA series of mathematicians applying harmonic analysis to number theory, most notably Martin Eichler, Atle Selberg, Robert Langlands, and James Arthur, have generalised the Poisson summation formula to the Fourier transform on non-commutative locally compact reductive algebraic groups formula_98 with a discrete subgroup formula_99 such that formula_100 has finite volume. For example, formula_98 can be the real points of formula_102 and formula_99 can be the integral points of formula_102. In this setting, formula_98 plays the role of the real number line in the classical version of Poisson summation, and formula_99 plays the role of the integers formula_107 that appear in the sum. The generalised version of Poisson summation is called the Selberg Trace Formula, and has played a role in proving many cases of Artin's conjecture and in Wiles's proof of Fermat's Last Theorem. The left-hand side of (1) becomes a sum over irreducible unitary representations of formula_98, and is called \"the spectral side,\" while the right-hand side becomes a sum over conjugacy classes of formula_99, and is called \"the geometric side.\"\n\nThe Poisson summation formula is the archetype for vast developments in harmonic analysis and number theory.\n\n\n"}
{"id": "381013", "url": "https://en.wikipedia.org/wiki?curid=381013", "title": "Support (mathematics)", "text": "Support (mathematics)\n\nIn mathematics, the support of a real-valued function \"f\" is the subset of the domain containing those elements which are not mapped to zero. If the domain of \"f\" is a topological space, the support of \"f\" is instead defined as the smallest \"closed\" set containing all points not mapped to zero. This concept is used very widely in mathematical analysis.\n\nSuppose that \"f\" : \"X\" → R is a real-valued function whose domain is an arbitrary set \"X\". The set-theoretic support of \"f\", written supp(\"f\"), is the set of points in \"X\" where \"f\" is non-zero\n\nThe support of \"f\" is the smallest subset of \"X\" with the property that \"f\" is zero on the subset's complement. If \"f\"(\"x\") = 0 for all but a finite number of points \"x\" in \"X\", then \"f\" is said to have finite support.\nIf the set \"X\" has an additional structure (for example, a topology), then the support of \"f\" is defined in an analogous way as the smallest subset of \"X\" of an appropriate type such that \"f\" vanishes in an appropriate sense on its complement. The notion of support also extends in a natural way to functions taking values in more general sets than R and to other objects, such as measures or distributions.\n\nThe most common situation occurs when \"X\" is a topological space (such as the real line or \"n\"-dimensional Euclidean space) and \"f\" : \"X\" → R is a continuous real (or complex)-valued function. In this case, the support of \"f\" is defined topologically as the closure of the subset of \"X\" where \"f\" is non-zero i.e.,\n\nSince the intersection of closed sets is closed, supp(\"f\") is the intersection of all closed sets that contain the set-theoretic support of \"f\".\n\nFor example, if \"f\" : R → R is the function defined by\n\nthen the support of \"f\" is the closed interval [−1,1], since \"f\" is non-zero on the open interval (−1,1) and the closure of this set is [−1,1].\n\nThe notion of closed support is usually applied to continuous functions, but the definition makes sense for arbitrary real or complex-valued functions on a topological space, and some authors do not require that \"f\" : \"X\" → R (or C) be continuous.\n\nFunctions with compact support on a topological space formula_4 are those whose closed support is a compact subset of formula_4. If formula_4 is the real line, or formula_7-dimensional Euclidean space, then a function has compact support if and only if it has bounded support, since a subset of formula_8 is compact if and only if it is closed and bounded.\n\nFor example, the function formula_9 defined above is a continuous function with compact support [−1, 1].\n\nThe condition of compact support is stronger than the condition of vanishing at infinity. For example, the function formula_9 defined by\n\nvanishes at infinity, since formula_12 as formula_13, but its support formula_14 is not compact.\n\nReal-valued compactly supported smooth functions on a Euclidean space are called bump functions. Mollifiers are an important special case of bump functions as they can be used in distribution theory to create sequences of smooth functions approximating nonsmooth (generalized) functions, via convolution.\n\nIn good cases, functions with compact support are dense in the space of functions that vanish at infinity, but this property requires some technical work to justify in a given example. As an intuition for more complex examples, and in the language of limits, for any formula_15, any function formula_16 on the real line formula_14 that vanishes at infinity can be approximated by choosing an appropriate compact subset formula_18 of formula_14 such that\n\nfor all formula_21, where formula_22 is the indicator function of formula_18. Every continuous function on a compact topological space has compact support since every closed subset of a compact space is indeed compact.\n\nIf \"X\" is a topological measure space with a Borel measure μ (such as R, or a Lebesgue measurable subset of R, equipped with Lebesgue measure), then one typically identifies functions that are equal μ-almost everywhere. In that case, the essential support of a measurable function \"f\" : \"X\" → R, written ess supp(\"f\"), is defined to be the smallest closed subset \"F\" of \"X\" such that \"f\" = 0 μ-almost everywhere outside \"F\". Equivalently, ess supp(f) is the complement of the largest open set on which \"f\" = 0 \"μ\"-almost everywhere\n\nThe essential support of a function \"f\" depends on the measure μ as well as on \"f\", and it may be strictly smaller than the closed support. For example, if \"f\" : [0,1] → R is the Dirichlet function that is 0 on irrational numbers and 1 on rational numbers, and [0,1] is equipped with Lebesgue measure, then the support of \"f\" is the entire interval [0,1], but the essential support of \"f\" is empty, since \"f\" is equal almost everywhere to the zero function.\n\nIn analysis one nearly always wants to use the essential support of a function, rather than its closed support, when the two sets are different, so ess supp(\"f\") is often written simply as supp(\"f\") and referred to as the support.\n\nIf \"M\" is an arbitrary set containing zero, the concept of support is immediately generalizable to functions \"f\" : \"X\"→\"M\". Support may also be defined for any algebraic structure with identity (such as a group, monoid, or composition algebra), in which the identity element assumes the role of zero. For instance, the family Z of functions from the natural numbers to the integers is the uncountable set of integer sequences. The subfamily { \"f\"  in Z :\"f\"  has finite support } is the countable set of all integer sequences that have only finitely many nonzero entries.\n\nFunctions of finite support are used in defining algebraic structures such as group rings and free abelian groups.\n\nIn probability theory, the support of a probability distribution can be loosely thought of as the closure of the set of possible values of a random variable having that distribution. There are, however, some subtleties to consider when dealing with general distributions defined on a sigma algebra, rather than on a topological space.\n\nMore formally, if formula_25 is a random variable on formula_26 then the support of formula_4 is the smallest closed set formula_28 such that formula_29.\n\nIn practice, support of a discrete random variable formula_4 is often defined as the set formula_31.\nAnd support of a continuous random variable formula_4 is defined as the set formula_33 where formula_34 is a probability density function of formula_4. \n\nNote that the word \"support\" can refer to the logarithm of the likelihood of a probability density function.\n\nIt is possible also to talk about the support of a distribution, such as the Dirac delta function δ(\"x\") on the real line. In that example, we can consider test functions \"F\", which are smooth functions with support not including the point 0. Since δ(\"F\") (the distribution δ applied as linear functional to \"F\") is 0 for such functions, we can say that the support of δ is {0} only. Since measures (including probability measures) on the real line are special cases of distributions, we can also speak of the support of a measure in the same way.\n\nSuppose that \"f\" is a distribution, and that \"U\" is an open set in Euclidean space such that, for all test functions formula_36 such that the support of formula_36 is contained in \"U\", formula_38. Then \"f\" is said to vanish on \"U\". Now, if \"f\" vanishes on an arbitrary family formula_39 of open sets, then for any test function formula_36 supported in formula_41, a simple argument based on the compactness of the support of formula_36 and a partition of unity shows that formula_38 as well. Hence we can define the \"support\" of \"f\" as the complement of the largest open set on which \"f\" vanishes. For example, the support of the Dirac delta is formula_44.\n\nIn Fourier analysis in particular, it is interesting to study the singular support of a distribution. This has the intuitive interpretation as the set of points at which a distribution \"fails to be a smooth function\".\n\nFor example, the Fourier transform of the Heaviside step function can, up to constant factors, be considered to be 1/\"x\" (a function) \"except\" at \"x\" = 0. While \"x\" = 0 is clearly a special point, it is more precise to say that the transform of the distribution has singular support {0}: it cannot accurately be expressed as a function in relation to test functions with support including 0. It \"can\" be expressed as an application of a Cauchy principal value \"improper\" integral.\n\nFor distributions in several variables, singular supports allow one to define \"wave front sets\" and understand Huygens' principle in terms of mathematical analysis. Singular supports may also be used to understand phenomena special to distribution theory, such as attempts to 'multiply' distributions (squaring the Dirac delta function fails – essentially because the singular supports of the distributions to be multiplied should be disjoint).\n\nAn abstract notion of family of supports on a topological space \"X\", suitable for sheaf theory, was defined by Henri Cartan. In extending Poincaré duality to manifolds that are not compact, the 'compact support' idea enters naturally on one side of the duality; see for example Alexander–Spanier cohomology.\n\nBredon, \"Sheaf Theory\" (2nd edition, 1997) gives these definitions. A family Φ of closed subsets of \"X\" is a \"family of supports\", if it is down-closed and closed under finite union. Its \"extent\" is the union over Φ. A \"paracompactifying\" family of supports that satisfies further that any \"Y\" in Φ is, with the subspace topology, a paracompact space; and has some \"Z\" in Φ which is a neighbourhood. If \"X\" is a locally compact space, assumed Hausdorff the family of all compact subsets satisfies the further conditions, making it paracompactifying.\n\n"}
{"id": "40705460", "url": "https://en.wikipedia.org/wiki?curid=40705460", "title": "Tonti diagram", "text": "Tonti diagram\n\nThe Tonti diagram, created by the Italian physicist and mathematician Enzo Tonti, is a diagram that classifies variables and equations of physical theories of classical and relativistic physics. The theories involved are: \"particle dynamics, analytical mechanics, mechanics of deformable solids, fluid mechanics, electromagnetism, gravitation, heat conduction,\" and \"irreversible thermodynamics\". The classification stems from the observation that each physical variable has a well-defined association with a space and a time element, as shown in Fig. 1, which can be grasped from the corresponding global variable and from its measuring process.\n\nThe starting point of this classification stems from a remark by Maxwell. Speaking about analogies in different physical theories, Maxwell wrote in 1871:\n\nOf the factors which compose it [energy], one is referred to unit of length, and the other to unit of area. This gives what I regard as a very important distinction among vector quantities.\n\nThis remark leads us to a distinction between vectors referred to lines and vectors referred to surfaces. This is not customarily considered in vector calculus or in physics. In electromagnetism, hence, vectors E and H are associated with lines, and vectors D and B are associated with surfaces. This distinction leads to a classification of physical variables based on their \"association\" with space elements. \nMaxwell continues:\n\nIt is only through the progress of science in recent times that we have become acquainted with so large a number of physical quantities that a classification of them is desirable. [...] But the classification which I now refer to is founded on the mathematical or formal analogy of the different quantities, and not on the matter to which they belong.\n\nThe classification diagram arises from an analysis of the \"association\" of physical variables in different physical theories, whatever their mathematical nature, i.e. scalars, vectors, tensors, etc., with space and time elements.\n\nPhysics, compared to other natural sciences, has the great privilege of considering the quantitative attributes of physical systems and from these originate the physical quantities, which can be scalars, vectors, tensors, etc. Physical quantities can be divided into three main categories: physical variables, physical parameters and fundamental constants.\n\nThe term space-global variables refers to all physical variables that are not densities of other variables. Distinguishing between global variables and corresponding densities is essential. Mass density is given by the ratio of mass to volume, mass being the \"global\" variable. Pressure is the ratio of the normal force on an element of plane surface to the surface area, therefore the normal force is the \"global\" variable and the pressure is its surface density. The strain of a bar is the ratio of the elongation to its original length, elongation being the \"global\" variable and strain the line density.\nThe very fact that we create volume, surface or line densities highlights that the corresponding global variables are \"associated\" with volumes, surfaces and lines.\nEvery density is obtained by dividing a global variable by the extension of the \"associated\" space element. The mathematical treatment of physics also customarily considers the limit of this ratio to obtain a pointwise density, i.e. a field variable. Generally, field variables are preferred to global variables, to the extent that we express the global variables as integrals of the respective field variables, and call them integral variables.\nIntegral variables are global variables, but there are also global variables which are \"associated\" with points, and which, therefore, cannot be considered integral variables. Hence, global variables form a broader class compared to integral variables; for which reason, in view of the classification, the use of the term “global variables” is preferred to that of \"integral variables\".\n\nThe term time-global variables is used to indicate variables that are not rates of other variables. Displacement, impulse, momentum and position vector are therefore global variables. Displacement and impulse are associated with time intervals, while momentum and position vector are associated with instants. This is evident if we think that we can perform the rates of the first two variables obtaining velocity and force respectively, while we cannot perform the rates of the last two variables.\n\nThe physical variables, both global variables and densities, in turn, can be divided into three classes: those characterising the \"configuration\" of a system or a field, those describing the \"source\" of a phenomenon or a field, and finally \"energy\" variables. Every physical system, even a field, has its own “configuration”, and the variables describing this configuration are called configuration variables. Each field has its sources (for example, electric charges are the source of electric fields, heat generators are the source of thermal fields and forces are the source of motion and deformation): variables describing sources are called source variables. The third category, that of energy variables, is created by multiplying a configuration variable by a source variable.\nThe fundamental problem of a field is finding the configuration of the field at every time instant, given the spatial distribution and the intensity of its sources (which is to say: given the causes, determine the effects).\n\nBy the term \"space elements\" we intend points, lines, surfaces and volumes, which are denoted P,L,S and V respectively.\nBy the term \"time elements\" we intend time instants and time intervals, which are denoted I and T respectively.\nSpace elements are naturally classified according to their dimension, from the smallest to the biggest, i.e. points, lines, surfaces and volumes. The same classification applies to time elements, i.e. instants and intervals.\n\nAll fluxes (e.g. magnetic flux, electric flux, vortex flux) make reference to a surface (S), all variables expressed by a line integral (e.g. electromotive force, velocity circulation, magnetomotive force) make reference to a line (L) and all contents (e.g. of energy, mass, entropy, etc.) make reference to a volume (V). Lastly all potentials (e.g. electric potential, velocity potential, temperature) make reference to a point (P).\n\nA similar association exists between time-global variables and time elements. Therefore, a displacement is \"associated\" with a time interval (T), whereas a position vector is \"associated\" with a time instant (I). In this association the measuring process must be taken into account, because temperature is \"referred\" to an instant but its measurement involves a time interval - the one needed to reach thermal equilibrium. Therefore, the temperature is said to be \"associated\" with a time interval (T). Similarly, the measurement of a force requires a mechanical equilibrium to be reached, hence it is \"associated\" with a time interval (T).\n\nSince in each field of physics the global variables are \"associated\" with a space and a time element, the association of the corresponding densities and the rates with the space and time element of the corresponding global variable is spontaneous. The densities and the rates are said to \"inherit\" the association from their corresponding global variables. The same inherited association remains once we have performed the limit to obtain the field variables.\n\nIn this classification, the orientation of the space elements has a fundamental role. There are two kinds of orientation: inner and outer orientation, as shown in Fig. 2.\n\nThere is a surprising correspondence between the role that a physical variable plays in a theory and the type of orientation of the corresponding space element: a detailed analysis of physical variables shows that \"the configuration variables are associated with the space elements endowed with inner orientation while the source and the energy variables are associated with the outer orientation.\"\n\nTo highlight the four space elements, it is expedient to divide a region of space into many cells, thus creating a cell complex. The vertices represent points, the edges lines, the faces surfaces and the cells themselves volumes.\nEach of these elements can be given an inner orientation. Since we also need space elements with outer orientation, it is expedient to consider the dual complex, obtained by joining the centroids of the cells belonging to the primal complex. Doing so, we see that the inner orientation of each element of the primal complex induces an outer orientation on the corresponding element of the dual complex.\n\nFigures 3 and 4 show how the space elements of the primal complex, which are endowed with inner orientation, induce an outer orientation on the elements of the dual complex. Moreover, the space elements of the two complexes can be arranged in a diagram such as the one shown on the right-hand side of the figures.\n\nA cell complex and its dual constitute a valid framework to describe the association of physical variables with the oriented space elements. To be precise, the configuration variables, which are associated with space elements with inner orientation, may be associated with the elements of the primal complex, while the source variables, which are associated with the space elements with an outer orientation, can be associated with the elements of the dual complex.\n\nAt first glance, the notions of inner and outer orientation of a time element may appear strange, certainly unusual. Let us consider a subdivision of the time axis into many adjacent time intervals. Doing so, we have constructed a one-dimensional cell complex in time. \nConsidering now the middle instants of each time interval we have a second cell complex in time. The first complex is called \"primal\" and the second \"dual\".\nPrimal complex, inner orientation: the fact that the time axis is oriented implies that each time interval is oriented: this is the inner orientation of the primal time intervals.\nSince the variation of a time function φ (t) is defined as Δφ = + φ (t + h)-φ (t), in order to conceive the \"+\" and \"-\" signs of this formula as incidence numbers between a time interval and its bounding instants, these should be considered as \"sinks\".\n\nDual complex, outer orientation: the middle instant of each time interval is called \"dual time instant\" and we can give it the same orientation of the primal time interval. This is called \"outer\" orientation of the dual time instant. In turn, the time intervals connecting two adjacent dual time instants are called \"dual time intervals\". Once more we can assign them the orientation induced by the primal time instants, as shown in Fig. 5. This is called \"outer\" orientation of the dual time intervals.\n\nThe fact that physical variables are associated with space and time elements endowed with inner or outer orientation and that space and time elements of a primal and a dual cell complex can be classified as shown on the right-hand side of Figs. 3 and 4, suggests a corresponding classification of physical variables. \nLet us consider, as an example, the classification diagram of electrostatics, shown in Fig. 6. The left column includes those physical variables associated with the primal cell complex, whose elements are endowed with inner orientation: these are the \"configuration\" variables. The right column includes those physical variables associated with the dual cell complex, whose elements are endowed with outer orientation: these are the \"source\" variables.\n\nThe equations linking the variables are contained in the rectangular boxes. The equations in each vertical column are \"balance\" equations, \"circuital\" equations and \"gradient-forming\" equations. They have a topological structure and are called topological equations. Those that link configuration variables to source variables—contained in the horizontal links—are \"material\" or \"constitutive\" equations, and belong to the category of phenomenological equations.\n\nParticle dynamics, analytical mechanics and electric networks make use of space-global variables that depend only on the time variable. Referring here to particle dynamics, we see that configuration variables are geometrical and kinematic variables, while source variables are static and dynamic variables. In Fig. 7 we see that kinematic variables lie in the left column while dynamic variables lie in the right one. The diagram shows three phenomenological equations: those connecting two variables on the same level describe a reversible relation (i.e. a non-dissipative relation), while those linking force with velocity describe an irreversible relation (i.e. a dissipative relation). The dissipative nature is shown by the fact that one variable, velocity, changes sign under reversal of motion, while the other, force, does not.\n\nSince every global physical variable is associated with both a time and a space element, it appears useful to have a classification diagram combining space and time elements. \nWhen the four space elements P, L, S and V are coupled with the two time elements I and T we obtain eight possible combinations. Furthermore, if one considers that each space element and each time element can be endowed with two orientations, inner and outer, we must combine the 4x2 oriented space elements with the 2x2 oriented time elements, thus obtaining 32 possible space-time combinations. Fig. 8 shows the two possible classification diagrams of the space-time elements.\nThe first version associates the space elements endowed with inner orientation with the time elements endowed with inner orientation and vice versa: it is the case of mechanics in all its manifestations, such as particle and analytical mechanics, mechanics of deformable solids and fluid mechanics. The second version associates the space elements endowed with inner orientation with the time elements endowed with outer orientation and vice versa. It is the case of field theories such as electromagnetism, gravitation, thermal conduction and irreversible thermodynamics.\n\nThe space-time diagrams show clearly which phenomenological equations describe irreversible phenomena: they are the ones that link variables that are on the same level but connect a box on the front-left side with a box on the back-right side.\n\n\nDiscrete Physics\n\nChronological Tables of famous people\n\nResearch gate\n"}
{"id": "401631", "url": "https://en.wikipedia.org/wiki?curid=401631", "title": "Ulisse Dini", "text": "Ulisse Dini\n\nUlisse Dini (14 November 1845 – 28 October 1918) was an Italian mathematician and politician, born in Pisa. He is known for his contribution to real analysis, partly collected in his book \"Fondamenti per la teorica delle funzioni di variabili reali\".\n\nDini attended the Scuola Normale Superiore in order to become a teacher. One of his professors was Enrico Betti. In 1865, a scholarship enabled him to visit Paris, where he studied under Charles Hermite as well as Joseph Bertrand, and published several papers. In 1866, he was appointed to the University of Pisa, where he taught algebra and geodesy. In 1871, he succeeded Betti as professor for analysis and geometry. From 1888 until 1890, Dini was \"rettore\" of the Pisa University, and of the \"Scuola Normale Superiore\" from 1908 until his death in 1918.\n\nHe was also active as a politician: in 1871 he was voted into the Pisa city council, and in 1880, he became a member of the Italian parliament.\n\nHe has been elected honorary member of the London Mathematical Society.\n\nDini worked in the field of mathematical analysis during a time when it was begun to be based on rigorous foundations. In addition to his books, he wrote about sixty papers.\n\nHe proved the Dini criterion for the convergence of Fourier series and investigated the potential theory and differential geometry of surfaces, based on work by Eugenio Beltrami.\n\nHis work on the theory of real functions was also important in the development of the concept of the measure on a set.\nThe implicit function theorem is known in Italy as the Dini's theorem.\n\nOne of his students was Luigi Bianchi.\n\n\n\n\n\n"}
{"id": "8337525", "url": "https://en.wikipedia.org/wiki?curid=8337525", "title": "Watts–Strogatz model", "text": "Watts–Strogatz model\n\nThe Watts–Strogatz model is a random graph generation model that produces graphs with small-world properties, including short average path lengths and high clustering. It was proposed by Duncan J. Watts and Steven Strogatz in their joint 1998 Nature paper. The model also became known as the (Watts) \"beta\" model after Watts used formula_1 to formulate it in his popular science book \"\".\n\nThe formal study of random graphs dates back to the work of Paul Erdős and Alfréd Rényi. The graphs they considered, now known as the classical or Erdős–Rényi (ER) graphs, offer a simple and powerful model with many applications.\n\nHowever the ER graphs do not have two important properties observed in many real-world networks:\n\nThe Watts and Strogatz model was designed as the simplest possible model that addresses the first of the two limitations. It accounts for clustering while retaining the short average path lengths of the ER model. It does so by interpolating between a randomized structure close to ER graphs and a regular ring lattice. Consequently, the model is able to at least partially explain the \"small-world\" phenomena in a variety of networks, such as the power grid, neural network of C. elegans, networks of movie actors, or fat-metabolism communication in budding yeast.\n\nGiven the desired number of nodes formula_2, the mean degree formula_3 (assumed to be an even integer), and a special parameter formula_1, satisfying formula_5 and formula_6, the model constructs an undirected graph with formula_2 nodes and formula_8 edges in the following way:\n\n\nThe underlying lattice structure of the model produces a locally clustered network, while the randomly rewired links dramatically reduce the average path lengths. The algorithm introduces about formula_27 of such non-lattice edges. Varying formula_1 makes it possible to interpolate between a regular lattice (formula_29) and a structure close to an Erdős–Rényi random graph formula_30 with formula_31 at formula_32. It does not approach the actual ER model since every node will be connected to at least formula_33 other nodes.\n\nThe three properties of interest are the average path length, the clustering coefficient, and the degree distribution.\n\nFor a ring lattice, the average path length is formula_34 and scales linearly with the system size. In the limiting case of formula_35, the graph approaches a random graph with formula_36, while not actually converging to it. In the intermediate region formula_37, the average path length falls very rapidly with increasing formula_1, quickly approaching its limiting value.\n\nFor the ring lattice the clustering coefficient formula_39, and so tends to formula_40 as formula_3 grows, independently of the system size. In the limiting case of formula_35 the clustering coefficient is of the same order as the clustering coefficient for classical random graphs, formula_43 and is thus inversely proportional to the system size. In the intermediate region the clustering coefficient remains quite close to its value for the regular lattice, and only falls at relatively high formula_1. This results in a region where the average path length falls rapidly, but the clustering coefficient does not, explaining the \"small-world\" phenomenon.\n\nThe degree distribution in the case of the ring lattice is just a Dirac delta function centered at formula_3. The degree distribution for formula_37 can be written as,\n\nwhere formula_51 is the number of edges that the formula_52 node has or its degree. Here formula_53, and formula_54. The shape of the degree distribution is similar to that of a random graph and has a pronounced peak at formula_55 and decays exponentially for large formula_56. The topology of the network is relatively homogeneous, meaning that all nodes are of similar degree.\n\nThe major limitation of the model is that it produces an unrealistic degree distribution. In contrast, real networks are often scale-free networks inhomogeneous in degree, having hubs and a scale-free degree distribution. Such networks are better described in that respect by the preferential attachment family of models, such as the Barabási–Albert (BA) model. (On the other hand, the Barabási–Albert model fails to produce the high levels of clustering seen in real networks, a shortcoming not shared by the Watts and Strogatz model. Thus, neither the Watts and Strogatz model nor the Barabási–Albert model should be viewed as fully realistic.)\n\nThe Watts and Strogatz model also implies a fixed number of nodes and thus cannot be used to model network growth.\n\n"}
{"id": "634240", "url": "https://en.wikipedia.org/wiki?curid=634240", "title": "Wheel theory", "text": "Wheel theory\n\nWheels are a type of algebra where division is always defined. In particular, division by zero is meaningful. The real numbers can be extended to a wheel, as can any commutative ring.\n\nThe Riemann sphere can also be extended to a wheel by adjoining an element formula_1, where formula_2. The Riemann sphere is an extension of the complex plane by an element formula_3, where formula_4 for any complex formula_5. However, formula_6 is still undefined on the Riemann sphere, but is defined in its extension to a wheel.\n\nThe term \"wheel\" is inspired by the topological picture formula_7 of the projective line together with an extra point formula_8.\n\nA wheel is an algebraic structure formula_9, satisfying:\n\n\nWheels replace the usual division as a binary operator with multiplication, with a unary operator applied to one argument formula_20 similar (but not identical) to the multiplicative inverse formula_21, such that formula_22 becomes shorthand for formula_23, and modifies the rules of algebra such that\n\n\nIf there is an element formula_29 such that formula_30, then we may define negation by formula_31 and formula_32.\n\nOther identities that may be derived are\n\nAnd, for formula_28 with formula_37 and formula_38, we get the usual\n\nIf negation can be defined as above then the subset formula_41 is a commutative ring, and every commutative ring is such a subset of a wheel. If formula_28 is an invertible element of the commutative ring, then formula_43. Thus, whenever formula_21 makes sense, it is equal to formula_20, but the latter is always defined, even when formula_46.\n\nLet formula_47 be a commutative ring, and let formula_48 be a multiplicative submonoid of formula_47. Define the congruence relation formula_50 on formula_51 via\nDefine the wheel of fractions of formula_47 with respect to formula_48 as the quotient formula_57 (and denoting the equivalence class containing formula_58 as formula_59) with the operations\n\n"}
{"id": "4277086", "url": "https://en.wikipedia.org/wiki?curid=4277086", "title": "Wigner–Weyl transform", "text": "Wigner–Weyl transform\n\nIn quantum mechanics, the Wigner–Weyl transform or Weyl–Wigner transform (after Hermann Weyl and Eugene Wigner) is the invertible mapping between functions in the quantum phase space formulation and Hilbert space operators in the Schrödinger picture.\n\nOften the mapping from functions on phase space to operators is called the Weyl transform or Weyl quantization, whereas the inverse mapping, from operators to functions on phase space, is called the Wigner transform. This mapping was originally devised by Hermann Weyl in 1927 in an attempt to map symmetrized \"classical\" phase space functions to operators, a procedure known as \"Weyl quantization\". It is now understood that Weyl quantization does not satisfy all the properties one would require for quantization and therefore sometimes yields unphysical answers. On the other hand, some of the nice properties described below suggest that if one seeks a single consistent quantization procedure mapping functions on the classical phase space to operators, the Weyl quantization is the best option. (Groenewold's theorem says that no such map can have all the properties one would ideally like.)\n\nRegardless, the Weyl-Wigner transform is a well-defined integral transform between the phase-space and operator representations, and yields insight into the workings of quantum mechanics. Most importantly, the Wigner quasi-probability distribution is the Wigner transform of the quantum density matrix, and, conversely, the density matrix is the Weyl transform of the Wigner function. \nIn contrast to Weyl's original intentions in seeking a consistent quantization scheme, this map merely amounts to a change of representation within quantum mechanics; it need not connect \"classical\" with \"quantum\" quantities. For example, the phase-space function may depend explicitly on Planck's constant ħ, as it does in some familiar cases involving angular momentum. This invertible representation change then allows one to express quantum mechanics in phase space, as was appreciated in the 1940s by Hilbrand J. Groenewold and José Enrique Moyal.\n\nThe following explains the Weyl transformation on the simplest, two-dimensional Euclidean phase space. Let the coordinates on phase space be , and let be a function defined everywhere on phase space. In what follows, we fix operators \"P\" and \"Q\" satisfying the canonical commutation relations, such as the usual position and momentum operators in the Schrödinger representation. We assume that the exponentiated operators formula_1 and formula_2 constitute an irreducible representation of the Weyl relations, so that the Stone–von Neumann theorem (guaranteeing uniqueness of the canonical commutation relations) holds. \n\nThe Weyl transform (or Weyl quantization) of the function is given by the following operator in Hilbert space,\n\nHere formula_3 is the reduced Planck constant. \n\nIt is instructive to perform the \"p\" and \"q\" integrals in the above formula first, which has the effect of computing the ordinary Fourier transform formula_4 of the function formula_5, while leaving the operator formula_6. In that case, the Weyl transform can be written as\n\nWe may therefore think of the Weyl map as follows: We take the ordinary Fourier transform of the function formula_8, but then when applying the Fourier inversion formula, we substitute the quantum operators formula_9 and formula_10 for the original classical variables formula_11 and formula_12, thus obtaining a \"quantum version of formula_5.\"\n\nA less symmetric form, but handy for applications, is the following,\nThe Weyl map may then also be expressed in terms of the integral kernel matrix elements of this operator,\n\nThe inverse of the above Weyl map is the Wigner map, which takes the operator back to the original phase-space kernel function , \nIf one replaces formula_16 in the above expression with an arbitrary operator, the resulting function may depend on Planck's constant , and may well describe quantum-mechanical processes, provided it is properly composed through the star product, below.\n\nWhile the above formulas give a nice understanding of the Weyl quantization of a very general observable on phase space, they are not very convenient for computing on simple observables, such as those that are polynomials in formula_12 and formula_11. In later sections, we will see that on such polynomials, the Weyl quantization represents the totally symmetric ordering of the noncommuting operators formula_10 and formula_9.\nFor example, the Wigner map of the quantum angular-momentum-squared operator L is not just the classical angular momentum squared, but it further contains an offset term , which accounts for the nonvanishing angular momentum of the ground-state Bohr orbit.\n\nThe action of the Weyl quantization on polynomial functions of formula_12 and formula_11 is completely determined by the following symmetric formula:\nfor all real numbers formula_24 and formula_25. From this formula, it is not hard to show that the Weyl quantization on a function of the form formula_26 gives the average of all possible orderings of formula_27 factors of formula_10 and formula_29 factors of formula_9. \nFor example, we have\nWhile this result is conceptually natural, it is not convenient for computations when formula_27 and formula_29 are large. In such cases, we can use instead McCoy's formula\nThis expression gives an apparently different answer for the case of formula_35 from the totally symmetric expression above. There is no contradiction, however, since the canonical commutation relations allow for more than one expression for the same operator. (The reader may find it instructive to use the commutation relations to rewrite the totally symmetric formula for the case of formula_36 in terms of the operators formula_37, formula_38, and formula_39 and verify the first expression in McCoy's formula with formula_40.)\n\nIt is widely thought that the Weyl quantization, among all quantization schemes, comes as close as possible to mapping the Poisson bracket on the classical side to the commutator on the quantum side. (An exact correspondence is impossible, in light of Groenewold's theorem.) For example,\n\n\nIntuitively, a deformation of a mathematical object is a family of the same kind of objects that depend on some parameter(s). \nHere, it provides rules for how to deform the \"classical\" commutative algebra of observables to a quantum non-commutative algebra of observables.\n\nThe basic setup in deformation theory is to start with an algebraic structure (say a Lie algebra) and ask: Does there exist a one or more parameter(s) family of \"similar\" structures, such that for an initial value of the parameter(s) one has the same structure (Lie algebra) one started with? (The oldest illustration of this may be the realization of Eratosthenes in the ancient world that a flat earth was deformable to a spherical earth, with deformation parameter 1/\"R\".) E.g., one may define a noncommutative torus as a deformation quantization through a -product to implicitly address all convergence subtleties (usually not addressed in formal deformation quantization). Insofar as the algebra of functions on a space determines the geometry of that space, the study of the star product leads to the study of a non-commutative geometry deformation of that space.\n\nIn the context of the above flat phase-space example, the star product (Moyal product, actually introduced by Groenewold in 1946), , of a pair of functions in , is specified by\n\nThe star product is not commutative in general, but goes over to the ordinary commutative product of functions in the limit of . As such, it is said to define a deformation of the commutative algebra of .\n\nFor the Weyl-map example above, the -product may be written in terms of the Poisson bracket as\n\nHere, Π is the Poisson bivector, an operator defined such that its powers are\nand\nwhere {\"f\", \"f\"} is the Poisson bracket. More generally,\nwhere formula_49 is the binomial coefficient.\n\nThus, e.g., Gaussians compose hyperbolically,\nor\netc.\nThese formulas are predicated on coordinates in which the Poisson bivector is constant (plain flat Poisson brackets). For the general formula on arbitrary Poisson manifolds, cf. the Kontsevich quantization formula.\n\nAntisymmetrization of this -product yields the Moyal bracket, the proper quantum deformation of the Poisson bracket, and the phase-space isomorph (Wigner transform) of the quantum commutator in the more usual Hilbert-space formulation of quantum mechanics. As such, it provides the cornerstone of the dynamical equations of observables in this phase-space formulation.\n\nThere results a complete phase space formulation of quantum mechanics, completely equivalent to the Hilbert-space operator representation, with star-multiplications paralleling operator multiplications isomorphically.\n\nExpectation values in phase-space quantization are obtained isomorphically to tracing operator observables with the density matrix in Hilbert space: they are obtained by phase-space integrals of observables such as the above with the Wigner quasi-probability distribution effectively serving as a measure.\n\nThus, by expressing quantum mechanics in phase space (the same ambit as for classical mechanics), the above Weyl map facilitates recognition of quantum mechanics as a deformation (generalization, cf. correspondence principle) of classical mechanics, with deformation parameter . (Other familiar deformations in physics involve the deformation of classical Newtonian into relativistic mechanics, with deformation parameter \"v/c\"; or the deformation of Newtonian gravity into General Relativity, with deformation parameter Schwarzschild-radius/characteristic-dimension. Conversely, group contraction leads to the vanishing-parameter undeformed theories—classical limits.)\n\nClassical expressions, observables, and operations (such as Poisson brackets) are modified by -dependent quantum corrections, as the conventional commutative multiplication applying in classical mechanics is generalized to the \"noncommutative star-multiplication\" characterizing quantum mechanics and underlying its uncertainty principle.\n\nIt should be emphasized, however, that, despite its name, Deformation Quantization does not constitute a successful quantization scheme, namely a method to produce a quantum theory out of a classical one. It amounts to a mere representation change from Hilbert space to phase space. \n\nIn more generality, Weyl quantization is studied in cases where the phase space is a symplectic manifold, or possibly a Poisson manifold. Related structures include the Poisson–Lie groups and Kac–Moody algebras.\n\n\n"}
{"id": "1002045", "url": "https://en.wikipedia.org/wiki?curid=1002045", "title": "Émilie du Châtelet", "text": "Émilie du Châtelet\n\nGabrielle Émilie Le Tonnelier de Breteuil, Marquise du Châtelet (; 17 December 1706  – 10 September 1749) was a French natural philosopher, mathematician, physicist, and author during the early 1730s until her untimely death due to childbirth in 1749. Her most recognized achievement is her translation of and commentary on Isaac Newton's book \"Principia\" containing basic laws of physics. The translation, published posthumously in 1759, is still considered the standard French translation today. Her commentary includes a profound contribution to Newtonian mechanics—the postulate of an additional conservation law for total energy, of which kinetic energy of motion is one element.\n\nHer philosophical magnum opus, \"Institutions de Physique\" (Paris, 1740, first edition), or \"Foundations of Physics\", circulated widely, generated heated debates, and was republished and translated into several other languages within two years of its original publication. She participated in the famous \"vis viva\" debate, concerning the best way to measure the force of a body and the best means of thinking about conservation principles. Posthumously, her ideas were heavily represented in the most famous text of the French Enlightenment, the \"Encyclopédie\" of Denis Diderot and Jean le Rond D'Alembert, first published shortly after Du Châtelet's death. Numerous biographies, books and plays have been written about her life and work in the two centuries since her death. In the early 21st century, her life and ideas have generated renewed interest.\n\nIn addition to producing famous translations of works by authors such as Bernard Mandeville and Isaac Newton, Du Châtelet wrote a number of significant philosophical essays, letters and books that were well known in her time.\n\nBecause of her well-known collaboration and romantic involvement with Voltaire, which spanned much of her adult life, for generations Du Châtelet has been known as mistress and collaborator to her much better known intellectual companion. Her accomplishments and achievements have often been subsumed under his, and as a result, even today she is often mentioned only within the context of Voltaire's life and work during the period of the early French Enlightenment.\n\nRecently, however, professional philosophers and historians have transformed the reception of Du Châtelet. Historical evidence indicates that Du Châtelet's work had a very significant influence on the philosophical and scientific conversations of the 1730s and 1740s – in fact, she was famous and respected by the greatest thinkers of her time.\n\nDu Châtelet corresponded with renowned mathematicians such as Johann II Bernoulli and Leonhard Euler, early developers of calculus. She was also tutored by Bernoulli's prodigy students, Pierre Louis Moreau de Maupertuis and Alexis Claude Clairaut. Frederick the Great of Prussia, who re-founded the Academy of Sciences in Berlin, was her great admirer, and corresponded with both Voltaire and Du Châtelet regularly. He introduced Du Châtelet to Leibniz's philosophy by sending her the works of Christian Wolff, and Du Châtelet sent him a copy of her \"Institutions.\"\n\nHer works were published and republished in Paris, London, and Amsterdam; they were translated into German and Italian; and, they were discussed in the most important scholarly journals of the era, including the \"Memoires des Trévoux\", the \"Journal des Sçavans\", the \"\", and others. Perhaps most intriguingly, many of her ideas were represented in various sections of the \"Encyclopédie\" of Diderot and D'Alembert, and some of the articles in the \"Encyclopédie\" are a direct copy of her work (this is an active area of current academic research - the latest research can be found at Project Vox, a Duke University research initiative).\n\nÉmilie du Châtelet was born on 17 December 1706 in Paris, the only girl amongst six children. Three brothers lived to adulthood: René-Alexandre (b. 1698), Charles-Auguste (b. 1701), and Elisabeth-Théodore (b. 1710). Her eldest brother, René-Alexandre, died in 1720, and the next brother, Charles-Auguste, died in 1731. However, her younger brother, Elisabeth-Théodore, lived to a successful old age, becoming an abbé and eventually a bishop. Two other brothers died very young. Du Châtelet also had an illegitimate half-sister, Michelle, who was born of her father and Anne Bellinzani, an intelligent woman who was interested in astronomy and married to an important Parisian official.\n\nHer father was Louis Nicolas le Tonnelier de Breteuil, a member of the lesser nobility. At the time of Du Châtelet's birth, her father held the position of the Principal Secretary and Introducer of Ambassadors to King Louis XIV. He held a weekly \"salon\" on Thursdays, to which well-respected writers and scientists were invited. Her mother was Gabrielle Anne de Froullay, Baronne de Breteuil.\n\nDu Châtelet's education has been the subject of much speculation, but nothing is known with certainty.\n\nAmong their acquaintances was Fontenelle, the perpetual secretary of the French Académie des Sciences. Du Châtelet's father Louis-Nicolas, recognizing her early brilliance, arranged for Fontenelle to visit and talk about astronomy with her when she was 10 years old. Du Châtelet's mother, Gabrielle-Anne de Froulay, was brought up in a convent, at the time the predominant educational institution available to French girls and women. While some sources believe her mother did not approve of her intelligent daughter, or of her husband's encouragement of Émilie's intellectual curiosity, there are also other indications that her mother not only approved of Du Châtelet's early education, but actually encouraged her to vigorously question stated fact.\n\nIn either case, such encouragement would have been seen as unusual for parents of their time and status. When she was small, her father arranged training for her in physical activities such as fencing and riding, and as she grew older, he brought tutors to the house for her. As a result, by the age of twelve she was fluent in Latin, Italian, Greek and German; she was later to publish translations into French of Greek and Latin plays and philosophy. She received education in mathematics, literature, and science. Her mother Gabrielle-Anne was horrified at her progress and fought Louis-Nicolas at every step, once attempting to have Émilie sent to a convent.\n\nDu Châtelet's also liked to dance, was a passable performer on the harpsichord, sang opera, and was an amateur actress. As a teenager, short of money for books, she used her mathematical skills to devise highly successful strategies for gambling.\n\nOn the 12 of June 1725, she married the Marquis Florent-Claude du Chastellet-Lomont. Her marriage conferred the title of Marquise du Chastellet. Like many marriages among the nobility, theirs was arranged. As a wedding gift, the husband was made governor of Semur-en-Auxois in Burgundy by his father; the recently married couple moved there at the end of September 1725. Du Châtelet was eighteen at the time, her husband thirty-four.\n\nThe Marquis Florent-Claude du Chastellet and Émilie du Châtelet had three children: Françoise Gabriel Pauline (born 30 June 1726), Louis Marie Florent (born 20 November 1727), and Victor-Esprit (born 11 April 1733). Victor-Esprit died as an infant in late summer 1734, likely the last Sunday in August. On 4 September 1749 Émilie du Châtelet gave birth to Stanislas-Adélaïde du Châtelet (daughter of Jean François de Saint-Lambert). She died as an infant in Lunéville on 6 May 1751.\n\nIn 1733, aged 26, Du Châtelet resumed her mathematical studies. Initially, she was tutored in algebra and calculus by Moreau de Maupertuis, a member of the Academy of Sciences; although mathematics was not his forte, he had received a solid education from Johann Bernoulli, who also taught Leonhard Euler. However by 1735 Du Châtelet had turned for her mathematical training to Alexis Clairaut, a mathematical prodigy known best for Clairaut's equation and Clairaut's theorem. Du Châtelet resourcefully sought some of France's best tutors and scholars to mentor her in mathematics. On one occasion at the Café Gradot, a place where men frequently gathered for intellectual discussion, she was politely ejected when she attempted to join one of her teachers. Undeterred, she simply had some men's clothing made for herself and strolled back in drag.\n\nDu Châtelet may have met Voltaire in her childhood at one of her father's \"salons\"; Voltaire himself dates their meeting to 1729, when he returned from his exile in London. However, their friendship developed from May 1733 when she re-entered society after the birth of her third child.\n\nDu Châtelet invited Voltaire to live at her country house at Cirey-sur-Blaise in Haute-Marne, northeastern France, and he became her long-time companion under the eyes of her tolerant husband. There she studied physics and mathematics and published scientific articles and translations. To judge from Voltaire's letters to friends and their commentaries on each other's work, they lived together with great mutual liking and respect. As a literary rather than scientific person, Voltaire implicitly acknowledged her contributions to his 1738 \"Elements of the Philosophy of Newton\", where the chapters on optics show strong similarities with her own \"Essai sur l'optique\". She was able to contribute further to the campaign by a laudatory review in the \"Journal des savants\".\n\nSharing a passion for science, Voltaire and Du Châtelet collaborated scientifically. They set up a laboratory in Du Châtelet's home. In a healthy competition, they both entered the 1738 Paris Academy prize contest on the nature of fire, since Du Châtelet disagreed with Voltaire's essay. Although neither of them won, both essays received honourable mention and were published. She thus became the first woman to have a scientific paper published by the Academy.\n\nDu Châtelet's relationship with Voltaire caused her to give up most of her social life to become more involved with her study in mathematics with the teacher of Pierre-Louis Moreau de Maupertuis. He introduced the ideas of Isaac Newton to her. Letters written by Du Châtelet explain how she felt during the transition from Parisian socialite to rural scholar, from \"one life to the next.\"\n\nIn May 1748, Du Châtelet began an affair with the poet Jean François de Saint-Lambert and became pregnant. In a letter to a friend she confided her fears that she would not survive her pregnancy. On the night of 4 September 1749 she gave birth to a daughter, Stanislas-Adélaïde. Du Châtelet died on 10 September 1749, at Lunéville, from a pulmonary embolism. She was 42. Her daughter died 20 months later.\n\nIn her writing, Du Châtelet criticizes John Locke's philosophy. She emphasizes the necessity of the verification of knowledge through experience: Locke's idea of the possibility of \"thinking matter\" is […] abstruse. Her critique on Locke originates in her Bernard de Mandeville commentary [on the \"Fable of the Bees\"]. She confronts us with her resolute statement in favor of universal principles which precondition human knowledge and action, and maintains that this kind of law is innate. […] Du Châtelet claims the necessity of a universal presupposition, because if there is no such beginning, all our knowledge is relative. In that way, Du Châtelet rejects John Locke's aversion of innate ideas and a priori principles. She also reverses Locke's negation of the principle of contradiction, which would constitute the basis of her methodic reflections in the \"Institutions\". On the contrary, she affirms her arguments in favor of the necessity of a priori and universal principles. \"two and two could then make as well 4 as 6\" if a priori principles did not exist.\n\nPierre Louis Moreau de Maupertuis' and Julien Offray de La Mettrie's reference to Du Châtelet's deliberations on motion and free will, on \"thinking matter\" and numbers and on the way to do metaphysics indicate the importance of her reflections. She rebuts the claim to finding truth by using mathematical laws, […] and argues against Maupertuis.\n\nIn 1737 Châtelet published a paper entitled \"Dissertation sur la nature et la propagation du feu\", based upon her research into the science of fire, that predicted what is today known as infrared radiation and the nature of light.\n\nHer book \"Institutions de Physique\" (\"Lessons in Physics\") was published in 1740; it was presented as a review of new ideas in science and philosophy to be studied by her 13 year old son, but it incorporated and sought to reconcile complex ideas from the leading thinkers of the time. The book and subsequent debate contributed to her becoming a member of the Academy of Sciences of the Institute of Bologna in 1746.\n\nIn 1741 du Châtelet published a book titled \"Réponse de Madame la Marquise du Chastelet, a la lettre que M. de Mairan\". Dortous de Mairan, secretary of the Academy of Sciences, had published a set of arguments addressed to her regarding the appropriate mathematical expression for \"forces vives\". Du Châtelet presented a spirited point by point rebuttal of de Mairan's arguments causing him to withdraw from the controversy.\n\nImmanuel Kant's first publication in 1747 'Gedanken zur wahren Schätzung der lebendigen Kräfte' focuses on Du Châtelet's pamphlet against the secretary of the French Academy of Sciences, Mairan. Kant's opponent, Johann Augustus Eberhard accused Kant of taking ideas from Du Châtelet.\n\nAlthough in the early 18th century the concepts of force and momentum had been long understood, the idea of \"energy\" as transferable between different systems was still in its infancy, and would not be fully resolved until the 19th Century. It is now accepted that the total mechanical momentum of a system is conserved and none is lost to friction. Simply put, there is no 'momentum friction' and momentum can not transfer between different forms, and particularly there is no potential momentum. Emmy Noether proved this to be true for all problems where the initial state is symmetric in generalized coordinates. Mechanical energy, kinetic and potential, may be lost to another form, but the total is conserved in time. The Du Châtelet contribution was the hypothesis of the conservation of total energy, as distinct from momentum. Inspired by the theories of Gottfried Leibniz, she repeated and publicized an experiment originally devised by Willem 's Gravesande in which balls were dropped from different heights into a sheet of soft clay. Each ball's kinetic energy - as indicated by the quantity of material displaced - was shown to be proportional to the square of the velocity. The deformation of the clay was found to be directly proportional to the height the balls were dropped from, equal to the initial potential energy. Earlier workers, such as Newton and Voltaire, had all believed that \"energy\" (so far as they understood the concept at all) was indistinct from momentum and therefore proportional to velocity. According to this understanding, the deformation of the clay should have been proportional to the square root of the height from which the balls were dropped. In classical physics the correct formula is formula_1, where formula_2 is the kinetic energy of an object, formula_3 its mass and formula_4 its speed.) Energy must always have the same dimensions in any form, which is necessary to be able to relate it in different forms (kinetic, potential, heat…). Newton's work assumed the exact conservation of only mechanical momentum. A broad range of mechanical problems are soluble only if energy conservation is included. The collision and scattering of two point masses is one of them. Leonhard Euler and Joseph-Louis Lagrange established a more formal framework for mechanics using the results of du Châtelet.\n\nIn 1749, the year of Du Châtelet's death, she completed the work regarded as her outstanding achievement: her translation into French, with her commentary, of Newton's \"Philosophiae Naturalis Principia Mathematica\" (often referred to as simply the \"Principia\"), including her derivation of the notion of conservation of energy from its principles of mechanics. Published ten years after her death, today Du Châtelet's translation of the \"Principia\" is still the standard translation of the work into French. Indeed, her translation and commentary of the \"Principia\" also contributed to the completion of the scientific revolution in France and to its acceptance in Europe.\n\nShe lost the considerable sum for the time of 84,000 francs—some of it borrowed—in one evening at the table at the Court of Fontainebleau, to card cheats. To raise the money to pay back her debts she devised an ingenious financing arrangement similar to modern derivatives, whereby she paid tax collectors a fairly low sum for the right to their future earnings (they were allowed to keep a portion of the taxes they collected for the King), and promised to pay the court gamblers part of these future earnings.\n\nDu Châtelet wrote a critical analysis of the entire Bible. A synthesis of her remarks on the book of Genesis was published in English in 1967 by Ira O. Wade of Princeton in his book \"Voltaire and Madame du Châtelet: An Essay on Intellectual Activity at Cirey\" and a book of her complete notes was published in 2011, in the original French, edited and annotated by Bertram Eugene Schwarzbach.\n\nDu Châtelet wrote a monograph, \"Discours sur le bonheur\", on the nature of happiness both in general and specialised to women.\n\nDu Châtelet translated \"The Fable of the Bees\" in a free adaptation. She also wrote works on optics, rational linguistics, and the nature of free will.\n\nIn her first independent work, the preface to her translation of the \"Fable of the Bees\", du Châtelet argues strongly for women's education, particularly a strong secondary education as was available for young men in the French \"collèges\". By denying women a good education, she argues, society prevents women from becoming eminent in the arts and sciences.\n\nDu Châtelet made a crucial scientific contribution in making Newton's historic work more accessible in a timely, accurate and insightful French translation, augmented by her own original concept of energy conservation.\n\nA main-belt minor planet and a crater on Venus have been named in her honor, and she is the subject of three plays: \"Legacy of Light\" by Karen Zacarías; \"Émilie: La Marquise Du Châtelet Defends Her Life Tonight\" by Lauren Gunderson and \"Urania: the Life of Émilie du Châtelet\" by Jyl Bonaguro. The opera \"Émilie\" of Kaija Saariaho is about the last moments of her life.\n\nDu Châtelet is often represented in portraits with mathematical iconography, such as holding a pair of dividers or a page of geometrical calculations. In the early nineteenth century, a French pamphlet of celebrated women (\"Femmes célèbres\") introduced a possibly apocryphal story of Du Châtelet's childhood. According to this story, a servant fashioned a doll for her by dressing up wooden dividers as a doll; however, du Châtelet undressed the dividers and intuiting their purpose, made a circle with them.\n\n\n\n\n\n\n\n"}
