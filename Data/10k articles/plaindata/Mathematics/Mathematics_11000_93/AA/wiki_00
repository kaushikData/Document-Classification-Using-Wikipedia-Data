{"id": "33593996", "url": "https://en.wikipedia.org/wiki?curid=33593996", "title": "A Mathematician's Lament", "text": "A Mathematician's Lament\n\nA Mathematician's Lament, often referred to informally as Lockhart's Lament, is a short book on the pedagogics and philosophy of mathematics by Paul Lockhart, originally a research mathematician but for many years a math teacher at Saint Ann's School in Brooklyn, New York. Characterized as a strongly worded opinion piece arguing for an aesthetic, intuitive and heuristic approach to teaching and the importance of mathematics teaching reforms, the book frames learning mathematics as an artistic and imaginative pursuit which is not reflected at all in the way the subject is taught in the American educational system.\n\nThe book was developed from a 25-page essay that was written in 2002, originally circulated in typewritten manuscript copies, and subsequently on the Internet.\n\n\n"}
{"id": "5834526", "url": "https://en.wikipedia.org/wiki?curid=5834526", "title": "Abel equation", "text": "Abel equation\n\nThe Abel equation, named after Niels Henrik Abel, is a type of functional equation which can be written in the form\nor, equivalently, \nand controls the iteration of   .\n\nThese equations are equivalent. Assuming that is an invertible function, the second equation can be written as\n\nTaking , the equation can be written as\n\nFor a function assumed to be known, the task is to solve the functional equation for the function , possibly satisfying additional requirements, such as .\n\nThe change of variables , for a real parameter , brings Abel's equation into the celebrated Schröder's equation, .\n\nThe further change into Böttcher's equation, .\n\nThe Abel equation is a special case of (and easily generalizes to) the translation equation,\ne.g., for formula_6, \n\nThe Abel function further provides the canonical coordinate for Lie advective flows (one parameter Lie groups).\n\nInitially, the equation in the more general form\nwas reported. Even in the case of a single variable, the equation is non-trivial, and admits special analysis.\nIn the case of a linear transfer function, the solution is expressible compactly. \n\nThe equation of tetration is a special case of Abel's equation, with .\n\nIn the case of an integer argument, the equation encodes a recurrent procedure, e.g.,\nand so on,\n\n\nFatou coordinates describe local dynamics of discrete dynamical system near a parabolic fixed point.\n\n"}
{"id": "25212268", "url": "https://en.wikipedia.org/wiki?curid=25212268", "title": "Additive K-theory", "text": "Additive K-theory\n\nIn mathematics, additive K-theory means some version of algebraic K-theory in which, according to Spencer Bloch, the general linear group \"GL\" has everywhere been replaced by its Lie algebra \"gl\". It is not, therefore, one theory but a way of creating additive or infinitesimal analogues of multiplicative theories.\n\nFollowing Boris Feigin and Boris Tsygan, let formula_1 be an algebra over a field formula_2 of characteristic zero and let formula_3 be the algebra of infinite matrices over formula_4 with only finitely many nonzero entries. Then the Lie algebra homology\n\nhas a natural structure of a Hopf algebra. The space of its primitive elements of degree formula_6 is denoted by formula_7 and called the formula_8-th additive K-functor of \"A\".\n\nThe additive K-functors are related to cyclic homology groups by the isomorphism\n"}
{"id": "31810848", "url": "https://en.wikipedia.org/wiki?curid=31810848", "title": "Alexei Kostrikin", "text": "Alexei Kostrikin\n\nAlexei Ivanovich Kostrikin () (12 February 1929 – 22 September 2000) was a Russian mathematician, specializing in algebra and algebraic geometry.\n\nKostrikin graduated from the MSU Faculty of Mechanics and Mathematics in 1952. His advisor was Igor Shafarevich.\n\nIn 1959 Kostrikin achieved important results on the Burnside problem and a year later, in 1960, he earned a Doctor of Sciences degree. Since 1963 he was worked in the faculty, becoming a professor in 1976.\n\nKostrikin was awarded the USSR State Prize in 1968 for his research on finite groups and Lie algebras and was elected the corresponding member of the USSR Academy of Sciences in 1976. In 1998 he became Honoured Professor of Moscow State University.\n\nAlexei Kostrikin published many scientific articles, books and textbooks, including a university textbook about algebra \"Introduction to algebra\", translated into English and other languages.\n\n"}
{"id": "1254615", "url": "https://en.wikipedia.org/wiki?curid=1254615", "title": "Arithmetic underflow", "text": "Arithmetic underflow\n\nThe term arithmetic underflow (or \"floating point underflow\", or just \"underflow\") is a condition in a computer program where the result of a calculation is a number of smaller absolute value than the computer can actually represent in memory on its CPU.\n\nArithmetic underflow can occur when the true result of a floating point operation is smaller in magnitude (that is, closer to zero) than the smallest value representable as a normal floating point number in the target datatype. Underflow can in part be regarded as negative overflow of the exponent of the floating point value.\nFor example, if the exponent part can represent values from −128 to 127, then a result with a value less than −128 may cause underflow.\n\nNote that storing values that are too low in an integer variable (e.g. attempting to store -1 in an unsigned integer) is properly referred to as integer overflow, or more broadly \"integer wraparound\". The term underflow normally refers to floating point numbers only, and is a separate issue. It is not possible in most floating-point designs to store a too-low value, as usually they are signed and have a negative infinity value.\n\nThe interval between −\"fminN\" and \"fminN\", where\n\"fminN\" is the smallest positive normal floating point value, is called the underflow gap.\nThis is because the size of this interval is many orders of magnitude larger than the distance between\nadjacent normal floating point values just outside the gap. For instance, if the floating\npoint datatype can represent 20 binary digits, the underflow gap is 2 times\nlarger than the absolute distance between adjacent floating point values just outside the gap.\n\nIn older designs, the underflow gap had just one usable value, zero. When an underflow occurred,\nthe true result was replaced by zero (either directly by the hardware, or by system software\nhandling the primary underflow condition). This replacement is called \"flush to zero\".\n\nThe 1984 edition of IEEE 754 introduced subnormal numbers. The subnormal numbers (including zero) fill the\nunderflow gap with values where the absolute distance between adjacent values is the same as\nfor adjacent values just outside the underflow gap. This enables \"gradual underflow\" where\na nearest subnormal value is used, just as a nearest normal value is used when possible.\nEven when using gradual underflow, the nearest value may be zero.\n\nThe absolute distance between adjacent floating point values just outside the gap is called the machine epsilon. The machine epsilon is typically characterized by the largest value whose sum with the value 1 will result in the answer with value 1 in that floating point scheme. This can be written as formula_1, where formula_2 is a function which converts the real value into the floating point representation. While the machine epsilon is not to be confused with the underflow level (assuming subnormal numbers), it is closely related. The machine epsilon is dependent on the number of bits which make up the significand, whereas the underflow level depends on the number of digits which make up the exponent field. In most floating point systems, the underflow level is smaller than the machine epsilon.\n\nThe occurrence of an underflow may set a ('sticky') status bit, raise an exception, at the hardware\nlevel generate an interrupt, or may cause some combination of these effects.\n\nAs specified in IEEE 754, the underflow condition is only signaled if there is also a loss of precision.\nTypically this is determined as the final result being inexact.\nHowever, if the user is trapping on underflow,\nthis may happen regardless of consideration for loss of precision.\nThe default handling in IEEE 754 for underflow (as well as other exceptions) is to record\nas a floating point status that underflow has occurred. This is specified for the application\nprogramming level, but often also interpreted as how to handle it at the hardware level.\n\n"}
{"id": "1653036", "url": "https://en.wikipedia.org/wiki?curid=1653036", "title": "Billionth", "text": "Billionth\n\nOne billionth is the reciprocal of a billion, which means it has one of two definitions depending on whether the \"long scale\" or \"short scale\" definition is being used.\n\nIn the short (or American) scale, a billionth is equal to 0.000 000 001, or 1 x 10 in scientific notation or standard form. The prefix for this number is nano, and is abbreviated as \"n\" (for example, in electronics, one nanofarad would be written as 1 nF).\n\nIn the long (or English) scale, a billionth is equal to 0.000 000 000 001, or 1 x 10 in scientific notation or standard form. The prefix for this number is pico-, and is abbreviated as \"p\" (for example, in electronics, one picofarad would be written as 1 pF).\n"}
{"id": "6703785", "url": "https://en.wikipedia.org/wiki?curid=6703785", "title": "Brownian dynamics", "text": "Brownian dynamics\n\nBrownian dynamics (BD) can be used to describe the motion of molecules for example in molecular simulations or in reality. It is a simplified version of Langevin dynamics and corresponds to the limit where no average acceleration takes place. This approximation can also be described as 'overdamped' Langevin dynamics, or as Langevin dynamics without inertia.\n\nIn Langevin dynamics, the equation of motion is\n\nwhere \n\nIn Brownian dynamics, the formula_11 term is neglected, and the sum of these terms is zero.\n\nUsing the Einstein relation, formula_13, it is often convenient to write the equation as,\n\n"}
{"id": "4636611", "url": "https://en.wikipedia.org/wiki?curid=4636611", "title": "Coefficient matrix", "text": "Coefficient matrix\n\nIn linear algebra, a coefficient matrix is a matrix consisting of the coefficients of the variables in a set of linear equations. The matrix is used in solving systems of linear equations.\n\nIn general, a system with \"m\" linear equations and \"n\" unknowns can be written as\n\nwhere formula_5 are the unknowns and the numbers formula_6 are the coefficients of the system. The coefficient matrix is the \"mxn\" matrix with the coefficient formula_7 as the (\"i\",\"j\")-th entry:\n\nThen the above set of equations can be expressed more succinctly as \n\nwhere \"A\" is the coefficient matrix and \"b\" is the column vector of constant terms.\n\nBy the Rouché–Capelli theorem, the system of equations is inconsistent, meaning it has no solutions, if the rank of the augmented matrix (the coefficient matrix augmented with an additional column consisting of the vector \"b\") is greater than the rank of the coefficient matrix. If, on the other hand, the ranks of these two matrices are equal, the system must have at least one solution. The solution is unique if and only if the rank \"r\" equals the number \"n\" of variables. Otherwise the general solution has \"n – r \" free parameters; hence in such a case there are an infinitude of solutions, which can be found by imposing arbitrary values on \"n – r\" of the variables and solving the resulting system for its unique solution; different choices of which variables to fix, and different fixed values of them, give different system solutions.\n\nA first-order matrix difference equation with constant term can be written as \n\nwhere \"A\" is \"n\" × \"n\" and \"y\" and \"c\" are \"n\" × 1. This system converges to its steady-state level of \"y\" if and only if the absolute values of all \"n\" eigenvalues of \"A\" are less than 1.\n\nA first-order matrix differential equation with constant term can be written as \n\nThis system is stable if and only if all \"n\" eigenvalues of \"A\" have negative real parts.\n"}
{"id": "23558700", "url": "https://en.wikipedia.org/wiki?curid=23558700", "title": "Decimal64 floating-point format", "text": "Decimal64 floating-point format\n\nIn computing, decimal64 is a decimal floating-point computer numbering format that occupies 8 bytes (64 bits) in computer memory.\nIt is intended for applications where it is necessary to emulate decimal rounding exactly, such as financial and tax computations.\n\nDecimal64 supports 16 decimal digits of significand and an exponent range of −383 to +384, i.e. to . (Equivalently, to .) In contrast, the corresponding binary format, which is the most commonly used type, has an approximate range of to . Because the significand is not normalized, most values with less than 16 significant digits have multiple possible representations; , etc. Zero has 768 possible representations (1536 if you include both signed zeros).\n\nDecimal64 floating point is a relatively new decimal floating-point format, formally introduced in the 2008 version of IEEE 754 as well as with .\n\nIEEE 754 allows two alternative representation methods for decimal64 values. The standard does not specify how to signify which representation is used, for instance in a situation where decimal64 values are communicated between systems:\n\n\nBoth alternatives provide exactly the same range of representable numbers: 16 digits of significand and 3×2 = 768 possible decimal exponent values. (All the possible decimal exponent values storable in a binary64 number are representable in decimal64, and most bits of the significand of a binary64 are stored keeping roughly the same number of decimal digits in the significand.)\n\nIn both cases, the most significant 4 bits of the significand (which actually only have 10 possible values) are combined with the most significant 2 bits of the exponent (3 possible values) to use 30 of the 32 possible values of a 5-bit field. The remaining combinations encode infinities and NaNs.\n\nIn the cases of Infinity and NaN, all other bits of the encoding are ignored. Thus, it is possible to initialize an array to Infinities or NaNs by filling it with a single byte value.\n\nThis format uses a binary significand from 0 to 10−1 = = 2386F26FC0FFFF = .\n\nThe encoding, completely stored on 64 bits, can represent binary significands up to 10×2−1 = = 27FFFFFFFFFFFF, but values larger than 10−1 are illegal (and the standard requires implementations to treat them as 0, if encountered on input).\n\nAs described above, the encoding varies depending on whether the most significant 4 bits of the significand are in the range 0 to 7 (0000 to 0111), or higher (1000 or 1001).\n\nIf the 2 bits after the sign bit are \"00\", \"01\", or \"10\", then the exponent field consists of the 10 bits following the sign bit, and the significand is the remaining 53 bits, with an implicit leading 0 bit:\n\nThis includes subnormal numbers where the leading significand digit is 0.\n\nIf the 2 bits after the sign bit are \"11\", then the 10-bit exponent field is shifted 2 bits to the right (after both the sign bit and the \"11\" bits thereafter), and the represented significand is in the remaining 51 bits. In this case there is an implicit (that is, not stored) leading 3-bit sequence \"100\" for the most bits of the true significand (in the remaining lower bits \"ttt...ttt\" of the significand, not all possible values are used).\n\nThe 2-bit sequence \"11\" after the sign bit indicates that there is an \"implicit\" 3-bit prefix \"100\" to the significand. Compare having an implicit 1-bit prefix \"1\" in the significand of normal values for the binary formats. Note also that the 2-bit sequences \"00\", \"01\", or \"10\" after the sign bit are part of the exponent field.\n\nNote that the leading bits of the significand field do \"not\" encode the most significant decimal digit; they are simply part of a larger pure-binary number. For example, a significand of is encoded as binary , with the leading 4 bits encoding 7; the first significand which requires a 54th bit is 2 = . The highest valid significant is whose binary encoding is\n\nIn the above cases, the value represented is\n\nIf the four bits after the sign bit are \"1111\" then the value is an infinity or a NaN, as described above:\n\nIn this version, the significand is stored as a series of decimal digits. The leading digit is between 0 and 9 (3 or 4 binary bits), and the rest of the significand uses the densely packed decimal (DPD) encoding.\n\nUnlike the binary integer significand version, where the exponent changed position and came before the significand, this encoding, combines the leading 2 bits of the exponent and the leading digit (3 or 4 bits) of the significand into the five bits that follow the sign bit.\n\nThis eight bits after that are the exponent continuation field, providing the less-significant bits of the exponent.\n\nThe last 50 bits are the significand continuation field, consisting of five 10-bit \"declets\". Each declet encodes three decimal digits using the DPD encoding.\n\nIf the first two bits after the sign bit are \"00\", \"01\", or \"10\", then those are the leading bits of the exponent, and the three bits \"TTT\" after that are interpreted as the leading decimal digit (0 to 7):\n\nIf the first two bits after the sign bit are \"11\", then the second 2-bits are the leading bits of the exponent, and the next bit \"T\" is prefixed with implicit bits \"100\" to form the leading decimal digit (8 or 9):\n\nThe remaining two combinations (11 110 and 11 111) of the 5-bit field after the sign bit are used to represent ±infinity and NaNs, respectively.\n\nThe DPD/3BCD transcoding for the declets is given by the following table. b9...b0 are the bits of the DPD, and d2...d0 are the three BCD digits.\n\nThe 8 decimal values whose digits are all 8s or 9s have four codings each.\nThe bits marked x in the table above are ignored on input, but will always be 0 in computed results.\n\nIn the above cases, with the \"true significand\" as the sequence of decimal digits decoded, the value represented is\n\n"}
{"id": "159587", "url": "https://en.wikipedia.org/wiki?curid=159587", "title": "Diffeology", "text": "Diffeology\n\nIn mathematics, a diffeology on a set declares what the smooth parametrizations in the set are. In some sense a diffeology generalizes the concept of smooth charts in a differentiable manifold. \n\nThe concept was first introduced by Jean-Marie Souriau in the 1980s and developed first by his students Paul Donato (homogeneous spaces and coverings) and Patrick Iglesias (diffeological fiber bundles, higher homotopy etc.), later by other people. A related idea was introduced by Kuo-Tsaï Chen (陳國才, \"Chen Guocai\") in the 1970s, using convex sets instead of open sets for the domains of the plots.\n\nIf \"X\" is a set, a diffeology on \"X\" is a set of maps, called plots, from open subsets of R (\"n\" ≥ 0) to \"X\" such that the following hold:\n\nNote that the domains of different plots can be subsets of R for different values of \"n\".\n\nA set together with a diffeology is called a diffeological space. \n\nA map between diffeological spaces is called differentiable if and only if composing it with every plot of the first space is a plot of the second space. It is a diffeomorphism if it is differentiable, bijective, and its inverse is also differentiable.\n\nThe diffeological spaces, together with differentiable maps as morphisms, form a category. The isomorphisms in this category are the diffeomorphisms defined above. The category of diffeological spaces is closed under many categorical operations.\n\nA diffeological space has the D-topology: the finest topology such that all plots are continuous.\n\nIf \"Y\" is a subset of the diffeological space \"X\", then \"Y\" is itself a diffeological space in a natural way: the plots of \"Y\" are those plots of \"X\" whose images are subsets of \"Y\".\n\nIf \"X\" is a diffeological space and ~ is some equivalence relation on \"X\", then the quotient set X/~ has the diffeology generated by all compositions of plots of \"X\" with the projection from \"X\" to \"X\"/~. This is called the quotient diffeology. The quotient D-topology is the D-topology of the quotient diffeology, and that this topology may be trivial without the diffeology being trivial.\n\nA Cartan De Rham calculus can be developed in the framework of diffeology, as well as fiber bundles, homotopy etc.\n\nDifferentiable manifolds also generalize smoothness. They are normally defined as topological manifolds with an atlas, whose transition maps are smooth, which is used to pull back the differential structure. \n\nEvery smooth manifold defined in this way has a natural diffeology, for which the plots correspond to the smooth maps from open subsets of R to the manifold. With this diffeology, a map between two smooth manifolds is smooth if and only if it is differentiable in the diffeological sense. Hence the smooth manifolds with smooth maps form a full subcategory of the diffeological spaces. \n\nThis allows one to give an alternative definition of smooth manifold which makes no reference to transition maps or to a specific atlas: a smooth manifold is a diffeological space which is locally diffeomorphic to R.\n\nThe relationship between smooth manifolds and diffeological spaces is analogous to the relationship between topological manifolds and topological spaces.\n\nThis method of \"modeling\" diffeological spaces can be extended to other locals models, for instance: orbifolds, modeled on quotient spaces R/Γ where Γ is a finite linear subgroup, or manifolds with boundary and corners, modeled on orthants etc.\n\n\n"}
{"id": "45584217", "url": "https://en.wikipedia.org/wiki?curid=45584217", "title": "Dot product representation of a graph", "text": "Dot product representation of a graph\n\nA dot product representation of a simple graph is a method of representing a graph using vector spaces and the dot product from linear algebra. Every graph has a dot product representation.\n\nLet \"G\" be a graph with vertex set \"V\". Let \"F\" be a field, and \"f\" a function from \"V\" to \"F\" such that \"xy\" is an edge of \"G\" if and only if \"f\"(\"x\")·\"f\"(\"y\") ≥ \"t\". This is the dot product representation of \"G\". The number \"t\" is called the dot product threshold, and the smallest possible value of \"k\" is called the dot product dimension.\n\n"}
{"id": "43724607", "url": "https://en.wikipedia.org/wiki?curid=43724607", "title": "E-semigroup", "text": "E-semigroup\n\nIn the area of mathematics known as semigroup theory, an \"E\"-semigroup is a semigroup in which the idempotents form a subsemigroup.\n\nCertain classes of \"E\"-semigroups have been studied long before the more general class, in particular, a regular semigroup that is also an \"E\"-semigroup is known as an orthodox semigroup.\n\nWeipoltshammer proved that the notion of weak inverse (the existence of which is one way to define \"E\"-inversive semigroups) can also be used to define/characterize \"E\"-semigroups as follows: a semigroup \"S\" is an \"E\"-semigroup if and only if, for all \"a\" and \"b\" ∈ \"S\", \"W\"(\"ab\") = \"W\"(\"b\")\"W\"(\"a\"), where \"W\"(\"x\") ≝ {\"x\" ∈ \"S\" | \"xax\" = \"x\"} is the set of weak inverses of \"x\".\n"}
{"id": "14721989", "url": "https://en.wikipedia.org/wiki?curid=14721989", "title": "Field arithmetic", "text": "Field arithmetic\n\nIn mathematics, field arithmetic is a subject that studies the interrelations between arithmetic properties of a and its absolute Galois group.\nIt is an interdisciplinary subject as it uses tools from algebraic number theory, arithmetic geometry, algebraic geometry, model theory, the theory of finite groups and of profinite groups.\n\nLet \"K\" be a field and let \"G\" = Gal(\"K\") be its absolute Galois group. If \"K\" is algebraically closed, then \"G\" = 1. If \"K\" = R is the real numbers, then\n\nHere C is the field of complex numbers and Z is the ring of integer numbers. \nA theorem of Artin and Schreier asserts that (essentially) these are all the possibilities for finite absolute Galois groups.\n\nArtin–Schreier theorem. Let \"K\" be a field whose absolute Galois group \"G\" is finite. Then either \"K\" is separably closed and \"G\" is trivial or \"K\" is real closed and \"G\" = Z/2Z.\n\nSome profinite groups occur as the absolute Galois group of non-isomorphic fields. A first example for this is\n\nThis group is isomorphic to the absolute Galois group of an arbitrary finite field. Also the absolute Galois group of the field of formal Laurent series C((\"t\")) over the complex numbers is isomorphic to that group.\n\nTo get another example, we bring below two non-isomorphic fields whose absolute Galois groups are free (that is free profinite group).\n\n\nIn contrast to the above examples, if the fields in question are finitely generated over Q, Florian Pop proves that an isomorphism of the absolute Galois groups yields an isomorphism of the fields:\n\nTheorem. Let \"K\", \"L\" be finitely generated fields over Q and let \"a\": Gal(\"K\") → Gal(\"L\") be an isomorphism. Then there exists a unique isomorphism of the algebraic closures, \"b\": \"K\" → \"L\", that induces \"a\".\n\nThis generalizes an earlier work of Jürgen Neukirch and Koji Uchida on number fields.\n\nA pseudo algebraically closed field (in short PAC) \"K\" is a field satisfying the following geometric property. Each absolutely irreducible algebraic variety \"V\" defined over \"K\" has a \"K\"-rational point.\n\nOver PAC fields there is a firm link between arithmetic properties of the field and group theoretic properties of its absolute Galois group. A nice theorem in this spirit connects Hilbertian fields with ω-free fields (\"K\" is ω-free if any embedding problem for \"K\" is properly solvable).\n\nTheorem. Let \"K\" be a PAC field. Then \"K\" is Hilbertian if and only if \"K\" is ω-free.\n\nPeter Roquette proved the right-to-left direction of this theorem and conjectured the opposite direction. Michael Fried and Helmut Völklein applied algebraic topology and complex analysis to establish Roquette's conjecture in characteristic zero. Later Pop \nproved the Theorem for arbitrary characteristic by developing \"rigid patching\".\n\n"}
{"id": "324744", "url": "https://en.wikipedia.org/wiki?curid=324744", "title": "Financial engineering", "text": "Financial engineering\n\nFinancial engineering is a multidisciplinary field involving financial theory, methods of engineering, tools of mathematics and the practice of programming. It has also been defined as the application of technical methods, especially from mathematical finance and computational finance, in the practice of finance. Despite its name, financial engineering does not belong to any of the fields in traditional professional engineering even though many financial engineers have studied engineering beforehand and many universities offering a postgraduate degree in this field require applicants to have a background in engineering as well. In the United States, the Accreditation Board for Engineering and Technology (ABET) does not accredit financial engineering degrees. In the United States, financial engineering programs are accredited by the \"International Association of Quantitative Finance\".\n\nFinancial engineering draws on tools from applied mathematics, computer science, statistics and economic theory.\nIn the broadest sense, anyone who uses technical tools in finance could be called a financial engineer, for example any computer programmer in a bank or any statistician in a government economic bureau. However, most practitioners restrict the term to someone educated in the full range of tools of modern finance and whose work is informed by financial theory. It is sometimes restricted even further, to cover only those originating new financial products and strategies. Financial engineering plays a key role in the customer-driven derivatives business which encompasses quantitative modelling and programming, trading and risk managing derivative products in compliance with the regulations and Basel capital/liquidity requirements.\n\nThe financial engineering program at New York University Polytechnic School of Engineering was the first curriculum to be certified by the International Association of Financial Engineers.\n\nComputational finance and mathematical finance are both subfields of financial engineering. Computational finance is a field in computer science and deals with the data and algorithms that arise in financial modeling. Mathematical finance is the application of mathematics to finance.\n\nQuantitative analyst (\"Quant\") is a broad term that covers any person who uses math for practical purposes, including financial engineers. Quant is often taken to mean “financial quant,” in which case it is similar to financial engineer. The difference is that it is possible to be a theoretical quant, or a quant in only one specialized niche in finance, while “financial engineer” usually implies a practitioner with broad expertise.\n\n“Rocket scientist” (aerospace engineer) is an older term, first coined in the development of rockets in WWII (Wernher von Braun), and later, the NASA space program; it was adapted by the first generation of financial quants who arrived on Wall Street in the late 1970s and early 1980s. While basically synonymous with financial engineer, it implies adventurousness and fondness for disruptive innovation. Financial \"Rocket scientists\" were usually trained in applied mathematics, statistics or finance; and spent their entire careers in risk-taking. They were not hired for their mathematical talents, they either worked for themselves or applied mathematical techniques to traditional financial jobs. The later generation of financial engineers were more likely to have PhDs in mathematics or physics and often started their careers in academics or non-financial fields.\n\nThe first degree programs in financial engineering were set up in the early 1990s. The number and size of programs has grown rapidly, so now some people use the term “financial engineer” to mean someone who has a degree in the field.\n\nAn older use of the term \"financial engineering\" that is less common today is aggressive restructuring of corporate balance sheets. It is generally (but not always) a disparaging term, implying that someone is profiting from paper games at the expense of employees and investors.\n\nThe main applications of financial engineering are to:\n\nOne of the critics of financial engineering is Nassim Taleb, a professor of financial engineering at Polytechnic Institute of New York University\n\nMany other authors have identified specific problems in financial engineering that caused catastrophes: Aaron Brown named confusion between quants and regulators over the meaning of “capital”, Felix Salmon gently pointed to the Gaussian copula, Ian Stewart criticized the Black-Scholes formula, Pablo Triana dislikes value at risk and Scott Patterson\n\nA gentler criticism came from Emanuel Derman who heads a financial engineering degree program at Columbia University. He blames over-reliance on models for financial problems.\n\nThe financial innovation often associated with financial engineers was mocked by former chairman of the Federal Reserve Paul Volcker in 2009 when he said it was a code word for risky securities, that brought no benefits to society. For most people, he said, the advent of the ATM was more crucial than any asset-backed bond.\n\n"}
{"id": "14535189", "url": "https://en.wikipedia.org/wiki?curid=14535189", "title": "Fisher's inequality", "text": "Fisher's inequality\n\nFisher's inequality, is a necessary condition for the existence of a balanced incomplete block design, that is, a system of subsets that satisfy certain prescribed conditions in combinatorial mathematics. Outlined by Ronald Fisher, a population geneticist and statistician, who was concerned with the design of experiments; studying the differences among several different varieties of plants, under each of a number of different growing conditions, called \"blocks\".\n\nLet:\n\n\nTo be a balanced incomplete block design it is required that:\n\n\nFisher's inequality states simply that\n\nLet the incidence matrix be a matrix defined so that is 1 if element is in block and 0 otherwise. Then is a matrix such that and for . Since , , so ; on the other hand, , so .\n\nFisher's inequality is valid for more general classes of designs. A \"pairwise balanced design\" (or PBD) is a set together with a family of non-empty subsets of (which need not have the same size and may contain repeats) such that every pair of distinct elements of is contained in exactly (a positive integer) subsets. The set is allowed to be one of the subsets, and if all the subsets are copies of , the PBD is called \"trivial\". The size of is and the number of subsets in the family (counted with multiplicity) is .\n\nTheorem: For any non-trivial PBD, .\n\nThis result also generalizes the Erdős–De Bruijn theorem:\n\nFor a PBD with having no blocks of size 1 or size , , with equality if and only if the PBD is a projective plane or a near-pencil (meaning that exactly of the points are collinear).\n\nIn another direction, Ray-Chaudhuri and Wilson proved in 1975 that in a design, the number of blocks is at least formula_1.\n\n"}
{"id": "15434066", "url": "https://en.wikipedia.org/wiki?curid=15434066", "title": "Florence Nightingale David", "text": "Florence Nightingale David\n\nFlorence Nightingale David, also known as F. N. David (23 August 1909 – 23 July 1993) was an English statistician, born in Ivington, Herefordshire, England. She was head of the Statistics Department at the University of California, Riverside in 1970.\n\nDavid was named after Florence Nightingale, who was a friend of her parents.\n\nDavid was tutored privately by a local parson, beginning at age five. By that age she already knew some arithmetic, so she began with algebra. Since David already knew English, the parson taught her Latin and Greek. At the age of ten, she entered to formal schooling. She studied mainly mathematics for three years, with the aim of becoming an actuary, but at that time the actuarial firms only accepted men. She earned a degree in Mathematics from Bedford College for Women in 1931.\n\nDavid received a scholarship and continued her studies with Karl Pearson at University College, London, as his research assistant. When Pearson retired, his son Egon, and R. A. Fisher, took over Karl's duties. After Karl Pearson died in 1934, David returned to the Biometrics laboratory to work with Jerzy Neyman, submitting her four most recently published papers as her PhD thesis, and earned a doctorate in 1938.\n\nWorking for Karl Pearson, F. N. David computed solutions to complicated multiple integrals, and the distribution of the correlation coefficients. As a result, her first book was released in 1938, called \"Tables of the Correlation Coefficient\". All the calculations were done on a hand-cranked mechanical calculator known as a Brunsviga.\n\nDuring World War II, David worked for the Ministry of Home Security. In late 1939 when war had started but England had not yet been attacked, she created statistical models to predict the possible consequences of bombs exploding in high density populations such as the big cities of England and especially London. From these models, she determined estimates of harm to humans and damage to non-humans. This included the possible numbers living and dead, the reactions to fires and damaged buildings as well as damages to communications, utilities such as phones, water, gas, electricity and sewers.\nAs a result, when the Germans bombed London in 1940 and 1941, vital services were kept going and her models were updated and modified with the evidence from the real harms and real damage.\n\nAfter World War II she returned to University College in London and became a Professor in 1962. In 1968 she moved to California and became a Professor, and in 1970 the Chair, in the Department of Statistics at the University of California, Riverside, and was the book review editor for the journal \"Biometrics\" for four years.\n\nBy 1977 she had retired but moved to the University of California, Berkeley where she continued to teach and do research in Biostatistics.\n\nDavid died in 1995.\n\nIn 1954 she was elected as a Fellow of the American Statistical Association.\nShe was also a Fellow of the Institute of Mathematical Statistics.\n\nIn conjunction with other numerous academic honours, in 1992 David won the first Elizabeth L. Scott Award \"...for her efforts in opening the door to women in statistics; for contributions to the professions over many years; for contributions to education, science, and public service; for research contributions to combinatorics, statistical methods, applications and understanding history; and her spirit as a lecturer and as a role model.\". The University named a library for her, and in 2001 established the Florence Nightingale David Award.\n\nDavid's research resulted in advances in combinatorics, including a clear exposition of complicated methods. She studied the Correlation coefficient, and computed solutions of complicated multiple integrals, using the distribution of the correlation coefficient.\n\nDavid investigated the origins and history of probability and statistical ideas. She wrote a book on history of probability, using problems thought of by famous mathematicians and scientists like Cardano and Galileo. It was called \"Games, Gods and Gambling: The Origins and History of Probability\". She \"speculat[ed] that gambling may be the first invention of human society. Her clue to this is the talus. This most common randomizer of ancient times is a predecessor of the die: the astragalus or talus is the 'knucklebone' or heel bone of a running animal. In creatures such as deer, horse, oxen, sheep and hartebeest this bone is so formed that when it is thrown to land on a level surface it can come to rest in only four ways. Well polished and often engraved examples are regularly found on the sites of ancient Egypt. Tomb illustrations and scoring boards make it virtually certain that these were used for gaming.\"\n\nDavid published ten books and more than 100 papers, including:\n\n\n"}
{"id": "9342843", "url": "https://en.wikipedia.org/wiki?curid=9342843", "title": "Fujiki class C", "text": "Fujiki class C\n\nIn algebraic geometry, a complex manifold is called Fujiki class C if it is bimeromorphic to a compact Kähler manifold. This notion was defined by Akira Fujiki.\n\nLet \"M\" be a compact manifold of Fujiki class C, and \nformula_1 its complex subvariety. Then \"X\"\nis also in Fujiki class C (, Lemma 4.6). Moreover, the Douady space of \"X\" (that is, the moduli of deformations of a subvariety formula_1, \"M\" fixed) is compact and in Fujiki class C.\n\nJ.-P. Demailly and M. Pǎun have\nshown that a manifold is in Fujiki class C if and only\nif it supports a Kähler current. \nThey also conjectured that a manifold \"M\" is in Fujiki class C if it admits a nef current which is \"big\", that is, satisfies\n\nFor a cohomology class formula_4 which is rational, this statement is known: by Grauert-Riemenschneider conjecture, a holomorphic line bundle \"L\" with first Chern class\n\nnef and big has maximal Kodaira dimension, hence the corresponding rational map to\n\nis generically finite onto its image, which is algebraic, and therefore Kähler.\n\nFujiki and Ueno asked whether the property C is stable under deformations. This conjecture was disproven in 1992 by Y.-S. Poon and Claude LeBrun \n"}
{"id": "27742479", "url": "https://en.wikipedia.org/wiki?curid=27742479", "title": "Gareth Loy", "text": "Gareth Loy\n\nDr. Gareth Loy is an American author, composer, musician and mathematician. Loy is the author of the two volume series on the intersection of music and mathematics titled \"Musimathics\". Loy was an early practitioner of music synthesis at Stanford, and wrote the first software compiler for the Systems Concepts Digital Synthesizer (Samson Box). More recently, Loy has published the freeware music programming language \"Musimat\", designed specifically for subjects covered in \"Musimathics\", available as a free download. Although Musimathics was first published in 2006 and 2007, the series continues to evolve with updates by the author and publishers, and the texts are being used in numerous math and music classes at both the graduate and undergraduate level, with more current reviews noting that the originally targeted academic distribution is now reaching a much wider audience. Music synthesis pioneer Max Mathews stated that Loy's books are a \"guided tour-de-force of the mathematics of physics and music... Loy has always been a brilliantly clear writer. In \"Musimathics\", he is also an encyclopedic writer. He covers everything needed to understand existing music and musical instruments, or to create new music or new instruments... Loy's book and John R. Pierce's famous \"The Science of Musical Sound\" belong on everyone's bookshelf, and the rest of the shelf can be empty.\" John Chowning states, in regard to Nekyia and the Samson Box, \"After completing the (Samson Box) software, Loy composed Nekyia, a beautiful and powerful composition in four channels that fully exploited the capabilities of the Samson Box. As an integral part of the (original Stanford) community, Loy has paid back many times over all that he learned, by conceiving the (Samson) system with maximal generality such that it could be used for research projects in psychoacoustics as well as for hundreds of compositions by a host of composers having diverse compositional strategies.\"\n\nDr. Gareth Loy was born in Los Angeles in 1945. He was an early employee at Apple Computer, and is the brother of the late Dr. Tom Loy, a renowned molecular archaeologist, and member of the team that researched Oetzi the Iceman.\n\nIn the 1960s and 1970s, CCRMA – the Center for Research in Music and Acoustics at Stanford University – which was then a research project at the Stanford Artificial Intelligence Laboratory (SAIL), developed fundamental technologies later used extensively in the digital synthesizer and digital audio industries. Dr. Loy was a grad student at CCRMA in the mid-70s, and wrote the compiler software for the original Samson Box, which was the original and most powerful and complex digital synthesizer/processor of the day. Since Dr. Loy is both a mathematician and a composer, in addition to the mathematics, engineering and software code for the Samson Box, Loy also composed Nekyia, a dynamic and powerful four channel composition, to fully demonstrate the capabilities of the Samson Box. Nekyia still stands today as a landmark in digital composition, and maintains its power despite the advances in synthesizer technology since then. Loy received his B.A. from San Francisco State University in 1975 and his DMA (Doctor of Musical Arts) from Stanford's Artificial Intelligence Laboratory and CCRMA, in Computer Science, Signal Processing and Digital Music Composition in 1980. Gareth lives with his wife Lisa in San Rafael, California.\n\nIn addition to composing, performing and writing journal articles on the technology of mathematics and music, Dr. Loy has been an expert witness in some high visibility cases, performing forensic analysis of technology details. Loy has testified in numerous such cases involving Guitar Hero and other technologies, performing forensic analysis of technology details to clarify patent issues.\n\nLoy has been a long time member of the Flying Without Instruments band, which has performed internationally, including compositions by Loy. Dr. Loy also composed the score for Das Kapital, a music video based on a poem by Hale Thatcher, and performed by violinist János Négyesy. Loy's composition \"Blood From a Stone\" (1992) was written for an electronic violin designed by Max Mathews and performed by Negyesy. Gareth also performs in the Tenaya Classical Guitar Duo, and founded the San Francisco performance art group \"Hermes,\" which performed live concerts of abstract electronic music with liquid light projections for 5 years in the early 1970s.\n\n\n\n\n"}
{"id": "392579", "url": "https://en.wikipedia.org/wiki?curid=392579", "title": "Hilbert's seventh problem", "text": "Hilbert's seventh problem\n\nHilbert's seventh problem is one of David Hilbert's list of open mathematical problems posed in 1900. It concerns the irrationality and transcendence of certain numbers (\"Irrationalität und Transzendenz bestimmter Zahlen\").\n\nTwo specific equivalent questions are asked:\n\n\nThe question (in the second form) was answered in the affirmative by Aleksandr Gelfond in 1934, and refined by Theodor Schneider in 1935. This result is known as Gelfond's theorem or the Gelfond–Schneider theorem. (The restriction to irrational \"b\" is important, since it is easy to see that formula_1 is algebraic for algebraic \"a\" and rational \"b\".)\n\nFrom the point of view of generalizations, this is the case\n\nof the general linear form in logarithms which was attacked by Gelfond and then solved by Alan Baker. It is called the Gelfond conjecture or Baker's theorem. Baker was awarded a Fields Medal in 1970 for this achievement.\n\n\n\n"}
{"id": "4059764", "url": "https://en.wikipedia.org/wiki?curid=4059764", "title": "Hong Kong Mathematical High Achievers Selection Contest", "text": "Hong Kong Mathematical High Achievers Selection Contest\n\nHong Kong Mathematical High Achievers Selection Contest (HKMHASC, Traditional Chinese: 香港青少年數學精英選拔賽) is a yearly mathematics competition for students of or below Secondary 3 in Hong Kong. It is jointly organized by Po Leung Kuk and Hong Kong Association of Science and Mathematics Education since the academic year 1998-1999. Recently, there are more than 250 secondary schools participating. \n\nEach participating school may send at most 5 students into the contest. There is one paper, divided into Part A and Part B, with two hours given. Part A is usually made up of 14 - 18 easier questions, carrying one mark each. In Part A, only answers are required. Part B is usually made up of 2 - 4 problems with different difficulties, and may carry different number of marks, varying from 4 to 8. In Part B, workings are required and marked. No calculators or calculation assisting equipments (e.g. printed mathematical tables) are allowed.\n\nAwards are given according to the total mark. The top 40 contestants are given the First Honour Award (一等獎), the next 80 the Second Honour Award (二等獎), and the Third Honour Award (三等獎) for the next 120. Moreover, the top 4 can obtain an award, namely the Champion and the 1st, 2nd and 3rd Runner-up. \n\nGroup Awards are given to schools, according to the sum of marks of the 3 contestants with highest mark. The first 4 are given the honour of Champion and 1st, 2nd and 3rd Runner-up. The honour of \"Top 10\" (首十名最佳成績) is given to the 5th-10th, and \"Group Merit Award\" (團體優異獎) is given to the next 10.\n\nFirst Honour Award achievers would receive further training. Eight students with best performance will be chosen to participate in the Invitational World Youth Mathematics Inter-City Competition (IWYMIC).\n\n\n\n"}
{"id": "14073367", "url": "https://en.wikipedia.org/wiki?curid=14073367", "title": "Institute of Mathematics of National Academy of Sciences of Armenia", "text": "Institute of Mathematics of National Academy of Sciences of Armenia\n\nThe Institute of Mathematics (Armenian: ) is owned and operated by the Armenian Academy of Sciences, located in Yerevan.\n\nThe Institute of Mathematics of National Academy of Sciences of Armenia originated as the Section for Mathematics and Mechanics, created within the newly formed Armenian Academy of Sciences in 1944. The section later developed into an Institute of Mathematics and Mechanics of Armenian Academy of Sciences, whose first Director was academician Artashes Shahinian, known for his results in complex analysis. The Institute of Mathematics of Armenian Academy of Sciences separated from the latter Institute in 1971. The bearer of the office of the Director of Institute has been academician Mkhitar Djrbashian (1971-1989, 1989-1994 Honorary Director).\n\nThe academicians Sergey Mergelyan, Norair Arakelian, Alexandr Talalyan, Raphayel Alexandrian, Rouben V. Ambartzumian and Anry Nersesyan also have greatly influenced the formation of the scientific profile of the Institute and largely contributed to mathematics in general. In particular Rouben V. Ambartzumian is famous for his work in Stochastic Geometry and Integral Geometry, where he created a new branch called Combinatorial Integral Geometry. He has provided solutions to a number of classical problems in particular the solution to the Buffon Sylvester problem as well as the Hilbert's fourth problem in dimensions 2 and 3.\n\nIn the early years, the investigations carried out in the Institute concentrated on Function Theory. Gradually the sphere of investigations expanded and now includes Differential and Integral Equations, Functional Analysis, Probability Theory and Mathematical Statistics.\n\nThe institute has a journal, \"Izvestia NAS RA Matematika\". The founder and the first Editor in Chief (1971–1990) of the journal was Mkhitar Djrbashian; under Rouben V. Ambartzumian Editor in Chief (1990 - 2010) the journal obtained international recognition and obtained an English version, \"Journal of Contemporary Mathematical Analysis\", published initially by Allerton Press, Inc. New York and later by Springer Science+Business Media. Journal covers a host of topics including: real analysis and complex analysis; approximation theory, boundary value problems; integral geometry and stochastic geometry; differential equations; probability and statistics; integral equations; algebra.\n\nAt present the Institute has about 30 main researchers as well as a number of associate researchers from Yerevan State University.\n\nNorair Arakelian in 1970 (Nice) and Mkhitar Djrbashian, Rouben V. Ambartzumian in 1974 (Vancouver) were invited speakers at the \nInternational Congresses of Mathematicians.\n\n\n"}
{"id": "29763944", "url": "https://en.wikipedia.org/wiki?curid=29763944", "title": "Invariant manifold", "text": "Invariant manifold\n\nIn dynamical systems, a branch of mathematics, an invariant manifold is a topological manifold that is invariant under the action of the dynamical system. Examples include the slow manifold, center manifold, stable manifold, unstable manifold, subcenter manifold and inertial manifold.\n\nTypically, although by no means always, invariant manifolds are constructed as a 'perturbation' of an invariant subspace about an equilibrium.\nIn dissipative systems, an invariant manifold based upon the gravest, longest lasting modes forms an effective low-dimensional, reduced, model of the dynamics.\nConsider the differential equation formula_1\nwith flow formula_2 being the solution of the differential equation with formula_3. \nA set formula_4 is called an \"invariant set\" for the differential equation if, for each formula_5, the solution formula_6, defined on its maximal interval of existence, has its image in formula_7. Alternatively, the orbit\npassing through each formula_5 lies in formula_7. In addition, formula_7 is called an \"invariant manifold\" if formula_7 is a manifold.\n\nFor any fixed parameter formula_12, consider the variables formula_13 governed by the pair of coupled differential equations\nThe origin is an equilibrium. This system has two invariant manifolds of interest through the origin. \n\nA differential equation \nrepresents a non-autonomous dynamical system, whose solutions are of the form formula_32 with formula_33. In the extended phase space formula_34 of such a system, any initial surface formula_35 generates an invariant manifold \nA fundamental question is then how one can locate, out of this large family of invariant manifolds, the ones that have the highest influence on the overall system dynamics. These most influential invariant manifolds in the extended phase space of a non-autonomous dynamical systems are known as Lagrangian Coherent Structures.\n"}
{"id": "5938558", "url": "https://en.wikipedia.org/wiki?curid=5938558", "title": "Isaac Milner", "text": "Isaac Milner\n\nIsaac Milner (11 January 1750 – 1 April 1820) was a mathematician, an inventor, the President of Queens' College, Cambridge and Lucasian Professor of Mathematics.\n\nHe was instrumental in the 1785 religious conversion of William Wilberforce and helped him through many trials and was a great supporter of the abolitionists' campaign against the slave trade, steeling Wilberforce with his assurance before the 1789 Parliamentary debate:\nHe was also a natural philosopher and the Dean of Carlisle.\n\nMilner was born on 11 January 1750 in Mabgate, Leeds. He began his education at a grammar school in Leeds in 1756, but this ended in 1760 with the death of his father. He was apprenticed as a weaver, reading the classics when time permitted, until his elder brother, Joseph Milner, provided him with an opportunity. Joseph was offered the mastership at Hull's grammar school and invited Isaac to become the institution's usher.\n\nThrough the patronage of his brother, Milner was subsequently freed from his duties in Hull and entered Queens' College, Cambridge, as a sizar in 1770. He graduated with a BA degree as senior wrangler in 1774, winning the Smith's first prize.\n\nShortly after he took his bachelor's degree he was ordained as deacon; in 1776 Queens' offered him a fellowship; in the following year he became a priest and college tutor; and in 1778 he was presented with the rectory of St Botolph's Church, Cambridge. However, he was a northerner at heart and thus was sent to reform the management of the Deanery of Carlisle. Taking a scientific approach to the Church of England's most northerly parishes he achieved success for the chapter and diocese. But Milner remained ambitious and seeking promotion he desired a return to Cambridge.\n\nDuring these years his career as a natural philosopher began to take off. In 1776 Nevil Maskelyne hired him as a computer for the board of longitude, and two of his mathematical papers were presented to the Royal Society, of which he was elected fellow in 1780. In these papers Milner displayed three things: proficiency in mathematics, suspicion of French philosophy, and adherence to English Newtonian mechanics. In 1782 the Jacksonian professorship of natural philosophy was established and the syndicate selected Milner as the inaugural professor, a position he retained until 1792.\n\nBesides lecturing, Milner also developed an important process to fabricate nitrous acid, a key ingredient in the production of gunpowder. His paper describing this process was published in the Royal Society's Philosophical Transactions in 1789 alongside an article of Joseph Priestley's, and the two corresponded on the subject. In later years Milner transferred his elaborate collection of chemical apparatus into the president's lodge at Queens' and performed experiments with E. D. Clarke, William Whewell, and the Wollaston brothers; he also collaborated with Humphry Davy and Joseph Banks in an attempt to cure gout.\n\nOver the span of his forty-five-year career, Milner's scientific sentiments came to reflect his religious sentiments strongly. Although he never parted from the Anglican fold, he came to embrace the central evangelical doctrines of the late eighteenth century. Milner, with Charles Simeon, was largely responsible for the evangelical revival at Cambridge in post as Master of Queens' College. Indeed, throughout the years of his tenure he dramatically changed the entire complexion of the college. He was also responsible for the conversion of William Wilberforce, which occurred during their long continental tour of 1784–5. The parliamentary act of 1807 to abolish slavery owed much to their partnership. Milner's co-authorship of the seven-volume \"Ecclesiastical History of the Church of Christ\" (1818) with his brother Joseph also earned him nationwide renown.\n\nAfter his death Milner was remembered for his astonishing intellect, his peculiar lifestyle, his tremendous physical bulk and his part in the rise in evangelicalism. Thomas De Quincey, in his preface to the Confessions, deemed Milner an 'eloquent and benevolent' opium user.\n\n"}
{"id": "50765752", "url": "https://en.wikipedia.org/wiki?curid=50765752", "title": "Kelmans–Seymour conjecture", "text": "Kelmans–Seymour conjecture\n\nIn graph theory, the Kelmans–Seymour conjecture states that every 5-vertex-connected graph that is not planar contains a subdivision of the 5-vertex complete graph . It is named for Paul Seymour and Alexander Kelmans, who independently described the conjecture; Seymour in 1977 and Kelmans in 1979.\n\nBy Kuratowski's theorem, a nonplanar graph necessarily contains a subdivision of either or the complete bipartite graph .\nThe conjecture refines this by providing a condition under which one of these two graphs can be guaranteed to exist. In this sense, it is the analogue for topological minors of Wagner's theorem that 4-connected nonplanar graphs contain as a graph minor.\n\nIn 2016, a proof was claimed by Xingxing Yu of the Georgia Institute of Technology and his Ph.D. students Dawei He and Yan Wang.\n\n"}
{"id": "39833214", "url": "https://en.wikipedia.org/wiki?curid=39833214", "title": "Kenneth Falconer (mathematician)", "text": "Kenneth Falconer (mathematician)\n\nKenneth John Falconer FRSE (born 25 January 1952) is a mathematician working in mathematical analysis and in particular on fractal geometry . He is Regius Professor of Mathematics in the School of Mathematics and Statistics at the University of St Andrews.\n\nHe is known for his work on the mathematics of fractals and in particular sets and measures arising from iterated function systems, especially self-similar and self-affine sets. Closely related is his research on\nHausdorff and other fractal dimensions. He formulated \"Falconer's conjecture\" on the dimension of distance sets and conceived the notion of a digital sundial. In combinatorial geometry he established a lower bound of 5 for the chromatic number of the plane in the Lebesgue measurable case.\n\nFalconer was educated at Kingston Grammar School, Kingston upon Thames and Corpus Christi College, Cambridge. He graduated in 1974 and completed his PhD in 1979 under the supervision of Hallard Croft. He was a Research Fellow at Corpus Christi College, Cambridge from 1977–1980 before moving to Bristol University. He was appointed Professor of Pure Mathematics at the University of St Andrews in 1993 and was Head of the School of Mathematics and Statistics from 2001-2004. He was elected a Fellow of the Royal Society of Edinburgh in 1998. He served on the Council of the London Mathematical Society from 2000-2009 including as Publications Secretary from 2006-2009.\n\nHis recreational interests include long distance walking and hill walking. He was Chair of the Long Distance Walkers Association from 2000–03 and Editor of their journal Strider from 1987–92 and 2007-12. He has twice climbed all the Munros as well as all the Corbetts.\n\n\n"}
{"id": "40862848", "url": "https://en.wikipedia.org/wiki?curid=40862848", "title": "Linear equation over a ring", "text": "Linear equation over a ring\n\nIn algebra, linear equations and systems of linear equations over a field are widely studied. \"Over a field\" means that the coefficients of the equations and the solutions that one is looking for belong to a given field, commonly the real or the complex numbers. This article is devoted to the same problems where \"field\" is replaced by \"commutative ring\", or, typically \"Noetherian integral domain\".\n\nIn the case of a single equation, the problem splits in two parts. First, the ideal membership problem, which consists, given a non homogeneous equation\nwith formula_2 and in a given ring , to decide if it has a solution with formula_3 in , and, if any, to provide one. This amounts to decide if belongs to the ideal generated by the . The simplest instance of this problem is, for \"k\" = 1 and , to decide if is a unit in .\n\nThe syzygy problem consists, given \"k\" elements formula_2 in , to provide a system of generators of the module of the syzygies of formula_5 that is a system of generators of the submodule of those elements formula_6 in that are solution of the homogeneous equation\nThe simplest case, when \"k\" = 1 amounts to find a system of generators of the annihilator of .\n\nGiven a solution of the ideal membership problem, one obtains all the solutions by adding to it the elements of the module of syzygies. In other words, all the solutions are provided by the solution of these two partial problems.\n\nIn the case of several equations, the same decomposition into subproblems occurs. The first problem becomes the submodule membership problem. The second one is also called the syzygy problem.\n\nA ring such that there are algorithms for the arithmetic operations (addition, subtraction, multiplication) and for the above problems may be called a computable ring, or effective ring. One may also say that linear algebra on the ring is effective.\n\nThe article considers the main rings for which linear algebra is effective.\n\nTo be able of solving the syzygy problem, it is necessary that the module of syzygies is finitely generated, because it is impossible to output an infinite list. Therefore the problems considered here make sense only for Noetherian rings, or at least a coherent ring. In fact, this article is restricted to Noetherian integral domains because of the following result.\n\n\"Given a Noetherian integral domain, if there are algorithms to solve the ideal membership problem and the syzygies problem for a single equation, then one may deduce from them algorithms for the similar problems concerning systems of equations.\"\n\nThis theorem is useful to prove the existence of algorithms. However, in practice, the algorithms for the systems are designed directly, as it is done for the systems of linear equations over a field.\n\nLet \"R\" be an effective commutative ring. \n\nThere are algorithms to solve all the problems addressed in this article over the integers. In other words, \"linear algebra is effective over the integers\". See Linear Diophantine system for details.\n\nThe same solution applies to the same problems over a principal ideal domain, with the following modifications.\n\nThe notion of unimodular matrix of integers must be extended by calling \"unimodular\" a matrix over a integral domain whose determinant is a unit. This means that the determinant is invertible and implies that unimodular matrices are the invertible matrices such all entries of the inverse matrix belong to the domain.\n\nTo have an algorithmic solution of linear systems, a solution for a single linear equation in two unknowns is clearly required. In the case of the integers, such a solution is provided by extended Euclidean algorithm. Thus one needs that, for the considered principal ideal domain, there is an algorithm with a similar specification as the extended Euclidean algorithm. That is, given \"a\" and \"b\" in the principal ideal domain, there is an algorithm computing a unimodular matrix \nsuch that \n\nHaving such an algorithm, the Smith normal form of a matrix may be computed exactly as in the integer case, and this suffices to apply the method of Linear Diophantine system.\n\nThe main case where this is commonly used is the case of linear systems over the ring of univariate polynomials over a field. In this case, the extended Euclidean algorithm may be used. See polynomial greatest common divisor#Bézout's identity and extended GCD algorithm for details.\n\n"}
{"id": "6563304", "url": "https://en.wikipedia.org/wiki?curid=6563304", "title": "Linux Unified Key Setup", "text": "Linux Unified Key Setup\n\nThe Linux Unified Key Setup (LUKS) is a disk encryption specification created by Clemens Fruhwirth in 2004 and originally intended for Linux.\n\nWhile most disk encryption software implements different, incompatible, and undocumented formats, LUKS implements a platform-independent standard on-disk format for use in various tools. This not only facilitates compatibility and interoperability among different programs, but also assures that they all implement password management in a secure and documented manner.\n\nThe reference implementation for LUKS operates on Linux and is based on an enhanced version of cryptsetup, using dm-crypt as the disk encryption backend. Under Microsoft Windows, LUKS-encrypted disks can be used with the now defunct LibreCrypt (formerly DoxBox).\n\nLUKS is designed to conform to the TKS1 secure key setup scheme.\n\n\n"}
{"id": "29232472", "url": "https://en.wikipedia.org/wiki?curid=29232472", "title": "List of Russian mathematicians", "text": "List of Russian mathematicians\n\nThis list of Russian mathematicians includes the famous mathematicians from the Russian Empire, the Soviet Union and the Russian Federation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "46504340", "url": "https://en.wikipedia.org/wiki?curid=46504340", "title": "Macaulay representation of an integer", "text": "Macaulay representation of an integer\n\nGiven positive integers formula_1 and formula_2, the formula_2-th Macaulay representation of formula_1 is an expression for formula_1 as a sum of binomial coefficients:\nHere, formula_7 is a uniquely determined, strictly increasing sequence of nonnegative integers known as the Macaulay coefficients. For any two positive integers formula_8 and formula_9, formula_10 if and only if the sequence of Macaulay coefficients for formula_8 comes before the sequence of Macaulay coefficients for formula_9 in lexicographic order.\n\n"}
{"id": "3758605", "url": "https://en.wikipedia.org/wiki?curid=3758605", "title": "Martingale representation theorem", "text": "Martingale representation theorem\n\nIn probability theory, the martingale representation theorem states that a random variable that is measurable with respect to the filtration generated by a Brownian motion can be written in terms of an Itô integral with respect to this Brownian motion.\n\nThe theorem only asserts the existence of the representation and does not help to find it explicitly; it is possible in many cases to determine the form of the representation using Malliavin calculus.\n\nSimilar theorems also exist for martingales on filtrations induced by jump processes, for example, by Markov chains.\n\nLet formula_1 be a Brownian motion on a standard filtered probability space formula_2 and let formula_3 be the augmented filtration generated by formula_4. If \"X\" is a square integrable random variable measurable with respect to formula_5, then there exists a predictable process \"C\" which is adapted with respect to formula_3, such that\n\nConsequently,\n\nThe martingale representation theorem can be used to establish the existence\nof a hedging strategy.\nSuppose that formula_9 is a Q-martingale process, whose volatility formula_10 is always non-zero.\nThen, if formula_11 is any other Q-martingale, there exists an formula_12-previsible process formula_13, unique up to sets of measure 0, such that formula_14 with probability one, and \"N\" can be written as:\n\nThe replicating strategy is defined to be:\nwhere formula_18 is the stock price discounted by the bond price to time formula_19 and formula_20 is the expected payoff of the option at time formula_19.\n\nAt the expiration day \"T\", the value of the portfolio is:\n\nand it's easy to check that the strategy is self-financing: the change in the value of the portfolio only depends on the change of the asset prices formula_23.\n\n"}
{"id": "26359063", "url": "https://en.wikipedia.org/wiki?curid=26359063", "title": "Minimalist grammar", "text": "Minimalist grammar\n\nMinimalist grammars are a class of formal grammars that aim to provide a more rigorous, usually proof-theoretic, formalization of Chomskyan Minimalist program than is normally provided in the mainstream Minimalist literature. A variety of particular formalizations exist, most of them developed by Edward Stabler, Alain Lecomte, Christian Retoré, or combinations thereof. \n\nLecomte and Retoré (2001) introduce a formalism that modifies that core of the Lambek Calculus to allow for movement-like processes to be described without resort to the combinatorics of Combinatory categorial grammar. The formalism is presented in proof-theoretic terms. Differing only slightly in notation from Lecomte and Retoré (2001), we can define a minimalist grammar as a 3-tuple formula_1, where formula_2 is a set of \"categorial\" features, formula_3 is a set of \"functional\" features (which come in two flavors, \"weak\", denoted simply formula_4, and \"strong\", denoted formula_5), and formula_6 is a set of lexical atoms, denoted as pairs formula_7, where formula_8 is some phonological/orthographic content, and formula_9 is a syntactic type defined recursively as follows:\n\nWe can now define 6 inference rules:\n\nThe first rule merely makes it possible to use lexical items with no extra assumptions. The second rule is just a means of introducing assumptions into the derivation. The third and fourth rules just perform directional feature checking, combining the assumptions required to build the subparts that are being combined. The entropy rule presumably allows the ordered sequents to be broken up into unordered sequents. And finally, the last rule implements \"movement\" by means of assumption elimination.\n\nThe last rule can be given a number of different interpretations in order to fully mimic movement of the normal sort found in the Minimalist Program. The account given by Lecomte and Retoré (2001) is that if one of the product types is a strong functional feature, then the phonological/orthographic content associated with that type on the right is substituted with the content of the \"a\", and the other is substituted with the empty string; whereas if neither is strong, then the phonological/orthographic content is substituted for the category feature, and the empty string is substituted for the weak functional feature. That is, we can rephrase the rule as two sub-rules as follows:\n\nAnother alternative would be to construct pairs in the \"/E\" and \"\\E\" steps, and use the formula_29 rule as given, substituting the phonological/orthographic content \"a\" into the highest of the substitution positions, and the empty string in the rest of the positions. This would be more in line with the Minimalist Program, given that multiple movements of an item are possible, where only the highest position is \"spelled out\".\n\nAs a simple example of this system, we can show how to generate the sentence \"who did John see\" with the following toy grammar:\n\nLet formula_30, where \"L\" contains the following words:\n\nThe proof for the sentence \"who did John see\" is therefore:\n\n"}
{"id": "13034946", "url": "https://en.wikipedia.org/wiki?curid=13034946", "title": "Modified Dietz method", "text": "Modified Dietz method\n\nThe modified Dietz method is a measure of the \"ex post\" (i.e. historical) performance of an investment portfolio in the presence of external flows. (External flows are movements of value such as transfers of cash, securities or other instruments in or out of the portfolio, with no equal simultaneous movement of value in the opposite direction, and which are not income from the investments in the portfolio, such as interest, coupons or dividends.) To calculate the modified Dietz return, divide the gain or loss in value, net of external flows, by the average capital over the period of measurement. The result of the calculation is expressed as a percentage return over the holding period. The average capital weights individual cash flows by the amount of time from when those cash flows occur until the end of the period.\n\nThis method has the practical advantage over internal rate of return (IRR) method that it does not require repeated trial and error to get a result.\n\nThe cash flows used in the formula are weighted based on the time they occurred in the period. For example, if they occurred in the beginning of the month they would have a higher weight than if they occurred at the end of the month. This is different from the simple Dietz method, in which the cash flows are weighted equally regardless of when they occurred during the measurement period, which works on an assumption that the flows are distributed evenly throughout the period.\n\nWith the advance of technology, most systems can calculate a true time-weighted return by calculating a daily return and geometrically linking in order to get a monthly, quarterly, annual or any other period return. However, the modified Dietz method remains useful for performance attribution, because it still has the advantage of allowing modified Dietz returns on assets to be combined with weights in a portfolio, calculated according to average invested capital, and the weighted average gives the modified Dietz return on the portfolio. Time weighted returns do not allow this.\n\nThis method for return calculation is used in modern portfolio management. It is one of the methodologies of calculating returns recommended by the Investment Performance Council (IPC) as part of their Global Investment Performance Standards (GIPS). The GIPS are intended to provide consistency to the way portfolio returns are calculated internationally.\n\nThe method is named after Peter O. Dietz. The original idea behind the work of Peter Dietz was to find a quicker, less computer-intensive way of calculating an IRR as the iterative approach using the then quite slow computers that were available was taking a significant amount of time; the research was produced for BAI, Bank Administration institute.\n\nHis approximation was therefore to generate money weighted rates of return for the period. Because there is a GIPS requirement to produce a valuation on a monthly basis at least, using modified Dietz with monthly valuations provides a series of individual monthly money-weighted rates with which can be compounded together to produce a good quality approximation for the longer time period time weighted rate of return \n\nThe formula for the modified Dietz method is as follows:\n\nwhere\n\nand\n\nThe weight formula_7 is the proportion of the time period between the point in time when the flow formula_6 occurs and the end of the period. Assuming that the flow happens at the end of the day, formula_7 can be calculated as\n\nwhere\n\nThis assumes that the flow happens at the end of the day. If the flow happens at the beginning of the day, the flow is in the portfolio for an additional day, so use the following formula for calculating the weight: \n\nIf either the start or the end value is zero, or both, the start and/or end dates need to be adjusted to cover the period over which the portfolio has content.\n\nSuppose we are calculating the 2016 calendar year return, and that the portfolio is empty until a transfer in of EUR 1m cash in a non-interest bearing account on Friday 30 December. By the end of the day on Saturday 31 December 2016, the exchange rate between euros and Hong Kong dollars has changed from 8.1 HKD per EUR to 8.181, which is a 1 percent increase in value, measured in Hong Kong dollar terms, so the right answer to the question of what is the return in Hong Kong dollars is intuitively 1 percent.\n\nHowever, blindly applying the modified Dietz formula, using an end-of-day transaction timing assumption, the day-weighting on the inflow of 8.1m HKD on 30 December, one day before the end of the year, is 1/366, and the average capital is calculated as:\n\nand the gain is:\n\nso the modified Dietz return is calculated as:\n\nSo which is the correct return, 1 percent or 366 percent?\n\nThe only sensible answer to the example above is that the holding period return is unambiguously 1 percent. This means the start date should be adjusted to the date of the initial external flow. Likewise, if the portfolio is empty at the end of the period, the end date should be adjusted to the final external flow. The end value is effectively the final external flow, not zero.\n\nThe return annualized using a simple method of multiplying-up 1 percent per day by the number of days in the year will give the answer 366 percent, but the holding period return is still 1 percent.\n\nThe example above is corrected if the start date is adjusted to the end of the day on 30 December, and the start value is now 8.1m HKD. There are no external flows thereafter.\n\nThe corrected gain or loss is the same as before:\n\nbut the corrected average capital is now:\n\nso the corrected modified Dietz return is now:\n\nSuppose that a bond is bought for HKD 1,128,728 including accrued interest and commission on trade date 14 November, and sold again three days later on trade date 17 November for HKD 1,125,990 (again, net of accrued interest and commission). Assuming transactions take place at the start of the day, what is the modified Dietz holding-period return in HKD for this bond holding over the year to-date until the end-of-day on 17 November?\n\nThe answer is that firstly, the reference to the holding period year to-date until the end-of-day on 17 November includes both the purchase and the sale. This means the effective adjusted holding period is actually from the purchase at the start of the day on 14 November until it is sold three days later on 17 November. The adjusted start value is the net amount of the purchase, the end value is the net amount of the sale, and there are no other external flows.\n\nThere are no flows, so the gain or loss is:\n\nand the average capital equals the start value, so the modified Dietz return is:\n\nThis method of restricting the calculation to the actual holding period by applying an adjusted start or end date applies when the return is calculated on an investment in isolation. When the investment belongs inside a portfolio, and the weight of the investment in the portfolio, and the contribution of that return to that of the portfolio as a whole is required, it is necessary to compare like with like, in terms of a common holding period.\n\nSuppose that at the beginning of the year, a portfolio contains cash, of value $10,000, in an account which bears interest without any charges. At the beginning of the third quarter, $8,000 of that cash is invested in some US dollar shares (in company X). The investor applies a buy-and-hold strategy, and there are further transactions for the remainder of the year. At the end of the year, the shares have increased in value by 10% to $8,800, and $100 interest is capitalized into the cash account.\n\nWhat is the return on the portfolio and the cash account over the year, and what are the contributions from the cash account and the shares? Furthermore, what is the return on the cash account?\n\nThe end value of the portfolio is $2,100 in cash, plus shares worth $8,800, which is in total $10,900. There has been a 9 percent increase in value since the beginning of the year. There are no external flows in or out of the portfolio over the year.\n\nso\n\nso the return is:\n\nThis 9% portfolio return breaks down between 8 percent contribution from the $800 earned on the shares and 1 percent contribution from the $100 interest earned on the cash account, but how more generally can we calculate contributions?\n\nThe first step is to calculate the average capital in each of the cash account and the shares over the full year period. These should sum to the $10,000 average capital of the portfolio as a whole. From the average capital of each of the two components of the portfolio, we can calculate weights. The weight of the cash account is the average capital of the cash account, divided by the average capital ($10,000) of the portfolio, and the weight of the shares is the average capital of the shares over the whole year, divided by the average capital of the portfolio.\n\nFor convenience, we will assume the time weight of the outflow of $8,000 cash to pay for the shares is exactly 1/4. This means that the four quarters of the year are treated as having equal length.\n\nThe average capital of the cash account is:\n\nThe average capital of the shares over the last quarter requires no calculation, because there are no flows after the beginning of the last quarter. It is the $8,000 invested in the shares. However, the average capital in the shares over the whole year is something else. The start value of the shares at the beginning of the year was zero, and there was an inflow of $8,000 at the beginning of the last quarter, so:\n\nWe can see immediately that the weight of the cash account in the portfolio over the year was:\n\nand the weight of the shares was:\n\nwhich sum to 100 percent.\n\nWe can calculate the return on the cash account, which was:\n\nThe contribution to the portfolio return is:\n\nHow about the contribution to the portfolio return from the shares?\n\nThe adjusted holding period return on the shares is 10 percent. If we multiply this by the 20 percent weight of the shares in the portfolio, the result is only 2 percent, but the correct contribution is 8 percent.\n\nThe answer is to use the return on the shares over the unadjusted full-year period to calculate the contribution:\n\nThen the contribution from the shares to the portfolio return is:\n\nThis does not mean that the correct holding period return on the shares is 40 percent, but for calculation of the contribution, use the unadjusted period return, which is the 40 percent figure, not the actual 10 percent holding period return.\n\nTo measure returns net of fees, allow the value of the portfolio to be reduced by the amount of the fees. To calculate returns gross of fees, compensate for them by treating them as an external flow, and exclude accrued fees from valuations.\n\nThe modified Dietz method has the practical advantage over the true time-weighted rate of return method, in that the calculation of a modified Dietz return does not require portfolio valuations at each point in time whenever an external flow occurs. The internal rate of return method shares this practical advantage with the modified Dietz method.\n\nThe modified Dietz method has the practical advantage over the internal rate of return method, in that there is a formula for the modified Dietz return, whereas iterative numerical methods are usually required to estimate the internal rate of return.\n\nThe modified Dietz method is based upon a simple rate of interest principle. It approximates the internal rate of return method, which applies a compounding principle, but if the flows and rates of return are large enough, the results of the Modified Dietz method will significantly diverge from the internal rate of return.\n\nThe modified Dietz return is the solution formula_16 to the equation:\n\nwhere\n\nand\n\nCompare this with the (unannualized) internal rate of return (IRR). The IRR (or more strictly speaking, an un-annualized holding period return version of the IRR) is a solution formula_16 to the equation:\n\nFor example, suppose the value of a portfolio is $100 at the beginning of the first year, and $300 at the end of the second year, and there is an inflow of $50 at the end of the first year/beginning of the second year. (Suppose further that neither year is a leap year, so the two years are of equal length.)\n\nTo calculate the gain or loss over the two-year period,\n\nTo calculate the average capital over the two-year period,\n\nso the modified Dietz return is:\n\nThe (unannualized) internal rate of return in this example is 125%:\n\nso in this case, the modified Dietz return is noticeably less than the unannualized IRR. This divergence between the modified Dietz return and the unannualized internal rate of return is due to a significant flow within the period, and the fact that the returns are large.\n\nNote that the Modified Dietz return is a holding-period return, not an annual rate of return, unless the period happens to be one year. Annualisation, which is conversion of the holding-period return to an annual rate of return, is a separate process.\n\nNote also that the simple Dietz method is a special case of the Modified Dietz method, in which external flows are assumed to occur at the midpoint of the period, or equivalently, spread evenly throughout the period, whereas no such assumption is made when using the Modified Dietz method, and the timing of any external flows is taken into account.\n\nThe modified Dietz method is an example of a money (or dollar) weighted methodology. In particular, if the modified Dietz return on two portfolios are formula_29 and formula_30, measured over a common matching time interval, then the modified Dietz return on the two portfolios put together over the same time interval is the weighted average of the two returns:\n\nwhere the weights of the portfolios depend on the average capital over the time interval:\n\nAn alternative to the modified Dietz method is to link geometrically the modified Dietz returns for shorter periods. The linked modified Dietz method is classed as a time-weighted method, but it does not produce the same results as the true time weighted method, which requires valuations at the time of each cash flow.\n\nThere are sometimes difficulties when calculating or decomposing portfolio returns, if all transactions are treated as occurring at a single time of day, such as the end of the day or beginning of the day. Whatever method is applied to calculate returns, an assumption that all transactions take place simultaneously at a single point in time each day can lead to errors.\n\nFor example, consider a scenario where a portfolio is empty at the start of a day, so that the start value A is zero. There is then an external inflow during a day of F = $100. By the close of the day, market prices have moved, and the end value is $99.\n\nIf all transactions are treated as occurring at the end of the day, then there is zero start value A, and zero value for average capital, because the day-weight on the inflow is zero, so no modified Dietz return can be calculated.\n\nSome such problems are resolved if the modified Dietz method is further adjusted so as to put purchases at the open and sales at the close, but more sophisticated exception-handling produces better results.\n\nThere are sometimes other difficulties when decomposing portfolio returns, if all transactions are treated as occurring at a single point during the day.\n\nFor example, consider a fund opening with just $100 of a single stock that is sold for $110 during the day. During the same day, another stock is purchased for $110, closing with a value of $120. The returns on each stock are 10% and 120/110 - 1 = 9.0909% (4 d.p.) and the portfolio return is 20%. The asset weights \"w\" (as opposed to the time weights \"W\") required to get the returns for these two assets to roll up to the portfolio return are 1200% for the first stock and a negative 1100% for the second:\n\nSuch weights are absurd, because the second stock is not held short.\n\nThe problem only arises because the day is treated as a single, discrete time interval.\n\nIn normal circumstances, average capital is positive. When an intra-period outflow is large and early enough, average capital can be negative or zero. Negative average capital causes the Modified Dietz return to be negative when there is a profit, and positive when there is a loss. This resembles the behaviour of a liability or short position, even if the investment is not actually a liability or a short position. In cases where the average capital is zero, no Modified Dietz return can be calculated. If the average capital is close to zero, the Modified Dietz will be large (large and positive, or large and negative).\n\nOne partial workaround solution involves as a first step, to capture the exception, detecting for example when the start value (or first inflow) is positive, and the average capital is negative. Then in this case, use the simple return method, adjusting the end value for outflows. This is equivalent to the sum of constituent contributions, where the contributions are based on simple returns and weights depending on start values.\n\nFor example, in a scenario where only part of the holdings are sold, for significantly more than the total starting value, relatively early in the period:\n\nThe gain or loss is end value - start value + outflow:\n\nThere is a gain, and the position is long, so we would intuitively expect a positive return.\n\nThe average capital in this case is:\n\nThe modified Dietz return in this case goes awry, because the average capital is negative, even though this is a long position. The Modified Dietz return in this case is:\n\nInstead, we notice that the start value is positive, but the average capital is negative. Furthermore, there is no short sale. In other words, at all times, the number of shares held is positive. \n\nWe then measure the simple return from the shares sold:\n\nand from the shares still held at the end:\n\nand combine these returns with the weights of these two portions of the shares within the starting position, which are:\n\nThis gives the contributions to the overall return, which are:\n\nThe sum of these contributions is the return:\n\nThis is equivalent to the simple return, adjusting the end value for outflows:\n\nThis workaround has limitations. It is possible only if the holdings can be split up like this. \n\nIt is not ideal, for two further reasons, which are that it does not cover all cases, and it is inconsistent with the Modified Dietz method. Combined with Modified Dietz contributions for other assets, the sum of constituent contributions will fail to add up to the overall return.\n\nAnother situation in which average capital can be negative is short selling. Instead of investing by buying shares, shares are borrowed and then sold. A decline in the share price results in a profit instead of a loss. The position is a liability instead of an asset. If the profit is positive, and the average capital is negative, the Modified Dietz return is negative, indicating that although the number of shares is unchanged, the absolute value of the liability has shrunk.\n\nIn the case of a purchase, followed by a sale of more shares than had been bought, resulting in a short position (a negative number of shares), the average capital can also be negative. What was an asset at the time of the purchase became a liability after the sale. The interpretation of the Modified Dietz return varies from one situation to another.\n\nPublic Function MDIETZ(dStartValue As Double, dEndValue As Double, iPeriod As Integer, rCash As Range, rDays As Range) As Double\n\nEnd Function\n\n"}
{"id": "1352428", "url": "https://en.wikipedia.org/wiki?curid=1352428", "title": "Modulo operation", "text": "Modulo operation\n\nIn computing, the modulo operation finds the remainder after division of one number by another (sometimes called \"modulus\").\n\nGiven two positive numbers, (the dividend) and (the divisor), modulo (abbreviated as ) is the remainder of the Euclidean division of by . For example, the expression \"5 mod 2\" would evaluate to 1 because 5 divided by 2 leaves a quotient of 2 and a remainder of 1, while \"9 mod 3\" would evaluate to 0 because the division of 9 by 3 has a quotient of 3 and leaves a remainder of 0; there is nothing to subtract from 9 after multiplying 3 times 3. (Note that doing the division with a calculator will not show the result referred to here by this operation; the quotient will be expressed as a decimal fraction.)\n\nAlthough typically performed with and both being integers, many computing systems allow other types of numeric operands. The range of numbers for an integer modulo of is 0 to . ( mod 1 is always 0; is undefined, possibly resulting in a division by zero error in programming languages.) See modular arithmetic for an older and related convention applied in number theory.\n\nWhen either or is negative, the naive definition breaks down and programming languages differ in how these values are defined.\n\nIn mathematics, the result of the modulo operation is the remainder of the Euclidean division. However, other conventions are possible. Computers and calculators have various ways of storing and representing numbers; thus their definition of the modulo operation depends on the programming language or the underlying hardware.\n\nIn nearly all computing systems, the quotient and the remainder of divided by satisfy\n\nHowever, this still leaves a sign ambiguity if the remainder is nonzero: two possible choices for the remainder occur, one negative and the other positive, and two possible choices for the quotient occur. Usually, in number theory, the positive remainder is always chosen, but programming languages choose depending on the language and the signs of or . Standard Pascal and ALGOL 68 give a positive remainder (or 0) even for negative divisors, and some programming languages, such as C90, leave it to the implementation when either of or is negative. See the table for details. modulo 0 is undefined in most systems, although some do define it as .\n\nAs described by Leijen,\nHowever, Boute concentrates on the properties of the modulo operation itself and does not rate the fact that the truncated division shows the symmetry and , which is similar to the ordinary division. As neither floor division nor Euclidean division offer this symmetry, Boute's judgement is at least incomplete.\n\nWhen the result of a modulo operation has the sign of the dividend, it can lead to surprising mistakes.\n\nFor example, to test if an integer is odd, one might be inclined to test if the remainder by 2 is equal to 1:\n\nBut in a language where modulo has the sign of the dividend, that is incorrect, because when (the dividend) is negative and odd, mod 2 returns −1, and the function returns false.\n\nOne correct alternative is to test that it is not 0 (because remainder 0 is the same regardless of the signs):\n\nOr, by understanding in the first place that for any odd number, the modulo remainder may be either 1 or −1:\n\nSome calculators have a function button, and many programming languages have a similar function, expressed as , for example. Some also support expressions that use \"%\", \"mod\", or \"Mod\" as a modulo or remainder operator, such as\nor\nor equivalent, for environments lacking a function (note that 'int' inherently produces the truncated value of )\n\nModulo operations might be implemented such that a division with a remainder is calculated each time. For special cases, on some hardware, faster alternatives exist. For example, the modulo of powers of 2 can alternatively be expressed as a bitwise AND operation:\n\nExamples (assuming is a positive integer):\n\nIn devices and software that implement bitwise operations more efficiently than modulo, these alternative forms can result in faster calculations.\n\nOptimizing compilers may recognize expressions of the form codice_8 where codice_9 is a power of two and automatically implement them as codice_10. This can allow writing clearer code without compromising performance. This optimization is not possible for languages in which the result of the modulo operation has the sign of the dividend (including C), unless the dividend is of an unsigned integer type. This is because, if the dividend is negative, the modulo will be negative, whereas codice_10 will always be positive.\n\nSome modulo operations can be factored or expanded similarly to other mathematical operations. This may be useful in cryptography proofs, such as the Diffie–Hellman key exchange.\n\n\n"}
{"id": "314493", "url": "https://en.wikipedia.org/wiki?curid=314493", "title": "Möbius transformation", "text": "Möbius transformation\n\nIn geometry and complex analysis, a Möbius transformation of the complex plane is a rational function of the form\n\nof one complex variable \"z\"; here the coefficients \"a\", \"b\", \"c\", \"d\" are complex numbers satisfying \"ad\" − \"bc\" ≠ 0.\n\nGeometrically, a Möbius transformation can be obtained by first performing stereographic projection from the plane to the unit two-sphere, rotating and moving the sphere to a new location and orientation in space, and then performing stereographic projection (from the new position of the sphere) to the plane.\nThese transformations preserve angles, map every straight line to a line or circle, and map every circle to a line or circle.\n\nThe Möbius transformations are the projective transformations of the complex projective line. They form a group called the Möbius group, which is the projective linear group PGL(2,C). Together with its subgroups, it has numerous applications in mathematics and physics.\n\nMöbius transformations are named in honor of August Ferdinand Möbius; they are also variously named homographies, homographic transformations, linear fractional transformations, bilinear transformations, or fractional linear transformations.\n\nMöbius transformations are defined on the extended complex plane formula_2 (i.e., the complex plane augmented by the point at infinity).\n\nStereographic projection identifies formula_3 with a sphere, which is then called the Riemann sphere; alternatively, formula_3 can be thought of as the complex projective line formula_5. The Möbius transformations are exactly the bijective conformal maps from the Riemann sphere to itself, i.e., the automorphisms of the Riemann sphere as a complex manifold; alternatively, they are the automorphisms of formula_5 as an algebraic variety. Therefore, the set of all Möbius transformations forms a group under composition. This group is called the Möbius group, and is sometimes denoted formula_7.\n\nThe Möbius group is isomorphic to the group of orientation-preserving isometries of hyperbolic 3-space and therefore plays an important role when studying hyperbolic 3-manifolds.\n\nIn physics, the identity component of the Lorentz group acts on the celestial sphere in the same way that the Möbius group acts on the Riemann sphere. In fact, these two groups are isomorphic. An observer who accelerates to relativistic velocities will see the pattern of constellations as seen near the Earth continuously transform according to infinitesimal Möbius transformations. This observation is often taken as the starting point of twistor theory.\n\nCertain subgroups of the Möbius group form the automorphism groups of the other simply-connected Riemann surfaces (the complex plane and the hyperbolic plane). As such, Möbius transformations play an important role in the theory of Riemann surfaces. The fundamental group of every Riemann surface is a discrete subgroup of the Möbius group (see Fuchsian group and Kleinian group).\nA particularly important discrete subgroup of the Möbius group is the modular group; it is central to the theory of many fractals, modular forms, elliptic curves and Pellian equations.\n\nMöbius transformations can be more generally defined in spaces of dimension \"n\">2 as the bijective conformal orientation-preserving maps from the \"n\"-sphere to the \"n\"-sphere. Such a transformation is the most general form of conformal mapping of a domain. According to Liouville's theorem a Möbius transformation can be expressed as a composition of translations, similarities, orthogonal transformations and inversions.\n\nThe general form of a Möbius transformation is given by\nwhere \"a\", \"b\", \"c\", \"d\" are any complex numbers satisfying . If , the rational function defined above is a constant since\nand is thus not considered a Möbius transformation.\n\nIn case , this definition is extended to the whole Riemann sphere by defining\n\nIf , we define\n\nThus a Möbius transformation is always a bijective holomorphic function from the Riemann sphere to the Riemann sphere.\n\nThe set of all Möbius transformations forms a group under composition. This group can be given the structure of a complex manifold in such a way that composition and inversion are holomorphic maps. The Möbius group is then a complex Lie group. The Möbius group is usually denoted formula_12 as it is the automorphism group of the Riemann sphere.\n\nEvery non-identity Möbius transformation has two fixed points formula_13 on the Riemann sphere. Note that the fixed points are counted here with multiplicity; the parabolic transformations are those where the fixed points coincide. Either or both of these fixed points may be the point at infinity.\n\nThe fixed points of the transformation\nare obtained by solving the fixed point equation f(γ) = γ. For \"c\" ≠ 0, this has two roots obtained by expanding this equation to\nand applying the quadratic formula. The roots are\nwith discriminant\nParabolic transforms have coincidental fixed points due to zero discriminant. For \"c\" nonzero and nonzero discriminant the transform is elliptic or hyperbolic.\n\nWhen \"c\" = 0, the quadratic equation degenerates into a linear equation and the transform is linear. This corresponds to the situation that one of the fixed points is the point at infinity. When \"a\" ≠ \"d\" the second fixed point is finite and is given by\n\nIn this case the transformation will be a simple transformation composed of translations, rotations, and dilations:\n\nIf \"c\" = 0 and \"a\" = \"d\", then both fixed points are at infinity, and the Möbius transformation corresponds to a pure translation:\n\nTopologically, the fact that (non-identity) Möbius transformations fix 2 points (with multiplicity) corresponds to the Euler characteristic of the sphere being 2:\n\nFirstly, the projective linear group PGL(2,\"K\") is sharply 3-transitive – for any two ordered triples of distinct points, there is a unique map that takes one triple to the other, just as for Möbius transforms, and by the same algebraic proof (essentially dimension counting, as the group is 3-dimensional). Thus any map that fixes at least 3 points is the identity.\n\nNext, one can see by identifying the Möbius group with formula_22 that any Möbius function is homotopic to the identity. Indeed, any member of the general linear group can be reduced to the identity map by Gauss-Jordan elimination, this shows that the projective linear group is path-connected as well, providing a homotopy to the identity map.The Lefschetz–Hopf theorem states that the sum of the indices (in this context, multiplicity) of the fixed points of a map with finitely many fixed points equals the Lefschetz number of the map, which in this case is the trace of the identity map on homology groups, which is simply the Euler characteristic.\n\nBy contrast, the projective linear group of the real projective line, PGL(2,R) need not fix any points – for example formula_23 has no (real) fixed points: as a complex transformation it fixes ±\"i\" – while the map 2\"x\" fixes the two points of 0 and ∞. This corresponds to the fact that the Euler characteristic of the circle (real projective line) is 0, and thus the Lefschetz fixed-point theorem says only that it must fix at least 0 points, but possibly more.\n\nMöbius transformations are also sometimes written in terms of their fixed points in so-called normal form. We first treat the non-parabolic case, for which there are two distinct fixed points.\n\n\"Non-parabolic case\":\n\nEvery non-parabolic transformation is conjugate to a dilation/rotation, i.e. a transformation of the form\n\n(\"k\" ∈ C) with fixed points at 0 and ∞. To see this define a map\n\nwhich sends the points (γ, γ) to (0, ∞). Here we assume that γ and γ are distinct and finite. If one of them is already at infinity then \"g\" can be modified so as to fix infinity and send the other point to 0.\n\nIf \"f\" has distinct fixed points (γ, γ) then the transformation formula_26 has fixed points at 0 and ∞ and is therefore a dilation: formula_27. The fixed point equation for the transformation \"f\" can then be written\n\nSolving for \"f\" gives (in matrix form):\n\nor, if one of the fixed points is at infinity:\n\nFrom the above expressions one can calculate the derivatives of \"f\" at the fixed points:\n\nObserve that, given an ordering of the fixed points, we can distinguish one of the multipliers (\"k\") of \"f\" as the characteristic constant of \"f\". Reversing the order of the fixed points is equivalent to taking the inverse multiplier for the characteristic constant:\n\nFor loxodromic transformations, whenever |\"k\"| > 1, one says that γ is the repulsive fixed point, and γ is the attractive fixed point. For |\"k\"| < 1, the roles are reversed.\n\n\"Parabolic case\":\n\nIn the parabolic case there is only one fixed point γ. The transformation sending that point to ∞ is\n\nor the identity if γ is already at infinity. The transformation formula_26 fixes infinity and is therefore a translation:\n\nHere, β is called the translation length. The fixed point formula for a parabolic transformation is then\n\nSolving for \"f\" (in matrix form) gives\n\nor, if γ = ∞:\n\nNote that β is \"not\" the characteristic constant of \"f\", which is always 1 for a parabolic transformation. From the above expressions one can calculate:\n\nThe point formula_41 is called the pole of formula_42; it is that point which is transformed to the point at infinity under formula_42.\n\nThe inverse pole formula_44 is that point to which the point at infinity is transformed.\nThe point midway between the two poles is always the same as the point midway between the two fixed points:\n\nThese four points are the vertices of a parallelogram which is sometimes called the characteristic parallelogram of the transformation.\n\nA transform formula_42 can be specified with two fixed points γ, γ and the pole formula_47.\n\nThis allows us to derive a formula for conversion between \"k\" and formula_47 given formula_13:\n\nwhich reduces down to\n\nThe last expression coincides with one of the (mutually reciprocal) eigenvalue ratios formula_54 of the matrix\nrepresenting the transform (compare the discussion in the preceding section about the characteristic constant of a transformation). Its characteristic polynomial is equal to\nwhich has roots\n\nA Möbius transformation can be composed as a sequence of simple transformations.\n\nThe following simple transformations are also Möbius transformations:\n\nformula_58\nis a translation\n\nformula_59\nis a combination of a (homothety and a rotation)\nIf formula_60 then it is a rotation, if formula_61 then it is a homothety\n\nformula_62 (inversion and reflection with respect to the real axis)\n\nLet:\n\n\nThen these functions can be composed, giving\n\nThis decomposition makes many properties of the Möbius transformation obvious.\n\nA Möbius transformation is equivalent to a sequence of simpler transformations.\nThe composition makes many properties of the Möbius transformation obvious.\n\nThe existence of the inverse Möbius transformation and its explicit formula are easily derived by the composition of the inverse functions of the simpler transformations. That is, define functions \"g\", \"g\", \"g\", \"g\" such that each \"g\" is the inverse of \"f\". Then the composition\n\nFrom this decomposition, we see that Möbius transformations carry over all non-trivial properties of circle inversion. For example, the preservation of angles is reduced to proving that circle inversion preserves angles since the other types of transformations are dilation and isometries (translation, reflection, rotation), which trivially preserve angles.\n\nFurthermore, Möbius transformations map generalized circles to generalized circles since circle inversion has this property. A generalized circle is either a circle or a line, the latter being considered as a circle through the point at infinity. Note that a Möbius transformation does not necessarily map circles to circles and lines to lines: it can mix the two. Even if it maps a circle to another circle, it does not necessarily map the first circle's center to the second circle's center.\n\nCross-ratios are invariant under Möbius transformations. That is, if a Möbius transformation maps four distinct points formula_69 to four distinct points formula_70 respectively, then\n\nIf one of the points formula_69 is the point at infinity, then the cross-ratio has to be defined by taking the appropriate limit; e.g. the cross-ratio of formula_73 is\n\nThe cross ratio of four different points is real if and only if there is a line or a circle passing through them. This is another way to show that Möbius transformations preserve generalized circles.\n\nTwo points \"z\" and \"z\" are conjugate with respect to a generalized circle \"C\", if, given a generalized circle \"D\" passing through \"z\" and \"z\" and cutting \"C\" in two points \"a\" and \"b\", are in harmonic cross-ratio (i.e. their cross ratio is −1). This property does not depend on the choice of the circle \"D\". This property is also sometimes referred to as being symmetric with respect to a line or circle.\n\nTwo points \"z\", \"z\" are conjugate with respect to a line, if they are symmetric with respect to the line. Two points are conjugate with respect to a circle if they are exchanged by the inversion with respect to this circle.\n\nThe point \"z\" conjugate to \"z\" when \"L\" is the line determined by the vector based \"e\" at the point \"z\" can be explicitly given as\n\nThe point \"z\" conjugate to \"z\" when \"C\" is the circle of radius \"r\" centered \"z\" can be explicitly given as\n\nSince Möbius transformations preserve generalized circles and cross-ratios, they preserve also the conjugation.\n\nWith every invertible complex 2-by-2 matrix\nwe can associate the Möbius transformation\nThe condition \"ad\" − \"bc\" ≠ 0 is equivalent to the condition that the determinant of above matrix be nonzero, i.e. that the matrix be invertible.\n\nIt is straightforward to check that then the product of two matrices will be associated with the composition of the two corresponding Möbius transformations. In other words, the map\nfrom the general linear group GL(2,C) to the Möbius group, which sends the matrix formula_42 to the transformation \"f\", is a group homomorphism.\n\nNote that any matrix obtained by multiplying formula_81 by a complex scalar λ determines the same transformation, so a Möbius transformation determines its matrix only up to scalar multiples. In other words: the kernel of consists of all scalar multiples of the identity matrix I, and the first isomorphism theorem of group theory states that the quotient group GL(2,C)/((C \\ {0})Id) is isomorphic to the Möbius group. This quotient group is known as the projective linear group and is usually denoted PGL(2,C).\nThe same identification of PGL(2,\"K\") with the group of fractional linear transformations and with the group of projective linear automorphisms of the projective line holds over any field \"K\", a fact of algebraic interest, particularly for finite fields, though the case of the complex numbers has the greatest geometric interest.\n\nThe natural action of PGL(2,C) on the complex projective line CP is exactly the natural action of the Möbius group on the Riemann sphere, where the projective line CP and the Riemann sphere are identified as follows:\nHere [\"z\":\"z\"] are homogeneous coordinates on CP; the point [1:0] corresponds to the point ∞ of the Riemann sphere.\nBy using homogeneous coordinates, many concrete calculations involving Möbius transformations can be simplified, since no case distinctions dealing with ∞ are required.\n\nIf one restricts formula_42 to matrices of determinant one, the map restricts to a surjective map from the special linear group SL(2,C) to the Möbius group; in the restricted setting the kernel is formed by plus and minus the identity, and the quotient group SL(2,C)/{±\"I\"}, denoted by PSL(2,C), is therefore also isomorphic to the Möbius group:\nFrom this we see that the Möbius group is a 3-dimensional complex Lie group (or a 6-dimensional real Lie group). It is a semisimple non-compact Lie group.\n\nNote that there are precisely two matrices with unit determinant which can be used to represent any given Möbius transformation. That is, SL(2,C) is a double cover of PSL(2,C). Since SL(2,C) is simply-connected it is the universal cover of the Möbius group. Therefore, the fundamental group of the Möbius group is Z.\n\nGiven a set of three distinct points \"z\", \"z\", \"z\" on the Riemann sphere and a second set of distinct points \"w\", \"w\", \"w\", there exists precisely one Möbius transformation \"f\"(\"z\") with \"f\"(\"z\") = \"w\" for \"i\" = 1,2,3. (In other words: the action of the Möbius group on the Riemann sphere is \"sharply 3-transitive\".) There are several ways to determine \"f\"(\"z\") from the given sets of points.\n\nIt is easy to check that the Möbius transformation\n\nwith matrix\nmaps \"z\", \"z\", \"z\" to 0, 1, ∞, respectively. If one of the \"z\" is ∞, then the proper formula for formula_88 is obtained from the above one by first dividing all entries by \"z\" and then taking the limit \"z\" → ∞.\n\nIf formula_89 is similarly defined to map \"w\", \"w\", \"w\" to 0, 1, ∞, then the matrix formula_42 which maps \"z\" to \"w\" becomes\n\nThe stabilizer of {0, 1, ∞} (as an unordered set) is a subgroup known as the anharmonic group.\n\nThe equation\nis equivalent to the equation of a standard hyperbola\nin the (\"z\",\"w\")-plane. The problem of constructing a Möbius transformation formula_94 mapping a triple formula_95 to another triple formula_96 is thus equivalent to finding the coefficients \"a\", \"b\", \"c\", \"d\" of the hyperbola passing through the points formula_97. An explicit equation can be found by evaluating the determinant\nby means of a Laplace expansion along the first row. This results in the determinant formulae\nfor the coefficients \"a,b,c,d\" of the representing matrix formula_103. The constructed matrix formula_104 has determinant equal to formula_105 which does not vanish if the \"z\" resp. \"w\" are pairwise different thus the Möbius transformation is well-defined. If one of the points \"z\" or \"w\" is ∞, then we first divide all four determinants by this variable and then take the limit as the variable approaches ∞.\n\nIf we require the coefficients \"a\", \"b\", \"c\", \"d\" of a Möbius transformation to be real numbers with , we obtain a subgroup of the\nMöbius group denoted as PSL(2,R). This is the group of those Möbius transformations that map the upper half-plane to itself, and is equal to the group of all biholomorphic (or equivalently: bijective, conformal and orientation-preserving) maps . If a proper metric is introduced, the upper half-plane becomes a model of the hyperbolic plane \"H\", the Poincaré half-plane model, and PSL(2,R) is the group of all orientation-preserving isometries of \"H\" in this model.\n\nThe subgroup of all Möbius transformations that map the open disk to itself consists of all transformations of the form\nwith formula_107 ∈ R, \"b\" ∈ C and |\"b\"| < 1. This is equal to the group of all biholomorphic (or equivalently: bijective, angle-preserving and orientation-preserving) maps . By introducing a suitable metric, the open disk turns into another model of the hyperbolic plane, the Poincaré disk model, and this group is the group of all orientation-preserving isometries of \"H\" in this model.\n\nSince both of the above subgroups serve as isometry groups of \"H\", they are isomorphic. A concrete isomorphism is given by conjugation with the transformation\nwhich bijectively maps the open unit disk to the upper half plane.\n\nAlternatively, consider an open disk with radius \"r\", centered at \"ri\". The Poincaré disk model in this disk becomes identical to the upper-half-plane model as \"r\" approaches ∞.\n\nA maximal compact subgroup of the Möbius group formula_109 is given by\nand corresponds under the isomorphism formula_111 to the projective special unitary group PSU(2,C) which is isomorphic to the special orthogonal group SO(3) of rotations in three dimensions, and can be interpreted as rotations of the Riemann sphere. Every finite subgroup is conjugate into this maximal compact group, and thus these correspond exactly to the polyhedral groups, the point groups in three dimensions.\n\nIcosahedral groups of Möbius transformations were used by Felix Klein to give an analytic solution to the quintic equation in ; a modern exposition is given in.\n\nIf we require the coefficients \"a\", \"b\", \"c\", \"d\" of a Möbius transformation to be integers with \"ad\" − \"bc\" = 1, we obtain the modular group PSL(2,Z), a discrete subgroup of PSL(2,R) important in the study of lattices in the complex plane, elliptic functions and elliptic curves. The discrete subgroups of PSL(2,R) are known as Fuchsian groups; they are important in the study of Riemann surfaces.\n\nIn the following discussion we will always assume that the representing matrix formula_112 is normalized such that formula_113.\n\nNon-identity Möbius transformations are commonly classified into four types, parabolic, elliptic, hyperbolic and loxodromic, with the hyperbolic ones being a subclass of the loxodromic ones. The classification has both algebraic and geometric significance. Geometrically, the different types result in different transformations of the complex plane, as the figures below illustrate.\n\nThe four types can be distinguished by looking at the trace formula_114. Note that the trace is invariant under conjugation, that is,\n\nand so every member of a conjugacy class will have the same trace. Every Möbius transformation can be written such that its representing matrix formula_42 has determinant one (by multiplying the entries with a suitable scalar). Two Möbius transformations formula_117 (both not equal to the identity transform) with formula_118 are conjugate if and only if formula_119\n\nA non-identity Möbius transformation defined by a matrix formula_42 of determinant one is said to be \"parabolic\" if\n\n(so the trace is plus or minus 2; either can occur for a given transformation since formula_42 is determined only up to sign). In fact one of the choices for formula_42 has the same characteristic polynomial \"X\"−2\"X\"+1 as the identity matrix, and is therefore unipotent. A Möbius transform is parabolic if and only if it has exactly one fixed point in the extended complex plane formula_124, which happens if and only if it can be defined by a matrix conjugate to\n\nwhich describes a translation in the complex plane.\n\nThe set of all parabolic Möbius transformations with a \"given\" fixed point in formula_3, together with the identity, forms a subgroup isomorphic to the group of matrices\n\nthis is an example of the unipotent radical of a Borel subgroup (of the Möbius group, or of SL(2,C) for the matrix group; the notion is defined for any reductive Lie group).\n\nAll non-parabolic transformations have two fixed points and are defined by a matrix conjugate to\n\nwith the complex number λ not equal to 0, 1 or −1, corresponding to a dilation/rotation through multiplication by the complex number \"k\" = λ, called the characteristic constant or multiplier of the transformation.\n\nThe transformation is said to be \"elliptic\" if it can be represented by a matrix formula_81 whose trace is real with\n\nA transform is elliptic if and only if |λ| = 1 and λ ≠ ±1. Writing formula_131, an elliptic transform is conjugate to\n\nwith α real.\n\nNote that for \"any\" formula_42 with characteristic constant \"k\", the characteristic constant of formula_134 is \"k\". Thus, all Möbius transformations of finite order are elliptic transformations, namely exactly those where λ is a root of unity, or, equivalently, where α is a rational multiple of . The simplest possibility of a fractional multiple means \"α\" = /2, which is also the unique case of formula_135, is also denoted as a ; this corresponds geometrically to rotation by 180° about two fixed points. This class is represented in matrix form as:\nThere are 3 representatives fixing {0, 1, ∞}, which are the three transpositions in the symmetry group of these 3 points: formula_137 which fixes 1 and swaps 0 with \"∞\" (rotation by 180° about the points 1 and −1), formula_138, which fixes \"∞\" and swaps 0 with 1 (rotation by 180° about the points 1/2 and \"∞\"), and formula_139 which fixes 0 and swaps 1 with \"∞\" (rotation by 180° about the points 0 and 2).\n\nThe transform is said to be \"hyperbolic\" if it can be represented by a matrix formula_81 whose trace is real with\n\nA transform is hyperbolic if and only if λ is real and positive.\n\nThe transform is said to be \"loxodromic\" if formula_142 is not in [0,4]. A transformation is loxodromic if and only if formula_143.\n\nHistorically, navigation by loxodrome or rhumb line refers to a path of constant bearing; the resulting path is a logarithmic spiral, similar in shape to the transformations of the complex plane that a loxodromic Möbius transformation makes. See the geometric figures below.\n\nOver the real numbers (if the coefficients must be real), there are no non-hyperbolic loxodromic transformations, and the classification is into elliptic, parabolic, and hyperbolic, as for real conics. The terminology is due to considering half the absolute value of the trace, |tr|/2, as the eccentricity of the transformation – division by 2 corrects for the dimension, so the identity has eccentricity 1 (tr/\"n\" is sometimes used as an alternative for the trace for this reason), and absolute value corrects for the trace only being defined up to a factor of ±1 due to working in PSL. Alternatively one may use half the trace \"squared\" as a proxy for the eccentricity squared, as was done above; these classifications (but not the exact eccentricity values, since squaring and absolute values are different) agree for real traces but not complex traces. The same terminology is used for the classification of elements of SL(2, R) (the 2-fold cover), and analogous classifications are used elsewhere. Loxodromic transformations are an essentially complex phenomenon, and correspond to complex eccentricities.\n\nThe following picture depicts (after stereographic transformation from the sphere to the plane) the two fixed points of a Möbius transformation in the non-parabolic case:\n\nThe characteristic constant can be expressed in terms of its logarithm:\nWhen expressed in this way, the real number ρ becomes an expansion factor. It indicates how repulsive the fixed point γ is, and how attractive γ is. The real number α is a rotation factor, indicating to what extent the transform rotates the plane anti-clockwise about γ and clockwise about γ.\n\nIf ρ = 0, then the fixed points are neither attractive nor repulsive but indifferent, and the transformation is said to be \"elliptic\". These transformations tend to move all points in circles around the two fixed points. If one of the fixed points is at infinity, this is equivalent to doing an affine rotation around a point.\n\nIf we take the one-parameter subgroup generated by any elliptic Möbius transformation, we obtain a continuous transformation, such that every transformation in the subgroup fixes the \"same\" two points. All other points flow along a family of circles which is nested between the two fixed points on the Riemann sphere. In general, the two fixed points can be any two distinct points.\n\nThis has an important physical interpretation.\nImagine that some observer rotates with constant angular velocity about some axis. Then we can take the two fixed points to be the North and South poles of the celestial sphere. The appearance of the night sky is now transformed continuously in exactly the manner described by the one-parameter subgroup of elliptic transformations sharing the fixed points 0, ∞, and with the number α corresponding to the constant angular velocity of our observer.\n\nHere are some figures illustrating the effect of an elliptic Möbius transformation on the Riemann sphere (after stereographic projection to the plane):\n\nThese pictures illustrate the effect of a single Möbius transformation. The one-parameter subgroup which it generates \"continuously\" moves points along the family of circular arcs suggested by the pictures.\n\nIf α is zero (or a multiple of 2), then the transformation is said to be \"hyperbolic\". These transformations tend to move points along circular paths from one fixed point toward the other.\n\nIf we take the one-parameter subgroup generated by any hyperbolic Möbius transformation, we obtain a continuous transformation, such that every transformation in the subgroup fixes the \"same\" two points. All other points flow along a certain family of circular arcs \"away\" from the first fixed point and \"toward\" the second fixed point. In general, the two fixed points may be any two distinct points on the Riemann sphere.\n\nThis too has an important physical interpretation. Imagine that an observer accelerates (with constant magnitude of acceleration) in the direction of the North pole on his celestial sphere. Then the appearance of the night sky is transformed in exactly the manner described by the one-parameter subgroup of hyperbolic transformations sharing the fixed points 0, ∞, with the real number ρ corresponding to the magnitude of his acceleration vector. The stars seem to move along longitudes, away from the South pole toward the North pole. (The longitudes appear as circular arcs under stereographic projection from the sphere to the plane.)\n\nHere are some figures illustrating the effect of a hyperbolic Möbius transformation on the Riemann sphere (after stereographic projection to the plane):\n\nThese pictures resemble the field lines of a positive and a negative electrical charge located at the fixed points, because the circular flow lines subtend a constant angle between the two fixed points.\n\nIf both ρ and α are nonzero, then the transformation is said to be \"loxodromic\". These transformations tend to move all points in S-shaped paths from one fixed point to the other.\n\nThe word \"loxodrome\" is from the Greek: \"λοξος (loxos), \"slanting\" + δρόμος (dromos), \"course\"\". When sailing on a constant bearing – if you maintain a heading of (say) north-east, you will eventually wind up sailing around the north pole in a logarithmic spiral. On the mercator projection such a course is a straight line, as the north and south poles project to infinity. The angle that the loxodrome subtends relative to the lines of longitude (i.e. its slope, the \"tightness\" of the spiral) is the argument of \"k\". Of course, Möbius transformations may have their two fixed points anywhere, not just at the north and south poles. But any loxodromic transformation will be conjugate to a transform that moves all points along such loxodromes.\n\nIf we take the one-parameter subgroup generated by any loxodromic Möbius transformation, we obtain a continuous transformation, such that every transformation in the subgroup fixes the \"same\" two points. All other points flow along a certain family of curves, \"away\" from the first fixed point and \"toward\" the second fixed point. Unlike the hyperbolic case, these curves are not circular arcs, but certain curves which under stereographic projection from the sphere to the plane appear as spiral curves which twist counterclockwise infinitely often around one fixed point and twist clockwise infinitely often around the other fixed point. In general, the two fixed points may be any two distinct points on the Riemann sphere.\n\nYou can probably guess the physical interpretation in the case when the two fixed points are 0, ∞: an observer who is both rotating (with constant angular velocity) about some axis and moving along the \"same\" axis, will see the appearance of the night sky transform according to the one-parameter subgroup of loxodromic transformations with fixed points 0, ∞, and with ρ, α determined respectively by the magnitude of the actual linear and angular velocities.\n\nThese images show Möbius transformations stereographically projected onto the Riemann sphere. Note in particular that when projected onto a sphere, the special case of a fixed point at infinity looks no different from having the fixed points in an arbitrary location.\n\nIf a transformation formula_42 has fixed points γ, γ, and characteristic constant \"k\", then formula_146 will have formula_147.\n\nThis can be used to iterate a transformation, or to animate one by breaking it up into steps.\n\nThese images show three points (red, blue and black) continuously iterated under transformations with various characteristic constants.\n\nAnd these images demonstrate what happens when you transform a circle under Hyperbolic, Elliptical, and Loxodromic transforms. Note that in the elliptical and loxodromic images, the α value is 1/10 .\n\nThe point\n\nis called the pole of formula_42; it is that point which is transformed to the point at infinity under formula_42.\n\nThe inverse pole\n\nis that point to which the point at infinity is transformed.\nThe point midway between the two poles is always the same as the point midway between the two fixed points:\n\nThese four points are the vertices of a parallelogram which is sometimes called the characteristic parallelogram of the transformation.\n\nA transform formula_42 can be specified with two fixed points γ, γ and the pole formula_47.\n\nThis allows us to derive a formula for conversion between \"k\" and formula_47 given formula_13:\n\nwhich reduces down to\n\nThe last expression coincides with one of the (mutually reciprocal) eigenvalue ratios formula_54 of the matrix\nrepresenting the transform (compare the discussion in the preceding section about the characteristic constant of a transformation). Its characteristic polynomial is equal to\nwhich has roots\n\nIn higher dimensions, a Möbius transformation is a homeomorphism of formula_165, the one-point compactification of formula_166, which is a finite composition of inversions in spheres and reflections in hyperplanes. Liouville's theorem in conformal geometry states that in dimension at least three, all conformal transformations are Möbius transformations. Every Möbius transformation can be put in the form\n\nformula_167 The components of () are precisely those obtained from the outer product\n\nIn summary, the action of the restricted Lorentz group SO(1,3) agrees with that of the Möbius group PSL(2,C). This motivates the following definition. In dimension \"n\" ≥ 2, the Möbius group Möb(\"n\") is the group of all orientation-preserving conformal isometries of the round sphere \"S\" to itself. By realizing the conformal sphere as the space of future-pointing rays of the null cone in the Minkowski space R, there is an isomorphism of Möb(\"n\") with the restricted Lorentz group SO(1,\"n\"+1) of Lorentz transformations with positive determinant, preserving the direction of time.\n\nCoxeter began instead with the equivalent quadratic form formula_169\n\nHe identified the Lorentz group with transformations for which {\"x\" : Q(\"x\") = -1} is stable. Then he interpreted the x's as homogeneous coordinates and {\"x\" : Q(\"x\") = 0}, the null cone, as the Cayley absolute for a hyperbolic space of points {\"x\" : Q(\"x\") < 0}. Next, Coxeter introduced the variables\n\nso that the Lorentz-invariant quadric corresponds to the sphere formula_171 Coxeter notes that Felix Klein also wrote of this correspondence, applying stereographic projection from (0, 0, 1) to the complex plane formula_172\nCoxeter used the fact that circles of the inversive plane represent planes of hyperbolic space, and the general homography is the product of inversions in two or four circles, corresponding to the general hyperbolic displacement which is the product of inversions in two or four planes.\n\nAs seen above, the Möbius group PSL(2,C) acts on Minkowski space as the group of those isometries that preserve the origin, the orientation of space and the direction of time. Restricting to the points where \"Q\"=1 in the positive light cone, which form a model of hyperbolic 3-space \"H\", we see that the Möbius group acts on \"H\" as a group of orientation-preserving isometries. In fact, the Möbius group is equal to the group of orientation-preserving isometries of hyperbolic 3-space.\n\nIf we use the Poincaré ball model, identifying the unit ball in R with \"H\", then we can think of the Riemann sphere as the \"conformal boundary\" of \"H\". Every orientation-preserving isometry of \"H\" gives rise to a Möbius transformation on the Riemann sphere and vice versa; this is the very first observation leading to the AdS/CFT correspondence conjectures in physics.\n\nSpecific\n\nGeneral\n\n"}
{"id": "2468892", "url": "https://en.wikipedia.org/wiki?curid=2468892", "title": "Newton's identities", "text": "Newton's identities\n\nIn mathematics, Newton's identities, also known as the Newton–Girard formulae, give relations between two types of symmetric polynomials, namely between power sums and elementary symmetric polynomials. Evaluated at the roots of a monic polynomial \"P\" in one variable, they allow expressing the sums of the \"k\"-th powers of all roots of \"P\" (counted with their multiplicity) in terms of the coefficients of \"P\", without actually finding those roots. These identities were found by Isaac Newton around 1666, apparently in ignorance of earlier work (1629) by Albert Girard. They have applications in many areas of mathematics, including Galois theory, invariant theory, group theory, combinatorics, as well as further applications outside mathematics, including general relativity.\n\nLet \"x\", …, \"x\" be variables, denote for \"k\" ≥ 1 by \"p\"(\"x\", …, \"x\") the \"k\"-th power sum:\n\nand for \"k\" ≥ 0 denote by \"e\"(\"x\", …, \"x\") the elementary symmetric polynomial (that is, the sum of all distinct products of \"k\" distinct variables), so\n\nThen Newton's identities can be stated as\n\nvalid for all \"n\" ≥ 1 and \"n\" ≥\"k\" ≥ 1.\n\nAlso, one has\n\nfor all \"k\" > \"n\" ≥ 1.\n\nConcretely, one gets for the first few values of \"k\":\n\nThe form and validity of these equations do not depend on the number \"n\" of variables (although the point where the left-hand side becomes 0 does, namely after the \"n\"-th identity), which makes it possible to state them as identities in the ring of symmetric functions. In that ring one has\n\nand so on; here the left-hand sides never become zero.\nThese equations allow to recursively express the \"e\" in terms of the \"p\"; to be able to do the inverse, one may rewrite them as\n\nIn general, we have\n\nvalid for all \"n\" ≥ 1 and \"n\" ≥\"k\" ≥ 1.\n\nAlso, one has\n\nfor all \"k\" > \"n\" ≥ 1.\n\nThe polynomial with roots \"x\" may be expanded as\n\nwhere the coefficients formula_11 are the symmetric polynomials defined above.\nGiven the \"power sums\" of the roots\n\nthe coefficients of the polynomial with roots formula_13 may be expressed recursively in terms of the power sums as\n\nFormulating polynomials in this way is useful in using the method of Delves and Lyness to find the zeros of an analytic function.\n\nWhen the polynomial above is the characteristic polynomial of a matrix \"A\" (in particular when \"A\" is the companion matrix of the polynomial), the roots formula_15 are the eigenvalues of the matrix, counted with their algebraic multiplicity. For any positive integer \"k\", the matrix \"A\" has as eigenvalues the powers \"x\", and each eigenvalue formula_15 of \"A\" contributes its multiplicity to that of the eigenvalue \"x\" of \"A\". Then the coefficients of the characteristic polynomial of \"A\" are given by the elementary symmetric polynomials \"in those powers\" \"x\". In particular, the sum of the \"x\", which is the \"k\"-th power sum s of the roots of the characteristic polynomial of \"A\", is given by its trace:\n\nThe Newton identities now relate the traces of the powers \"A\" to the coefficients of the characteristic polynomial of \"A\". Using them in reverse to express the elementary symmetric polynomials in terms of the power sums, they can be used to find the characteristic polynomial by computing only the powers \"A\" and their traces.\n\nThis computation requires computing the traces of matrix powers \"A\" and solving a triangular system of equations. Both can be done in complexity class NC (solving a triangular system can be done by divide-and-conquer). Therefore, characteristic polynomial of a matrix can be computed in NC. By the Cayley–Hamilton theorem, every matrix satisfies its characteristic polynomial, and a simple transformation allows to find the adjugate matrix in NC.\n\nRearranging the computations into an efficient form leads to the \"Faddeev–LeVerrier algorithm\" (1840), a fast parallel implementation of it is due to L. Csanky (1976). Its disadvantage is that it requires division by integers, so in general the field should have characteristic, 0.\n\nFor a given \"n\", the elementary symmetric polynomials \"e\"(\"x\",…,\"x\") for \"k\" = 1,…, \"n\" form an algebraic basis for the space of symmetric polynomials in \"x\",…. \"x\": every polynomial expression in the \"x\" that is invariant under all permutations of those variables is given by a polynomial expression in those elementary symmetric polynomials, and this expression is unique up to equivalence of polynomial expressions. This is a general fact known as the fundamental theorem of symmetric polynomials, and Newton's identities provide explicit formulae in the case of power sum symmetric polynomials. Applied to the monic polynomial formula_18 with all coefficients \"a\" considered as free parameters, this means that every symmetric polynomial expression \"S\"(\"x\",…,\"x\") in its roots can be expressed instead as a polynomial expression \"P\"(\"a\",…,\"a\") in terms of its coefficients only, in other words without requiring knowledge of the roots. This fact also follows from general considerations in Galois theory (one views the \"a\" as elements of a base field with roots in an extension field whose Galois group permutes them according to the full symmetric group, and the field fixed under all elements of the Galois group is the base field).\n\nThe Newton identities also permit expressing the elementary symmetric polynomials in terms of the power sum symmetric polynomials, showing that any symmetric polynomial can also be expressed in the power sums. In fact the first \"n\" power sums also form an algebraic basis for the space of symmetric polynomials.\n\nThere are a number of (families of) identities that, while they should be distinguished from Newton's identities, are very closely related to them.\n\nDenoting by \"h\" the complete homogeneous symmetric polynomial that is the sum of all monomials of degree \"k\", the power sum polynomials also satisfy identities similar to Newton's identities, but not involving any minus signs. Expressed as identities of in the ring of symmetric functions, they read\n\nvalid for all n ≥ \"k\" ≥ 1. Contrary to Newton's identities, the left-hand sides do not become zero for large \"k\", and the right-hand sides contain ever more non-zero terms. For the first few values of \"k\", one has\n\nThese relations can be justified by an argument analogous to the one by comparing coefficients in power series given above, based in this case on the generating function identity\n\nProofs of Newton's identities, like these given below, cannot be easily adapted to prove these variants of those identities.\n\nAs mentioned, Newton's identities can be used to recursively express elementary symmetric polynomials in terms of power sums. Doing so requires the introduction of integer denominators, so it can be done in the ring Λ of symmetric functions with rational coefficients:\n\nand so forth. The general formula can be conveniently expressed as\n\nwhere the \"B\" is the complete exponential Bell polynomial. This expression also leads to the following identity for generating functions:\nApplied to a monic polynomial, these formulae express the coefficients in terms of the power sums of the roots: replace each \"e\" by \"a\" and each \"p\" by \"s\".\n\nThe analogous relations involving complete homogeneous symmetric polynomials can be similarly developed, giving equations\n\nand so forth, in which there are only plus signs. In terms of the complete Bell polynomial,\n\nThese expressions correspond exactly to the cycle index polynomials of the symmetric groups, if one interprets the power sums \"p\" as indeterminates: the coefficient in the expression for \"h\" of any monomial \"p\"\"p\"…\"p\" is equal to the fraction of all permutations of \"k\" that have \"m\" fixed points, \"m\" cycles of length 2, …, and \"m\" cycles of length \"l\". Explicitly, this coefficient can be written as formula_27 where formula_28; this \"N\" is the number permutations commuting with any given permutation  of the given cycle type. The expressions for the elementary symmetric functions have coefficients with the same absolute value, but a sign equal to the sign of , namely (−1).\n\nIt can be proved by considering the following inductive step:\n\nOne may also use Newton's identities to express power sums in terms of symmetric polynomials, which does not introduce denominators:\n\nThe first four formulas were obtained by Albert Girard in 1629 (thus before Newton).\n\nThe general formula (for all non-negative integers \"m\") is:\n\nThis can be conveniently stated in terms of ordinary Bell polynomials as \n\nor equivalently as the generating function:\nwhich is analogous to the Bell polynomial \"exponential\" generating function given in the previous subsection.\n\nThe multiple summation formula above can be proved by considering the following inductive step: \n\nFinally one may use the variant identities involving complete homogeneous symmetric polynomials similarly to express power sums in term of them:\n\nand so on. Apart from the replacement of each \"e\" by the corresponding \"h\", the only change with respect to the previous family of identities is in the signs of the terms, which in this case depend just on the number of factors present: the sign of the monomial formula_36 is −(−1). In particular the above description of the absolute value of the coefficients applies here as well.\n\nThe general formula (for all non-negative integers \"m\") is:\n\nOne can obtain explicit formulas for the above expressions in the form of determinants, by considering the first \"n\" of Newton's identities (or it counterparts for the complete homogeneous polynomials) as linear equations in which the elementary symmetric functions are known and the power sums are unknowns (or vice versa), and apply Cramer's rule to find the solution for the final unknown. For instance taking Newton's identities in the form \n\nwe consider formula_39 and formula_40 as unknowns, and solve for the final one, giving\n\nSolving for formula_42 instead of for formula_40 is similar, as the analogous computations for the complete homogeneous symmetric polynomials; in each case the details are slightly messier than the final results, which are (Macdonald 1979, p. 20):\n\nNote that the use of determinants makes that the formula for formula_45 has additional minus signs compared to the one for formula_42, while the situation for the expanded form given earlier is opposite. As remarked in (Littlewood 1950, p. 84) one can alternatively obtain the formula for formula_45 by taking the permanent of the matrix for formula_42 instead of the determinant, and more generally an expression for any Schur polynomial can be obtained by taking the corresponding immanant of this matrix.\n\nEach of Newton's identities can easily be checked by elementary algebra; however, their validity in general needs a proof. Here are some possible derivations.\n\nOne can obtain the \"k\"-th Newton identity in \"k\" variables by substitution into\n\nas follows. Substituting \"x\" for \"t\" gives\n\nSumming over all \"j\" gives\n\nwhere the terms for \"i\" = 0 were taken out of the sum because \"p\" is (usually) not defined. This equation immediately gives the \"k\"-th Newton identity in \"k\" variables. Since this is an identity of symmetric polynomials (homogeneous) of degree \"k\", its validity for any number of variables follows from its validity for \"k\" variables. Concretely, the identities in \"n\" < \"k\" variables can be deduced by setting \"k\" − \"n\" variables to zero. The \"k\"-th Newton identity in \"n\" > \"k\" variables contains more terms on both sides of the equation than the one in \"k\" variables, but its validity will be assured if the coefficients of any monomial match. Because no individual monomial involves more than \"k\" of the variables, the monomial will survive the substitution of zero for some set of \"n\" − \"k\" (other) variables, after which the equality of coefficients is one that arises in the \"k\"-th Newton identity in \"k\" (suitably chosen) variables.\n\nAnother derivation can be obtained by computations in the ring of formal power series \"R\", where \"R\" is Z[\"x\",…, \"x\"], the ring of polynomials in \"n\" variables \"x\",…, \"x\" over the integers.\n\nStarting again from the basic relation\n\nand \"reversing the polynomials\" by substituting 1/\"t\" for \"t\" and then multiplying both sides by \"t\" to remove negative powers of \"t\", gives\n\nSwapping sides and expressing the \"a\" as the elementary symmetric polynomials they stand for gives the identity\n\nOne formally differentiates both sides with respect to \"t\", and then (for convenience) multiplies by \"t\", to obtain\n\nwhere the polynomial on the right hand side was first rewritten as a rational function in order to be able to factor out a product out of the summation, then the fraction in the summand was developed as a series in \"t\", using the formula\n\nand finally the coefficient of each \"t\"  was collected, giving a power sum. (The series in \"t\" is a formal power series, but may alternatively be thought of as a series expansion for \"t\" sufficiently close to 0, for those more comfortable with that; in fact one is not interested in the function here, but only in the coefficients of the series.) Comparing coefficients of \"t\" on both sides one obtains\n\nwhich gives the \"k\"-th Newton identity.\n\nThe following derivation, given essentially in (Mead, 1992), is formulated in the ring of symmetric functions for clarity (all identities are independent of the number of variables). Fix some \"k\" > 0, and define the symmetric function \"r\"(\"i\") for 2 ≤ \"i\" ≤ \"k\" as the sum of all distinct monomials of degree \"k\" obtained by multiplying one variable raised to the power \"i\" with \"k\" − \"i\" distinct other variables (this is the monomial symmetric function \"m\" where γ is a hook shape (\"i\",1,1,…,1)). In particular \"r\"(\"k\") = \"p\"; for \"r\"(1) the description would amount to that of \"e\", but this case was excluded since here monomials no longer have any distinguished variable. All products \"p\"\"e\" can be expressed in terms of the \"r\"(\"j\") with the first and last case being somewhat special. One has\nFinally the product \"p\"\"e\" for \"i\" = 1 gives contributions to \"r\"(\"i\" + 1) = \"r\"(2) like for other values \"i\" < \"k\", but the remaining contributions produce \"k\" times each monomial of \"e\", since any one of the variables may come from the factor \"p\"; thus\nThe \"k\"-th Newton identity is now obtained by taking the alternating sum of these equations, in which all terms of the form \"r\"(\"i\") cancel out.\n\nA short combinatorial proof of Newton's Identities is given in (Zeilberger, 1984)\n\n\n\n"}
{"id": "5007494", "url": "https://en.wikipedia.org/wiki?curid=5007494", "title": "Parabolic cylindrical coordinates", "text": "Parabolic cylindrical coordinates\n\nIn mathematics, parabolic cylindrical coordinates are a three-dimensional orthogonal coordinate system that results from projecting the two-dimensional parabolic coordinate system in the\nperpendicular formula_1-direction. Hence, the coordinate surfaces are confocal parabolic cylinders. Parabolic cylindrical coordinates have found many applications, e.g., the potential theory of edges.\n\nThe parabolic cylindrical coordinates are defined in terms of the Cartesian coordinates by:\n\nThe surfaces of constant form confocal parabolic cylinders\n\nthat open towards , whereas the surfaces of constant form confocal parabolic cylinders\n\nthat open in the opposite direction, i.e., towards . The foci of all these parabolic cylinders are located along the line defined by . The radius has a simple formula as well\n\nthat proves useful in solving the Hamilton–Jacobi equation in parabolic coordinates for the inverse-square central force problem of mechanics; for further details, see the Laplace–Runge–Lenz vector article.\n\nThe scale factors for the parabolic cylindrical coordinates and are:\n\nThe infinitesimal element of volume is\n\nThe differential displacement is given by:\n\nThe differential normal area is given by:\n\nLet be a scalar field. The gradient is given by\n\nThe Laplacian is given by\n\nLet be a vector field of the form:\n\nThe divergence is given by\n\nThe curl is given by\n\nOther differential operators can be expressed in the coordinates by substituting the scale factors into the general formulae found in orthogonal coordinates.\n\nRelationship to cylindrical coordinates :\n\nParabolic unit vectors expressed in terms of Cartesian unit vectors:\n\nSince all of the surfaces of constant , and are conicoids, Laplace's equation is separable in parabolic cylindrical coordinates. Using the technique of the separation of variables, a separated solution to Laplace's equation may be written:\n\nand Laplace's equation, divided by , is written:\n\nSince the equation is separate from the rest, we may write\n\nwhere is constant. has the solution:\n\nSubstituting for formula_21, Laplace's equation may now be written:\n\nWe may now separate the and functions and introduce another constant to obtain:\n\nThe solutions to these equations are the parabolic cylinder functions\n\nThe parabolic cylinder harmonics for are now the product of the solutions. The combination will reduce the number of constants and the general solution to Laplace's equation may be written:\n\nThe classic applications of parabolic cylindrical coordinates are in solving partial differential equations, e.g., Laplace's equation or the Helmholtz equation, for which such coordinates allow a separation of variables. A typical example would be the electric field surrounding a flat semi-infinite conducting plate.\n\n\n\n"}
{"id": "2784317", "url": "https://en.wikipedia.org/wiki?curid=2784317", "title": "Poincaré–Bendixson theorem", "text": "Poincaré–Bendixson theorem\n\nIn mathematics, the Poincaré–Bendixson theorem is a statement about the long-term behaviour of orbits of continuous dynamical systems on the plane, cylinder, or two-sphere.\n\nGiven a differentiable real dynamical system defined on an open subset of the plane, then every non-empty compact \"ω\"-limit set of an orbit, which contains only finitely many fixed points, is either\n\nMoreover, there is at most one orbit connecting different fixed points in the same direction. However, there could be countably many homoclinic orbits connecting one fixed point.\n\nA weaker version of the theorem was originally conceived by Henri Poincaré, although he lacked a complete proof which was later given by .\n\nThe condition that the dynamical system be on the plane is necessary to the theorem. On a torus, for example, it is possible to have a recurrent non-periodic orbit.\nIn particular, chaotic behaviour can only arise in continuous dynamical systems whose phase space has three or more dimensions. However the theorem does not apply to discrete dynamical systems, where chaotic behaviour can arise in two- or even one-dimensional systems.\n\nOne important implication is that a two-dimensional continuous dynamical system cannot give rise to a strange attractor. If a strange attractor C did exist in such a system, then it could be enclosed in a closed and bounded subset of the phase space. By making this subset small enough, any nearby stationary points could be excluded. But then the Poincaré–Bendixson theorem says that C is not a strange attractor at all—it is either a limit cycle or it converges to a limit cycle.\n\n"}
{"id": "340198", "url": "https://en.wikipedia.org/wiki?curid=340198", "title": "Pointwise convergence", "text": "Pointwise convergence\n\nIn mathematics, pointwise convergence is one of various senses in which a sequence of functions can converge to a particular function. It is weaker than uniform convergence, to which it is often compared.\n\nSuppose formula_1 is a sequence of functions sharing the same domain and codomain. The codomain is most commonly the reals, but in general can be any metric space. The sequence formula_1 converges pointwise to the function formula_3, often written as\n\nif and only if\n\nfor every \"x\" in the domain. The function formula_3 is said to be the pointwise limit function of formula_7.\n\nThis concept is often contrasted with uniform convergence. To say that\n\nmeans that\n\nThat is a stronger statement than the assertion of pointwise convergence: every uniformly convergent sequence is pointwise convergent, to the same limiting function, but some pointwise convergent sequences are not uniformly convergent. For example, if formula_10 is a sequence of functions defined by formula_11, then formula_12 pointwise on the interval [0,1), but not uniformly.\n\nThe pointwise limit of a sequence of continuous functions may be a discontinuous function, but only if the convergence is not uniform. For example,\n\ntakes the value 1 when \"x\" is an integer and 0 when \"x\" is not an integer, and so is discontinuous at every integer.\n\nThe values of the functions \"f\" need not be real numbers, but may be in any topological space, in order that the concept of pointwise convergence make sense. Uniform convergence, on the other hand, does not make sense for functions taking values in topological spaces generally, but makes sense for functions taking values in metric spaces, and, more generally, in uniform spaces.\n\nPointwise convergence is the same as convergence in the product topology on the space \"Y\", where \"X\" is the domain and \"Y\" is the codomain. If the codomain \"Y\" is compact, then, by Tychonoff's theorem, the space \"Y\" is also compact.\n\nIn measure theory, one talks about \"almost everywhere convergence\" of a sequence of measurable functions defined on a measurable space. That means pointwise convergence almost everywhere, i.e. on a subset of the domain whose complement has measure zero. Egorov's theorem states that pointwise convergence almost everywhere on a set of finite measure implies uniform convergence on a slightly smaller set.\n\n"}
{"id": "921927", "url": "https://en.wikipedia.org/wiki?curid=921927", "title": "Proof net", "text": "Proof net\n\nIn proof theory, proof nets are a geometrical method of representing proofs that\neliminates two forms of \"bureaucracy\" that differentiates proofs: (A) irrelevant syntactical features of regular proof calculi such as the natural deduction calculus and the sequent calculus, and (B) the order of rules applied in a derivation. In this way, the formal properties of proof identity correspond more closely to the intuitively desirable properties. Proof nets were introduced by Jean-Yves Girard.\n\nFor instance, these two linear logic proofs are “morally” identical:\n\nAnd their corresponding nets will be the same.\n\nSeveral correctness criteria are known to check if a sequential proof structure (i.e. something which seems to be a proof net) is actually a concrete proof structure (i.e. something which encodes a valid derivation in linear logic). The first such criterion is the long-trip criterion which was described by Jean-Yves Girard.\n\n\n"}
{"id": "348780", "url": "https://en.wikipedia.org/wiki?curid=348780", "title": "Proof that e is irrational", "text": "Proof that e is irrational\n\nThe number \"e\" was introduced by Jacob Bernoulli in 1683. More than half a century later, Euler, who had been a student of Jacob's younger brother Johann, proved that \"e\" is irrational; that is, that it cannot be expressed as the quotient of two integers.\n\nEuler wrote the first proof of the fact that \"e\" is irrational in 1737 (but the text was only published seven years later). He computed the representation of \"e\" as a simple continued fraction, which is\n\nSince this continued fraction is infinite and every rational number has a terminating continued fraction, \"e\" is irrational. A short proof of the previous equality is known. Since the simple continued fraction of \"e\" is not periodic, this also proves that \"e\" is not a root of second degree polynomial with rational coefficients; in particular, \"e\" is irrational.\n\nThe most well-known proof is Joseph Fourier's proof by contradiction, which is based upon the equality\n\nInitially \"e\" is assumed to be a rational number of the form ⁄. Note that \"b\" could not be equal to 1 as \"e\" is not an integer. It can be shown using the above equality that \"e\" is strictly between 2 and 3:\n\nWe then analyze a blown-up difference \"x\" of the series representing \"e\" and its strictly smaller partial sum, which approximates the limiting value \"e\". By choosing the magnifying factor to be the factorial of \"b\", the fraction ⁄ and the partial sum are turned into integers, hence \"x\" must be a positive integer. However, the fast convergence of the series representation implies that the magnified approximation error \"x\" is still strictly smaller than 1. From this contradiction we deduce that \"e\" is irrational.\n\nSuppose that \"e\" is a rational number. Then there exist positive integers \"a\" and \"b\" such that \"e\" = ⁄. Define the number\n\nTo see that if \"e\" is rational, then \"x\" is an integer, substitute \"e\" = ⁄ into this definition to obtain\n\nThe first term is an integer, and every fraction in the sum is actually an integer because \"n\" ≤ \"b\" for each term. Therefore, \"x\" is an integer.\n\nWe now prove that . First, to prove that \"x\" is strictly positive, we insert the above series representation of \"e\" into the definition of \"x\" and obtain\n\nbecause all the terms are strictly positive.\n\nWe now prove that \"x\" < 1. For all terms with we have the upper estimate\n\nThis inequality is strict for every \"n\" ≥ \"b\" + 2. Changing the index of summation to \"k\" = \"n\" – \"b\" and using the formula for the infinite geometric series, we obtain\n\nSince there is no integer strictly between 0 and 1, we have reached a contradiction, and so \"e\" must be irrational. Q.E.D.\n\nAnother proof can be obtained from the previous one by noting that\n\nand this inequality is equivalent to the assertion that \"bx\" < 1. This is impossible, of course, since \"b\" and \"x\" are natural numbers.\n\nStill another proof can be obtained from the fact that\n\nDefine formula_11 as follows:\n\nThen:\n\nwhich implies:\n\nfor any integer formula_15\n\nNote that formula_16 is always an integer. Assume formula_17 is rational, so, formula_18 where formula_19 are co-prime and formula_20 It's possible to appropriately choose formula_21 so that formula_22 is an integer i.e. formula_23 Hence, for this choice, the difference between formula_22 and formula_16 would be an integer. But from the above inequality, that's impossible.So, formula_17 is irrational. This means that formula_27 is irrational.\n\nIn 1840, Liouville published a proof of the fact that \"e\" is irrational followed by a proof that \"e\" is not a root of a second degree polynomial with rational coefficients. This last fact implies that \"e\" is irrational. His proofs are similar to Fourier's proof of the irrationality of \"e\". In 1891, Hurwitz explained how it is possible to prove along the same line of ideas that \"e\" is not a root of a third degree polynomial with rational coefficients. In particular, \"e\" is irrational.\n\nMore generally, \"e\" is irrational for any non-zero rational \"q\".\n\n"}
{"id": "7726870", "url": "https://en.wikipedia.org/wiki?curid=7726870", "title": "Query (complexity)", "text": "Query (complexity)\n\nIn descriptive complexity, a query is a mapping from structures of one signature to structures of another vocabulary. Neil Immerman, in his book Descriptive Complexity, \"use[s] the concept of query as the fundamental paradigm of computation\" (p. 17).\n\nGiven signatures formula_1 and formula_2, we define the set of structures on each language, formula_3 and formula_4. A query is then any mapping\n\nformula_5\n\nComputational complexity theory can then be phrased in terms of the power of the mathematical logic necessary to express a given query.\n\nA query is order-independent if the ordering of objects in the structure does not affect the results of the query. In databases, these queries correspond to generic queries (Immerman 1999, p. 18). A query is order-independent iff formula_6 for any isomorphic structures formula_7 and formula_8.\n"}
{"id": "37862118", "url": "https://en.wikipedia.org/wiki?curid=37862118", "title": "Rice's formula", "text": "Rice's formula\n\nIn probability theory, Rice's formula counts the average number of times an ergodic stationary process \"X\"(\"t\") per unit time crosses a fixed level \"u\". Adler and Taylor describe the result as \"one of the most important results in the applications of smooth stochastic processes.\" The formula is often used in engineering.\n\nThe formula was published by Stephen O. Rice in 1944, having previously been discussed in his 1936 note entitled \"Singing Transmission Lines.\"\n\nWrite \"D\" for the number of times the ergodic stationary stochastic process \"x\"(\"t\") takes the value \"u\" in a unit of time (i.e. \"t\" ∈ [0,1]). Then Rice's formula states that\n\nwhere \"p\"(\"x\",\"x\"<nowiki>'</nowiki>) is the joint probability density of the \"x\"(\"t\") and its mean-square derivative \"x\"'(\"t\").\n\nIf the process \"x\"(\"t\") is a Gaussian process and \"u\" = 0 then the formula simplifies significantly to give\nwhere \"ρ\"<nowiki>\"</nowiki> is the second derivative of the normalised autocorrelation of \"x\"(\"t\") at 0.\n\nRice's formula can be used to approximate an excursion probability\nas for large values of \"u\" the probability that there is a level crossing is approximately the probability of reaching that level.\n"}
{"id": "2907387", "url": "https://en.wikipedia.org/wiki?curid=2907387", "title": "Signed zero", "text": "Signed zero\n\nSigned zero is zero with an associated sign. In ordinary arithmetic, the number 0 does not have a sign, so that −0, +0 and 0 are identical. However, in computing, some number representations allow for the existence of two zeros, often denoted by −0 (negative zero) and +0 (positive zero), regarded as equal by the numerical comparison operations but with possible different behaviors in particular operations. This occurs in the \"sign and magnitude\" and \"ones' complement\" signed number representations for integers, and in most floating-point number representations. The number 0 is usually encoded as +0, but can be represented by either +0 or −0.\n\nThe IEEE 754 standard for floating-point arithmetic (presently used by most computers and programming languages that support floating point numbers) requires both +0 and −0. Real arithmetic with signed zeros can be considered a variant of the extended real number line such that 1/−0 = −∞ and 1/+0 = +∞; division is only undefined for ±0/±0 and ±∞/±∞.\n\nNegatively signed zero echoes the mathematical analysis concept of approaching 0 from below as a one-sided limit, which may be denoted by \"x\" → 0, \"x\" → 0−, or \"x\" → ↑0. The notation \"−0\" may be used informally to denote a small negative number that has been rounded to zero. The concept of negative zero also has some theoretical applications in statistical mechanics and other disciplines.\n\nIt is claimed that the inclusion of signed zero in IEEE 754 makes it much easier to achieve numerical accuracy in some critical problems, in particular when computing with complex elementary functions. On the other hand, the concept of signed zero runs contrary to the general assumption made in most mathematical fields that negative zero is the same thing as zero. Representations that allow negative zero can be a source of errors in programs, if software developers do not take into account that while the two zero representations behave as equal under numeric comparisons, they yield different results in some operations.\n\nThe widely used two's complement encoding does not allow a negative zero. In a 1+7-bit sign-and-magnitude representation for integers, negative zero is represented by the bit string . In an 8-bit one's complement representation, negative zero is represented by the bit string . In all three encodings, positive zero is represented by .\nIn IEEE 754 binary floating point numbers, zero values are represented by the biased exponent and significand both being zero. Negative zero has the sign bit set to one. One may obtain negative zero as the result of certain computations, for instance as the result of arithmetic underflow on a negative number, or codice_1, or simply as codice_2.\n\nIn IEEE 754 decimal floating point encoding, a negative zero is represented by an exponent being any valid exponent in the range for the encoding, the true significand being zero, and the sign bit being one.\n\nThe IEEE 754 floating point standard specifies the behavior of positive zero and negative zero under various operations. The outcome may depend on the current IEEE rounding mode settings.\n\nIn systems that include both signed and unsigned zeros, the notation formula_1 and formula_2 is sometimes used for signed zeros.\n\nAddition and multiplication are commutative, but there are some special rules that have to be followed, which mean the usual mathematical rules for algebraic simplification may not apply. The formula_3 sign below shows the signed result of the operations.\n\nThe usual rule for signs is always followed when multiplying or dividing:\n\n\nThere are special rules for adding or subtracting signed zero:\n\n\nBecause of negative zero (and also when the rounding mode is upward or downward), the expressions and , for floating-point variables \"x\" and \"y\", cannot be replaced by . However can be replaced by \"x\" with rounding to nearest (except when \"x\" can be a signaling NaN).\n\nSome other special rules:\n\n\nDivision of a non-zero number by zero sets the divide by zero flag, and an operation producing a NaN sets the invalid operation flag. An exception handler is called if enabled for the corresponding flag.\n\nAccording to the IEEE 754 standard, negative zero and positive zero should compare as equal with the usual (numerical) comparison operators, like the codice_3 operators of C and Java. In those languages, special programming tricks may be needed to distinguish the two values:\n\n\nNote: Casting to integral type will not always work, especially on two's complement systems.\n\nHowever, some programming languages may provide alternative comparison operators that do distinguish the two zeros. This is the case, for example, of the equals method in Java's codice_6 wrapper class.\n\nInformally, one may use the notation \"−0\" for a negative value that was rounded to zero. This notation may be useful when a negative sign is significant; for example, when tabulating Celsius temperatures, where a negative sign means \"below freezing\".\n\nIn statistical mechanics, one sometimes uses negative temperatures to describe systems with population inversion, which can be considered to have a temperature greater than positive infinity, because the coefficient of energy in the population distribution function is −1/Temperature. In this context, a temperature of −0 is a (theoretical) temperature larger than any other negative temperature, corresponding to the (theoretical) maximum conceivable extent of population inversion, the opposite extreme to +0.\n\n\n"}
{"id": "3327747", "url": "https://en.wikipedia.org/wiki?curid=3327747", "title": "Sumner Byron Myers", "text": "Sumner Byron Myers\n\nSumner Byron Myers (February 19, 1910 – October 8, 1955) was an American mathematician specialized in topology. He studied at Harvard University under H. C. Marston Morse, where he was graduated with a Ph.D. in 1932. Myers then pursued postdoctoral studies at Princeton University (1934–1936) before becoming a professor for mathematics at the University of Michigan, where an award for outstanding students of mathematics has been named in his honor. He died unexpectedly from a heart attack during the 1955 Michigan–Army football game at Michigan Stadium.\n"}
{"id": "56015853", "url": "https://en.wikipedia.org/wiki?curid=56015853", "title": "Ugo Amaldi (mathematician)", "text": "Ugo Amaldi (mathematician)\n\nUgo Amaldi (18 April 1875 – 11 November 1957) was an Italian mathematician. He contributed to the field of analytic geometry and worked on Lie groups. His son Edoardo was a physicist.\n"}
{"id": "288270", "url": "https://en.wikipedia.org/wiki?curid=288270", "title": "Uniformization theorem", "text": "Uniformization theorem\n\nIn mathematics, the uniformization theorem says that every simply connected Riemann surface is conformally equivalent to one of three Riemann surfaces: the open unit disk, the complex plane, or the Riemann sphere. In particular it implies that every Riemann surface admits a Riemannian metric of constant curvature. For compact Riemann surfaces, those with universal cover the unit disk are precisely the hyperbolic surfaces of genus greater than 1, all with non-abelian fundamental group; those with universal cover the complex plane are the Riemann surfaces of genus 1, namely the complex tori or elliptic curves with fundamental group ; and those with universal cover the Riemann sphere are those of genus zero, namely the Riemann sphere itself, with trivial fundamental group.\n\nThe uniformization theorem is a generalization of the Riemann mapping theorem from proper simply connected open subsets of the plane to arbitrary simply connected Riemann surfaces. The uniformization theorem also has an equivalent statement in terms of closed Riemannian 2-manifolds: each such manifold has a conformally equivalent Riemannian metric with constant curvature.\n\nMany classical proofs of the uniformization theorem rely on constructing a real-valued harmonic function on the simply connected Riemann surface, possibly with a singularity at one or two points and often corresponding to a form of Green's function. Four methods of constructing the harmonic function are widely employed: the Perron method; the Schwarz alternating method; Dirichlet's principle; and Weyl's method of orthogonal projection. In the context of closed Riemannian 2-manifolds, several modern proofs invoke nonlinear differential equations on the space of conformally equivalent metrics. These include the Beltrami equation from Teichmüller theory and an equivalent formulation in terms of harmonic maps; Liouville's equation, already studied by Poincaré; and Ricci flow along with other nonlinear flows.\n\nFelix and Henri conjectured the uniformization theorem for (the Riemann surfaces of) algebraic curves. extended this to arbitrary multivalued analytic functions and gave informal arguments in its favor. The first rigorous proofs of the general uniformization theorem were given by and . Paul Koebe later gave several more proofs and generalizations. The history is described in ; a complete account of uniformization up to the 1907 papers of Koebe and Poincaré is given with detailed proofs in (the Bourbaki-type pseudonym of the group of fifteen mathematicians who jointly produced this publication).\n\nEvery Riemann surface is the quotient of a free, proper and holomorphic action of a discrete group on its universal covering and this universal covering is holomorphically isomorphic (one also says: \"conformally equivalent\" or \"biholomorphic\") to one of the following:\n\n\nRado's theorem shows that every Riemann surface is automatically second-countable. Although Rado's theorem is often used in proofs of the uniformization theorem, some proofs have been formulated so that Rado's theorem becomes a consequence. Second countability is automatic for compact Riemann surfaces.\n\nOn an oriented 2-manifold, a Riemannian metric induces a complex structure using the passage to isothermal coordinates. If the Riemannian metric is given locally as\n\nthen in the complex coordinate \"z\" = \"x\" + i\"y\", it takes the form\n\nwhere\n\nso that \"λ\" and \"μ\" are smooth with \"λ\" > 0 and |\"μ\"| < 1. In isothermal coordinates (\"u\", \"v\") the metric should take the form\n\nwith \"ρ\" > 0 smooth. The complex coordinate \"w\" = \"u\" + i \"v\" satisfies\n\nso that the coordinates (\"u\", \"v\") will be isothermal locally provided the Beltrami equation\n\nhas a locally diffeomorphic solution, i.e. a solution with non-vanishing Jacobian.\n\nThese conditions can be phrased equivalently in terms of the exterior derivative and the Hodge star operator .\non differentials by .\nLet be the Laplace–Beltrami operator. By standard elliptic theory, can be chosen to be harmonic near a given point, i.e. , with non-vanishing. By the Poincaré lemma has a local solution exactly when . This condition is equivalent to , so can always be solved locally. Since is non-zero and the square of the Hodge star operator is −1 on 1-forms, and must be linearly independent, so that and give local isothermal coordinates.\n\nThe existence of isothermal coordinates can be proved by other methods, for example using the general theory of the Beltrami equation, as in , or by direct elementary methods, as in and .\n\nFrom this correspondence with compact Riemann surfaces, a classification of closed orientable Riemannian 2-manifolds follows. Each such is conformally equivalent to a unique closed 2-manifold of constant curvature, so a quotient of one of the following by a free action of a discrete subgroup of an isometry group:\n\n\nThe first case gives the 2-sphere, the unique 2-manifold with constant positive curvature and hence positive Euler characteristic (equal to 2). The second gives all flat 2-manifolds, i.e. the tori, which have Euler characteristic 0. The third case covers all 2-manifolds of constant negative curvature, i.e. the \"hyperbolic\" 2-manifolds all of which have negative Euler characteristic. The classification is consistent with the Gauss–Bonnet theorem, which implies that for a closed surface with constant curvature, the sign of that curvature must match the sign of the Euler characteristic. The Euler characteristic is equal to 2 – 2\"g\", where \"g\" is the genus of the 2-manifold, i.e. the number of \"holes\".\n\nIn 1913 Hermann Weyl published his classic textbook \"Die Idee der Riemannschen Fläche\" based on his Göttingen lectures from 1911 to 1912. It was the first book to present the theory of Riemann surfaces in a modern setting and through its three editions has remained influential. Dedicated to Felix Klein, the first edition incorporated Hilbert's treatment of the Dirichlet problem using Hilbert space techniques; Brouwer's contributions to topology; and Koebe's proof of the uniformization theorem and its subsequent improvements. Much later developed his method of orthogonal projection which gave a streamlined approach to the Dirichlet problem, also based on Hilbert space; that theory, which included Weyl's lemma on elliptic regularity, was related to Hodge's theory of harmonic integrals; and both theories were subsumed into the modern theory of elliptic operators and Sobolev spaces. In the third edition of his book from 1955, translated into English in , Weyl adopted the modern definition of differential manifold, in preference to triangulations, but decided not to make use of his method of orthogonal projection. followed Weyl's account of the uniformisation theorem, but used the method of orthogonal projection to treat the Dirichlet problem. This approach will be outlined below. describes the approach in Weyl's book and also how to shorten it using the method of orthogonal projection. A related account can be found in .\n\nIn introducing the Ricci flow, Richard S. Hamilton showed that the Ricci flow on a closed surface uniformizes the metric (i.e., the flow converges to a constant curvature metric). However, his proof relied on the uniformization theorem. The missing step involved Ricci flow on the 2-sphere: a method for avoiding an appeal to the uniformization theorem (for genus 0) was provided by ; a short self-contained account of Ricci flow on the 2-sphere was given in .\n\nKoebe proved the general uniformization theorem that if a Riemann surface is homeomorphic to an open subset of the complex sphere (or equivalently if every Jordan curve separates it), then it is conformally equivalent to an open subset of the complex sphere.\n\nIn 3 dimensions, there are 8 geometries, called the eight Thurston geometries. Not every 3-manifold admits a geometry, but Thurston's geometrization conjecture proved by Grigori Perelman states that every 3-manifold can be cut into pieces that are geometrizable.\n\nThe simultaneous uniformization theorem of Lipman Bers shows that it is possible to simultaneously uniformize two compact Riemann surfaces of the same genus >1 with the same quasi-Fuchsian group.\n\nThe measurable Riemann mapping theorem shows more generally that the map to an open subset of the complex sphere in the uniformization theorem can be chosen to be a quasiconformal map with any given bounded measurable Beltrami coefficient.\n\n\n\n\nPerron's method\n\nSchwarz's alternating method\n\nDirichlet principle\n\nWeyl's method of orthogonal projection\n\nSario operators\n\nBeltrami's equation\n\nHarmonic maps\n\nLiouville's equation\n\nFlows on Riemannian metrics\n\n\n"}
{"id": "52297221", "url": "https://en.wikipedia.org/wiki?curid=52297221", "title": "Volume and displacement indicators for an architectural structure", "text": "Volume and displacement indicators for an architectural structure\n\nThe volume (W) and displacement (Δ) indicators have been discovered by Philippe Samyn in 1997 to help the search for the optimal geometry of architectural structures.\n\nA resistant structure is anything amorphous or living, which supports the forces to which it is normally subjected without breaking. \nCharacterised by its shape and its constituent materials, and three-dimensional by nature, the amorphous structure usually has a two-dimensional geometry, which is given a thickness, or a three-dimensional geometry (the three-dimensional structure). The latter is formed of a pair of two-dimensional structures on non-parallel planes or three-dimensional curved volumes as in the case for any living things, including a specific group: the shells (a three-dimensional surface with a thickness). An example of these is the structure of cars, boats or planes, or even human skulls, sea shells or the stem of a dandelion. \nThe geometry of most \"architectural\" structures (such as buildings or bridges) is twodimensional and it is essential to study this aspect, whether for aesthetic, commodity-related or economic reasons. Several criteria are therefore taken into account in its definition.\n\nThe study is limited to the quest of the geometry giving the structure of minimum volume.\n\nThe cost of a structure depends on the nature and the quantity of the materials used as well as the tools and human resources required for its production.\n\nAlthough technological progress has reduced the cost of tools and the amount of human resources required, and despite the fact that computerised calculation tools can now be used to determine the dimension of a structure so that the load it bears at every point is within the admissible limits allowed by its constituent materials, it is also necessary for its geometry to be optimal. It is far from simple to find this optimal point because the choice available is so vast.\n\nFurthermore, the resistance of the structure is not the only criterion to take into account. In many cases, it is also important to ensure that it will not undergo excessive deformation under static loads or that it does not vibrate to inconvenient or dangerous levels when subjected to dynamic loads.\n\nVolume and displacement indocators, W and Δ, discovered by Philippe Samyn in August 1997, are useful tools in this regard. This approach does not take into account phenomena of elastic instability. Indeed, it can be shown that it is always possible to design a structure so that this effect becomes negligible.\n\nThe objective is to ascertain the optimal morphology for a two-dimensional structure with constant thickness, which:\n\nEach form chosen corresponds to a volume of material V (in m³) and a maximum deformation δ (in m). \nTheir calculation depends on the factors L, H, E, σ and F. These calculations are long and tedious, they cloud the objective of finding the optimal form.\n\nIt is, nevertheless, possible to overcome this problem by setting each factor to unity: while all other characteristics remain the same. Length L is therefore set to 1m, H to H/L, E and σ to 1Pa, and F to 1N.\nThis \"reduced\" structure has a volume of material W= σV/ FL (the volume indicator) and a maximum deformation Δ = Eδ / σL (the displacement indicator). Their main characteristic is that they are numbers without physical dimensions (dimensionless) and their value, for every morphology considered, depends only on the ratio L/H, i.e. the geometric slenderness ratio of the form.\n\nThis method can easily be applied to three-dimensional structures as illustrated in the following examples.\n\nThe theory related to the indicators has been taught since 2000, and among other institutions, at the department of Civil Engineering and of Architecture at the Vrije Universiteit Brussel (VUB ; section \"material mechanics and constructions\") leading to research and publications under the direction of Prof. Dr. Ir. Philippe Samyn (from 2000 to 2006); Prof. Dr. Ir. Willy Patrick De Wilde (from 2000 to 2011) and now Prof. Dr. Ir. Lincy Pyl.\nThe \"reference book\", since the reference thesis, reports the developments of the theory at Samyn and Partners as well as the VUB, up to 2004.\n\nThe theory is open to everyone who wants to contribute, W and Δ being to be calculated for any resistant structure as defined in paragraph 1 here above. \nProgresses in material sciences, robotics and three dimensional printing, lead to the creation of new structural forms lighter than anyone known today. \nThe geometry of minimal surfaces of constant thickness in a homogeneous material is, for example, substantially modified when thickness and/or local alloable stress are varying.\n\nThe macrostructures considered here may be composed of \"structural elements\" which material presents a \"microstructure\".\n\nWhether searching to limit the stress or the deformation, macrostructure, structural element and microstructure have each, a weight \"Vρ\", when \"ρ\" is the volumic weight of materials, in N/m³, function of the sollicitations {\"F\"} (for \"force\" in général) applied to them, of their size {\"L\"} (for length or \"size\" in general) , of their shape {\"G\"} (for geometry or \"shape\" in general), and of their constituting material {\"M\"} (for \"material\" in general).\n\nIt can also be expressed as shape and material ({\"G\"}{\"M\"}) defining the weight (\"Vρ\") for the structure of a given size under given force ({\"F\"}{\"L\"}). \n\nIn material mechanics and for the structural elements under a specific loading case, the factor {\"G\"} corresponds to the \"form factor\" for elements of continuous section out of a solid material (without voids).\n\nThe constituting material might however present a microstructure with voids. This cellular structure enhances than the form factor, whatever the loading case.\n\nThe factor {\"M\"} caracterises a material which efficiency might be compared to another for a given loading case, and the independently of the form factor {\"G\"}.\n\nThe indicators \"W\" = \"σV\"/\"FL\" and Δ = \"δE\"/\"σL\" just defined, caracterise the macrostructures, while the same notations and symbols in small letters, \"w\" = \"σv\"/\"fl\" and Δ = \"δE\"/\"σl\", refer to the structural element.\n\nThe figure 1 gives the values of \"W\" and Δ for the structural element subject to traction, compression, bending and shear. The left column relates to the limitation of stress and the right column to the limitation of deformation. It shows the direct relation of \"W\" to {\"G\"}{\"M\"} as:\n\nand\n\nor\n\nThen, as \"W\" and Δ depend only on formula_7:\n\nand:\n\nwhich for a given loading case, is the specific weight of a macrostructure per unit of force and length, depending only from the geometry through \"L/H\", and the materials though \"σ\"/\"ρ\".\n\n\"Wρ\"/\"σ\" includes thus, the material factor {\"M\"} (\"ρ\"/\"σ\" and \"ρ\"/\"E\" for tension and compression without buckling, \"ρ\"/\"E\" for compression limited by buckling, \"ρ\"/\"σ\" and \"ρ\"/\"E\" for pure bending, \"ρ\" and \"ρ\"/\"G\" for pure shear) and the form factor {\"G\"}.\n\nAll other factor being equal, a cluster of tubes with a diameter \"H\" and a wall thickness \"e\", compared to a solid bar of equal volume in a material caracterised by \"ρ\" , \"σ\" , \"E\" et \"G\" , presents an apparent density \"ρ\" = 4\"k\"(1 − \"k\")\"ρ\" with \"k\" = \"e\"/\"H\", allowable stress \"σ\" = 4\"k\"(1 − \"k\")\"σ\",\n\nThe Young's modulus is formula_10 and the shear modulus is formula_11.\n\nThus\n\nand\n\nThis explains the better performances of lighter materials for structural elements subject to compression or bending. \nThis indicator allows to compare the efficiency of macrostructures including geometry and material.\n\nIt echos the work of M.F. Ashby: \"Materials Selection in Mechanical Design\" (1992). He analyses {\"G\"} and {\"M\"} separately as, for his studies, {\"M\"} relates to a large amount of the materials physical properties.\n\nDifferent and complementary, it can also be placed alongside work carried out since 1969 by the Institut Für Leichte Flächentragwerke in Stuttgart under the direction of Frei Otto and now Werner SobekK, which refers to indices named \"Tra\" and \"Bic\". The \"Tra\" is defined as the product of the length of the trajectory of the force \"F\", (causing the collapse of the structure) onto the supports by the intensity of this force, and the \"Bic\" is the relationship of the mass of the structure with \"Tra\".\n\nSince \"ρ*\" is the density of the material (in kg/m), and \"α\" is, like \"W\", a constant depending on the type of structure and the loading case: \n\ntherefore, with stress formula_15 reached under formula_16<br>\n\nand as\n\nUnlike \"W\" , which is dimensionless, \"Bic\" is expressed in \"kg/Nm\". Therefore, depending on the material, an independent comparison of different morphologies is not possible. \nIt is surprising to note that despite the abundance of their works, none of them mention or make any effort to study \"W\" and its relationship with \"L/H\".\n\nIt appears that only V. Quintas Ripoll and W. Zalewski and St. Kus mentioned the volume indicator \"W\" without examining it in depth. \n\n\n\nIn this regard, it is important to note that the existence of anchoring points of an element in traction may reduce the apparent permissible stress to the same level as the reduction necessary to take into account a moderate level of elastic instability. \nThe influence on \"W\" of the buckling of the compressed parts on one side and of the anchoring points at the extremities of an element in traction on the other side is analysed on pages 30 to 58 in the « reference book ».\n\n\n\n\n\nIt follows that initially, only \"W\" and Δ should be taken into account for the morphological design of a structure, assuming that it is ultra-dampened (i.e. its internal damping is greater than the critical damping), which makes it impervious to dynamic stress. \nThe volume \"V\" of a structure is therefore directly proportional to the total intensity of the force \"F\" which is applied to it, to its length \"L\" and to the morphological factor \"W\"; it is inversely proportional to the stress \"σ\" to which it can be subjected. Furthermore, the weight of a structure is proportional to the density \"ρ\" of the material from which it is constructed. However, its maximum displacement \"δ\" remains proportional to the span \"L\" and the morphological factor Δ, as well as the ratio between its working stress \"σ\" and the modulus of elasticity \"E\".\n\nIf it is a case of limiting the weight (or the volume) and the deformation of a structure for a given stress \"F\" and span \"L\", with all other aspects remaining unchanged, then the work of the structural engineer involves minimising \"W\" and \"ρ/σ\" on one side and Δ and \"σ/E\" ont the other.\n\nFor the large majority of compressed elements, it is possible to limit the reduction of the working stress to 25% by taking into account elastic instability, providing that the designer focuses on ensuring an efficient geometric design from as early as the initial sketches. This means that the increase in their volume indicator can also be limited to 25% . The volume of the elements subject to pure traction is also only very rarely limited to the product of the net distance over which a force is applied by a section strained at the permissible stress. In other words, their real volume indicator is thus also higher than the one which results from the calculation of \"W\". A bar under traction can be welded at its extremities; no extra material apart from the negligible welding material is added, but the rigidity introduce parasitic moments which absorb some of the permissible stress.\n\nThe bar can be articulated at its extremities and work at its permissible stress, but this requires close end sockets or attachment mechanisms whose volume is far from negligible, especially if the bar is short or highly stressed. As L.H. Cox demonstrated, in this case, it is worth taking into account \"n\" bars each with a cross-section of Ω/\"n\", strained by force \"F/n\" with 2\"n\" sockets, instead of one bar with a cross-section Ω strained by a force \"F\" with 2 sockets, since the total volume of 2\"n\" sockets in the first case is much less than that of 2 sockets in the second.\n\nThe anchoring of the extremities of a bar under traction can also be ensured by adherence, as is usually the case for the rebars in elements made of reinforced concrete. In this specific case, it is necessary to have an anchoring length at least 30 times the diameter of the bar. The bar then has a length \"L\" + 60\"H\" for a useful length \"L\"; its theoretical volume indicator \"W\" = 1 becomes \"W\" = 1 + 60\"H\"/\"L\". Consequently, \"L\"/\"H\" must be greater than 240 (which is always theoretically possible) so that \"W\" does not increase by more than 25%. This observation also helps to show another reason for taking into account n bars with a crosssection Ω/\"n\" instead of one bar with a cross-section Ω.\n\nFinally, connections consisting of bolts, dowels, pins or nails, especially in the case of wooden components, significantly reduce usable sections. For elements in traction, a reduction of 25% in the working stress or an increase of 25% in the volume is therefore also necessary in the majority of cases. Determining the volume and the displacement of a structure using the indicators \"W\" and Δ is therefore reliable theoretically, providing that:\n\n\n\n\nThe volume of the material of the structure, as determined using \"W\", can only be obtained accurately if the theoretical values of the relevant characteristic of the sections under strain \"σ\" can be measured in practice.\nAs shown in Figure 1 above, this characteristic is:\n\npure bending) ;\n\nIt is always possible to obtain the precise value of these characteristics when the parts are made of moulded materials, such as reinforced concrete, or squared-off materials, such as wood or stone. However, this is not the case for laminated or extruded materials, produced on an industrial production line, such as steel or aluminium. It is important therefore to produce these elements with the smallest possible difference in size between two of them in order to avoid an unnecessary use of material. This use is consistent when the related deviation \"c\" between two successive values \"k\" and \"k\" is constant, thus (\"k\" − \"k\") / \"k\" = \"c\" or \"k\" = (\"c\" + 1) \"k\" or \"k\" = \"k\".\n\nThis is the principle of the geometric series known as the Renard Series (named after Colonel Renard who was the first to use them in calculating the diameter of cabling on aircraft) featured in the French standard NF X01-002. When all the necessary values are only very slightly greater than a series value, \"c\" represents the maximum increase and \"c\"/2 the average increase of \"W\". Being universally used, the case of the steel profiles requires an in-depth examination (see the “reference book”; page 26 to 29). Consequently, the use of industrial steel profiles automatically leads to a significant increase of \"W\":\n\n\nThis situation is magnified when the number of profiles available is restricted, which may explain the use of forms which are not theoretically optimal but which tend to subject the available profiles to the permissible stress \"σ\" (such as, for example, pylons for high-voltage electric lines or variable height truss bridges). For structures subject to pure bending, this also explains the use of flat plates of variable lengths added to the flanges of these \"I\" profiles to obtain the inertia or resisting moment required, with the greatest degree of accuracy. Conversely, the significant variety in the tubes available enables a relative deviation value \"c\" which is both smaller and more constant. They also cover a much wider range in both the lower and higher characteristic values. Since their geometric performance is practically identical to that of the I profiles, tubes are the most appropriate industrial solution in order to practically eliminate any increase in the volume indicator \"W\". Nevertheless, practical issues of availability and corrosion may limit their use.\n\nThe following figures show the values of the indicators according to the ratio L/H for a number of types of structures.\n\nFigure 2 and 3: W and Δ for a horizontal isostatic span under a uniformly distributed vertical load made up of: \n\nFigure 4: for the transfer to two equidistant supports on the horizontal of a vertical point load (in this case Δ=W) or evenly distributed lead: \"F\" = 1. \n\nFigure 5 and 6: \"W\" for a vertical mast, with a constant width, subject to a horizontal load which is evenly distributed along its height or concentrated at the top.\n\nFigure 7: \"W\" for a membrane of revolution on a vertical axis, with a constant or variable thickness, under an evenly distributed vertical load. It is surprising to note that the minimum value is reached for a conical dome of variable thickness with an opening angle of 90° (\"L\"/\"H\" = 2 ; \"W\" = 0,5!).\n\nApplications discussed in the « reference book » are:\n\n\"W\" can easily be determined in order to optimise structures made up of a number of different construction elements (see « reference book » pages 100–106) as shown, for instance, for the wind turbine in Figure 8.\n\nOr a parabolic roof coupled with large vertical glazed gables subject to wind loads, as seen at Leuven station in Belgium, shown in Figure 9 (see reference for a detailed analysis).\n\nThe optimisation of the King Cross truss for the facade of the Europa building in Brussels (see reference pages 93–101 for detailed analysis) is another example.\n"}
{"id": "58203904", "url": "https://en.wikipedia.org/wiki?curid=58203904", "title": "Yitzchak Ratner", "text": "Yitzchak Ratner\n\nYitzchak ben Nechemia Ratner (; 1857, Shklov, Russian Empire — ?) was a nineteenth-century Jewish maskilic mathematician. He wrote mathematical and astronomical articles for various journals, and was the author of \"Mishpat Emet\" (1884), a criticism of Lichtenfeld's pamphlets against Slonimski's works. In 1888 he edited a second edition of Slonimski's \"Yesodei Chokmat ha-Shi'ur\" on the principles of algebra.\n\n"}
