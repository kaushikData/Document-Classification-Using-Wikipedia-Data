{"id": "4356683", "url": "https://en.wikipedia.org/wiki?curid=4356683", "title": "177 (number)", "text": "177 (number)\n\n177 (one hundred [and] seventy-seven) is the natural number following 176 and preceding 178.\n\nformula_1\n\n\n\n\n\n\n\n177 is also:\n\n\n"}
{"id": "7088921", "url": "https://en.wikipedia.org/wiki?curid=7088921", "title": "Abel's test", "text": "Abel's test\n\nIn mathematics, Abel's test (also known as Abel's criterion) is a method of testing for the convergence of an infinite series. The test is named after mathematician Niels Henrik Abel. There are two slightly different versions of Abel's test – one is used with series of real numbers, and the other is used with power series in complex analysis. Abel's uniform convergence test is a criterion for the uniform convergence of a series of functions dependent on parameters.\n\nSuppose the following statements are true:\n\n\nThen formula_2 is also convergent.\n\nIt is important to understand that this test is mainly pertinent and \nuseful in the context of non absolutely convergent series formula_3.\nFor absolutely convergent series, this theorem, albeit true, is almost self evident.\n\nThis theorem can be considered a special case of Dirichlet's test, or can be proved directly using summation by parts.\n\nA closely related convergence test, also known as Abel's test, can often be used to establish the convergence of a power series on the boundary of its circle of convergence. Specifically, Abel's test states that if a sequence of \"positive real numbers\" formula_4 is decreasing monotonically (or at least that for all \"n\" greater than some natural number \"m\", we have formula_5) with\n\nthen the power series\n\nconverges everywhere on the closed unit circle, except when \"z\" = 1. Abel's test cannot be applied when \"z\" = 1, so convergence at that single point must be investigated separately. Notice that Abel's test implies in particular that the radius of convergence is at least 1. It can also be applied to a power series with radius of convergence \"R\" ≠ 1 by a simple change of variables \"ζ\" = \"z\"/\"R\". Notice that Abel's test is a generalization of the Leibniz Criterion by taking \"z\" = −1.\n\nProof of Abel's test: Suppose that \"z\" is a point on the unit circle, \"z\" ≠ 1. For each formula_8, we define\n\nBy multiplying this function by (1 − \"z\"), we obtain\nThe first summand is constant, the second converges uniformly to zero (since by assumption the sequence formula_4 converges to zero). It only remains to show that the series converges. We will show this by showing that it even converges absolutely:\nformula_12\nwhere the last sum is a converging telescoping sum. The absolute value vanished because the sequence formula_4 is decreasing by assumption.\n\nHence, the sequence formula_14 converges (even uniformly) on the closed unit disc. If formula_15, we may divide by (1 − \"z\") and obtain the result.\n\nAbel's uniform convergence test is a criterion for the uniform convergence of a series of functions or an improper integration of functions dependent on parameters. It is related to Abel's test for the convergence of an ordinary series of real numbers, and the proof relies on the same technique of summation by parts.\n\nThe test is as follows. Let {\"g\"} be a uniformly bounded sequence of real-valued continuous functions on a set \"E\" such that \"g\"(\"x\") ≤ \"g\"(\"x\") for all \"x\" ∈ \"E\" and positive integers \"n\", and let {\"f\"} be a sequence of real-valued functions such that the series Σ\"f\"(\"x\") converges uniformly on \"E\". Then Σ\"f\"(\"x\")\"g\"(\"x\") converges uniformly on \"E\".\n\n\n"}
{"id": "37663200", "url": "https://en.wikipedia.org/wiki?curid=37663200", "title": "Atiyah–Hitchin–Singer theorem", "text": "Atiyah–Hitchin–Singer theorem\n\nIn differential geometry, the Atiyah–Hitchin–Singer theorem, introduced by , states that the space of SU(2) anti self dual Yang–Mills fields on a 4-sphere with index \"k\" > 0 has dimension 8\"k\" – 3.\n\n"}
{"id": "32829967", "url": "https://en.wikipedia.org/wiki?curid=32829967", "title": "Base (exponentiation)", "text": "Base (exponentiation)\n\nIn exponentiation, the base is the number b in an expression of the form b.\n\nThe number n is called the exponent and the expression is known formally as exponentiation of b by n or the exponential of n with base b. It is more commonly expressed as \"the nth power of b\", \"b to the nth power\" or \"b to the power n\". For example, the fourth power of 10 is 10,000 because . The term \"power\" strictly refers to the entire expression, but is sometimes used to refer to the exponent.\n\nRadix is the traditional term for \"base\", but usually refers then to one of the common bases: decimal (10), binary (2), hexadecimal (16), or sexagesimal (60). When the concepts of variable and constant came to be distinguished, the process of exponentiation was seen to transcend the algebraic functions.\n\nIn his 1748 \"Introductio in analysin infinitorum\", Leonhard Euler referred to \"base a = 10\" in an example. He referred to \"a\" as a \"constant number\" in an extensive consideration of the function F(\"z\") = \"a\". First \"z\" is a positive integer, then negative, then a fraction, or rational number.\n\nWhen the nth power of b equals a number a, or a = b, then b is called an \"nth root\" of a. For example, 10 is a fourth root of 10,000.\n\nThe inverse function to exponentiation with base b (when it is well-defined) is called the logarithm to base b, denoted log. Thus:\n\nFor example, log 10,000 = 4.\n"}
{"id": "393359", "url": "https://en.wikipedia.org/wiki?curid=393359", "title": "Beth number", "text": "Beth number\n\nIn mathematics, the infinite cardinal numbers are represented by the Hebrew letter formula_1 (aleph) indexed with a subscript that runs over the ordinal numbers (see aleph number). The second Hebrew letter formula_2 (beth) is used in a related way, but does not necessarily index all of the numbers indexed by formula_1.\n\nTo define the beth numbers, start by letting\n\nbe the cardinality of any countably infinite set; for concreteness, take the set formula_5 of natural numbers to be a typical case. Denote by \"P\"(\"A\") the power set of \"A\"; i.e., the set of all subsets of \"A\". Then define\n\nwhich is the cardinality of the power set of \"A\" if formula_7 is the cardinality of \"A\".\n\nGiven this definition,\n\nare respectively the cardinalities of\n\nso that the second beth number formula_10 is equal to formula_11, the cardinality of the continuum, and the third beth number formula_12 is the cardinality of the power set of the continuum.\n\nBecause of Cantor's theorem each set in the preceding sequence has cardinality strictly greater than the one preceding it. For infinite limit ordinals λ the corresponding beth number is defined as the supremum of the beth numbers for all ordinals strictly smaller than λ:\n\nOne can also show that the von Neumann universes formula_14 have cardinality formula_15.\n\nAssuming the axiom of choice, infinite cardinalities are linearly ordered; no two cardinalities can fail to be comparable. Thus, since by definition no infinite cardinalities are between formula_16 and formula_17, it follows that \nRepeating this argument (see transfinite induction) yields \nformula_19 \nfor all ordinals formula_20.\n\nThe continuum hypothesis is equivalent to\n\nThe generalized continuum hypothesis says the sequence of beth numbers thus defined is the same as the sequence of aleph numbers, i.e., \nformula_22 \nfor all ordinals formula_20.\n\nSince this is defined to be formula_16 or aleph null then sets with cardinality formula_25 include:\n\n\nSets with cardinality formula_10 include:\n\n\nformula_12 (pronounced \"beth two\") is also referred to as 2 (pronounced \"two to the power of c\").\n\nSets with cardinality formula_12 include:\n\n\nformula_29 (pronounced \"beth omega\") is the smallest uncountable strong limit cardinal.\n\nThe more general symbol formula_30, for ordinals α and cardinals κ, is occasionally used. It is defined by:\n\nSo\n\nIn ZF, for any cardinals κ and μ, there is an ordinal α such that:\n\nAnd in ZF, for any cardinal κ and ordinals α and β:\n\nConsequently, in Zermelo–Fraenkel set theory absent ur-elements with or without the axiom of choice, for any cardinals κ and μ, the equality\n\nholds for all sufficiently large ordinals β (that is, there is an ordinal α such that the equality holds for every ordinal β ≥ α).\n\nThis also holds in Zermelo–Fraenkel set theory with ur-elements with or without the axiom of choice provided the ur-elements form a set which is equinumerous with a pure set (a set whose transitive closure contains no ur-elements). If the axiom of choice holds, then any set of ur-elements is equinumerous with a pure set.\n\n"}
{"id": "35727092", "url": "https://en.wikipedia.org/wiki?curid=35727092", "title": "Better-quasi-ordering", "text": "Better-quasi-ordering\n\nIn order theory a better-quasi-ordering or bqo is a quasi-ordering that does not admit a certain type of bad array. Every better-quasi-ordering is a well-quasi-ordering.\n\nThough \"well-quasi-ordering\" is an appealing notion, many important infinitary operations do not preserve well-quasi-orderedness. \nAn example due to Richard Rado illustrates this. \nIn a 1965 paper Crispin Nash-Williams formulated the stronger notion of \"better-quasi-ordering\" in order to prove that the class of trees of height ω is well-quasi-ordered under the \"topological minor\" relation. Since then, many quasi-orderings have been proven to be well-quasi-orderings by proving them to be better-quasi-orderings. For instance, Richard Laver established Fraïssé's conjecture by proving that the class of scattered linear order types is better-quasi-ordered. More recently, Carlos Martinez-Ranero has proven that, under the Proper Forcing Axiom, the class of Aronszajn lines is better-quasi-ordered under the embeddability relation.\n\nIt is common in better-quasi-ordering theory to write formula_1 for the sequence formula_2 with the first term omitted. Write formula_3 for the set of finite, strictly increasing sequences with terms in formula_4, and define a relation formula_5 on formula_3 as follows: formula_7 if there is formula_8 such that formula_9 is a strict initial segment of formula_10 and formula_11. The relation formula_5 is not transitive.\n\nA \"block\" formula_13 is an infinite subset of formula_3 that contains an initial segment of every\ninfinite subset of formula_15. For a quasi-order formula_16, a \"formula_16-pattern\" is a function from some block formula_13 into formula_16. A formula_16-pattern formula_21 is said to be \"bad\" if formula_22 for every pair formula_23 such that formula_7; otherwise formula_25 is \"good\". A quasi-ordering formula_16 is called a \"better-quasi-ordering\" if there is no bad formula_16-pattern.\n\nIn order to make this definition easier to work with, Nash-Williams defines a \"barrier\" to be a block whose elements are pairwise incomparable under the inclusion relation formula_28. A \"formula_16-array\" is a formula_16-pattern whose domain is a barrier. By observing that every block contains a barrier, one sees that formula_16 is a better-quasi-ordering if and only if there is no bad formula_16-array.\n\nSimpson introduced an alternative definition of \"better-quasi-ordering\" in terms of Borel functions formula_33, where formula_34, the set of infinite subsets of formula_4, is given the usual product topology.\n\nLet \"formula_16\" be a quasi-ordering and endow formula_16 with the discrete topology. A \"formula_16-array\" is a Borel function formula_39 for some infinite subset formula_40 of formula_4. A formula_16-array formula_25 is \"bad\" if formula_44 for every formula_45;\nformula_25 is \"good\" otherwise. The quasi-ordering formula_16 is a \"better-quasi-ordering\" if there is no bad formula_16-array in this sense.\n\nMany major results in better-quasi-ordering theory are consequences of the Minimal Bad Array Lemma, which appears in Simpson's paper as follows. See also Laver's paper, where the Minimal Bad Array Lemma was first stated as a result. The technique was present in Nash-Williams' original 1965 paper.\n\nSuppose formula_49 is a quasi-order. A \"partial ranking\" formula_50 of formula_16 is a well-founded partial ordering of formula_16 such that formula_53. For bad formula_16-arrays (in the sense of Simpson) formula_55 and formula_56, define:\nWe say a bad formula_16-array formula_60 is \"minimal bad\" (with respect to the partial ranking formula_50) if there is no bad formula_16-array formula_25 such that formula_64.\nNote that the definitions of formula_65 and formula_66 depend on a partial ranking formula_50 of formula_16. Note also that the relation formula_69 is not the strict part of the relation formula_65.\n\nTheorem (Minimal Bad Array Lemma). Let formula_16 be a quasi-order equipped with a partial ranking and suppose formula_25 is a bad formula_16-array. Then there is a minimal bad formula_16-array formula_60 such that formula_76.\n\n"}
{"id": "1197421", "url": "https://en.wikipedia.org/wiki?curid=1197421", "title": "Bipolar coordinates", "text": "Bipolar coordinates\n\nBipolar coordinates are a two-dimensional orthogonal coordinate system. There are two commonly defined types of bipolar coordinates. The first is based on the Apollonian circles. The curves of constant \"σ\" and of \"τ\" are circles that intersect at right angles. The coordinates have two foci \"F\" and \"F\", which are generally taken to be fixed at (−\"a\", 0) and (\"a\", 0), respectively, on the \"x\"-axis of a Cartesian coordinate system. The second system is two-center bipolar coordinates. There is also a third coordinate system that is based on two poles (biangular coordinates). \n\nThe term \"bipolar\" is sometimes used to describe other curves having two singular points (foci), such as ellipses, hyperbolas, and Cassini ovals. However, the term \"bipolar coordinates\" is reserved for the coordinates described here, and never used to describe coordinates associated with those other curves, such as elliptic coordinates.\n\nThe most common definition of bipolar coordinates (\"σ\", \"τ\") is\n\nwhere the \"σ\"-coordinate of a point \"P\" equals the angle \"F\" \"P\" \"F\", and the \"τ\"-coordinate equals the natural logarithm of the ratio of the distances \"d\" and \"d\" to the foci \n\n(Recall that \"F\" and \"F\" are located at (−\"a\", 0) and (\"a\", 0), respectively.) Note that \"σ\" ranges from \"-π/2\" to \"π/2\", and \"τ\" ranges from formula_4 to formula_5. Equivalently\n\nThe curves of constant \"σ\" correspond to non-concentric circles \n\nthat intersect at the two foci. The centers of the constant-\"σ\" circles lie on the \"y\"-axis. Circles of positive \"σ\" are centered above the \"x\"-axis, whereas those of negative \"σ\" lie below the axis. As the magnitude |\"σ\"| increases, the radius of the circles decreases and the center approaches the origin (0, 0), which is reached when |\"σ\"| = \"π\"/2, its maximum value.\n\nThe curves of constant formula_8 are non-intersecting circles of different radii\n\nthat surround the foci but again are not concentric. The centers of the constant-\"τ\" circles lie on the \"x\"-axis. The circles of positive \"τ\" lie in the right-hand side of the plane (\"x\" > 0), whereas the circles of negative \"τ\" lie in the left-hand side of the plane (\"x\" < 0). The \"τ\" = 0 curve corresponds to the \"y\"-axis (\"x\" = 0). As the magnitude of \"τ\" increases, the radius of the circles decreases and their centers approach the foci.\n\nThe passage from the Cartesian coordinates towards the bipolar coordinates can be done via the following formulas:\nand\n\nWe notice also those two remarkable identities: \nand\n\nThe scale factors for the bipolar coordinates (\"σ\", \"τ\") are equal\n\nThus, the infinitesimal area element equals\n\nand the Laplacian is given by \n\nOther differential operators such as formula_17 and formula_18 can be expressed in the coordinates (\"σ\", \"τ\") by substituting the scale factors into the general formulae found in orthogonal coordinates.\n\nThe classic applications of bipolar coordinates are in solving partial differential equations, e.g., Laplace's equation or the Helmholtz equation, for which bipolar coordinates allow a separation of variables. A typical example would be the electric field surrounding two parallel cylindrical conductors with differing diameters.\n\nBipolar coordinates form the basis for several sets of three-dimensional orthogonal coordinates.\n\n\n\n\n"}
{"id": "4819580", "url": "https://en.wikipedia.org/wiki?curid=4819580", "title": "Capstone (cryptography)", "text": "Capstone (cryptography)\n\nCapstone is the name of a United States government long-term project to develop cryptography standards for public and government use. Capstone was authorized by the Computer Security Act of 1987 and was driven by the NIST and the NSA; the project began in 1993. The initiative involved four standard algorithms: a data encryption algorithm called Skipjack, along with the Clipper chip that included the Skipjack algorithm, a digital signature algorithm, DSA, a hash function, SHA-1, and a key exchange protocol. Capstone's first implementation was in the Fortezza PCMCIA card. All Capstone components were designed to provide 80-bit security.\n\nThe initiative encountered massive resistance from the cryptographic community, and eventually the US government abandoned the effort. The main reasons for this resistance were concerns about Skipjack's design, which was classified, and the use of key escrow in the Clipper chip. \n\n\n"}
{"id": "11153189", "url": "https://en.wikipedia.org/wiki?curid=11153189", "title": "Casus irreducibilis", "text": "Casus irreducibilis\n\nIn algebra, casus irreducibilis (Latin for \"the irreducible case\") is one of the cases that may arise in attempting to solve a cubic equation with integer coefficients with roots that are expressed with radicals. Specifically, if a cubic polynomial is irreducible over the rational numbers and has three real roots, then in order to express the roots with radicals, one must introduce complex-valued expressions, even though the resulting expressions are ultimately real-valued. This was proven by Pierre Wantzel in 1843.\n\nOne can decide whether a given irreducible cubic polynomial is in \"casus irreducibilis\" using the discriminant \"D\", via Cardano's formula. Let the cubic equation be given by\n\nThen the discriminant appearing in the algebraic solution is given by\n\n\nMore generally, suppose that \"F\" is a formally real field, and that \"p\"(\"x\") ∈ \"F\"[\"x\"] is a cubic polynomial, irreducible over \"F\", but having three real roots (roots in the real closure of \"F\"). Then \"casus irreducibilis\" states that it is impossible to find any solution of \"p\"(\"x\") = 0 by real radicals.\n\nTo prove this, note that the discriminant is positive. Form the field extension . Since this is or a quadratic extension of (depending in whether or not is a square in ), remains irreducible in it. Consequently, the Galois group of over is the cyclic group . Suppose that can be solved by real radicals. Then can be split by a tower of cyclic extensions\n\nAt the final step of the tower, is irreducible in the penultimate field , but splits in for some . But this is a cyclic field extension, and so must contain a primitive root of unity.\n\nHowever, there are no primitive 3rd roots of unity in a real closed field. Indeed, suppose that ω is a primitive 3rd root of unity. Then, by the axioms defining an ordered field, ω, ω, and 1 are all positive. But if ω>ω, then cubing both sides gives 1>1, a contradiction; similarly if ω>ω.\n\nThe equation can be depressed to a monic trinomial by dividing by formula_4 and substituting (the Tschirnhaus transformation), giving the equation where\n\nThen regardless of the number of real roots, by Cardano's solution the three roots are given by\n\nwhere formula_8 (\"k\"=1, 2, 3) is a cube root of 1 (formula_9, formula_10, and formula_11, where is the imaginary unit). Here if the radicands under the cube roots are non-real, the cube roots expressed by radicals are defined to be any pair of complex conjugate cube roots, while if they are real these cube roots are defined to be the real cube roots.\n\n\"Casus irreducibilis\" occurs when none of the roots is rational and when all three roots are distinct and real; the case of three distinct real roots occurs if and only if , in which case Cardano's formula involves first taking the square root of a negative number, which is imaginary, and then taking the cube root of a complex number (which cube root cannot itself be placed in the form with specifically given expressions in real radicals for and , since doing so would require independently solving the original cubic). Note that even in the reducible case in which one of three real roots is rational and hence can be factored out by polynomial long division, Cardano's formula (unnecessarily in this case) expresses that root (and the others) in terms of non-real radicals.\n\nThe depressed cubic equation\n\nis irreducible, because if it could be factored there would be a linear factor giving a rational solution, while by the rational root test there is no rational root. Since its discriminant is positive, it has three real roots, so it is an example of \"casus irreducibilis\". Cardano's formula gives these three real roots as \n\nfor \"k\"=1, 2, 3. This solution in radicals involves the imaginary number formula_14 and hence involves the cube roots of complex conjugate numbers.\n\nWhile \"casus irreducibilis\" cannot be solved in radicals in terms of real quantities, it \"can\" be solved trigonometrically in terms of real quantities. Specifically, the depressed monic cubic equation formula_15 is solved by\n\nThese solutions are in terms of real quantities if and only if formula_17 — i.e., if and only if there are three real roots. The formula involves starting with an angle whose cosine is known, trisecting the angle by multiplying it by 1/3, and taking the cosine of the resulting angle and adjusting for scale.\n\nThe distinction between the reducible and irreducible cubic cases with three real roots is related to the issue of whether or not an angle with rational cosine or rational sine is trisectible by the classical means of compass and unmarked straightedge. If the cosine of an angle is known to have a particular rational value, then one third of this angle has a cosine that is one of the three real roots of the equation\n\nLikewise, if the sine of is known to have a particular rational value, then one third of this angle has a sine that is one of the three real roots of the equation\n\nIn either case, if the rational root test reveals a rational root of the equation, or minus that root can be factored out of the polynomial on the left side, leaving a quadratic that can be solved for the remaining two roots in terms of a square root; then all of these roots are classically constructible since they are expressible in no higher than square roots, so in particular or is constructible and so is the associated angle . On the other hand, if the rational root test shows that there is no rational root, then \"casus irreducibilis\" applies, or is not constructible, the angle is not constructible, and the angle is not classically trisectible.\n\n\"Casus irreducibilis\" can be generalized to higher degree polynomials as follows. Let \"p\" ∈ \"F\"[\"x\"] be an irreducible polynomial which splits in a formally real extension \"R\" of \"F\" (i.e., \"p\" has only real roots). Assume that \"p\" has a root in formula_20 which is an extension of \"F\" by radicals. Then the degree of \"p\" is a power of 2, and its splitting field is an iterated quadratic extension of \"F\".\n\nThus for any irreducible polynomial whose degree is not a power of 2 and which has all roots real, no root can be expressed purely in terms of real radicals. Moreover, if the polynomial degree \"is\" a power of 2 and the roots are all real, then if there is a root that can be expressed in real radicals it can be expressed in terms of square roots and no higher-degree roots, as can the other roots, and so the roots are classically constructible.\n\n\"Casus irreducibilis\" for quintic polynomials is discussed by Dummit.\n\n"}
{"id": "44135401", "url": "https://en.wikipedia.org/wiki?curid=44135401", "title": "Derivative of the exponential map", "text": "Derivative of the exponential map\n\nIn the theory of Lie groups, the exponential map is a map from the Lie algebra of a Lie group into . In case is a matrix Lie group, the exponential map reduces to the matrix exponential. The exponential map, denoted , is analytic and has as such a derivative , where is a path in the Lie algebra, and a closely related differential .\n\nThe formula for was first proved by Friedrich Schur (1891). It was later elaborated by Henri Poincaré (1899) in the context of the problem of expressing Lie group multiplication using Lie algebraic terms. It is also sometimes known as Duhamel's formula.\n\nThe formula is important both in pure and applied mathematics. It enters into proofs of theorems such as the Baker–Campbell–Hausdorff formula, and it is used frequently in physics for example in quantum field theory, as in the Magnus expansion in perturbation theory, and in lattice gauge theory.\n\nThroughout, the notations and will be used interchangeably to denote the exponential given an argument, \"except\" when, where as noted, the notations have dedicated \"distinct\" meanings. The calculus-style notation is preferred here for better readability in equations. On the other hand, the -style is sometimes more convenient for inline equations, and is necessary on the rare occasions when there is a real distinction to be made.\n\nThe derivative of the exponential map is given by\n}{\\mathrm{ad}_{X}}\\frac{dX(t)}{dt}.</math>               \nderived from the power series of the exponential map of a linear endomorphism, as in matrix exponentiation\n\nTo compute the differential of at , , the standard recipe\nis employed. With the result\nfollows immediately from . In particular, is the identity because (since is a vector space) and .\n\nThe proof given below assumes a matrix Lie group. This means that the exponential mapping from the Lie algebra to the matrix Lie group is given by the usual power series, i.e. matrix exponentiation. The conclusion of the proof still holds in the general case, provided each occurrence of is correctly interpreted. See comments on the general case below.\n\nThe outline of proof makes use of the technique of differentiation with respect to of the parametrized expression\nto obtain a first order differential equation for which can then be solved by direct integration in . The solution is then .\n\nLemma\nLet denote the adjoint action of the group on its Lie algebra. The action is given by for . A frequently useful relationship between and is given by\nProof\nUsing the product rule twice one finds,\nThen one observes that\nby above. Integration yields\nUsing the formal power series to expand the exponential, integrating term by term, and finally recognizing ,\nand the result follows. The proof, as presented here, is essentially the one given in . A proof with a more algebraic touch can be found in .\nBy direct differentiation of the standard limit definition of the exponential, and exchanging the order of differentiation and limit,\nwhere each factor owes its place to the non-commutativity of and .\n\nDivide the unit interval into sections ( since the sum indices are integers) and let → ∞, , . It follows that \nThe virtue of a formal proof like this is that it tells what the right answer \"must\" be, provided it exists. Existence needs to be proved separately in each case.\nThe formula in the general case is given by\nwhere\nwhich formally reduces to\nHere the -notation is used for the exponential mapping of the Lie algebra and the calculus-style notation in the fraction indicates the usual formal series expansion. For more information and two full proofs in the general case, see the freely available reference.\n\nThe inverse function theorem together with the derivative of the exponential map provides information about the local behavior of . Any map between vector spaces (here first considering matrix Lie groups) has a inverse such that is a bijection in an open set around a point in the domain provided is invertible. From it follows that this will happen precisely when\n\nis invertible. This, in turn, happens when the eigenvalues of this operator are all nonzero. The eigenvalues of are related to those of as follows. If is an analytic function of a complex variable expressed in a power series such that for a matrix converges, then the eigenvalues of will be , where are the eigenvalues of , the double subscript is made clear below. In the present case with and , the eigenvalues of are\nwhere the are the eigenvalues of . Putting one sees that is invertible precisely when\n\nThe eigenvalues of are, in turn, related to those of . Let the eigenvalues of be . Fix an ordered basis of the underlying vector space such that is lower triangular. Then \nwith the remaining terms multiples of with . Let be the corresponding basis for matrix space, i.e. . Order this basis such that if . One checks that the action of is given by\nwith the remaining terms multiples of . This means that is lower triangular with its eigenvalues on the diagonal. The conclusion is that is invertible, hence is a local bianalytical bijection around , when the eigenvalues of satisfy\n\nIn particular, in the case of matrix Lie groups, it follows, since is invertible, by the inverse function theorem that is a bi-analytic bijection in a neighborhood of in matrix space. Furthermore, , is a bi-analytic bijection from a neighborhood of in to a neighborhood of . The same conclusion holds for general Lie groups using the manifold version of the inverse function theorem.\n\nIt also follows from the implicit function theorem that itself is invertible for sufficiently small.\n\nIf is defined such that \nan expression for , the BCH formula, can be derived from the above formula,\n\nIts left-hand side is easy to see to equal \"Y\". Thus,\nand hence, formally,\nHowever, using the relationship between and given by , it is straightforward to further see that \nand hence \nPutting this into the form of an integral in \"t\" from 0 to 1 yields,\nan integral formula for that is more tractable in practice than the explicit Dynkin's series formula due to the simplicity of the series expansion of . Note this expression consists of and nested commutators thereof with or . A textbook proof along these lines can be found in and .\n\nDynkin's formula mentioned may also be derived analogously, starting from the parametric extension\nwhence \nso that, using the above general formula,\n\nSince, however, \nthe last step by virtue of the Mercator series expansion, it follows that\nand, thus, integrating,\n\nIt is at this point evident that the qualitative statement of the BCH formula holds, namely lies in the Lie algebra generated by and is expressible as a series in repeated brackets . For each , terms for each partition thereof are organized inside the integral . The resulting Dynkin's formula is then\nFor a similar proof with detailed series expansions, see . For complete details, click on \"show\" below.\nChange the summation index in to and expand\nin a power series. To handle the series expansions simply, consider first\n. The -series and the -series are given by\nrespectively. Combining these one obtains\n\\sum_{k = 1}^\\infty \\frac{(-1)^{k + 1}}{k}\\left({\\sum_{i = 0}^\\infty \\frac{X^i}{i!}\\sum_{j = 0}^\\infty \\frac{Y^j}{j!} - I}\\right)^k = \nThis becomes\nwhere is the set of all sequences of length subject to the conditions in .\n\nNow substitute for in the LHS of . Equation then gives\nor, with a switch of notation, see An explicit Baker–Campbell–Hausdorff formula,\n\nNote that the summation index for the rightmost in the second term in is denoted , but is \"not\" an element of a sequence . Now integrate , using ,\n\nWrite this as \n\nBut this equals\n\nusing the simple observation that for all . That is, in , the leading term vanishes unless equals or , corresponding to the first and second terms in the equation before it. In case , must equal , else the term vanishes for the same reason ( 0 is not allowed). Finally, shift the index, ,\nThis is Dynkin's formula. The striking similarity with (99) is not accidental: It reflects the Dynkin–Specht–Wever map, underpinning the original, different, derivation of the formula. Namely, \"if\"\nis expressible as a bracket series, then necessarily\n\nPutting observation and theorem together yields a concise proof of the explicit BCH formula.\n\n\n"}
{"id": "9451796", "url": "https://en.wikipedia.org/wiki?curid=9451796", "title": "Disk covering problem", "text": "Disk covering problem\n\nThe disk covering problem asks for the smallest real number formula_1 such that formula_2 disks of radius formula_1 can be arranged in such a way as to cover the unit disk. Dually, for a given radius \"ε\", one wishes to find the smallest integer \"n\" such that \"n\" disks of radius \"ε\" can cover the unit disk.\n\nThe best solutions known to date are as follows:\n\nThe following picture shows an example of a dashed disk of radius 1 covered by six solid-line disks of radius ~0.6. One of the covering disks is placed central and the remaining five in a symmetrical way around it.\n\nWhile this is not the best layout for r(6), similar arrangements of six, seven, eight, and nine disks around a central disk all having same radius result in the best layout strategies for r(7), r(8), r(9), and r(10), respectively. The corresponding angles θ are written in the \"Symmetry\" column in the above table. Pictures showing these arrangements can be found at \n\n"}
{"id": "39530296", "url": "https://en.wikipedia.org/wiki?curid=39530296", "title": "Dodecahedral number", "text": "Dodecahedral number\n\nA dodecahedral number is a figurate number that represents a dodecahedron. The \"n\"th dodecahedral number is given by the formula\n\nformula_1\n\nThe first such numbers are 0, 1, 20, 84, 220, 455, 816, 1330, 2024, 2925, 4060, 5456, 7140, 9139, 11480, … .\n"}
{"id": "29130644", "url": "https://en.wikipedia.org/wiki?curid=29130644", "title": "Egyptian geometry", "text": "Egyptian geometry\n\nEgyptian geometry refers to geometry as it was developed and used in Ancient Egypt. Ancient Egyptian mathematics as discussed here spans a time period ranging from ca. 3000 BC to ca 300 BC.\n\nWe only have a limited number of problems from ancient Egypt that concern geometry. Geometric problems appear in both the Moscow Mathematical Papyrus (MMP) and in the Rhind Mathematical Papyrus (RMP). The examples demonstrate that the Ancient Egyptians knew how to compute areas of several geometric shapes and the volumes of cylinders and pyramids. Also the Egyptians used many sacred geometric shapes such as squares and triangles on temples and obelisks.\n\nThe Ancient Egyptians wrote out their problems in multiple parts. They gave the title and the data for the given problem, in some of the texts they would show how to solve the problem, and as the last step they verified that the problem was correct. The scribes did not use any variables and the problems were written in prose form. The solutions were written out in steps, outlining the process.\n\nTriangles: <br>\nThe Ancient Egyptians knew that the area of a triangle is formula_1 where \"b\" = base and \"h\" = height. Calculations of the area of a triangle appear in both the RMP and the MMP.\n\nRectangles: <br>\nProblem 49 from the RMP finds the area of a rectangular plot of land Problem 6 of MMP finds the lengths of the sides of a rectangular area given the ratio of the lengths of the sides. This problem seems to be identical to one of the Lahun Mathematical Papyri in London. The problem is also interesting because it is clear that the Egyptians were familiar with square roots. They even had a special hieroglyph for finding a square root. It looks like a corner and appears in the fifth line of the problem. We suspect that they had tables giving the square roots of some often used numbers. No such tables have been found however. Problem 18 of the MMP computes the area of a length of garment-cloth.\n\nThe Lahun PapyrusProblem 1 in LV.4 is given as: \"An area of 40 \"mH\" by 3 \"mH\" shall be divided in 10 areas, each of which shall have a width that is 1/2 1/4 of their length.\" A translation of the problem and its solution as it appears on the fragment is given on the website maintained by University College London.\n\nCircles: <br>\nProblem 48 of the RMP compares the area of a circle (approximated by an octagon) and its circumscribing square. This problem's result is used in problem 50.\n\n\"Trisect each side. Remove the corner triangles. The resulting octagonal figure approximates the circle. The area of the octagonal figure is: \"\nformula_2\nNext we approximate 63 to be 64 and note that formula_3\n\"Thus the number formula_4 plays the role of π = 3.14159... \n\nThat this octagonal figure, whose area is easily calculated, so accurately approximates the area of the circle is just plain good luck. Obtaining a better approximation to the area using finer divisions of a square and a similar argument is not simple.\" \n\nProblem 50 of the RMP finds the area of a round field of diameter 9 khet. This is solved by using the approximation that circular field of diameter 9 has the same area as a square of side 8. Problem 52 finds the area of a trapezium with (apparently) equally slanting sides. The lengths of the parallel sides and the distance between them being the given numbers. \n\nHemisphere: <br>\nProblem 10 of the MMP computes the area of a hemisphere.\n\nSeveral problems compute the volume of cylindrical granaries (41, 42, and 43 of the RMP), while problem 60 RMP seems to concern a pillar or a cone instead of a pyramid. It is rather small and steep, with a seked (slope) of four palms (per cubit).\n\nA problem appearing in section IV.3 of the Lahun Mathematical Papyri computes the volume of a granary with a circular base. A similar problem and procedure can be found in the Rhind papyrus (problem 43).\nSeveral problems in the Moscow Mathematical Papyrus (problem 14) and in the Rhind Mathematical Papyrus (numbers 44, 45, 46) compute the volume of a rectangular granary.\n\nProblem 14 of the Moscow Mathematical Papyrus computes the volume of a truncated pyramid, also known as a frustum.\n\nProblem 56 of the RMP indicates an understanding of the idea of geometric similarity. This problem discusses the ratio run/rise, also known as the seqed. Such a formula would be need for building pyramids. In the next problem (Problem 57), the height of a pyramid is calculated from the base length and the \"seked\" (Egyptian for slope), while problem 58 gives the length of the base and the height and uses these measurements to compute the seqed.\n\nIn Problem 59 part 1 computes the seqed, while the second part may be a computation to check the answer: \"If you construct a pyramid with base side 12 [cubits] and with a seqed of 5 palms 1 finger; what is its altitude?\" \n"}
{"id": "53452", "url": "https://en.wikipedia.org/wiki?curid=53452", "title": "Euler's totient function", "text": "Euler's totient function\n\nIn number theory, Euler's totient function counts the positive integers up to a given integer that are relatively prime to . It is written using the Greek letter phi as or , and may also be called Euler's phi function. It can be defined more formally as the number of integers in the range for which the greatest common divisor is equal to 1. The integers of this form are sometimes referred to as totatives of .\n\nFor example, the totatives of are the six numbers 1, 2, 4, 5, 7 and 8. They are all relatively prime to 9, but the other three numbers in this range, 3, 6, and 9 are not, because and . Therefore, . As another example, since for the only integer in the range from 1 to is 1 itself, and .\n\nEuler's totient function is a multiplicative function, meaning that if two numbers and are relatively prime, then .\nThis function gives the order of the multiplicative group of integers modulo (the group of units of the ring ). It also plays a key role in the definition of the RSA encryption system.\n\nLeonhard Euler introduced the function in 1763. However, he did not at that time choose any specific symbol to denote it. In a 1784 publication, Euler studied the function further, choosing the Greek letter to denote it: he wrote for \"the multitude of numbers less than , and which have no common divisor with it\". This definition varies from the current definition for the totient function at but is otherwise the same. The now-standard notation comes from Gauss's 1801 treatise \"Disquisitiones Arithmeticae\", although Gauss didn't use parentheses around the argument and wrote . Thus, it is often called Euler's phi function or simply the phi function.\n\nIn 1879, J. J. Sylvester coined the term totient for this function, so it is also referred to as Euler's totient function, the Euler totient, or Euler's totient. Jordan's totient is a generalization of Euler's.\n\nThe cototient of is defined as . It counts the number of positive integers less than or equal to that have at least one prime factor in common with .\n\nThere are several formulas for computing .\n\nIt states\nwhere the product is over the distinct prime numbers dividing . (The notation is described in the article Arithmetical function.)\n\nThe proof of Euler's product formula depends on two important facts.\n\nThis means that if , then . (\"Outline of proof\": let , , be the sets of nonnegative integers, which are, respectively, coprime to and less than , , and ; then there is a bijection between and , by the Chinese remainder theorem.)\n\nIf is prime and , then\n\n\"Proof\": since is a prime number the only possible values of are , and the only way for to not equal 1 is for to be a multiple of . The multiples of that are less than or equal to are , and there are of them. Therefore, the other numbers are all relatively prime to .\n\nThe fundamental theorem of arithmetic states that if there is a unique expression for ,\n\nwhere are prime numbers and each . (The case corresponds to the empty product.)\n\nRepeatedly using the multiplicative property of and the formula for gives\n\nThis is Euler's product formula.\n\nIn words, this says that the distinct prime factors of 36 are 2 and 3; half of the thirty-six integers from 1 to 36 are divisible by 2, leaving eighteen; a third of those are divisible by 3, leaving twelve numbers that are coprime to 36. And indeed there are twelve positive integers that are coprime with 36 and lower than 36: 1, 5, 7, 11, 13, 17, 19, 23, 25, 29, 31, and 35.\n\nThe totient is the discrete Fourier transform of the gcd, evaluated at 1. Let\n\nwhere for . Then\n\nThe real part of this formula is\n\nNote that unlike the other two formulae (the Euler product and the divisor sum) this one does not require knowing the factors of . However, it does involve the calculation of the greatest common divisor of and every positive integer less than , which suffices to provide the factorization anyway.\n\nThe property established by Gauss, that\n\nwhere the sum is over all positive divisors of , can be proven in several ways. (see Arithmetical function for notational conventions.)\n\nOne way is to note that is also equal to the number of possible generators of the cyclic group ; specifically, if , then is a generator for every coprime to . Since every element of generates a cyclic subgroup, and all subgroups of are generated by some element of , the formula follows. In the article Root of unity Euler's formula is derived by using this argument in the special case of the multiplicative group of the th roots of unity.\n\nThis formula can also be derived in a more concrete manner. Let and consider the fractions between 0 and 1 with denominator 20:\n\nPut them into lowest terms:\n\nFirst note that all the divisors of 20 are denominators. And second, note that there are 20 fractions. Which fractions have 20 as denominator? The ones whose numerators are relatively prime to 20 (, , , , , , , ). By definition this is fractions. Similarly, there are fractions with denominator 10 (, , , ), fractions with denominator 5 (, , , ), and so on.\n\nIn detail, we are considering the fractions of the form where is an integer from 1 to inclusive. Upon reducing these to lowest terms, each fraction will have as its denominator some divisor of . We can group the fractions together by denominator, and we must show that for a given divisor of , the number of such fractions with denominator is .\n\nNote that to reduce to lowest terms, we divide the numerator and denominator by . The reduced fractions with denominator are therefore precisely the ones originally of the form in which . The question therefore becomes: how many are there less than or equal to which verify ? Any such must clearly be a multiple of , but it must also be coprime to (if it had any common divisor with , then would be a larger common divisor of and ). Conversely, any multiple of which is coprime to will satisfy . We can generate such numbers by taking the numbers less than coprime to and multiplying each one by (these products will of course each be smaller than , as required). This in fact generates all such numbers, as if is a multiple of coprime to (and less than ), then will still be coprime to , and must also be smaller than , else would be larger than . Thus there are precisely values of less than or equal to such that , which was to be demonstrated.\n\nMöbius inversion gives\n\nwhere is the Möbius function.\n\nThis formula may also be derived from the product formula by multiplying out\n\nto get\n\nThe first 143 values are shown in the table and graph below:\n\nThe top line in the graph, , is a true upper bound. It is attained whenever is prime. There is no lower bound that is a straight line of positive slope; no matter how gentle the slope of a line is, there will eventually be points of the plot below the line. More precisely, the lower limit of the graph is proportional to rather than being linear.\n\nThis states that if and are relatively prime then\n\nThe special case where is prime is known as Fermat's little theorem.\n\nThis follows from Lagrange's theorem and the fact that is the order of the multiplicative group of integers modulo.\n\nThe RSA cryptosystem is based on this theorem: it implies that the inverse of the function , where is the (public) encryption exponent, is the function , where , the (private) decryption exponent, is the multiplicative inverse of modulo . The difficulty of computing without knowing the factorization of is thus the difficulty of computing : this is known as the RSA problem which can be solved by factoring . The owner of the private key knows the factorization, since an RSA private key is constructed by choosing as the product of two (randomly chosen) large primes and . Only is publicly disclosed, and given the difficulty to factor large numbers we have the guarantee that no-one else knows the factorization.\n\n\n\n\n\n\nIn 1965 P. Kesava Menon proved\nwhere is the number of divisors of .\n\nSchneider found a pair of identities connecting the totient function, the golden ratio and the Möbius function . In this section is the totient function, and is the golden ratio.\n\nThey are:\nand\nSubtracting them gives\nApplying the exponential function to both sides of the preceding identity yields an infinite product formula for :\n\nThe proof is based on the two formulae\n\nThe Dirichlet series for may be written in terms of the Riemann zeta function as:\n\nThe Lambert series generating function is\n\nwhich converges for .\n\nBoth of these are proved by elementary series manipulations and the formulae for .\n\nIn the words of Hardy & Wright, the order of is “always ‘nearly ’.”\n\nFirst\n\nbut as \"n\" goes to infinity, for all \n\nThese two formulae can be proved by using little more than the formulae for and the divisor sum function .\n\nIn fact, during the proof of the second formula, the inequality\n\ntrue for , is proved.\nWe also have\n\nHere is Euler's constant, , so and .\n\nProving this does not quite require the prime number theorem. Since goes to infinity, this formula shows that\n\nIn fact, more is true.\n\nand\n\nThe second inequality was shown by Jean-Louis Nicolas. Ribenboim says \"The method of proof is interesting, in that the inequality is shown first under the assumption that the Riemann hypothesis is true, secondly under the contrary assumption.\"\n\nFor the average order, we have\n\ndue to Arnold Walfisz, its proof exploiting estimates on exponential sums due to I. M. Vinogradov and N. M. Korobov (this is currently the best known estimate of this type). The \"Big \" stands for a quantity that is bounded by a constant times the function of inside the parentheses (which is small compared to ).\n\nThis result can be used to prove that the probability of two randomly chosen numbers being relatively prime is .\n\nIn 1950 Somayajulu proved\n\nIn 1954 Schinzel and Sierpiński strengthened this, proving that the set\n\nis dense in the positive real numbers. They also proved that the set\n\nis dense in the interval (0,1).\n\nA totient number is a value of Euler's totient function: that is, an for which there is at least one for which . The \"valency\" or \"multiplicity\" of a totient number is the number of solutions to this equation. A \"nontotient\" is a natural number which is not a totient number. Every odd integer exceeding 1 is trivially a nontotient. There are also infinitely many even nontotients, and indeed every positive integer has a multiple which is an even nontotient.\n\nThe number of totient numbers up to a given limit is\n\nfor a constant .\n\nIf counted accordingly to multiplicity, the number of totient numbers up to a given limit is\n\nwhere the error term is of order at most for any positive .\n\nIt is known that the multiplicity of exceeds infinitely often for any .\n\n proved that for every integer there is a totient number of multiplicity : that is, for which the equation has exactly solutions; this result had previously been conjectured by Wacław Sierpiński, and it had been obtained as a consequence of Schinzel's hypothesis H. Indeed, each multiplicity that occurs, does so infinitely often.\n\nHowever, no number is known with multiplicity . Carmichael's totient function conjecture is the statement that there is no such .\n\nIn the last section of the \"Disquisitiones\" Gauss proves that a regular -gon can be constructed with straightedge and compass if is a power of 2. If is a power of an odd prime number the formula for the totient says its totient can be a power of two only if is a first power and is a power of 2. The primes that are one more than a power of 2 are called Fermat primes, and only five are known: 3, 5, 17, 257, and 65537. Fermat and Gauss knew of these. Nobody has been able to prove whether there are any more.\n\nThus, a regular -gon has a straightedge-and-compass construction if \"n\" is a product of distinct Fermat primes and any power of 2. The first few such are\n\nSetting up an RSA system involves choosing large prime numbers and , computing and , and finding two numbers and such that . The numbers and (the \"encryption key\") are released to the public, and (the \"decryption key\") is kept private.\n\nA message, represented by an integer , where , is encrypted by computing .\n\nIt is decrypted by computing . Euler's Theorem can be used to show that if , then .\n\nThe security of an RSA system would be compromised if the number could be factored or if could be computed without factoring .\n\nIf is prime, then . In 1932 D. H. Lehmer asked if there are any composite numbers such that . None are known.\n\nIn 1933 he proved that if any such exists, it must be odd, square-free, and divisible by at least seven primes (i.e. ). In 1980 Cohen and Hagis proved that and that . Further, Hagis showed that if 3 divides then and .\n\nThis states that there is no number with the property that for all other numbers , , . See Ford's theorem above.\n\nAs stated in the main article, if there is a single counterexample to this conjecture, there must be infinitely many counterexamples, and the smallest one has at least ten billion digits in base 10.\n\n\nThe \"Disquisitiones Arithmeticae\" has been translated from Latin into English and German. The German edition includes all of Gauss' papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.\n\nReferences to the \"Disquisitiones\" are of the form Gauss, DA, art. \"nnn\".\n\n"}
{"id": "1198398", "url": "https://en.wikipedia.org/wiki?curid=1198398", "title": "Everything and More (book)", "text": "Everything and More (book)\n\nEverything and More: A Compact History of Infinity is a book by American novelist and essayist David Foster Wallace that examines the history of infinity, focusing primarily on the work of Georg Cantor, the 19th-century German mathematician who created set theory. The book is part of the W. W. Norton \"Great Discoveries\" series.\n\nNeal Stephenson provided an \"Introduction\" to a reissued paperback edition (2010), which Stephenson reprinted in his collection \"Some Remarks : Essays and Other Writing\".\n\nReviewers including Rudy Rucker, A.W. Moore and Michael Harris have criticized its style and mathematical content.\n\n"}
{"id": "21313650", "url": "https://en.wikipedia.org/wiki?curid=21313650", "title": "Exponential field", "text": "Exponential field\n\nIn mathematics, an exponential field is a field that has an extra operation on its elements which extends the usual idea of exponentiation.\n\nA field is an algebraic structure composed of a set of elements, \"F\", two binary operations, addition (+) such that \"F\" forms an abelian group with identity 0 and multiplication (·), such that \"F\" excluding 0 forms an abelian group under multiplication with identity 1, and such that multiplication is distributive over addition, that is for any elements \"a\", \"b\", \"c\" in \"F\", one has . If there is also a function \"E\" that maps \"F\" into \"F\", and such that for every \"a\" and \"b\" in \"F\" one has\nthen \"F\" is called an exponential field, and the function \"E\" is called an exponential function on \"F\". Thus an exponential function on a field is a homomorphism between the additive group of \"F\" and its multiplicative group.\n\nThere is a trivial exponential function on any field, namely the map that sends every element to the identity element of the field under multiplication. Thus every field is trivially also an exponential field, so the cases of interest to mathematicians occur when the exponential function is non-trivial.\n\nExponential fields are sometimes required to have characteristic zero as the only exponential function on a field with nonzero characteristic is the trivial one. To see this first note that for any element \"x\" in a field with characteristic \"p\" > 0,\nHence, taking into account the Frobenius endomorphism,\nAnd so \"E\"(\"x\") = 1 for every \"x\".\n\n\nThe underlying set \"F\" may not be required to be a field but instead allowed to simply be a ring, \"R\", and concurrently the exponential function is relaxed to be a homomorphism from the additive group in \"R\" to the multiplicative group of units in \"R\". The resulting object is called an exponential ring.\n\nAn example of an exponential ring with a nontrivial exponential function is the ring of integers Z equipped with the function \"E\" which takes the value +1 at even integers and −1 at odd integers, i.e., the function formula_4 This exponential function, and the trivial one, are the only two functions on Z that satisfy the conditions.\n\nExponential fields are much-studied objects in model theory, occasionally providing a link between it and number theory as in the case of Zilber's work on Schanuel's conjecture. It was proved in the 1990s that R is model complete, a result known as Wilkie's theorem. This result, when combined with Khovanskiĭ's theorem on pfaffian functions, proves that R is also o-minimal. On the other hand, it is known that C is not model complete. The question of decidability is still unresolved. Alfred Tarski posed the question of the decidability of R and hence it is now known as Tarski's exponential function problem. It is known that if the real version of Schanuel's conjecture is true then R is decidable.\n\n"}
{"id": "38576819", "url": "https://en.wikipedia.org/wiki?curid=38576819", "title": "Flow-equivalent server method", "text": "Flow-equivalent server method\n\nIn queueing theory, a discipline within the mathematical theory of probability, the flow-equivalent server method (also known as flow-equivalent aggregation technique, Norton's theorem for queueing networks or the Chandy–Herzog–Woo method) is a divide-and-conquer method to solve product form queueing networks inspired by Norton's theorem for electrical circuits. The network is successively split into two, one portion is reconfigured to a closed network and evaluated.\n\nMarie's algorithm is a similar method where analysis of the sub-network are performed with state-dependent Poisson process arrivals.\n"}
{"id": "87599", "url": "https://en.wikipedia.org/wiki?curid=87599", "title": "G. H. Hardy", "text": "G. H. Hardy\n\nGodfrey Harold Hardy (7 February 1877 – 1 December 1947) was an English mathematician, known for his achievements in number theory and mathematical analysis. In biology, he is known for the Hardy–Weinberg principle, a basic principle of population genetics. In addition to his research, he is remembered for his 1940 essay on the aesthetics of mathematics, titled \"A Mathematician's Apology\". Hardy also was the mentor of the Indian mathematician Srinivasa Ramanujan.\n\nG. H. Hardy is usually known by those outside the field of mathematics for his essay from 1940 on the aesthetics of mathematics, \"A Mathematician's Apology\", which is often considered one of the best insights into the mind of a working mathematician written for the layperson.\n\nStarting in 1914, Hardy was the mentor of the Indian mathematician Srinivasa Ramanujan, a relationship that has become celebrated. Hardy almost immediately recognised Ramanujan's extraordinary albeit untutored brilliance, and Hardy and Ramanujan became close collaborators. In an interview by Paul Erdős, when Hardy was asked what his greatest contribution to mathematics was, Hardy unhesitatingly replied that it was the discovery of Ramanujan. He called their collaboration \"the one romantic incident in my life.\"\n\nG. H. Hardy was born on 7 February 1877, in Cranleigh, Surrey, England, into a teaching family. His father was Bursar and Art Master at Cranleigh School; his mother had been a senior mistress at Lincoln Training College for teachers. Both parents were mathematically inclined.\n\nHardy's own natural affinity for mathematics was perceptible at an early age. When just two years old, he wrote numbers up to millions, and when taken to church he amused himself by factorising the numbers of the hymns.\n\nAfter schooling at Cranleigh, Hardy was awarded a scholarship to Winchester College for his mathematical work. In 1896 he entered Trinity College, Cambridge. After only two years of preparation under his coach, Robert Alfred Herman, Hardy was fourth in the Mathematics Tripos examination. Years later, he sought to abolish the Tripos system, as he felt that it was becoming more an end in itself than a means to an end. While at university, Hardy joined the Cambridge Apostles, an elite, intellectual secret society.\n\nHardy cited as his most important influence his independent study of \"Cours d'analyse de l'École Polytechnique\" by the French mathematician Camille Jordan, through which he became acquainted with the more precise mathematics tradition in continental Europe. In 1900 he passed part II of the Tripos and was awarded a fellowship. In 1903 he earned his M.A., which was the highest academic degree at English universities at that time. From 1906 onward he held the position of a lecturer where teaching six hours per week left him time for research. In 1919 he left Cambridge to take the Savilian Chair of Geometry (and thus become a Fellow of New College) at Oxford in the aftermath of the Bertrand Russell affair during World War I. Hardy spent the academic year 1928–1929 at Princeton in an academic exchange with Oswald Veblen, who spent the year at Oxford. Hardy gave the Josiah Willards Gibbs lecture for 1928. Hardy left Oxford and returned to Cambridge in 1931, where he was Sadleirian Professor until 1942.\n\nHardy is credited with reforming British mathematics by bringing rigour into it, which was previously a characteristic of French, Swiss and German mathematics. British mathematicians had remained largely in the tradition of applied mathematics, in thrall to the reputation of Isaac Newton (see Cambridge Mathematical Tripos). Hardy was more in tune with the \"cours d'analyse\" methods dominant in France, and aggressively promoted his conception of pure mathematics, in particular against the hydrodynamics which was an important part of Cambridge mathematics.\n\nFrom 1911 he collaborated with John Edensor Littlewood, in extensive work in mathematical analysis and analytic number theory. This (along with much else) led to quantitative progress on Waring's problem, as part of the Hardy–Littlewood circle method, as it became known. In prime number theory, they proved results and some notable conditional results. This was a major factor in the development of number theory as a system of conjectures; examples are the first and second Hardy–Littlewood conjectures. Hardy's collaboration with Littlewood is among the most successful and famous collaborations in mathematical history. In a 1947 lecture, the Danish mathematician Harald Bohr reported a colleague as saying, \"Nowadays, there are only three really great English mathematicians: Hardy, Littlewood, and Hardy–Littlewood.\"\n\nHardy is also known for formulating the Hardy–Weinberg principle, a basic principle of population genetics, independently from Wilhelm Weinberg in 1908. He played cricket with the geneticist Reginald Punnett who introduced the problem to him, and Hardy thus became the somewhat unwitting founder of a branch of applied mathematics.\n\nHardy's collected papers have been published in seven volumes by Oxford University Press.\n\nHardy preferred his work to be considered \"pure mathematics\", perhaps because of his detestation of war and the military uses to which mathematics had been applied. He made several statements similar to that in his \"Apology\":\n\nHowever, aside from formulating the Hardy–Weinberg principle in population genetics, his famous work on integer partitions with his collaborator Ramanujan, known as the Hardy–Ramanujan asymptotic formula, has been widely applied in physics to find quantum partition functions of atomic nuclei (first used by Niels Bohr) and to derive thermodynamic functions of non-interacting Bose–Einstein systems. Though Hardy wanted his maths to be \"pure\" and devoid of any application, much of his work has found applications in other branches of science.\n\nMoreover, Hardy deliberately pointed out in his \"Apology\" that mathematicians generally do not \"glory in the uselessness of their work,\" but rather – because science can be used for evil ends as well as good – \"mathematicians may be justified in rejoicing that there is one science at any rate, and that their own, whose very remoteness from ordinary human activities should keep it gentle and clean.\" Hardy also rejected as a \"delusion\" the belief that the difference between pure and applied mathematics had anything to do with their utility. Hardy regards as \"pure\" the kinds of mathematics that are independent of the physical world, but also considers some \"applied\" mathematicians, such as the physicists Maxwell and Einstein, to be among the \"real\" mathematicians, whose work \"has permanent aesthetic value\" and \"is eternal because the best of it may, like the best literature, continue to cause intense emotional satisfaction to thousands of people after thousands of years.\" Although he admitted that what he called \"real\" mathematics may someday become useful, he asserted that, at the time in which the \"Apology\" was written, only the \"dull and elementary parts\" of either pure or applied mathematics could \"work for good or ill.\"\n\nSocially, Hardy was associated with the Bloomsbury group and the Cambridge Apostles; G. E. Moore, Bertrand Russell and J. M. Keynes were friends. He was an avid cricket fan. Maynard Keynes observed that if Hardy had read the stock exchange for half an hour every day with as much interest and attention as he did the day's cricket scores, he would have become a rich man.\n\nHe was at times politically involved, if not an activist. He took part in the Union of Democratic Control during World War I, and For Intellectual Liberty in the late 1930s.\n\nHardy was an atheist. Apart from close friendships, he had a few platonic relationships with young men who shared his sensibilities, and often his love of cricket. A mutual interest in cricket led him to befriend the young C. P. Snow. Hardy was a lifelong bachelor and in his final years he was cared for by his sister.\n\nHardy was extremely shy as a child, and was socially awkward, cold and eccentric throughout his life. During his school years he was top of his class in most subjects, and won many prizes and awards but hated having to receive them in front of the entire school. He was uncomfortable being introduced to new people, and could not bear to look at his own reflection in a mirror. It is said that, when staying in hotels, he would cover all the mirrors with towels.\n\n\nHardy is a key character, played by Jeremy Irons, in the 2015 film \"The Man Who Knew Infinity\", based on the biography of Ramanujan with the same title. Hardy is a major character in David Leavitt's fictive biography, \"The Indian Clerk\" (2007), which depicts his Cambridge years and his relationship with John Edensor Littlewood and Ramanujan. Hardy is a secondary character in \"Uncle Petros and Goldbach's Conjecture\" (1992), a mathematics novel by Apostolos Doxiadis.\n\n\n\n"}
{"id": "8371092", "url": "https://en.wikipedia.org/wiki?curid=8371092", "title": "Gödel numbering for sequences", "text": "Gödel numbering for sequences\n\nIn mathematics, a Gödel numbering for sequences provides us an effective way to represent each finite sequence of natural numbers as a single natural number. Of course, the embedding is surely possible set theoretically, but the emphasis is on the effectiveness of the functions manipulating such representations of sequences: the operations on sequences (accessing individual members, concatenation) can be \"implemented\" using total recursive functions, and in fact by primitive recursive functions.\n\nIt is usually used to build sequential “data types” in the realm of arithmetic-based formalizations of some fundamental notions of mathematics. It is a specific case of the more general idea of Gödel numbering.\n\nFor example, recursive function theory can be regarded as a formalization of the notion of an algorithm, and if we regard it as a programming language, we can mimic lists by encoding a sequence of natural numbers in a single natural number. To achieve this, we can use various number theoretic ideas; using the fundamental theorem of arithmetic is a straightforward way, but there are also more economic approaches, such as using the pairing function combined with the Chinese remainder theorem in a sophisticated way.\n\nBesides using Gödel numbering to encode unique sequences of symbols into unique natural numbers (i.e. place numbers into mutually exclusive or one-to-one correspondence with the sequences), we can use it to encode whole “architectures” of sophisticated “machines”. For example, we can encode Markov algorithms, or Turing machines into natural numbers and thereby prove that the expressive power of recursive function theory is no less than that of the former machine-like formalizations of algorithms.\n\nAny such representation of sequences should contain all the information as in the original sequence—most importantly, each individual member must be retrievable. However, the length does not have to match directly; even if we want to handle sequences of different length, we can store length data as a surplus member, or as the other member of an ordered pair by using a pairing function.\n\nWe expect that there is an effective way for this information retrieval process in form of an appropriate total recursive function. We want to find a totally recursive function \"f\" with the property that\nfor all \"n\" and for any \"n\"-length sequence of natural numbers formula_1, there exists an appropriate natural number \"a\", called the Gödel number of the sequence, such that for all \"i\" where formula_2, formula_3.\n\nThere are effective functions which can retrieve each member of the original sequence from a Gödel number of the sequence. Moreover, we can define some of them in a constructive way, so we can go well beyond mere proofs of existence.\n\nBy an ingenious use of the Chinese remainder theorem, we can constructively define such a recursive function formula_4 (using simple number-theoretical functions, all of which can be defined in a total recursive way) fulfilling the specifications given above. Gödel defined the formula_4 function using the Chinese remainder theorem in his article written in 1931. This is a primitive recursive function.\n\nThus, for all \"n\" and for any \"n\"-length sequence of natural numbers formula_1, there exists an appropriate natural number \"a\", called the Gödel number of the sequence such that formula_7.\n\nOur specific solution will depend on a pairing function—there are several ways to implement the pairing function, so one method must be selected. Now, we can abstract from the details of the implementation of the pairing function. We need only to know its “interface”: let formula_8, \"K\", and \"L\" denote the pairing function and its two projection functions, respectively, satisying specification\n\nWe shall not discuss and formalize the axiom for excluding alien objects here, as it is not required to understand the method.\n\nWe shall use another auxiliary function that will compute the remainder for natural numbers. Examples:\n\n\nIt can be proven that this function can be implemented as a recursive function.\n\nUsing the Chinese remainder theorem, we can prove that implementing formula_4 as\nwill work, according to the specification we expect formula_4 to satisfy. We can use a more concise form by an abuse of notation (constituting a sort of pattern matching):\nLet us achieve even more readability by more modularity and reuse (as these notions are used in computer science): by defining formula_17 the sequence formula_18, we can write\nWe shall use this formula_20 notation in the proof.\n\nFor proving the correctness of the above definition of the formula_4 function, we shall use several lemmas. These have their own assumptions. Now we try to find out these assumptions, calibrating and tuning their strength carefully: they should not be said in an either superfluously sharp, or unsatisfactorily weak form.\n\nLet formula_22 be a sequence of natural numbers.\nLet \"m\" be chosen to satisfy\nThe first assumption is meant as\nIt is needed to meet an assumption of the Chinese remainder theorem (that of being pairwise coprime). In the literature, sometimes this requirement is replaced with a stronger one, e.g. constructively built with the factorial function, but the stronger premise is not required for this proof.\n\nThe second assumption does not concern the Chinese remainder theorem in any way. It will have importance in proving that the specification for formula_4 is met eventually. It ensures that an formula_27 solution of the simultaneous congruence system\nalso satisfies\nA stronger assumption for \"m\" requiring formula_31 automatically satisfies the second assumption (if we define the notation formula_20 as above).\n\nIn the section Hand-tuned assumptions, we required that\n\nIn detail:\nremembering that formula_17 we defined formula_18.\n\nThe proof is by contradiction; assume the negation of the original statement:\n\nWe know what “coprime” relation means (in a lucky way, its negation can be formulated in a concise form); thus, let us substitute in the appropriate way:\nUsing a “more” prenex normal form (but note allowing a constraint-like notation in quantifiers):\n\nBecause of a theorem on divisibility, formula_40 allows us to also say\n\nSubstituting the definitions of formula_42-sequence notation, we get formula_43, thus (as equality axioms postulate identity to be a congruence relation ) we get\nSince \"p\" is a prime element (note that the irreducible element property is used), we get\n\nNow we must resort to our assumption\nThe assumption was chosen carefully to be as weak as possible, but strong enough to enable us to use it now.\n\nThe assumed negation of the original statement contains an appropriate existential statement using indices formula_47; this entails formula_48, thus the mentioned assumption can be applied, so formula_49 holds.\n\nWe can prove by several means known in propositional calculus that\nholds.\n\nSince formula_49, by the transitivity property of the divisibility relation, formula_52. Thus (as equality axioms postulate identity to be a congruence relation )\ncan be proven.\n\nThe negation of original statement contained\nand we have just proved\nThus,\nshould also hold.\nBut after substituting the definition of formula_20,\nThus, summarizing the above three statements, by transitivity of the equality,\nshould also hold.\n\nHowever, in the negation of the original statement \"p\" is existentially quantified and restricted to primes formula_60. This establishes the contradiction we wanted to reach.\n\nBy reaching contradiction with its negation, we have just proven the original statement:\n\nWe build a system of simultaneous congruences\n\nWe can write it in a more concise way:\n\nMany statements will be said below, all beginning with \"formula_66\". To achieve a more ergonomic treatment, from now on all statements should be read as being in the scope of an formula_66 quantification. Thus, formula_68 begins here.\n\nLet us chose a solution formula_69 for the system of simultaneous congruences. At least one solution must exist, because formula_70 are pairwise comprime as proven in the previous sections, so we can refer to the solution ensured by the Chinese remainder theorem. Thus, from now on we can regard formula_69 as satisfying\nwhich means (by definition of modular arithmetic) that\n\nRecall the second assumption, “formula_74”, and remember that we are now in the scope of an implicit quantification for \"i\", so we don't repeat its quantification for each statement.\n\nThe second assumption formula_75 implies that\nNow by transitivity of equality we get\n\nOur original goal was to prove that the definition\nis good for achieving what we declared in the specification of formula_4: we want formula_80 to hold.\n\nThis can be seen now by transitivity of equality, looking at the above three equations.\n\nWe have just proven the correctness of the definition of formula_4: its specification requiring\nis met. Although proving this was most important for establishing an encoding scheme for sequences, we have to fill in some gaps yet. These are related notions similar to existence and uniqueness (although on uniqueness, “at most one” should be meant here, and the conjunction of both is delayed as a final result).\n\nOur ultimate question is: what number should stand for the encoding of sequence formula_83? The specification declares only an existential quantification, not yet a functional connection. We want a constructive and algorithmic connection: a (total) recursive function that performs the encoding.\n\nThis gap can be filled in in a straightforward way: we shall use minimalization, and the totality of the resulting function is ensured by everything we have proven till now (i.e. the correctness of the definition of formula_4 by meeting its specification). In fact, the specification\nplays a role here of a more general notion (“special function”). The importance of this notion is that it enables us to split off the (sub)class of (total) recursive functions from the (super)class of partial recursive functions. In brief, the specification says that a function \"f\"\n\nsatisfying the specification\nis a special function; that is, for each fixed combination of all-but-last arguments, the function \"f\" has root in its last argument:\n\nThus, let us choose the minimal possible number that fits well in the specification of the formula_4 function:\nIt can be proven (using the notions of the previous section ) that \"g\" is (total) recursive.\n\nIf we use the above scheme for encoding sequences only in contexts where the length of the sequences is fixed, then no problem arises. In other words, we can use them in an analogous way as arrays are used in programming.\n\nBut sometimes we need dynamically stretching sequences, or we need to deal with sequences whose length cannot be typed in a static way. In other words, we may encode sequences in an analogous way to lists in programming.\n\nTo illustrate both cases: if we form the Gödel numbering of a Turing machine, then the each row in the matrix of the “program” can be represented with tuples, sequences of fixed length (thus, without storing the length), because the number of the columns is fixed. But if we want to reason about configuration-like things (of Turing-machines), and specifically if we want to encode the significant part of the tape of a running Turing machine, then we have to represent sequences together with their length. We can mimic dynamically stretching sequences by representing sequence concatenation (or at least, augmenting a sequence with one more element) with a totally recursive function.\n\nLength can be stored simply as a surplus member:\n\nThe corresponding modification of the proof is straightforward, by adding a surplus\nto the system of simultaneous congruences (provided that the surplus member index is chosen to be 0). Also, the assumptions have to be modified accordingly.\n\n"}
{"id": "142488", "url": "https://en.wikipedia.org/wiki?curid=142488", "title": "Harmonic series (mathematics)", "text": "Harmonic series (mathematics)\n\nIn mathematics, the harmonic series is the divergent infinite series:\n\nIts name derives from the concept of overtones, or harmonics in music: the wavelengths of the overtones of a vibrating string are , , , etc., of the string's fundamental wavelength. Every term of the series after the first is the harmonic mean of the neighboring terms; the phrase \"harmonic mean\" likewise derives from music.\n\nThe fact that the harmonic series diverges was first proven in the 14th century by Nicole Oresme, but this achievement fell into obscurity. Proofs were given in the 17th century by Pietro Mengoli, Johann Bernoulli, and Jacob Bernoulli.\n\nHistorically, harmonic sequences have had a certain popularity with architects. This was so particularly in the Baroque period, when architects used them to establish the proportions of floor plans, of elevations, and to establish harmonic relationships between both interior and exterior architectural details of churches and palaces.\n\nThe harmonic series can be counterintuitive to students first encountering it, because it is a divergent series even though the limit of the th term as goes to infinity is zero. The divergence of the harmonic series is also the source of some apparent paradoxes. One example of these is the \"worm on the rubber band\". Suppose that a worm crawls along an infinitely-elastic one-meter rubber band at the same time as the rubber band is uniformly stretched. If the worm travels 1 centimeter per minute and the band stretches 1 meter per minute, will the worm ever reach the end of the rubber band? The answer, counterintuitively, is \"yes\", for after minutes, the ratio of the distance travelled by the worm to the total length of the rubber band is\n\nBecause the series gets arbitrarily large as becomes larger, eventually this ratio must exceed 1, which implies that the worm reaches the end of the rubber band. However, the value of at which this occurs must be extremely large: approximately , a number exceeding 10 minutes (10 years). Although the harmonic series does diverge, it does so very slowly.\n\nAnother problem involving the harmonic series is the Jeep problem, which (in one form) asks how much total fuel is required for a jeep with a limited fuel-carrying capacity to cross a desert, possibly leaving fuel drops along the route. The distance that can be traversed with a given amount of fuel is related to the partial sums of the harmonic series, which grow logarithmically. And so the fuel required increases exponentially with the desired distance.\nAnother example is the block-stacking problem: given a collection of identical dominoes, it is clearly possible to stack them at the edge of a table so that they hang over the edge of the table without falling. The counterintuitive result is that one can stack them in such a way as to make the overhang arbitrarily large, provided there are enough dominoes.\n\nA simpler example, on the other hand, is the swimmer that keeps adding more speed when touching the walls of the pool. The swimmer starts crossing a 10-meter pool at a speed of 2 m/s, and with every cross, another 2 m/s is added to the speed. In theory, the swimmer's speed is unlimited, but the number of pool crosses needed to get to that speed becomes very large; for instance, to get to the speed of light (ignoring special relativity), the swimmer needs to cross the pool 150 million times. Contrary to this large number, the time required to reach a given speed depends on the sum of the series at any given number of pool crosses (iterations):\n\nCalculating the sum (iteratively) shows that to get to the speed of light the time required is only 97 seconds. By continuing beyond this point (exceeding the speed of light, again ignoring special relativity), the time taken to cross the pool will in fact approach zero as the number of iterations becomes very large, and although the time required to cross the pool appears to tend to zero (at an infinite number of iterations), the sum of iterations (time taken for total pool crosses) will still diverge at a very slow rate.\n\nThere are several well-known proofs of the divergence of the harmonic series. A few of them are given below.\n\nOne way to prove divergence is to compare the harmonic series with another divergent series, where each denominator is replaced with the next-largest power of two:\n\nEach term of the harmonic series is greater than or equal to the corresponding term of the second series, and therefore the sum of the harmonic series must be greater than the sum of the second series. However, the sum of the second series is infinite:\n\nIt follows (by the comparison test) that the sum of the harmonic series must be infinite as well. More precisely, the comparison above proves that\n\nfor every positive integer .\n\nThis proof, proposed by Nicole Oresme in around 1350, is considered by many in the mathematical community to be a high point of medieval mathematics. It is still a standard proof taught in mathematics classes today. Cauchy's condensation test is a generalization of this argument.\n\nIt is possible to prove that the harmonic series diverges by comparing its sum with an improper integral. Specifically, consider the arrangement of rectangles shown in the figure to the right. Each rectangle is 1 unit wide and units high, so the total area of the infinite number of rectangles is the sum of the harmonic series:\n\nAdditionally, the total area under the curve from 1 to infinity is given by a divergent improper integral:\n\nSince this area is entirely contained within the rectangles, the total area of the rectangles must be infinite as well. More precisely, this proves that\n\nThe generalization of this argument is known as the integral test.\n\nThe harmonic series diverges very slowly. For example, the sum of the first 10 terms is less than 100. This is because the partial sums of the series have logarithmic growth. In particular,\nwhere is the Euler–Mascheroni constant and which approaches 0 as goes to infinity. Leonhard Euler proved both this and also the more striking fact that the sum which includes only the reciprocals of primes also diverges, i.e.\n\nThe finite partial sums of the diverging harmonic series,\n\nare called harmonic numbers.\n\nThe difference between and converges to the Euler–Mascheroni constant. The difference between any two harmonic numbers is never an integer. No harmonic numbers are integers, except for .\n\nThe series\n\nis known as the alternating harmonic series. This series converges by the alternating series test. In particular, the sum is equal to the natural logarithm of 2:\n\nThe alternating harmonic series, while conditionally convergent, is not absolutely convergent: if the terms in the series are systematically rearranged, in general the sum becomes different and, dependent on the rearrangement, possibly even infinite.\n\nThe alternating harmonic series formula is a special case of the Mercator series, the Taylor series for the natural logarithm.\n\nA related series can be derived from the Taylor series for the arctangent:\n\nThis is known as the Leibniz series.\n\nThe general harmonic series is of the form\n\nwhere and are real numbers and is not a nonpositive integer.\n\nBy the limit comparison test with the harmonic series, all general harmonic series also diverge.\n\nA generalization of the harmonic series is the -series (or hyperharmonic series), defined as\n\nfor any real number . When , the -series is the harmonic series, which diverges. Either the integral test or the Cauchy condensation test shows that the -series converges for all (in which case it is called the over-harmonic series) and diverges for all . If then the sum of the -series is , i.e., the Riemann zeta function evaluated at .\n\nThe problem of finding the sum for is called the Basel problem; Leonhard Euler showed it is . The value of the sum for is called Apéry's constant.\n\nRelated to the -series is the ln-series, defined as\n\nfor any positive real number . This can be shown by the integral test to diverge for but converge for all .\n\nFor any convex, real-valued function such that\n\nthe series formula_20 is convergent.\n\nThe random harmonic series\n\nwhere the are independent, identically distributed random variables taking the values +1 and −1 with equal probability , is a well-known example in probability theory for a series of random variables that converges with probability 1. The fact of this convergence is an easy consequence of either the Kolmogorov three-series theorem or of the closely related Kolmogorov maximal inequality. Byron Schmuland of the University of Alberta further examined the properties of the random harmonic series, and showed that the convergent is a random variable with some interesting properties. In particular, the probability density function of this random variable evaluated at +2 or at −2 takes on the value …, differing from by less than 10. Schmuland's paper explains why this probability is so close to, but not exactly, . The exact value of this probability is given by the infinite cosine product integral divided by .\n\nThe depleted harmonic series where all of the terms in which the digit 9 appears anywhere in the denominator are removed can be shown to converge and its value is less than 80. In fact, when all the terms containing any particular string of digits (in any base) are removed the series converges.\n\n\n"}
{"id": "10412371", "url": "https://en.wikipedia.org/wiki?curid=10412371", "title": "Hirsch conjecture", "text": "Hirsch conjecture\n\nIn mathematical programming and polyhedral combinatorics, the Hirsch conjecture is the statement that the edge-vertex graph of an \"n\"-facet polytope in \"d\"-dimensional Euclidean space has diameter no more than \"n\" − \"d\". That is, any two vertices of the polytope must be connected to each other by a path of length at most \"n\" − \"d\". The conjecture was first put forth in a letter by to George B. Dantzig in 1957 and was motivated by the analysis of the simplex method in linear programming, as the diameter of a polytope provides a lower bound on the number of steps needed by the simplex method. The conjecture is now known to be false in general.\n\nThe Hirsch conjecture was proven for \"d\" < 4 and for various special cases, while the best known upper bounds on the diameter are only sub-exponential in \"n\" and \"d\". After more than fifty years, a counter-example was announced in May 2010 by Francisco Santos Leal, from the University of Cantabria. The result was presented at the conference \"100 Years in Seattle: the mathematics of Klee and Grünbaum\" and appeared in \"Annals of Mathematics\". Specifically, the paper presented a 43-dimensional polytope of 86 facets with a diameter of more than 43. The counterexample has no direct consequences for the analysis of the simplex method, as it does not rule out the possibility of a larger but still linear or polynomial number of steps.\n\nVarious equivalent formulations of the problem had been given, such as the \"d\"-step conjecture, which states that the diameter of any 2\"d\"-facet polytope in \"d\"-dimensional Euclidean space is no more than \"d\"; Leal's counterexample also disproves this conjecture.\n\n"}
{"id": "57013358", "url": "https://en.wikipedia.org/wiki?curid=57013358", "title": "IBM 4765", "text": "IBM 4765\n\nThe IBM 4765. PCIe Cryptographic Coprocessor is a hardware security module (HSM) that includes a secure cryptoprocessor implemented on a high-security, tamper resistant, programmable PCIe board. Specialized cryptographic electronics, microprocessor, memory, and random number generator housed within a tamper-responding environment provide a highly secure subsystem in which data processing and cryptography can be performed.\n\nThe IBM 4765 is validated to FIPS PUB 140-2 Level 4, the highest level of certification achievable for commercial cryptographic devices. The IBM 4765 data sheet describes the coprocessor in detail.\n\nIBM supplies two cryptographic-system implementations:\nToolkits for custom application development are also available.\n\nApplications may include financial PIN transactions, bank-to-clearing-house transactions, EMV transactions for integrated circuit (chip) based credit cards, and general-purpose cryptographic applications using symmetric key algorithms, hashing algorithms, and public key algorithms.\n\nThe operational keys (symmetric or RSA private) are generated in the coprocessor and are then saved either in a keystore file or in application memory, encrypted under the master key of that coprocessor. Any coprocessor with an identical master key can use those keys.\n\nIBM supports the 4765 on IBM Z, IBM POWER Systems, and IBM-approved x86 servers (Linux or Microsoft Windows). \n\nAs of May 2011, the IBM 4765 superseded the IBM 4764 that was discontinued.\n\nThe IBM 4765 has been discontinued on all platforms. The successor to the 4765, the IBM 4767, was introduced on each of the IBM server platforms:\n\nThese links point to various relevant cryptographic standards.\n\nISO 13491 - Secure Cryptographic Devices: https://www.iso.org/standard/61137.html\n\nISO 9564 - PIN security: https://www.iso.org/standard/68669.html\n\nANSI X9.24 Part 1: Key Management using Symmetric Techniques: https://webstore.ansi.org/RecordDetail.aspx?sku=ANSI+X9.24-1-2017\n\nANSI X9.24 Part 2: Key Management using Asymmetric Techniques: https://webstore.ansi.org/RecordDetail.aspx?sku=ANSI+X9.24-2-2016\n\nFIPS 140-2: https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.140-2.pdf\n"}
{"id": "6974619", "url": "https://en.wikipedia.org/wiki?curid=6974619", "title": "Incurred but not reported", "text": "Incurred but not reported\n\nIn insurance, incurred but not reported (IBNR) claims is the amount owed by an insurer to all valid claimants who have had a covered loss but have not yet reported it. Since the insurer knows neither how many of these losses have occurred, nor the severity of each loss, IBNR is necessarily an estimate. The sum of IBNR losses plus reported losses yields an estimate of the total eventual liabilities the insurer will cover, known as ultimate losses.\n\nThe term \"IBNR\" is sometimes ambiguous, as it is not always clear whether it includes development on reported claims.\n\n\"Pure IBNR\" refers to only unreported claims, not any development on reported claims.\n\n\"Incurred but not enough reported (IBNER)\", in contrast, refers to development on reported claims. For example, when a claim is first reported, a $100 payment might be made, and a $900 case reserve might be established, for a total initial reported amount of $1000. However, the claim may later settle for a larger amount, resulting in $2000 of payments from the insurer to the claimant before the claim is closed. The estimated amount of this future development on reported claims is known as IBNER.\n\nIn some cases, the term \"IBNR\" refers only to pure IBNR; in other case, it is understood to be the sum of pure IBNR and IBNER.\n\nActuarial loss reserving methods including the chain-ladder method, Bornhuetter-Ferguson method, expected claims technique, and others are used to estimate IBNR and, hence, ultimate losses. Since the implementation of Solvency II, stochastic claims reserving methods have become more common.\n\n"}
{"id": "605011", "url": "https://en.wikipedia.org/wiki?curid=605011", "title": "Inequality of arithmetic and geometric means", "text": "Inequality of arithmetic and geometric means\n\nIn mathematics, the inequality of arithmetic and geometric means, or more briefly the AM–GM inequality, states that the arithmetic mean of a list of non-negative real numbers is greater than or equal to the geometric mean of the same list; and further, that the two means are equal if and only if every number in the list is the same.\n\nThe simplest non-trivial case — i.e., with more than one variable — for two non-negative numbers and , is the statement that \nwith equality if and only if . \nThis case can be seen from the fact that the square of a real number is always non-negative (greater than or equal to zero) and from the elementary case of the binomial formula:\nHence , with equality precisely when , i.e. . The AM-GM inequality then follows from taking the positive square root of both sides.\n\nFor a geometrical interpretation, consider a rectangle with sides of length  and , hence it has perimeter and area . Similarly, a square with all sides of length has the perimeter and the same area as the rectangle. The simplest non-trivial case of the AM–GM inequality implies for the perimeters that and that only the square has the smallest perimeter amongst all rectangles of equal area.\n\nExtensions of the AM–GM inequality are available to include weights or generalized means.\n\nThe \"arithmetic mean\", or less precisely the \"average\", of a list of numbers is the sum of the numbers divided by :\n\nThe \"geometric mean\" is similar, except that it is only defined for a list of \"nonnegative\" real numbers, and uses multiplication and a root in place of addition and division:\n\nIf , this is equal to the exponential of the arithmetic mean of the natural logarithms of the numbers:\n\nRestating the inequality using mathematical notation, we have that for any list of nonnegative real numbers ,\n\nand that equality holds if and only if .\n\nIn two dimensions, is the perimeter of a rectangle with sides of length  and . Similarly, is the perimeter of a square with the same area, , as that rectangle. Thus for the AM–GM inequality states that only the square has the smallest perimeter amongst all rectangles of equal area.\n\nThe full inequality is an extension of this idea to dimensions. Every vertex of an -dimensional box is connected to edges. If these edges' lengths are , then is the total length of edges incident to the vertex. There are vertices, so we multiply this by ; since each edge, however, meets two vertices, every edge is counted twice. Therefore, we divide by  and conclude that there are edges. There are equally many edges of each length and lengths; hence there are edges of each length and the total of all edge lengths is . On the other hand,\n\nis the total length of edges connected to a vertex on an -dimensional cube of equal volume, since in this case . Since the inequality says\n\nit can be restated by multiplying through by to obtain\n\nwith equality if and only if \n\nThus the AM–GM inequality states that only the -cube has the smallest sum of lengths of edges connected to each vertex amongst all -dimensional boxes with the same volume.\n\nConsider the function\n\nfor all positive real numbers , and . Suppose we wish to find the minimal value of this function. First we rewrite it a bit:\nwith\n\nApplying the AM–GM inequality for , we get\n\nFurther, we know that the two sides are equal exactly when all the terms of the mean are equal:\n\nAll the points satisfying these conditions lie on a half-line starting at the origin and are given by\n\nAn important practical application in financial mathematics is to computing the rate of return: the annualized return, computed via the geometric mean, is less than the average annual return, computed by the arithmetic mean (or equal if all returns are equal). This is important in analyzing investments, as the average return overstates the cumulative effect.\n\nJensen's inequality states that the value of a concave function of an arithmetic mean is greater than or equal to the arithmetic mean of the function's values. Since the logarithm function is concave, we have\n\nTaking antilogs of the far left and far right sides, we have the AM-GM inequality.\n\nWe have to show that\n\nwith equality only when all numbers are equal. If , then replacing both and by\n\nThus the right-hand side will be largest when all s are equal to the arithmetic mean\n\nthus as this is then the largest value of right-hand side of the expression, we have\n\nThis is a valid proof for the case , but the procedure of taking iteratively pairwise averages may fail to produce equal numbers in the case . An example of this case is : Averaging two different numbers produces two equal numbers, but the third one is still different. Therefore, we never actually get an inequality involving the geometric mean of three equal numbers.\n\nHence, an additional trick or a modified argument is necessary to turn the above idea into a valid proof for the case .\n\nWith the arithmetic mean\nof the non-negative real numbers , the AM–GM statement is equivalent to\nwith equality if and only if for all .\n\nFor the following proof we apply mathematical induction and only well-known rules of arithmetic.\n\nInduction basis: For the statement is true with equality.\n\nInduction hypothesis: Suppose that the AM–GM statement holds for all choices of non-negative real numbers.\n\nInduction step: Consider non-negative real numbers , . Their arithmetic mean satisfies\nIf all the are equal to , then we have equality in the AM–GM statement and we are done. In the case where some are not equal to , there must exist one number that is greater than the arithmetic mean , and one that is smaller than . Without loss of generality, we can reorder our in order to place these two particular elements at the end: and . Then\n\nNow define with\nand consider the numbers which are all non-negative. Since\n\nThus, is also the arithmetic mean of numbers and the induction hypothesis implies\n\nDue to (*) we know that\n\nhence\n\nin particular . Therefore, if at least one of the numbers is zero, then we already have strict inequality in (**). Otherwise the right-hand side of (**) is positive and strict inequality is obtained by using the estimate (***) to get a lower bound of the right-hand side of (**). Thus, in both cases we can substitute (***) into (**) to get\n\nwhich completes the proof.\n\nFirst of all we shall prove that for real numbers and there follows\n\nIndeed, multiplying both sides of the inequality by , gives\n\nwhence the required inequality is obtained immediately.\n\nNow, we are going to prove that for positive real numbers satisfying\n, there holds\n\nThe equality holds only if .\n\nInduction basis: For the statement is true because of the above property.\n\nInduction hypothesis: Suppose that the statement is true for all natural numbers up to .\n\nInduction step: Consider natural number , i.e. for positive real numbers , there holds . There exists at least one , so there must be at least one . The generality will not be lost, if we let and .\n\nFurther, the equality we shall write in the form of . Then, the induction hypothesis implies\n\nHowever, taking into account the induction basis, we have\n\nwhich completes the proof.\n\nFor positive real numbers , let's denote\n\nThe numbers satisfy the condition . So we have\n\nwhence we obtain\n\nwith the equality holding only for .\n\nThe following proof by cases relies directly on well-known rules of arithmetic but employs the rarely used technique of forward-backward-induction. It is essentially from Augustin Louis Cauchy and can be found in his \"Cours d'analyse\".\n\nIf all the terms are equal:\n\nthen their sum is , so their arithmetic mean is ; and their product is , so their geometric mean is ; therefore, the arithmetic mean and geometric mean are equal, as desired.\n\nIt remains to show that if \"not\" all the terms are equal, then the arithmetic mean is greater than the geometric mean. Clearly, this is only possible when .\n\nThis case is significantly more complex, and we divide it into subcases.\n\nIf , then we have two terms, and , and since (by our assumption) not all terms are equal, we have:\n\nhence\n\nas desired.\n\nConsider the case where , where is a positive integer. We proceed by mathematical induction.\n\nIn the base case, , so . We have already shown that the inequality holds when , so we are done.\n\nNow, suppose that for a given , we have already shown that the inequality holds for , and we wish to show that it holds for . To do so, we apply the inequality twice for numbers and once for numbers to obtain:\n\nwhere in the first inequality, the two sides are equal only if\n\nand\n\n(in which case the first arithmetic mean and first geometric mean are both equal to , and similarly with the second arithmetic mean and second geometric mean); and in the second inequality, the two sides are only equal if the two geometric means are equal. Since not all numbers are equal, it is not possible for both inequalities to be equalities, so we know that:\n\nas desired.\n\nIf is not a natural power of , then it is certainly \"less\" than some natural power of 2, since the sequence is unbounded above. Therefore, without loss of generality, let be some natural power of that is greater than .\n\nSo, if we have terms, then let us denote their arithmetic mean by , and expand our list of terms thus:\n\nWe then have:\n\nso\n\nand\n\nas desired.\n\nThe following proof uses mathematical induction and some basic differential calculus.\n\nInduction basis: For the statement is true with equality.\n\nInduction hypothesis: Suppose that the AM–GM statement holds for all choices of non-negative real numbers.\n\nInduction step: In order to prove the statement for non-negative real numbers , we need to prove that\n\nwith equality only if all the numbers are equal.\n\nIf all numbers are zero, the inequality holds with equality. If some but not all numbers are zero, we have strict inequality. Therefore, we may assume in the following, that all numbers are positive.\n\nWe consider the last number as a variable and define the function\n\nProving the induction step is equivalent to showing that for all , with only if and  are all equal. This can be done by analyzing the critical points of  using some basic calculus.\n\nThe first derivative of is given by\n\nA critical point has to satisfy , which means\n\nAfter a small rearrangement we get\n\nand finally\n\nwhich is the geometric mean of . This is the only critical point of . Since for all , the function  is strictly convex and has a strict global minimum at . Next we compute the value of the function at this global minimum:\n\nwhere the final inequality holds due to the induction hypothesis. The hypothesis also says that we can have equality only when are all equal. In this case, their geometric mean   has the same value, Hence, unless are all equal, we have . This completes the proof.\n\nThis technique can be used in the same manner to prove the generalized AM–GM inequality and Cauchy–Schwarz inequality in Euclidean space .\n\nGeorge Pólya provided a proof similar to what follows. Let for all real , with first derivative and second derivative . Observe that , and for all real , hence is strictly convex with the absolute minimum at . Hence for all real  with equality only for .\n\nConsider a list of non-negative real numbers . If they are all zero, then the AM–GM inequality holds with equality. Hence we may assume in the following for their arithmetic mean . By -fold application of the above inequality, we obtain that\n\nwith equality if and only if for every . The argument of the exponential function can be simplified:\n\nReturning to ,\n\nwhich produces , hence the result\n\nReformulate the problem given:\n\n1. formula_63 leads to constraint function formula_64 \n\nTask is to to find the minimum **using conditional extrema** of the following (the induction method that is most convinient is forbidden), if we proove this special case then the derivation can be generalised to prove the AMGM theorem:\n\n2. formula_66 \n\nIdea is that it should be formula_68:\n\nAnd finally Using the derivation above prove the AM-GM theorem:\n\nformula_69\n\nwriting down the Lagrangian:\n\nformula_70\n\ntaking the partial derivatives\n\nformula_71\n\nformula_72\n\nformula_73\n\nformula_74 formula_63\n\nformula_76 is critical point.\n\nTaking the differential of constraint\n\nformula_77\n\nformula_78\n\nformula_79\n\nsubstituting the roots of critical point formula_80 and formula_81 leads to \n\nformula_82\n\nTaking the second derivatives and evaluating at formula_83 gives\nformula_84\nformula_85\nformula_86\nformula_87\n\nNow for any vector formula_88 with formula_82 holds: formula_90. \nLeading to\nformula_91. And thus the point formula_76 is local minima. \n\nTaking the Weierstrass Theorem and applying it to any closed Domain interval of Lagrangian function formula_93 leads to the critical point to be global minima, outside the Domain interval formula_94, thus it is concluded\nthat the critical point formula_95 is global minima. \n\nBy taking the formula_96 The proof can be generalized to AM-GM inequality.\n\nThere is a similar inequality for the weighted arithmetic mean and weighted geometric mean. Specifically, let the nonnegative numbers and the nonnegative weights be given. Set . If , then the inequality\n\nholds with equality if and only if all the with are equal. Here the convention is used.\n\nIf all , this reduces to the above inequality of arithmetic and geometric means.\n\nUsing the finite form of Jensen's inequality for the natural logarithm, we can prove the inequality between the weighted arithmetic mean and the weighted geometric mean stated above.\n\nSince an with weight has no influence on the inequality, we may assume in the following that all weights are positive. If all are equal, then equality holds. Therefore, it remains to prove strict inequality if they are not all equal, which we will assume in the following, too. If at least one is zero (but not all), then the weighted geometric mean is zero, while the weighted arithmetic mean is positive, hence strict inequality holds. Therefore, we may assume also that all are positive.\n\nSince the natural logarithm is strictly concave, the finite form of Jensen's inequality and the functional equations of the natural logarithm imply\n\nSince the natural logarithm is strictly increasing,\n\nOther generalizations of the inequality of arithmetic and geometric means include:\n\n\n"}
{"id": "56543622", "url": "https://en.wikipedia.org/wiki?curid=56543622", "title": "Katherine Heinrich", "text": "Katherine Heinrich\n\nKatherine A. Heinrich (born February 21, 1954) is a mathematician and mathematics educator who became the first female president of the Canadian Mathematical Society. Her research interests include graph theory and the theory of combinatorial designs. Originally from Australia, she moved to Canada where she worked as a professor at Simon Fraser University and as an academic administrator at the University of Regina.\n\nHeinrich was born in Murwillumbah, New South Wales.\nAs an undergraduate at the University of Newcastle in Australia, Heinrich graduated as a University Medalist in 1976.\nShe continued at Newcastle as a graduate student, and completed her doctorate there in 1979.\nHer dissertation, \"Some problems on combinatorial arrays\", was supervised by Walter D. Wallis.\n\nHeinrich joined the mathematics faculty at Simon Fraser University in 1981, and married another graph theorist at Simon Fraser, Brian Alspach. She became a full professor in 1987, and chaired the department from 1991 to 1996.\nWhile working at Simon Fraser, Heinrich coordinated several outreach activities including a conference for pre-teen girls called \"Women Do Math\" and later \"Discover the Possibilities\", a shopping-center exhibit called \"Math in the Malls\", and a series of national conferences on mathematics education.\n\nFrom 1996 to 1998, she served as president of the Canadian Mathematical Society, its first female president. In 1999, she moved to the University of Regina as academic vice president, and in 2003 she was confirmed for a second five-year term as vice president. At Regina, she helped establish an institute for French-language education, and built stronger connections between Regina and the First Nations University of Canada.\n\n, MathSciNet lists 73 publications for Heinrich, dated from 1976 to 2012. Several of Heinrich's research publications concern orthogonal Latin squares, analogous concepts in graph theory, and applications of these concepts in parallel computing. As well, she has published works on finding spanning subgraphs with constraints on the degree of each vertex, and on Alspach's conjecture on disjoint cycle covers of complete graphs, among other topics.\n\nThe University of Newcastle gave Heinrich a Gold Medal for Professional Excellence in 1995. In 2005, she won the Adrien Pouliot Award of the Canadian Mathematical Society for her work in mathematics education.\n"}
{"id": "53563061", "url": "https://en.wikipedia.org/wiki?curid=53563061", "title": "Kousha Etessami", "text": "Kousha Etessami\n\nKousha Etessami is a professor of Computer Science at the University of Edinburgh, Scotland, UK. He has received his Ph.D from the University of Massachusetts Amherst in 1995. He works on theoretical computer science, in particular on computational complexity theory, game theory and probabilistic systems.\n"}
{"id": "61351", "url": "https://en.wikipedia.org/wiki?curid=61351", "title": "Laurent polynomial", "text": "Laurent polynomial\n\nIn mathematics, a Laurent polynomial (named\nafter Pierre Alphonse Laurent) in one variable over a field formula_1 is a linear combination of positive and negative powers of the variable with coefficients in formula_1. Laurent polynomials in \"X\" form a ring denoted formula_1[\"X\", \"X\"]. They differ from ordinary polynomials in that they may have terms of negative degree. The construction of Laurent polynomials may be iterated, leading to the ring of Laurent polynomials in several variables. Laurent polynomials are of particular importance in the study of complex variables.\n\nA Laurent polynomial with coefficients in a field formula_1 is an expression of the form\n\nwhere \"X\" is a formal variable, the summation index \"k\" is an integer (not necessarily positive) and only finitely many coefficients \"p\" are non-zero. Two Laurent polynomials are equal if their coefficients are equal. Such expressions can be added, multiplied, and brought back to the same form by reducing similar terms. Formulas for addition and multiplication are exactly the same as for the ordinary polynomials, with the only difference that both positive and negative powers of \"X\" can be present:\n\nand\n\nSince only finitely many coefficients \"a\" and \"b\" are non-zero, all sums in effect have only finitely many terms, and hence represent Laurent polynomials.\n\n\n\n"}
{"id": "747223", "url": "https://en.wikipedia.org/wiki?curid=747223", "title": "Lev Schnirelmann", "text": "Lev Schnirelmann\n\nLev Genrikhovich Schnirelmann (also Shnirelman, Shnirel'man; ; January 2, 1905 – September 24, 1938) was a Soviet mathematician who worked on number theory, topology and differential geometry.\n\nHe sought to prove Goldbach's conjecture. In 1930, using the Brun sieve, he proved that any natural number greater than 1 can be written as the sum of not more than C prime numbers, where C is an effectively computable constant.\n\nHis other fundamental work is joint with Lazar Lyusternik. Together, they developed the \"Lusternik–Schnirelmann category\", as it is called now, based on the previous work by Henri Poincaré, David Birkhoff, and Marston Morse. The theory gives a global invariant of spaces, and has led to advances in differential geometry and topology. They also proved the theorem of the three geodesics, that a Riemannian manifold topologically equivalent to a sphere has at least three simple closed geodesics.\n\nSchnirelmann graduated from Moscow State University (1925) and then worked in Steklov Mathematical Institute (1934–1938). His advisor was Nikolai Luzin.\n\nAccording to Pontryagin's memoir, Schnirelmann committed suicide in Moscow.\n\n\n"}
{"id": "18266692", "url": "https://en.wikipedia.org/wiki?curid=18266692", "title": "Lochs's theorem", "text": "Lochs's theorem\n\nIn number theory, Lochs's theorem is a theorem concerning the rate of convergence of the continued fraction expansion of a typical real number. A proof of the theorem was published by Gustav Lochs in 1964.\n\nThe theorem states that for almost all real numbers in the interval (0,1), the number of terms \"m\" of the number's continued fraction expansion that are required to determine the first \"n\" places of the number's decimal expansion behaves asymptotically as follows:\n\nAs this limit is only slightly smaller than 1, this can be interpreted as saying that each additional term in the continued fraction representation of a \"typical\" real number increases the accuracy of the representation by approximately one decimal place. The decimal system is the last positional system for which each digit carries less information than one continued fraction quotient; going to base-11 (changing formula_2 to formula_3 in the equation) makes the above value exceed 1.\n\nThe reciprocal of this limit,\n\nis twice the base-10 logarithm of Lévy's constant.\n\nA prominent example of a number not exhibiting this behavior is the golden ratio—sometimes known as the \"most irrational\" number—whose continued fraction terms are all ones, the smallest possible in canonical form. On average it requires approximately 2.39 continued fraction terms per decimal digit.\n"}
{"id": "30732388", "url": "https://en.wikipedia.org/wiki?curid=30732388", "title": "Louis-Pierre-Eugène Sédillot", "text": "Louis-Pierre-Eugène Sédillot\n\nLouis-Pierre-Eugène Amélie Sédillot (23 June 1808 in Paris – 2 December 1875), was a French orientalist and historian of science and mathematics.\n\nHis father, Jean Jacques Emmanuel Sédillot, orientalist and astronomer, worked alongside Delambre and Laplace. His older brother, Charles-Emmanuel Sédillot, became a renowned surgeon. Louis-Pierre-Eugene also showed predispositions towards study. He began his career as a history teacher before becoming Secretary of the Collège de France and the School of Oriental Languages in 1832.\n\n\n"}
{"id": "902801", "url": "https://en.wikipedia.org/wiki?curid=902801", "title": "Ludics", "text": "Ludics\n\nIn proof theory, ludics is an analysis of the principles governing inference rules of mathematical logic. Key features of ludics include notion of compound connectives, using a technique known as \"focusing\" or \"focalisation\" (invented by the computer scientist Jean-Marc Andreoli), and its use of \"locations\" or \"loci\" over a base instead of propositions.\n\nMore precisely, ludics tries to retrieve known logical connectives and proof behaviours by following the paradigm of interactive computation, similarly to what is done in game semantics to which it is closely related. By abstracting the notion of formulae and focusing of their concrete uses -- that is distinct occurrences -- it provides an abstract syntax for computer science, as loci can be seen as pointers on memory.\n\nThe primary achievement of ludics is the discovery of a relationship between two natural, but distinct notions of type, or proposition.\n\nThe first view, which might be termed the proof-theoretic or Gentzen-style interpretation of propositions, says that the meaning of a proposition arises from its introduction and elimination rules. Focalization refines this viewpoint by distinguishing between positive propositions, whose meaning arises from their introduction rules, and negative propositions, whose meaning arises from their elimination rules. In focused calculi, it is possible to define positive connectives by giving only their introduction rules, with the shape of the elimination rules being forced by this choice. (Symmetrically, negative connectives can be defined in focused calculi by giving only the elimination rules, with the introduction rules forced by this choice.)\n\nThe second view, which might be termed the computational or Brouwer-Heyting-Kolmogorov interpretation of propositions, takes the view that we fix a computational system up front, and then give a realizability interpretation of propositions to give them constructive content. For example, a realizer for the proposition \"A implies B\" is a computable function which takes a realizer for A, and uses it to compute a realizer for B. Realizability models characterize realizers for propositions in terms of their visible behavior, and not in terms of their internal structure.\n\nGirard shows that for second-order affine linear logic, given a computational system with nontermination and error stops as effects, realizability and focalization give the same meaning to types.\n\nLudics was proposed by the logician Jean-Yves Girard. His paper introducing Ludics, \"Locus solum: from the rules of logic to the logic of rules\", has some features that may be seen as eccentric for a publication in mathematical logic (such as illustrations of Positive Skunks). It has to be noted that the intent of these features is to enforce the point of view of Jean-Yves Girard at the time of its writing. And, thus, it offers to readers the possibility to understand ludics independently of their backgrounds.\n\n"}
{"id": "19731900", "url": "https://en.wikipedia.org/wiki?curid=19731900", "title": "Maria Chudnovsky", "text": "Maria Chudnovsky\n\nMaria Chudnovsky (born January 6, 1977) is an Israeli-American mathematician working on graph theory and combinatorial optimization. She is a 2012 MacArthur Fellow.\n\nChudnovsky is a professor in the department of mathematics at Princeton University. She grew up in Russia (attended Saint Petersburg Lyceum 30) and Israel, studying at the Technion, and received her Ph.D. in 2003 from Princeton University under the supervision of Paul Seymour. After postdoctoral research at the Clay Mathematics Institute, she became an assistant professor at Princeton University in 2005, and moved to Columbia University in 2006. By 2014, she was the Liu Family Professor of Industrial Engineering and Operations Research at Columbia. She returned to Princeton as a professor of mathematics in 2015.\n\nShe is a citizen of Israel and a permanent resident of the USA.\n\nIn 2012, she married Daniel Panner, a viola player who teaches at Mannes School of Music and the Juilliard School. They have a son named Rafael.\n\nChudnovsky's contributions to graph theory include the proof of the strong perfect graph theorem (with Robertson, Seymour, and Thomas) characterizing perfect graphs as being exactly the graphs with no odd induced cycles of length at least 5 or their complements. Other research contributions of Chudnovsky include co-authorship of the first polynomial time algorithm for recognizing perfect graphs (degree 9), and of a structural characterization of the claw-free graphs.\n\n\nIn 2004 Chudnovsky was named one of the \"Brilliant 10\" by Popular Science magazine. Her work on the strong perfect graph theorem won for her and her co-authors the 2009 Fulkerson Prize.\nIn 2012 she was awarded a \"genius award\" under the MacArthur Fellows Program.\n\n"}
{"id": "125280", "url": "https://en.wikipedia.org/wiki?curid=125280", "title": "Matrix multiplication", "text": "Matrix multiplication\n\nIn mathematics, matrix multiplication or matrix product is a binary operation that produces a matrix from two matrices with entries in a field, or, more generally, in a ring or even a semiring. The matrix product is designed for representing the composition of linear maps that are represented by matrices. Matrix multiplication is thus a basic tool of linear algebra, and as such has numerous applications in many areas of mathematics, as well as in applied mathematics, statistics, physics, economics, and engineering. In more detail, if is an matrix and is an matrix, their matrix product is an matrix, in which the entries across a row of are multiplied with the entries down a column of and summed to produce an entry of . When two linear maps are represented by matrices, then the matrix product represents the composition of the two maps.\n\nThe definition of matrix product requires that the entries belong to a semiring, and does not require multiplication of elements of the semiring to be commutative. In many applications, the matrix elements belong to a field, although the tropical semiring is also a common choice for graph shortest path problems. Even in the case of matrices over fields, the product is not commutative in general, although it is associative and is distributive over matrix addition. The identity matrices (which are the square matrices whose entries are zero outside of the main diagonal and 1 on the main diagonal) are identity elements of the matrix product. It follows that the matrices over a ring form a ring, which is noncommutative except if and the ground ring is commutative.\n\nA square matrix may have a multiplicative inverse, called an inverse matrix. In the common case where the entries belong to a commutative ring , a matrix has an inverse if and only if its determinant has a multiplicative inverse in . The determinant of a product of square matrices is the product of the determinants of the factors. The matrices that have an inverse form a group under matrix multiplication, the subgroups of which are called matrix groups. Many classical groups (including all finite groups) are isomorphic to matrix groups; this is the starting point of the theory of group representations.\n\nComputing matrix products is a central operation in all computational applications of linear algebra. Its computational complexity is (for matrices) for the basic algorithm (this complexity is for the asymptotically fastest known algorithm). This nonlinear complexity means that matrix product is often the critical part of many algorithms. This is enforced by the fact that many operations on matrices, such as matrix inversion, determinant, solving systems of linear equations, have the same complexity. Therefore various algorithms have been devised for computing products of large matrices, taking into account the architecture of computers (see BLAS, for example).\n\nThis article will use the following notational conventions: matrices are represented by capital letters in bold, e.g. , vectors in lowercase bold, e.g. , and entries of vectors and matrices are italic (since they are numbers from a field), e.g. and . Index notation is often the clearest way to express definitions, and is used as standard in the literature. The entry of matrix is indicated by , or , whereas a numerical label (not matrix entries) on a collection of matrices is subscripted only, e.g. , etc.\n\nIf is an matrix and is an matrix,\n\nthe \"matrix product\" (denoted without multiplication signs or dots) is defined to be the matrix\nsuch that \nfor and .\n\nThat is, the entry of the product is obtained by multiplying term-by-term the entries of the th row of and the th column of , and summing these products. In other words, is the dot product of the th row of and the th column of .\n\nThus the product is defined if and only if the number of columns in equals the number of rows in , in this case .\n\nUsually the entries are numbers, but they may be any kind mathematical objects for which an addition and a multiplication are defined, that are associative, and such that the addition is commutative, and the multiplication is distributive with respect to the addition. In particular, the entries may be matrices themselves (see block matrix).\n\nThe figure to the right illustrates diagrammatically the product of two matrices and , showing how each intersection in the product matrix corresponds to a row of and a column of .\n\nThe values at the intersections marked with circles are:\n\nHistorically, matrix multiplication has been introduced for making easier and clarifying computations in linear algebra. This strong relationship between matrix multiplication and linear algebra remains fundamental in all mathematics, as well as in physics, engineering and computer science.\n\nIf a vector space has a finite basis, its elements (vectors) are uniquely represented by a finite sequence, called coordinate vector, or scalars, which are the coordinates of the vector on the basis. These coordinates are commonly organized as a column matrix (also called \"column vector\"), that is a matrix with only one column.\n\nA linear map from a vector space of dimension into a vector space of dimension maps a column vector\nonto the column vector\nThe linear map is thus defined by the matrix \nand maps the column vector formula_9 to the matrix product \n\nIf is another linear map from the preceding vector space of dimension , into a vector space of dimension , it is represented by a matrix formula_11 A straightforward computation shows that the matrix of the composite map is the matrix product formula_12 The general formula of the function composition (that is, ) is instanced here as a specific case of associativity of matrix product (see below):\n\nThe general form of a system of linear equations is\n\nUsing same notation as above, such a system is equivalent with the single matrix equation\n\nThe dot product of two column vectors is the matrix product \nwhere formula_17 is the row vector obtained by transposing formula_9 and the resulting 1×1 matrix is identified with its unique entry.\n\nMore generally, any bilinear form over a vector space of finite dimension may be expressed as a matrix product\nand any inner product may be expressed as \nwhere formula_21 denotes the conjugate transpose of formula_9 (conjugate of the transpose, or equivalently transpose of the conjugate).\n\nMatrix multiplication shares some properties with usual multiplication. However, matrix multiplication is not defined if the number of columns of the first factor differs from the number of rows of the second factor, and it is non-commutative, even when the product remains definite after changing the order of the factors.\n\nAn operation is commutative if, given two elements and such that the product formula_23 is defined, then formula_24 is also defined, and formula_25\n\nIf and are matrices of respective sizes and , then formula_23 is defined if , and formula_24 is defined if . Therefore, if one of the products is defined, the other is not defined in general. If , the two products are defined, but have different sizes; thus they cannot be equal.\n\nIt follows that the equality of the two products makes sense only if , that is if and are square matrices of the same size. Even in this case, one has in general\nFor example\nand\n\nThis example may be expanded for showing that, if is a matrix with entries in a field , then formula_31 for every matrix with entries in , if and only if formula_32 where , and is the identity matrix. If, instead of a field, the entries are supposed to belong to a ring, then one must add the condition that belongs to the center of the ring.\n\nThe matrix product is distributive with respect of matrix addition. That is, if are matrices of respective sizes , , , and , one has (left distributivity)\nand (right distributivity)\n\nThis results from the distributivity for coefficients by \n\nIf is a matrix and a scalar, then the matrices formula_37 and formula_38 are obtained by left or right multiplying all entries of by . If the scalars have the commutative property, then formula_39\n\nIf the product formula_40 is defined (that is the number of columns of equals the number of rows of , then \nIf the scalars have the commutative property, then all four matrices are equal. More generally, all four are equal if belongs to the center of a ring containing the entries of the matrices, because in this case for all matrices .\n\nThese properties result from the bilinearity of the product of scalars:\n\nIf the scalars have the commutative property, the transpose of a product of matrices is the product, in the reverse order, of the transposes of the factors. That is \nwhere denotes the transpose, that is the interchange of rows and columns.\n\nThis identity does not hold for noncommutative entries, since the order between the entries of and is reversed, when one expands the definition of the matrix product.\n\nIf and have complex entries, then\nwhere denotes the entry-wise complex conjugate of a matrix.\n\nThis results of applying to the definition of matrix product the fact that the conjugate of a sum is the sum of the conjugates of the summands and the conjugate of a product is the product of the conjugates of the factors.\n\nTransposition acts on the indices of the entries, while conjugation acts independently on the entries themselves. It results that, if and have complex entries, one has\n\nwhere denotes the conjugate transpose (conjugate of the transpose, or equivalently transpose of the conjugate).\n\nGiven three matrices and , the products and are defined if and only if the number of columns of equals the number of rows of and the number of columns of equals the number of rows of (in particular, if one of the product is defined, the other is also defined). In this case, one has the associative property\n\nAs for any associative operation, this allows omitting parentheses, and writing the above products as \n\nThis extends naturally to the product of any number of matrix provided that the dimension match. That is, if are matrices such that the number of columns of equals the number of rows of for , then the product \nis defined and does not depend on the order of the multiplications, if the order of the matrices is kept fixed.\n\nThese properties may be proved by straightforward but complicate summation manipulations. This result also from the fact that matrices represent linear maps. Therefore, the associative property of matrices is simply a specific case of the associative property of function composition.\n\nAlthough the result of a sequence of matrix product does not depend on the order of operation (provided that the order of the matrices is not changed), the computational complexity may depend dramatically on this order.\n\nFor example, if and are matrices of respective sizes , computing needs multiplications, while computing needs multiplications.\n\nAlgorithms have been designed for choosing the best order of products, see Matrix chain multiplication. When the number of matrices increases, it has been shown that the choice of the best order has a complexity of formula_50\n\nAny invertible matrix formula_51 defines a similarity transformation (on square matrices of the same size as formula_51)\n\nSimilarity transformations map product to products, that is \n\nIn fact, one has \n\nLet us denote formula_56 the set of square matrices with entries in a ring , which, in practice, is often a field.\n\nIn formula_56, the product is defined for every pair of matrices. This makes formula_56 a ring, which has the identity matrix as identity element (the matrix whose diagonal entries are equal to 1 and all other entries are 0). This ring is also an associative -algebra.\n\nIf , many matrices do not have a multiplicative inverse. For example, a matrix such that all entries of a row (or a column) are 0 does not have an inverse. If it exists, the inverse of a matrix is denoted , and, thus verifies\nA matrix that has an inverse is an invertible matrix. Otherwise, it is a singular matrix.\n\nA product of matrices is invertible if and only if each factor is invertible. In this case, one has\n\nWhen is commutative, and, in particular, when it is a field, the determinant of a product is the product of the determinants. As determinants are scalars, and scalars commute, one has thus \n\nThe other matrix invariants do not behave as well with products. Nevertheless, if is commutative, formula_40 and formula_63 have the same trace, the same characteristic polynomial, and the same eigenvalues with the same multiplicities.\nHowever, the eigenvectors are generally different if formula_64\n\nOne may raise a square matrix to any nonnegative integer power multiplying it by itself repeatedly in the same way as for ordinary numbers. That is,\n\nComputing the th power of a matrix needs times the time of a single matrix multiplication, if it is done with the trivial algorithm (repeated multiplication). As this may be very time consuming, one generally prefers using exponentiation by squaring, which requires less than matrix multiplications, and is therefore much more efficient.\n\nAn easy case for exponentiation is that of a diagonal matrix. Since the product of diagonal matrices amounts to simply multiplying corresponding diagonal elements together, the th power of a diagonal matrix is obtained by raising the entries to the power :\n\nThe matrix multiplication algorithm that results of the definition requires, in the worst case, multiplications of scalars and additions for computing the product of two square matrices. Its computational complexity is therefore , in a model of computation for which the scalar operations require a constant time (in practice, this is the case for floating point numbers, but not for integers).\n\nRather surprisingly, this complexity is not optimal, as shown in 1969 by Volker Strassen, who provided an algorithm, now called Strassen's algorithm, with a complexity of formula_69 The exponent appearing in the complexity of matrix multiplication has been improved several times, leading to \nCoppersmith–Winograd algorithm with a complexity of (1990). This algorithm has been slightly improved in 2013 by Virginia Vassilevska Williams (exponent 2.3729) and in 2014 by François Le Gall, for a final (up to date) complexity of .\n\nThe greatest lower bound for the exponent of matrix multiplication algorithm is generally called . One has , because one has to read the elements of a matrix for multiplying it by another matrix. Thus . It is unknown whether . The largest known lower bound for matrix-multiplication complexity is , for a restricted kind of arithmetic circuits, and is due Ran Raz.\n\nThe importance of the computational complexity of matrix multiplication relies on the facts that many algorithmic problems may be solved by means of matrix computation, and most problems on matrices have a complexity which is either the same as that of matrix multiplication (up to a multiplicative constant), or may be expressed in term of the complexity of matrix multiplication or its exponent formula_70\n\nThere are several advantages of expressing complexities in terms of the exponent formula_71 of matrix multiplication. Firstly, if formula_71 is improved, this will automatically improve the known upper bound of complexity of many algorithms. Secondly, in practical implementations, one never uses the matrix multiplication algorithm that has the best asymptotical complexity, because the constant hidden behind the big O notation is too large for making the algorithm competitive for sizes of matrices that can be manipulated in a computer. Thus expressing complexities in terms of formula_71 provide a more realistic complexity, since it remains valid whichever algorithm is chosen for matrix computation.\n\nProblems that have the same asymptotic complexity as matrix multiplication include determinant, matrix inversion, Gaussian elimination (see next section). Problems with complexity that is expressible in terms of formula_71 include characteristic polynomial, eigenvalues (but not eigenvectors), Hermite normal form, and Smith normal form.\n\nIn his 1969 paper, where he proved the complexity formula_75 for matrix computation, Strassen proved also the Matrix inversion, determinant and Gaussian elimination have, up to a multiplicative constant, the same computational complexity as matrix multiplication. The proof does not make any assumptions on matrix multiplication that is used, except that its complexity is formula_76 for some formula_77\n\nThe starting point of Strassen's proof is using block matrix multiplication. Specifically, a matrix of even dimension may be partitioned in four blocks\nUnder this form, its inverse is \nprovided that and formula_80 are invertible.\n\nThus, the inverse of a matrix may be computed with two inversions, six multiplications and four additions or additive inverses of matrices. It follows that, denoting respectively by , and the number of operations needed for multiplying, inverting and adding matrices, one has \nIf formula_82 one may apply this formula recursively:\nIf formula_84 and formula_85 one gets eventually \nfor some constant .\n\nFor matrices whose dimension is not a power of two, the same complexity is reached by increasing the dimension of the matrix to a power of two, by padding the matrix with rows and columns whose entries are 1 on the diagonal and 0 elsewhere.\n\nThis proves the asserted complexity for matrices such that all submatrices that have to be inverted are indeed invertible. This complexity is thus proved for almost all matrices, as a matrix with randomly chosen entries is invertible with probability one.\n\nThe same argument applies to LU decomposition, as, if the matrix is invertible, the equality\ndefines a block LU decomposition that may be applied recursively to formula_88 and formula_89 for getting eventually a true LU decomposition of the original matrix.\n\nThe argument applies also for the determinant, since it results from the block LU decomposition that \n\nThe term \"matrix multiplication\" is most commonly reserved for the definition given in this article. It could be more loosely applied to other operations on matrices.\n\n\n"}
{"id": "3942941", "url": "https://en.wikipedia.org/wiki?curid=3942941", "title": "Method of averaging", "text": "Method of averaging\n\nIn mathematics, more specifically in nonlinear dynamical systems, the method of averaging (also called averaging theory) exploits systems which has the structure \n\nformula_1\n\nof a phase space variable formula_2The separation of system's time-scales a \"fast oscillation\" of formula_3 versus a \"slow drift\" of formula_4 suggests that we iron out the fast oscillations by averaging over an amount of time. This calculation yields an autonomous dynamical system\n\nformula_5\n\nUnder the validity of this averaging technique, the asymptotic behavior of the system is captured by the dynamical equation for formula_6. In this way, qualitative methods for autonomous dynamical systems may be employed to analyze the equilibria and more complex structures, such as slow manifold and invariant manifolds, as well as their stability in the phase space of the averaged system. Besides, in a physical application it might be reasonable or natural to replace a mathematical model, which is given in the form of the diﬀerential equation for formula_4, with the corresponding averaged system formula_8, to use the averaged system to make a prediction, and to then test the prediction against the results of a physical experiment . \n\nThe averaging method has a long history, which is deeply rooted in perturbation problems that arise in celestial mechanics (see, for example in ). \n\nConsider a perturbed logistic growth \n\nformula_9\n\nand the averaged equation\n\nformula_10\n\nThe purpose of the method of averaging is to tell us the qualitative behavior of the vector field when we average it over a period of time. It guarantees that the solution formula_11 approximates for times formula_12\n\nConsider a nonlinear dynamical system given by\n\nformula_13\n\nwhere formula_14with formula_15 bounded on bounded sets, and periodic with period formula_16 in formula_17. The evolution of this system is said to occur in two time-scales: a fast oscillatory one associated with the presence of formula_17 in formula_3 and a slow one associated with the presence of formula_20 in front of formula_3. The corresponding autonomous \"averaged\" \"system\" is\n\nformula_22\n\nNonlinear oscillators may be better understood when we apply periodic averaging to some classical systems.\n\nThe method contains some assumptions and restrictions. These limitations play important role when we average the original equation which is not into the standard form, and we can discuss counter examples of it. The following example in order to discourage this hurried averaging : \n\nformula_23\n\nThis systems corresponds to a damped harmonic oscillator where the damping term oscillates between formula_24 and formula_25. Averaging the friction term over one cycle of formula_26 yields the equation:\n\nformula_27\n\nThe solution is \n\nformula_28\n\nThe averaged system obtained from the standard form yields:\n\nformula_29 \n\nwhich indeed is different.\n\nConsider a damped pendulum whose point of suspension is vibrated vertically by a small amplitude, high frequency signal (this is usually known as \"dithering\"). The equation of motion for such a pendulum is given by\n\nformula_30\n\nwhere formula_31 describes the motion of the suspension point, formula_32 describes the damping of the pendulum, and formula_33 is the angle made by the pendulum with the vertical.\n\nThe phase space form of this equation is given by\n\nformula_34\n\nwhere we have introduced the variable formula_35 and written the system as an \"autonomous\", first-order system in formula_36-space.\n\nSuppose that the angular frequency of the vertical vibrations, formula_37, is much greater than the natural frequency of the pendulum, formula_38. Suppose also that the amplitude of the vertical vibrations, formula_39, is much less than the length formula_40 of the pendulum. The pendulum's trajectory in phase space will trace out a spiral around a curve formula_41, moving along formula_41 at the slow rate formula_38 but moving around it at the fast rate formula_37. The radius of the spiral around formula_41 will be small and proportional to formula_39. The average behaviour of the trajectory, over a timescale much larger than formula_47, will be to follow the curve formula_41.\n"}
{"id": "26485293", "url": "https://en.wikipedia.org/wiki?curid=26485293", "title": "Michael Stifel", "text": "Michael Stifel\n\nMichael Stifel or Styfel (1487 – April 19, 1567) was a German monk, Protestant reformer and mathematician. He was an Augustinian who became an early supporter of Martin Luther. He was later appointed professor of mathematics at Jena University.\n\nStifel was born in Esslingen am Neckar. He joined the Order of Saint Augustine and was ordained a priest in 1511. Tensions in the abbey grew after he published the poem \"Von der Christförmigen, rechtgegründeten leer Doctoris Martini Luthers\" (1522, i.e. On the Christian, righteous doctrine of Doctor Martin Luther) and came into conflict with Thomas Murner. Stifel then left for Frankfurt, and soon went to Mansfeld, where he began his mathematical studies. In 1524 upon a recommendation by Martin Luther, Stifel was called to the Jörger on Tollet Palace in Tollet close to Grieskirchen, Upper Austria. Due to the tightened situation in Austria (execution of Leonhard Kaiser in Schaerding), Stifel returned to Wittenberg in 1527. At this time Stifel started writing a book collecting letter transcripts of Martin Luther. It was completed in 1534.\n\nBy intercession of Martin Luther, Stifel became minister in Lochau (what is Annaburg now). Luther also confirmed the marriage of Michael Stifel and the widow of his predecessor in the ministry. Michael Stifel was fascinated regarding the properties and possibilities of numbers. At Lochau he had the opportunity to do mathematical studies on number theory and numerology. He also performed the so-called \"Wortrechnung\" (i.e. word-calculation), studying the statistical properties of letters and words in the bible, a common method at that time. In 1532 Stifel published anonymously his \"Ein Rechenbuchlin vom EndChrist. Apocalyps in Apocalypsim\" (A Book of Arithmetic about the AntiChrist. A Revelation in the Revelation). This predicted that Judgement Day the world would end at 8am on October 19, 1533. The German saying \"to talk a Stiefel\" or \"to calculate a Stiefel\" (Stiefel is the German word for boot) meaning to say or calculate something based on an unusual track can be traced back to this incident. When this prediction failed, he did not make any other predictions.\n\nIn 1535 he became minister in Holzdorf near Wittenberg and stayed there for 12 years. Stifel now continued with serious mathematical studies. Worth mentioning were \"the Coss\" (the first algebra book written in German) of Christoph Rudolff, which he did in self study and \"the Elements\" of Euclid in the Latin edition by Campanus of Novara.\nA proposal of Jacob Milich, who supported his scientific development. Milich encouraged Michael Stifel to write a comprehensive work on arithmetic and algebra.\nIn 1541, during his time as minister in Holzdorf, he also registered for mathematics at the University of Wittenberg to extend his mathematical knowledge. In 1558 Stifel became first professor of mathematics at the new founded University of Jena.\n\nStifel's most important work \"Arithmetica integra\" (1544) contained important innovations in mathematical notation. It has the first use of multiplication by juxtaposition (with no symbol between the terms) in Europe. He is the first to use the term \"exponent\" and also included the following rules for calculating powers: formula_1 and formula_2. The book contains a table of integers and powers of 2 that some have considered to be an early version of a logarithmic table.\nStifel explicitly points out, that multiplication and division operations in the (lower) geometric series can be mapped by addition and subtraction in the (upper) arithmetic series. On the following page 250, he shows examples also using negative exponents. He also realized that this would create a lot of work. So he wrote, that regarding this issue marvelous books could be written, but he himself will refrain and keep his eyes shut.\n\nStifel was the first, who had a standard method to solve quadratic equations. He was able to reduce the different cases known to one case, because he uses both, positive and negative coefficients. He called his method/rule AMASIAS. The letters A, M, A/S, I, A/S each are representing a single operation step when solving a quadratic equation. Stifel, however avoided to show the negative results.\n\nAnother topic dealt with in the \"Arithmetica integra\" are negative numbers (which Stifel calls \"numeri absurdi\"). Negative numbers were refused and considered as preposterous by the authorities at that time. Stifel however, used negative numbers equal to the other numbers. He also discussed the properties of irrational numbers and if the irrationals are real numbers, or only fictitious (AI page 103). Stifel found them very useful for mathematics, and not dispensable. Further issues were a method of calculating roots of higher order by using binomial coefficients and sequences.\n\n\n"}
{"id": "21890097", "url": "https://en.wikipedia.org/wiki?curid=21890097", "title": "Multilinear polynomial", "text": "Multilinear polynomial\n\nIn algebra, a multilinear polynomial is a polynomial that is linear in each of its variables. In other words, no variable occurs to a power of 2 or higher; or alternatively, each monomial is a constant times a product of distinct variables. For example p(x,y,z) = 3xy + 2.5 y - 7z is a multilinear polynomial with degree 2 (because of the monomial 3xy) whereas p(x,y,z) = x² +4y is not.\n\nMultilinear polynomials are important in the study of polynomial identity testing. The degree of a multilinear polynomial is the maximum number of distinct variables occurring in any monomial.\n"}
{"id": "10101991", "url": "https://en.wikipedia.org/wiki?curid=10101991", "title": "Newton's inequalities", "text": "Newton's inequalities\n\nIn mathematics, the Newton inequalities are named after Isaac Newton. Suppose \"a\", \"a\", ..., \"a\" are real numbers and let formula_1 denote the \"k\"th elementary symmetric function in \"a\", \"a\", ..., \"a\". Then the elementary symmetric means, given by\n\nsatisfy the inequality\n\nIf all the numbers \"a\" are nonzero, then equality holds if and only if all the numbers \"a\" are equal. \"S\" is the arithmetic mean, and \"S\" is the \"n\"-th power of the geometric mean.\n\n\n"}
{"id": "12673586", "url": "https://en.wikipedia.org/wiki?curid=12673586", "title": "Paul Monsky", "text": "Paul Monsky\n\nPaul Monsky (born June 17, 1936) is an American mathematician and professor at Brandeis University.\n\nAfter earning a bachelor's degree from Swarthmore College, he received his Ph.D. in 1962 from the University of Chicago under the supervision of Walter Lewis Baily, Jr. He has introduced the Monsky–Washnitzer cohomology and he has worked intensively on Hilbert–Kunz functions and Hilbert–Kunz multiplicity. In 2007, Monsky and Holger Brenner gave an example showing that tight closure does not commute with localization.\n\nMonsky's theorem, the statement that a square cannot be divided into an odd number of equal-area triangles, is named after Monsky, who published the first proof of it in 1970.\n\nIn the mid-1970s, Monsky stopped paying U.S. federal income tax in protest against military spending. He resisted income tax withholding by claiming extra exemptions, and this led to a criminal conviction on tax charges in 1980.\n\n"}
{"id": "33848514", "url": "https://en.wikipedia.org/wiki?curid=33848514", "title": "Preissman's theorem", "text": "Preissman's theorem\n\nIn Riemannian geometry, a field of mathematics, Preissman's theorem is a statement that restricts the possible topology of a negatively curved compact Riemannian manifold \"M\". Specifically, the theorem states that every non-trivial abelian subgroup of the fundamental group of \"M\" must be isomorphic to the additive group of integers, Z.\n\nA corollary of Preissman's theorem is that the \"n\"-dimensional torus, where \"n\" is at least two, admits no Riemannian metric of negative sectional curvature.\n"}
{"id": "372426", "url": "https://en.wikipedia.org/wiki?curid=372426", "title": "Production equipment control", "text": "Production equipment control\n\nProduction equipment control involves production equipment that resides in the shop floor of a manufacturing company and its purpose is to produce goods of a wanted quality when provided with production resources of a required quality. In modern production lines the production equipment is fully automated using industrial control methods and involves limited unskilled labour participation. Modern production equipment consists of mechatronic modules that are integrated according to a control architecture. The most widely known architectures involve hierarchy, polyarchy, hetaerarchy and hybrid. The methods for achieving a technical effect are described by control algorithms, which may or may not utilize formal methods in their design.\n"}
{"id": "3913145", "url": "https://en.wikipedia.org/wiki?curid=3913145", "title": "Projection (set theory)", "text": "Projection (set theory)\n\nIn set theory, a projection is one of two closely related types of functions or operations, namely:\n\n\n"}
{"id": "48490486", "url": "https://en.wikipedia.org/wiki?curid=48490486", "title": "Ralph Louis Cohen", "text": "Ralph Louis Cohen\n\nRalph Louis Cohen (born 1952) is an American mathematician, specializing in algebraic topology and differential topology.\n\nCohen received his bachelor's degree from the University of Michigan in 1973 and his Ph.D. in 1978 from Brandeis University where he worked under the supervision of Edgar H. Brown, Jr. His thesis was titled \"On Odd Primary Stable Homotopy Theory\".[2] He did his postdoctoral training as an L.E. Dickson Instructor at the University Chicago, and then became an Assistant Professor of Mathematics at Stanford University in 1980. In 1983, he became an Associate Professor and was promoted to Full Professor in 1987. Cohen is now the Barbara Kimball Browning Professor of Mathematics at Stanford. He was Chair of the Mathematics Department from 1992 to 1995, from 1999 to 2009 he was the Director of the Mathematics Research Center at Stanford, and from 2010 to 2016 was the Senior Associate Dean for the Natural Sciences in the School of Humanities and Sciences.\n\nCohen has been a visiting professor at Princeton University, the University of Oxford, the University of Cambridge, Paris Diderot University, Paris 13 University, the University of Lille, and the University of Copenhagen.\n\nIn 1985, Cohen proved the Immersion Conjecture, which says that each smooth, compact n-manifold has an immersion in Euclidean space of dimension formula_1, where formula_2 is the number of ones in the binary expansion of formula_3. In 1991, Cohen, together with Frederick Cohen, Benjamin Mann, and R. James Milgram gave a complete description of the algebraic topology of the space of rational functions, and in the following years he made several contributions to the study of related moduli spaces. In 1995 Cohen, John D. S. Jones, and Graeme Segal introduced an approach for understanding the homotopy theory underlying Floer homology theory in Symplectic geometry. Since 2002 Cohen has been one of the leading developers and contributors to the theory of String topology, which was introduced originally by Moira Chas and Dennis Sullivan.\n\nIn 1995, Cohen was a founder of the Stanford University Math Camp (SUMaC), a summer camp for mathematically talented high school students. In 2002 Cohen received the Distinguished Teaching Award from Stanford University, and in 2005 he became a Bass Fellow in Undergraduate Education at Stanford.\n\nIn 1982 Cohen was a Sloan Fellow. In 1983 he was an invited speaker at the International Congress of Mathematicians in Warsaw. In 1984 he received the Presidential Young Investigator Award. In 1988 he received an NSF International Award, in 2010 he served on the Executive Committee of the American Mathematical Society, and in 2012 he was elected a Fellow of the American Mathematical Society.\n\nCohen has been an editor of many mathematics journals and text series. In particular, he was a founding editor of both the \"Journal of Topology\" and \"Geometry and Topology\".\n\nCohen has been the Ph.D. supervisor to over 30 doctoral students including Ulrike Tillmann, Paul Norbury, Ernesto Lupercio, and David Ayala.\n\n"}
{"id": "1612114", "url": "https://en.wikipedia.org/wiki?curid=1612114", "title": "Reinhold Baer", "text": "Reinhold Baer\n\nReinhold Baer (22 July 1902 – 22 October 1979) was a German mathematician, known for his work in algebra. He introduced injective modules in 1940. He is the eponym of Baer rings and Baer groups.\n\nBaer studied mechanical engineering for a year at the University of Hanover. He then went to study philosophy at Freiburg in 1921. While he was at Göttingen in 1922 he was influenced by Emmy Noether and Hellmuth Kneser. In 1924 he won a scholarship for specially gifted students. Baer wrote up his doctoral dissertation and it was published in Crelle's Journal in 1927.\n\nBaer accepted a post at Halle in 1928. There, he published Ernst Steinitz's \"Algebraische Theorie der Körper\" with Helmut Hasse, first published in Crelle's Journal in 1910.\n\nWhile Baer was with his wife in Austria, Adolf Hitler and the Nazis came into power. Baer was later informed that his services at Halle were no longer required. Louis Mordell invited him to go to Manchester and Baer accepted.\n\nBaer stayed at Princeton University and was a visiting scholar at the nearby Institute for Advanced Study from 1935 to 1937. For a short while he lived in North Carolina. From 1938 to 1956 he worked at the University of Illinois at Urbana-Champaign. He returned to Germany in 1956.\n\nAccording to biographer K. W. Gruenberg,\n\nHe died of heart failure on October 22nd.\n\nIn 2016 the Reinhold Baer Prize for the best Ph.D. thesis in Group Theory was set up in his honour.\n\n\n\n\n"}
{"id": "12184856", "url": "https://en.wikipedia.org/wiki?curid=12184856", "title": "Solid harmonics", "text": "Solid harmonics\n\nIn physics and mathematics, the solid harmonics are solutions of the Laplace equation in spherical polar coordinates. There are two kinds: the \"regular solid harmonics\" formula_1, which vanish at the origin and the \"irregular solid harmonics\" formula_2, which are singular at the origin. Both sets of functions play an important role in potential theory, and are obtained by rescaling spherical harmonics appropriately:\n\nIntroducing \"r\", θ, and φ for the spherical polar coordinates of the 3-vector r, we can write the Laplace equation in the following form\nwhere \"l\" is the square of the nondimensional angular momentum operator,\n\nIt is known that spherical harmonics Y are eigenfunctions of \"l\":\n\nSubstitution of Φ(r) = \"F\"(\"r\") Y into the Laplace equation gives, after dividing out the spherical harmonic function, the following radial equation and its general solution,\n\nThe particular solutions of the total Laplace equation are regular solid harmonics:\nand irregular solid harmonics:\n\nRacah's normalization (also known as Schmidt's semi-normalization) is applied to both functions \n(and analogously for the irregular solid harmonic) instead of normalization to unity. This is convenient because in many applications the Racah normalization factor appears unchanged throughout the derivations.\n\nThe translation of the regular solid harmonic gives a finite expansion,\nwhere the Clebsch-Gordan coefficient is given by\n\nThe similar expansion for irregular solid harmonics gives an infinite series,\nwith formula_15. The quantity between pointed brackets is again a Clebsch-Gordan coefficient,\n\nThe addition theorems were proved in different manners by several authors. For example, see the two different proofs in:\n\nBy a simple linear combination of solid harmonics of ±\"m\" these functions are transformed into real functions. The real regular solid harmonics, expressed in Cartesian coordinates, are homogeneous polynomials of order \"l\" in \"x\", \"y\", \"z\". The explicit form of these polynomials is of some importance. They appear, for example, in the form of spherical atomic orbitals and real multipole moments. The explicit cartesian expression of the real regular harmonics will now be derived.\n\nWe write in agreement with the earlier definition \nwith\nwhere formula_19 is a Legendre polynomial of order \"l\".\nThe \"m\" dependent phase is known as the Condon-Shortley phase.\n\nThe following expression defines the real regular solid harmonics:\nand for \"m\" = 0:\nSince the transformation is by a unitary matrix the normalization of the real and the complex solid harmonics is the same.\n\nUpon writing \"u\" = cos θ the \"m\"th derivative of the Legendre polynomial can be written as the following expansion in \"u\"\nwith\nSince \"z\" = \"r\" cosθ it follows that this derivative, times an appropriate power of \"r\", is a simple polynomial in \"z\",\n\nConsider next, recalling that \"x\" = \"r\" sinθcosφ and \"y\" = \"r\" sinθsinφ,\nLikewise\nFurther\nand\n\nWe list explicitly the lowest functions up to and including \"l = 5\" .\nHere formula_31\nThe lowest functions formula_33 and formula_34 are:\n\n"}
{"id": "3089478", "url": "https://en.wikipedia.org/wiki?curid=3089478", "title": "Standard normal table", "text": "Standard normal table\n\nA standard normal table, also called the unit normal table or Z table, is a mathematical table for the values of Φ, which are the values of the cumulative distribution function of the normal distribution. It is used to find the probability that a statistic is observed below, above, or between values on the standard normal distribution, and by extension, any normal distribution. Since probability tables cannot be printed for every normal distribution, as there are an infinite variety of normal distributions, it is common practice to convert a normal to a standard normal and then use the standard normal table to find probabilities.\n\nNormal distributions are symmetrical, bell-shaped distributions that are useful in describing real-world data. The \"standard\" normal distribution, represented by the letter Z, is the normal distribution having a mean of 0 and a standard deviation of 1.\n\nIf \"X\" is a random variable from a normal distribution with mean μ and standard deviation σ, its Z-score may be calculated from X by subtracting μ and dividing by the standard deviation:\n\nFor the average of a sample of size n from some population in which the mean is μ and the standard deviation is σ, the standard error is σ/√\"n\":\n\nZ tables are typically composed as follows:\n\nExample: To find 0.69, one would look down the rows to find 0.6 and then across the columns to 0.09 which would yield a probability of 0.25490 for a \"cumulative from mean\" table or 0.75490 from a \"cumulative\" table.\n\nBecause the normal distribution curve is symmetrical, probabilities for only positive values of Z are typically given. The user has to use a complementary operation on the absolute value of Z, as in the example below.\n\nZ tables use at least three different conventions:\n\n\n\n\nThis table gives a probability that a statistic is between 0 (the mean) and Z.\n\nNote that for z = 1, 2, 3, one obtains (after multiplying by 2 to account for the [-z,z] interval) the results f(z) = 0.6827, 0.9545, 0.9974, \ncharacteristic of the 68–95–99.7 rule.\n\nThis table gives a probability that a statistic is less than Z (i.e. between negative infinity and Z).\n\nThe values are calculated using the cumulative distribution function of a standard normal distribution with mean of zero and standard deviation of one, usually denoted with the capital Greek letter formula_4 (phi), is the integral\n\nformula_4(z) is related to the error function, or erf(\"z\").\n\nThis table gives a probability that a statistic is greater than Z.\n\nThis table gives a probability that a statistic is greater than Z, for large integer Z values.\n\nA professor's exam scores are approximately distributed normally with mean 80 and standard deviation 5. Only a \"cumulative from mean\" table is available.\n\n\n\n\n\n"}
{"id": "7386145", "url": "https://en.wikipedia.org/wiki?curid=7386145", "title": "Type erasure", "text": "Type erasure\n\nIn programming languages, type erasure refers to the load-time process by which explicit type annotations are removed from a program, before it is executed at run-time. Operational semantics that do not require programs to be accompanied by types are called \"type-erasure semantics\", to be contrasted with \"type-passing semantics\". The possibility of giving type-erasure semantics is a kind of abstraction principle, ensuring that the run-time execution of a program does not depend on type information. In the context of generic programming, the opposite of type erasure is called reification. \n\nThe reverse operation is called type inference. Though type erasure can be used as an easy way to define typing over implicitly typed languages (an implicitly typed term is well-typed if and only if it is the erasure of a well-typed explicitly typed lambda term), it does not always lead to an algorithm to check implicitly typed terms.\n\n"}
{"id": "366208", "url": "https://en.wikipedia.org/wiki?curid=366208", "title": "Typed lambda calculus", "text": "Typed lambda calculus\n\nA typed lambda calculus is a typed formalism that uses the lambda-symbol (formula_1) to denote anonymous function abstraction. In this context, types are usually objects of a syntactic nature that are assigned to lambda terms; the exact nature of a type depends on the calculus considered (see kinds below). From a certain point of view, typed lambda calculi can be seen as refinements of the untyped lambda calculus but from another point of view, they can also be considered the more fundamental theory and \"untyped lambda calculus\" a special case with only one type.\n\nTyped lambda calculi are foundational programming languages and are the base of typed functional programming languages such as ML and Haskell and, more indirectly, typed imperative programming languages. Typed lambda calculi play an important role in the design of type systems for programming languages; here typability usually captures desirable properties of the program, e.g. the program will not cause a memory access violation.\n\nTyped lambda calculi are closely related to mathematical logic and proof theory via the Curry–Howard isomorphism and they can be considered as the internal language of classes of categories, e.g. the simply typed lambda calculus is the language of Cartesian closed categories (CCCs).\n\nVarious typed lambda calculi have been studied. The simply typed lambda calculus has only one type constructor, the arrow formula_2, and its only types are basic types and function types formula_3. System T extends the simply typed lambda calculus with a type of natural numbers and higher order primitive recursion; in this system all functions provably recursive in Peano arithmetic are definable. System F allows polymorphism by using universal quantification over all types; from a logical perspective it can describe all functions that are provably total in second-order logic. Lambda calculi with dependent types are the base of intuitionistic type theory, the calculus of constructions and the logical framework (LF), a pure lambda calculus with dependent types. Based on work by Berardi on pure type systems, Henk Barendregt proposed the Lambda cube to systematize the relations of pure typed lambda calculi (including simply typed lambda calculus, System F, LF and the calculus of constructions).\n\nSome typed lambda calculi introduce a notion of \"subtyping\", i.e. if formula_4 is a subtype of formula_5, then all terms of type formula_4 also have type formula_5. Typed lambda calculi with subtyping are the simply typed lambda calculus with conjunctive types and System F.\n\nAll the systems mentioned so far, with the exception of the untyped lambda calculus, are \"strongly normalizing\": all computations terminate. As a consequence they are consistent as a logic, i.e. there are uninhabited types. There exist, however, typed lambda calculi that are not strongly normalizing. For example the dependently typed lambda calculus with a type of all types (Type : Type) is not normalizing due to Girard's paradox. This system is also the simplest pure type system, a formalism which generalizes the Lambda cube. Systems with explicit recursion combinators, such as Plotkin's PCF, are not normalizing, but they are not intended to be interpreted as a logic. Indeed, PCF (for Programming language for Computable Functions) is a prototypical, typed functional programming language, where types are used to ensure that programs are well-behaved but not necessarily terminating.\n\nIn computer programming, the routines (functions, procedures, methods) of strongly typed programming languages closely correspond to typed lambda expressions.\n\n\n"}
{"id": "49758265", "url": "https://en.wikipedia.org/wiki?curid=49758265", "title": "Why Johnny Can't Add", "text": "Why Johnny Can't Add\n\nWhy Johnny Can't Add: The Failure of the New Math is a book written by Morris Kline, first published in 1973. In it, Kline severely criticized the teaching practices characteristic of the \"New Math\" fashion for school teaching, which were based on Bourbaki's approach to mathematical research, and were being pushed into schools in the United States. Reactions were immediate, and the book became a best seller in its genre and translated into many languages.\n\n\n"}
{"id": "51457085", "url": "https://en.wikipedia.org/wiki?curid=51457085", "title": "Švarc–Milnor lemma", "text": "Švarc–Milnor lemma\n\nIn the mathematical subject of geometric group theory, the Švarc–Milnor lemma (sometimes also called Milnor–Švarc lemma, with both variants also sometimes spelling Švarc as Schwarz) is a statement which says that a group formula_1, equipped with a \"nice\" discrete isometric action on a metric space formula_2, is quasi-isometric to formula_2.\n\nThis result goes back, in different form, before the notion of quasi-isometry was formally introduced, to the work of Albert S. Schwarz (1955) and John Milnor (1968). Pierre de la Harpe called the Švarc–Milnor lemma ``the \"fundamental observation in geometric group theory\"\" because of its importance for the subject. Occasionally the name \"fundamental observation in geometric group theory\" is now used for this statement, instead of calling it the Švarc–Milnor lemma; see, for example, Theorem 8.2 in the book of Farb and Margalit.\n\nSeveral minor variations of the statement of the lemma exist in the literature (see the Notes section below). Here we follow the version given in the book of Bridson and Haefliger (see Proposition 8.19 on p. 140 there).\n\nLet formula_1 be a group acting by isometries on a proper length space formula_2 such that the action is properly discontinuous and cocompact.\n\nThen the group formula_1 is finitely generated and for every finite generating set formula_7 of formula_1 and every point formula_9\nthe orbit map\nis a quasi-isometry.\n\nHere formula_11 is the word metric on formula_1 corresponding to formula_7.\n\nIn many sources the Švarc–Milnor lemma is stated under a slightly more restrictive assumption that the space formula_2 be a geodesic metric space (rather that a length space), and most applications concern this context.\n\nSometimes a properly discontinuous cocompact isometric action of a group formula_1 on a proper geodesic metric space formula_2 is called a \"geometric\" action.\n\nRecall that a metric formula_17 space is \"proper\" if every closed ball in formula_2 is compact.\n\nAn action of formula_1 on formula_17 is \"properly discontinuous\" if for every compact formula_21 the set\nis finite.\n\nThe action of formula_1 on formula_17 is \"cocompact\" if the quotient space formula_25, equipped with the quotient topology, is compact.\nUnder the other assumptions of the Švarc–Milnor lemma, the cocompactness condition is equivalent to the existence of a closed ball formula_26 in formula_2 such that\n\nFor Examples 1 through 5 below see pp. 89–90 in the book of de la Harpe.\nExample 6 is the starting point of the part of the paper of Richard Schwartz.\n\n1. For every formula_29 the group formula_30 is quasi-isometric to the Euclidean space formula_31.\n\n2. If formula_32 is a closed connected oriented surface of negative Euler characteristic then the fundamental group formula_33 is quasi-isometric to the hyperbolic plane formula_34.\n\n3. If formula_35 is a closed connected smooth manifold with a smooth Riemannian metric formula_36 then formula_37 is quasi-isometric to formula_38, where formula_39 is the universal cover of formula_40, where formula_41 is the pull-back of formula_42 to formula_39, and where formula_44 is the path metric on formula_39 defined by the Riemannian metric formula_41.\n\n4. If formula_1 is a connected finite-dimensional Lie group equipped with a left-invariant Riemannian metric and the corresponding path metric, and if formula_48 is a uniform lattice then formula_49 is quasi-isometric to formula_1.\n\n5. If formula_40 is a closed hyperbolic 3-manifold, then formula_37 is quasi-isometric to formula_53.\n\n6. If formula_40 is a complete finite volume hyperbolic 3-manifold with cusps, then formula_55 is quasi-isometric to formula_56, where formula_57 is a certain formula_49-invariant collection of horoballs, and where formula_59 is equipped with the induced path metric.\n"}
