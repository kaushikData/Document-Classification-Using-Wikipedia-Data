{"id": "43181502", "url": "https://en.wikipedia.org/wiki?curid=43181502", "title": "100 prisoners problem", "text": "100 prisoners problem\n\nThe 100 prisoners problem is a mathematical problem in probability theory and combinatorics. In this problem, 100 numbered prisoners must find their own numbers in one of 100 drawers in order to survive. The rules state that each prisoner may open only 50 drawers and cannot communicate with other prisoners. At first glance, the situation appears hopeless, but a clever strategy offers the prisoners a realistic chance of survival. Danish computer scientist Peter Bro Miltersen first proposed the problem in 2003.\n\nThe 100 prisoners problem has different renditions in the literature. The following version is by Philippe Flajolet and Robert Sedgewick:\n\nIf every prisoner selects 50 drawers at random, the probability that a single prisoner finds his number is 50%. Therefore, the probability that all prisoners find their numbers is the product of the single probabilities, which is () ≈ , a vanishingly small number. The situation appears hopeless.\n\nSurprisingly, there is a strategy that provides a survival probability of more than 30%. The key to success is that the prisoners do not have to decide beforehand which drawers to open. Each prisoner can use the information gained from the contents of every drawer he already opened to help decide which one to open next. Another important observation is that this way the success of one prisoner is not independent of the success of the other prisoners, because they all depend on the way the numbers are distributed.\n\nTo describe the strategy, not only the prisoners, but also the drawers are numbered from 1 to 100, for example row by row starting with the top left drawer. The strategy is now as follows:\n\n\nBy starting with his own number, the prisoner guarantees he is on a sequence of boxes eventually containing his number. The only question is whether this sequence is longer than 50 boxes.\n\nThe reason this is a promising strategy is illustrated with the following example using 8 prisoners and drawers, whereby each prisoner may open 4 drawers. The prison director has distributed the prisoners' numbers into the drawers in the following fashion:\n\nThe prisoners now act as follows:\n\nIn this case, all prisoners find their numbers. This is, however, not always the case. For example, the small change to the numbers of swapping drawers 5 and 8 would cause prisoner 1 to fail after opening 1, 7, 5, and 2 (and not finding his own number):\n\nAnd in the following arrangement, prisoner 1 opens drawers 1, 3, 7, and 4, at which point he has to stop unsuccessfully:\n\nIndeed, all prisoners except 6 (who succeeds directly) fail.\n\nThe prison director's assignment of prisoner numbers to drawers can mathematically be described as a permutation of the numbers 1 to 100. Such a permutation is a one-to-one mapping of the set of natural numbers from 1 to 100 to itself. A sequence of numbers which after repeated application of the permutation returns to the first number is called a cycle of the permutation. Every permutation can be decomposed into disjoint cycles, that is, cycles which have no common elements. The permutation of the first example above can be written in cycle notation as\n\nand thus consists of two cycles of length 3 and one cycle of length 2. The permutation of the second example is accordingly\n\nand consists of a cycle of length 7 and a cycle of length 1. The cycle notation is not unique since a cycle of length formula_3 can be written in formula_3 different ways depending on the starting number of the cycle. During the opening the drawers in the above strategy, each prisoner follows a single cycle which always ends with his own number. In the case of eight prisoners, this cycle-following strategy is successful if and only if the length of the longest cycle of the permutation is at most 4. If a permutation contains a cycle of length 5 or more, all prisoners whose numbers lie in such a cycle do not reach their own number after four steps.\n\nIn the initial problem, the 100 prisoners are successful if the longest cycle of the permutation has a length of at most 50. Their survival probability is therefore equal to the probability that a random permutation of the numbers 1 to 100 contains no cycle of length greater than 50. This probability is determined in the following.\n\nA permutation of the numbers 1 to 100 can contain at most one cycle of length formula_5. There are exactly formula_6 ways to select the numbers of such a cycle (see combination). Within this cycle, these numbers can be arranged in formula_7 ways since there are formula_8 permutations to represent distinct cycles of length formula_3 because of cyclic symmetry. The remaining numbers can be arranged in formula_10 ways. Therefore, the number of permutations of the numbers 1 to 100 with a cycle of length formula_5 is equal to\n\nThe probability, that a (uniformly distributed) random permutation contains no cycle of length greater than 50 is calculated with the formula for single events and the formula for complementary events thus given by\n\nwhere formula_14 is the formula_15-th harmonic number. Therefore, using the cycle-following strategy the prisoners survive in a surprising 31% of cases.\n\nIf formula_16 instead of 100 prisoners are considered, where formula_15 an arbitrary natural number, the prisoners' survival probability with the cycle-following strategy is given by\n\nWith the Euler–Mascheroni constant formula_19, for formula_20\n\nholds, which results in an asymptotic survival probability of\n\nSince the sequence of probabilities is monotonically decreasing, the prisoners survive with the cycle-following strategy in more than 30% of cases independently of the number of prisoners.\n\nIn 2006, Eugene Curtin and Max Warshauer gave a proof for the optimality of the cycle-following strategy. The proof is based on an equivalence to a related problem in which all prisoners are allowed to be present in the room and observe the opening of the drawers. Mathematically, this equivalence is based on Foata's transition lemma, a one-to-one correspondence of the (canonical) cycle notation and the one-line notation of permutations. In the second problem, the survival probability is independent of the chosen strategy and equal to the survival probability in the original problem with the cycle-following strategy. Since an arbitrary strategy for the original problem can also be applied to the second problem, but cannot attain a higher survival probability there, the cycle-following strategy has to be optimal.\n\nThe 100 prisoners problem was first considered in 2003 by Danish computer scientist Peter Bro Miltersen who published it with Anna Gál in the proceedings of the \"30. International Colloquium on Automata, Languages and Programming\" (ICALP). In their version, player A (the prison director) randomly colors strips of paper with the names of the players of team B (the prisoners) in red or blue and puts each strip into a different box. Some of the boxes may be empty (see below). Every player of team B must guess his color correctly after opening half of the boxes for their team to win. Initially, Milterson assumed that the winning probability quickly tends to zero with increasing number of players. Sven Skyum, a colleague of Miltersen at Aarhus University, however brought his attention to the cycle-following strategy for the a case of this problem when there is no empty boxes. To find this strategy was left open as an exercise in the publication. The paper was honored with the best paper award.\n\nIn spring 2004, the problem appeared in Joe Buhler and Elwyn Berlekamp's puzzle column of the quarterly \"The Emissary\" of the Mathematical Sciences Research Institute. Thereby, the authors replaced boxes by ROMs and colored strips of paper by signed numbers. The authors noted that the winning probability can be increased also in the case where the team members don't find their own numbers. If the given answer is the product of all the signs found and if the length of the longest cycle is half the (even) number of players plus one, then the team members in this cycle either all guess wrong or all guess right. Even if this extension of the strategy offers a visible improvement for a small number of players, it becomes negligible when the number of players becomes large.\n\nIn the following years, the problem entered the mathematical literature, where it was shaped in further different ways, for example with cards on a table or wallets in lockers (\"locker puzzle\"). In the form of a prisoner problem it was posed in 2006 by Christoph Pöppe in the journal \"Spektrum der Wissenschaft\" and by Peter Winkler in the \"College Mathematics Journal\". With slight alterations this form was adopted by Philippe Flajolet, Robert Sedgewick and Richard P. Stanley in their textbooks on combinatorics.\n\nAt first, Gál and Miltersen considered in their paper the case that the number of boxes is twice the number of team members while half of the boxes are empty. This is a more difficult problem since empty boxes lead nowhere and thus the cycle-following strategy cannot be applied. It is an open problem if in this case the winning probability tends to zero with growing number of team members.\n\nIn 2005, Navin Goyal and Michael Saks developed a strategy for team B based on the cycle-following strategy for a more general problem in which the fraction of empty boxes as well as the fraction of boxes each team member is allowed to open are variable. The winning probability still tends to zero in this case, but slower than suggested by Gál and Miltersen. If the number of team members and the fraction of boxes which are opened is fixed, the winning probability stays strictly larger than zero when more empty boxes are added.\n\nDavid Avis and Anne Broadbent considered in 2009 a quantum theoretical variant in which team B wins with certainty.\n\nIn case the prison director does not have to distribute the numbers into the drawers randomly, he can foil the prisoners' strategy if he knows the numbering of the drawers. To this end, he just has to ensure that his assignment of prisoners' numbers to drawers constitutes a permutation with a cycle of length larger than 50. The prisoners in turn can counter this by choosing their own numbering of the drawers randomly.\n\nIn the case that one prisoner may enter the room first, inspect all boxes, and then switch the content of two boxes, all prisoners will survive with probability 1. This is so since any cycle of length larger than 50 can be broken, so that it can be guaranteed that there is a cycle of length at most 50.\n\nIn 2009, Adam S. Landsberg proposed the following simpler variant of the 100 prisoners problem which is based on the well-known Monty Hall problem:\n\nIf the players select their doors randomly, the winning probability is only (about 44%). The optimal strategy is, however, as follows:\n\n\nIn the six possible distributions of car, keys and goat behind the three doors, the players open the following doors (in the green cases, the player was successful):\n\nThe success of the strategy is based on building a correlation between the successes and failures of the two players. Here, the winning probability is , which is optimal since the first player cannot have a higher winning probability than that. In a further variant, three prizes are hidden behind the three doors and three players have to independently find their assigned prizes with two tries. In this case the winning probability is also when the optimal strategy is employed.\n\n\n\n"}
{"id": "11669836", "url": "https://en.wikipedia.org/wiki?curid=11669836", "title": "620 (number)", "text": "620 (number)\n\n620 is the natural number following 619 and preceding 621.\n\n"}
{"id": "22929977", "url": "https://en.wikipedia.org/wiki?curid=22929977", "title": "Alan J. Hoffman", "text": "Alan J. Hoffman\n\nAlan Jerome Hoffman (born May 30, 1924) is an American mathematician and IBM Fellow emeritus, T. J. Watson Research Center, IBM, in Yorktown Heights, New York. He is the founding editor of the journal \"Linear Algebra and its Applications\", and holds several patents. He has contributed to combinatorial optimization and the eigenvalue theory of graphs. Hoffman and Robert Singleton constructed the Hoffman–Singleton graph, which is the unique Moore graph of degree 7 and diameter 2.\n\nAlan Hoffman is a recipient of many awards.\n\n\n"}
{"id": "34165119", "url": "https://en.wikipedia.org/wiki?curid=34165119", "title": "Alexander Nabutovsky", "text": "Alexander Nabutovsky\n\nAlexander Nabutovsky is a Canadian mathematician specializing in differential geometry, geometric calculus of variations and quantitative aspects of topology of manifolds. He is a professor at the University of Toronto Department of Mathematics.\n\nNabutovsky earned a Ph.D. degree from the Weizmann Institute of Science\nin 1993; his advisor was Shmuel Kiro.\n\nHe was an invited speaker on \"Geometry\" at International Congress of Mathematicians, 2010 in Hyderabad.\n"}
{"id": "15202398", "url": "https://en.wikipedia.org/wiki?curid=15202398", "title": "Anisotropy energy", "text": "Anisotropy energy\n\nAnisotropic energy is energy that is directionally specific. The word anisotropy means \"directionally dependent\", hence the definition. The most common form of anisotropic energy is magnetocrystalline anisotropy, which is commonly studied in ferrimagnets. In ferrimagnets, there are islands or domains of atoms that are all coordinated in a certain direction; this spontaneous positioning is often called the \"easy\" direction, indicating that this is the lowest energy state for these atoms. In order to study magnetocrystalline anisotropy, energy (usually in the form of an electric current) is applied to the domain, which causes the crystals to deflect from the \"easy\" to \"hard\" positions. The energy required to do this is defined as the anisotropic energy. The easy and hard alignments and their relative energies are due to the interaction between spin magnetic moment of each atom and the crystal lattice of the compound being studied. One of the many projects currently researching this phenomenon is directed by Stefan Krause and Roland Wiesendanger of the University of Hamburg. Using spin-polarized scanning tunnelling microscopes they are observing the effect upon the macrospin states of domains by passing a spin-polarized current through the atoms, and observing their alignment and how long they maintain their spin state.\n\n\n"}
{"id": "1349294", "url": "https://en.wikipedia.org/wiki?curid=1349294", "title": "Bell series", "text": "Bell series\n\nIn mathematics, the Bell series is a formal power series used to study properties of arithmetical functions. Bell series were introduced and developed by Eric Temple Bell.\n\nGiven an arithmetic function formula_1 and a prime formula_2, define the formal power series formula_3, called the Bell series of formula_1 modulo formula_2 as:\n\nTwo multiplicative functions can be shown to be identical if all of their Bell series are equal; this is sometimes called the \"uniqueness theorem\": given multiplicative functions formula_1 and formula_8, one has formula_9 if and only if:\n\nTwo series may be multiplied (sometimes called the \"multiplication theorem\"): For any two arithmetic functions formula_1 and formula_8, let formula_14 be their Dirichlet convolution. Then for every prime formula_2, one has: \n\nIn particular, this makes it trivial to find the Bell series of a Dirichlet inverse.\n\nIf formula_1 is completely multiplicative, then formally: \n\nThe following is a table of the Bell series of well-known arithmetic functions.\n\n\n"}
{"id": "41048991", "url": "https://en.wikipedia.org/wiki?curid=41048991", "title": "Bloch's formula", "text": "Bloch's formula\n\nIn algebraic K-theory, a branch of mathematics, Bloch's formula, introduced by Spencer Bloch for formula_1, states that the Chow group of a smooth variety \"X\" over a field is isomorphic to the cohomology of \"X\" with coefficients in the K-theory of the structure sheaf formula_2; that is,\nwhere the right-hand side is the sheaf cohomology; formula_4 is the sheaf associated to the presheaf formula_5, \"U\" Zariski open subsets of \"X\". The general case is due to Quillen. For \"q\" = 1, one recovers formula_6. (see also Picard group.)\n\nThe formula for the mixed characteristic is still open.\n\n"}
{"id": "40892755", "url": "https://en.wikipedia.org/wiki?curid=40892755", "title": "Canonical correspondence analysis", "text": "Canonical correspondence analysis\n\nIn applied statistics, canonical correspondence analysis (CCA) is a multivariate constrained ordination technique that extracts major gradients among combinations of explanatory variables in a dataset. The requirements of a CCA are that the samples are random and independent. Also, the data are categorical and that the independent variables are consistent within the sample site and error-free.\n\n"}
{"id": "491964", "url": "https://en.wikipedia.org/wiki?curid=491964", "title": "Cat's cradle", "text": "Cat's cradle\n\nCat's cradle is one of the oldest games in recorded human history, and involves creating various string figures, either individually or by passing a loop of string back and forth between two or more players. The true origin of the name is debated, though the first known reference is in \"The light of nature pursued\" by Abraham Tucker in 1768. The type of string, the specific figures, their order, and the names of the figures vary. Independent versions of this game have been found in indigenous cultures throughout the world, including in Africa, Eastern Asia, the Pacific Islands, Australia, the Americas, and the Arctic.\n\nThe game consists of two or more players making a sequence of string figures, each altering the figure made by the previous player. The game begins with one player making the eponymous figure \"Cat's Cradle\" (above). After each figure, the next player manipulates that figure and removes the string figure from the hands of the previous player with one of a few simple motions and tightens the loop to create another figure, for example, \"Diamonds\". \"Diamonds\" might then lead to \"Candles\", for example, and then \"Manger\"—an inverted \"Cat's Cradle\"—and so on. Most of the core figures allow a choice between two or more subsequent figures: for example, \"Fish in a Dish\" can become \"Cat's Eye\" or \"Manger\". The game ends when a player makes a mistake or creates a dead-end figure, such as \"Two Crowns\", which cannot be turned into anything else.\n\nThe game also may be played solo, as is done in Japan.\n\nThe origin of the name \"cat's cradle\" is debated but the first known reference is in \"The light of nature pursued\" by Abraham Tucker in 1768. \"An ingenious play they call cat's cradle; one ties the two ends of a packthread together, and then winds it about his fingers, another with both hands takes it off perhaps in the shape of a gridiron, the first takes it from him again in another form, and so on alternately changing the packthread into a multitude of figures whose names I forget, it being so many years since I played at it myself.\"The name may have come from a corruption of cratch-cradle, or manger cradle (although this derivation is disputed by the OED). The connection between the two words, \"cratches\" and \"cradle\", may come from the Christian story of the birth of Jesus, in which a manger is used as a cradle.\n\nIn an 1858 \"Punch\" cartoon it is referred to as \"scratch cradle\", a name supported by Brewer's 1898 \"Dictionary\". As \"Cat's cradle\" often is used to refer to string figures and games in general, Jayne uses \"Real Cat's-Cradle\" to refer to the specific game.\n\nDifferent cultures have different names for the game, and often different names for the individual figures. The French word for manger is \"crèche\", and cattle feed racks are still known as \"cratches\". In Russia the whole game is called simply, \"the game of string\", and the \"diamonds\" pattern is called \"carpet\", with other pattern names such as \"field\", \"fish\", and \"sawhorse\" for the other figures—a \"cat\" isn't mentioned. The game may have originated in China. In China the game is called \"fan sheng\" (), or catch cradle. In some regions of the U.S., this game also is known as \"Jack in the Pulpit\".\n\nGeneva Hultenius, Maryann DiVona, and Rita Divona completed 21,200 changes of cat's cradles in 21 hours in Chula Vista, California between August 17–18, 1974. The \"Guinness Book of World Records\" reported it as a world record in the 1975 and 1976 editions.\n\nJane Muir and Robyn Lawrick completed 22,700 changes of cat's cradles in 21 hours at Calgary Market Mall, Alberta, Canada on August 25, 1976.\n\n\n"}
{"id": "43063214", "url": "https://en.wikipedia.org/wiki?curid=43063214", "title": "Communications Machine", "text": "Communications Machine\n\nThe \"Communications Machine\", or \"CM\", is a mechanical device used by the United States Navy for the most of the 1920s. It used a sliding alphabet system. It was developed by Agnes Meyer Driscoll and William Gresham. In 1937 the United States Congress recognized the achievement of these two by awarding them both $15,000.\n"}
{"id": "622966", "url": "https://en.wikipedia.org/wiki?curid=622966", "title": "Cousin problems", "text": "Cousin problems\n\nIn mathematics, the Cousin problems are two questions in several complex variables, concerning the existence of meromorphic functions that are specified in terms of local data. They were introduced in special cases by Pierre Cousin in 1895. They are now posed, and solved, for any complex manifold \"M\", in terms of conditions on \"M\".\n\nFor both problems, an open cover of \"M\" by sets \"U\" is given, along with a meromorphic function \"f\" on each \"U\".\n\nThe first Cousin problem or additive Cousin problem assumes that each difference\n\nis a holomorphic function, where it is defined. It asks for a meromorphic function \"f\" on \"M\" such that\n\nis \"holomorphic\" on \"U\"; in other words, that \"f\" shares the singular behaviour of the given local function. The given condition on the formula_1 is evidently \"necessary\" for this; so the problem amounts to asking if it is sufficient. The case of one variable is the Mittag-Leffler theorem on prescribing poles, when \"M\" is an open subset of the complex plane. Riemann surface theory shows that some restriction on \"M\" will be required. The problem can always be solved on a Stein manifold.\n\nThe first Cousin problem may be understood in terms of sheaf cohomology as follows. Let K be the sheaf of meromorphic functions and O the sheaf of holomorphic functions on \"M\". A global section formula_4 of K passes to a global section formula_5 of the quotient sheaf K/O. The converse question is the first Cousin problem: given a global section of K/O, is there a global section of K from which it arises? The problem is thus to characterize the image of the map\n\nBy the long exact cohomology sequence,\n\nis exact, and so the first Cousin problem is always solvable provided that the first cohomology group \"H\"(\"M\",O) vanishes. In particular, by Cartan's theorem B, the Cousin problem is always solvable if \"M\" is a Stein manifold.\n\nThe second Cousin problem or multiplicative Cousin problem assumes that each ratio\n\nis a non-vanishing holomorphic function, where it is defined. It asks for a meromorphic function \"f\" on \"M\" such that\n\nis holomorphic and non-vanishing. The second Cousin problem is a multi-dimensional generalization of the Weierstrass theorem on the existence of a holomorphic function of one variable with prescribed zeros.\n\nThe attack on this problem by means of taking logarithms, to reduce it to the additive problem, meets an obstruction in the form of the first Chern class (see also exponential sheaf sequence). In terms of sheaf theory, let formula_10 be the sheaf of holomorphic functions that vanish nowhere, and formula_11 the sheaf of meromorphic functions that are not identically zero. These are both then sheaves of abelian groups, and the quotient sheaf formula_12 is well-defined. The multiplicative Cousin problem then seeks to identify the image of quotient map formula_13\n\nThe long exact sheaf cohomology sequence associated to the quotient is\n\nso the second Cousin problem is solvable in all cases provided that formula_16 The quotient sheaf formula_12 is the sheaf of germs of Cartier divisors on \"M\". The question of whether every global section is generated by a meromorphic function is thus equivalent to determining whether every line bundle on \"M\" is trivial.\n\nThe cohomology group formula_18 for the multiplicative structure on formula_10 can be compared with the cohomology group formula_20 with its additive structure by taking a logarithm. That is, there is an exact sequence of sheaves\n\nwhere the leftmost sheaf is the locally constant sheaf with fiber formula_22. The obstruction to defining a logarithm at the level of \"H\" is in formula_23, from the long exact cohomology sequence\n\nWhen \"M\" is a Stein manifold, the middle arrow is an isomorphism because formula_25 for formula_26 so that a necessary and sufficient condition in that case for the second Cousin problem to be always solvable is that formula_27\n\n\n"}
{"id": "18692872", "url": "https://en.wikipedia.org/wiki?curid=18692872", "title": "Decidable sublanguages of set theory", "text": "Decidable sublanguages of set theory\n\nIn mathematical logic, various sublanguages of set theory are decidable. These include:\n"}
{"id": "695917", "url": "https://en.wikipedia.org/wiki?curid=695917", "title": "Dirac adjoint", "text": "Dirac adjoint\n\nIn quantum field theory, the Dirac adjoint defines the dual operation of a Dirac spinor. The Dirac adjoint is motivated by the need to form well-behaved, measurable quantities out of Dirac spinors. Since the usual Hermitian adjoint lacks the Lorentz symmetry of the system, the Dirac adjoint must be used instead.\n\nPossibly to avoid confusion with the usual Hermitian adjoint, some textbooks do not provide a name for the Dirac adjoint but simply call it \"ψ-bar\".\n\nLet ψ be a Dirac spinor. Then its Dirac adjoint is defined as\n\nwhere ψ denotes the Hermitian adjoint of the spinor ψ and γ is the time-like gamma matrix.\n\nThe Lorentz group of special relativity is not compact, therefore representations of Lorentz transformations in the Dirac spinor space are not unitary. That is, in general,\n\nwhere λ is the corresponding Lorentz transformation that maps spinors:\n\nThe Hermitian adjoint of spinors transforms according to\n\nTherefore, using only the Hermitian adjoint, one finds that is not a Lorentz scalar and is not even Hermitian.\n\nUsing the definition, one finds that the Dirac adjoint of spinors transforms according to\n\nUsing the identity , the transformation reduces to\n\nwhich possesses the required Lorentz symmetry for and .\n\nUsing the Dirac adjoint, the probability four-current J for a spin-1/2 particle field can be written as\n\nwhere c is the speed of light and the components of J represent the probability density ρ and the probability 3-current j:\n\nTaking and using the relation for gamma matrices\n\nthe probability density becomes\n\n\n"}
{"id": "245978", "url": "https://en.wikipedia.org/wiki?curid=245978", "title": "Elimination theory", "text": "Elimination theory\n\nIn commutative algebra and algebraic geometry, elimination theory is the classical name for algorithmic approaches to eliminating some variables between polynomials of several variables, in order to solve systems of polynomial equations.\n\nThe classical elimination theory culminated with the work of Macaulay on multivariate resultants, and its description in chapter \"Elimination theory\" of the first editions (1930) of van der Waerden's \"Moderne Algebra\". After that, elimination theory was ignored by most algebraic geometers for almost thirty years, until the introduction of new methods for solving polynomial equations, such as Gröbner bases, which were needed for computer algebra.\n\nThe field of elimination theory was motivated by the need of methods for solving systems of polynomial equations.\n\nOne of the first results was Bézout's theorem, which bounds the number of solutions (in the case of two polynomials in two variables at Bézout time).\n\nExcept for Bézout's theorem, the general approach was to \"eliminate\" variables for reducing the problem to a single equation in one variable.\n\nThe case of linear equations was completely solved by Gaussian elimination, where the older method of Cramer's rule does not proceeds by elimination, and works only when the number of equations equals the number of variables. During 19th century, this has been extended to linear Diophantine equations and abelian group with Hermite normal form and Smith normal form.\n\nBefore 20th century, different types of \"eliminants\" were introduced, including \"resultants\", and various kinds of \"discriminants\". In general, these eliminants are also invariant, and are also fundamental in invariant theory.\n\nAll these concepts are effective, in the sense that their definition include a method of computation. Around 1890, David Hilbert introduced non-effective methods, and this was seen as a revolution, which led most algebraic-geometers of the first half of 20th century to try to \"eliminate elimination\". Nevertheless Hilbert's Nullstellensatz, may be considered to belong to elimination theory, as it asserts that a system of polynomial equations does not has any solution if and only one may eliminate all unknowns for getting 1.\n\nElimination theory culminated with the work of Kronecker, and, finally, F.S. Macaulay, who introduced multivariate resultants and U-resultants, providing complete elimination methods for systems of polynomial equations, which have been described in chapter \"Elimination theory\" of the first editions (1930) of van der Waerden's \"Moderne Algebra\".\n\nAfter that, elimination theory has been considered as old fashioned, removed from next editions of \"Moderne Algebra\", and generally ignored, until the introduction of computers, and more specifically of computer algebra, which set the problem of designing elimination algorithms that are sufficiently efficient for being implemented. The main methods for this renewing of elimination theory are Gröbner bases and cylindrical algebraic decomposition, which were introduced around 1970.\n\nThere is also a logical facet to elimination theory, as seen in the Boolean satisfiability problem. In the worst case, it is presumably hard to eliminate variables computationally. \"Quantifier elimination\" is a term used in mathematical logic to explain that, in some theories, every formula is equivalent to a formula without quantifier. This is the case of the theory of polynomials over an algebraically closed field, where elimination theory may be viewed as the theory of the methods to make quantifier elimination algorithmically effective. Quantifier elimination over the reals is another example, which is fundamental in computational algebraic geometry.\n\n\n"}
{"id": "20388747", "url": "https://en.wikipedia.org/wiki?curid=20388747", "title": "Epps effect", "text": "Epps effect\n\nIn econometrics and time series analysis, the Epps effect, named after T. W. Epps, is the phenomenon that the empirical correlation between the returns of two different stocks decreases with the length of the interval for which the price changes are measured. The phenomenon is caused by non-synchronous/asynchronous trading\n"}
{"id": "42482272", "url": "https://en.wikipedia.org/wiki?curid=42482272", "title": "Equivariant bundle", "text": "Equivariant bundle\n\nIn differential geometry, given a compact Lie group \"G\", an equivariant bundle is a fiber bundle such that the total space and the base spaces are both \"G\"-spaces and the projection map formula_1 between them is equivariant: formula_2 with some extra requirement depending on a typical fiber.\n\nFor example, an equivariant vector bundle is an equivariant bundle.\n\n"}
{"id": "4370229", "url": "https://en.wikipedia.org/wiki?curid=4370229", "title": "Fierz identity", "text": "Fierz identity\n\nIn theoretical physics, a Fierz identity is an identity that allows one to rewrite \"bilinears of the product\" of two spinors as a linear combination of \"products of the bilinears\" of the individual spinors. It is named after Swiss physicist Markus Fierz.\n\nThere is a version of the Fierz identities for Dirac spinors and there is another version for Weyl spinors. And there are versions for other dimensions besides 3+1 dimensions.\n\nSpinor bilinears can be thought of as elements of a Clifford Algebra. Then the Fierz identity is the concrete realization of the relation to the exterior algebra.\nThe identities for a generic scalar written as the contraction of two Dirac bilinears of the same type can be written with coefficients according to the following table.\n\nThe signs in the table correspond to the case of commuting spinors, otherwise all coefficients change signs. For example, under the assumption of commuting bispinors, the V × V product can be expanded as,\n\nSimplifications arise when the considered spinors are chiral or Majorana spinors as some term in the expansion can be vanishing.\n\nA derivation of identities for rewriting any scalar contraction of Dirac bilinears can be found in 29.3.4 of \nSee also appendix B.1.2 in \n"}
{"id": "6195096", "url": "https://en.wikipedia.org/wiki?curid=6195096", "title": "Fleming–Viot process", "text": "Fleming–Viot process\n\nIn probability theory, a Fleming–Viot process (F–V process) is a member of a particular subset of probability measure-valued Markov processes on compact metric spaces, as defined in the 1979 paper by Wendell Helms Fleming and Michel Viot. Such processes are martingales and diffusions.\n\nThe Fleming–Viot processes have proved to be important to the development of a mathematical basis for the theories behind allele drift.\nThey are generalisations of the Wright–Fisher process and arise as infinite population limits of suitably rescaled variants of Moran processes.\n\n\n"}
{"id": "10766404", "url": "https://en.wikipedia.org/wiki?curid=10766404", "title": "Generalised circle", "text": "Generalised circle\n\nA generalized circle, also referred to as a \"cline\" or \"circline\", is a straight line or a circle. The concept is mainly used in inversive geometry, because straight lines and circles have very similar properties in that geometry and are best treated together.\n\nInversive plane geometry is formulated on the plane extended by one point at infinity. A straight line is then thought of as one of the circles that passes through the asymptotic point at infinity. \nThe fundamental transformations in inversive geometry, the \"inversions\", have the property that they map generalized circles to generalized circles. Möbius transformations, which are compositions of inversions, inherit that property. These transformations do not necessarily map lines to lines and circles to circles: they can mix the two. \n\nInversions come in two kinds: inversions at circles and reflections at lines. Since the two have very similar properties, we combine them and talk about inversions at generalized circles.\n\nGiven any three distinct points in the extended plane, there exists precisely one generalized circle that passes through the three points.\nThe extended plane can be identified with the sphere using a stereographic projection. The point at infinity then becomes an ordinary point on the sphere, and all generalized circles become circles on the sphere.\n\nThe extended plane of inversive geometry can be identified with the extended complex plane, so that equations of complex numbers can be used to describe lines, circles and inversions.\n\nA circle Γ is the set of points \"z\" in a plane that lie at radius \"r\" from a center point \"γ\". \n\nUsing the complex plane, we can treat \"γ\" as a complex number and circle Γ as a set of complex numbers.\n\nUsing the property that a complex number multiplied by its conjugate gives us the square of the modulus of the number, and that its modulus is its Euclidean distance from the origin, we can express the equation for Γ as follows:\n\nWe can multiply this by a real constant \"A\" to get an equation of the form\n\nwhere \"A\" and \"D\" are real, and \"B\" and \"C\" are complex conjugates. Reversing the steps, we see that in order for this to be a circle, the radius squared must be equal to \"BC\"/\"A\" − \"D\"/\"A\" > 0. So the above equation defines a generalized circle whenever \"AD < BC\". Note that when \"A\" is zero, this equation defines a straight line.\n\nIt is now easy to see that the transformation \"w\" = 1/\"z\" maps generalized circles to generalized circles:\n\nWe see that the lines through the origin (\"A\" = \"D\" = 0) are mapped to the lines through the origin, the lines not passing through the origin (\"A\" = 0; \"D\" ≠ 0) to circles passing through the origin, circles passing through the origin (\"A\" ≠ 0; \"D\" = 0) to the lines not passing through the origin, and circles not passing through the origin (\"A\" ≠ 0; \"D\" ≠ 0) to circles not passing through the origin.\n\nThe data defining the equation of a generalized circle \ncan be usefully put into the form of an invertible hermitian matrix\n\nTwo such invertible hermitian matrices specify the same generalized circle if and only if they differ by a real multiple.\n\nTo transform a generalized circle described by formula_11 by the Möbius transformation formula_12, take the inverse formula_13 of the transformation formula_12 and do\n\n"}
{"id": "30562", "url": "https://en.wikipedia.org/wiki?curid=30562", "title": "Glossary of topology", "text": "Glossary of topology\n\nThis is a glossary of some terms used in the branch of mathematics known as topology. Although there is no absolute distinction between different areas of topology, the focus here is on general topology. The following definitions are also fundamental to algebraic topology, differential topology and geometric topology.\n\nAll spaces in this glossary are assumed to be topological spaces unless stated otherwise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere are some facts about submaximality as a property of topological spaces:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "504109", "url": "https://en.wikipedia.org/wiki?curid=504109", "title": "Hausdorff measure", "text": "Hausdorff measure\n\nIn mathematics a Hausdorff measure is a type of outer measure, named for Felix Hausdorff, that assigns a number in [0,∞] to each set in R or, more generally, in any metric space. The zero-dimensional Hausdorff measure is the number of points in the set (if the set is finite) or ∞ if the set is infinite. The one-dimensional Hausdorff measure of a simple curve in R is equal to the length of the curve. Likewise, the two dimensional Hausdorff measure of a measurable subset of R is proportional to the area of the set. Thus, the concept of the Hausdorff measure generalizes counting, length, and area. It also generalizes volume. In fact, there are \"d\"-dimensional Hausdorff measures for any \"d\" ≥ 0, which is not necessarily an integer. These measures are fundamental in geometric measure theory. They appear naturally in harmonic analysis or potential theory.\n\nLet formula_1 be a metric space. For any subset formula_2, let formula_3 denote its diameter, that is\n\nLet \"formula_5\" be any subset of \"formula_6\", and formula_7 a real number. Define\n\nNote that formula_12 is monotone decreasing in formula_13 since the larger formula_13 is, the more collections of sets are permitted, making the infimum smaller. Thus, the limit formula_15 exists but may be infinite. Let\n\nIt can be seen that formula_17 is an outer measure (more precisely, it is a metric outer measure). By general theory, its restriction to the σ-field of Carathéodory-measurable sets is a measure. It is called the formula_18-dimensional Hausdorff measure of formula_5. Due to the metric outer measure property, all Borel subsets of formula_6 are formula_21 measurable.\n\nIn the above definition the sets in the covering are arbitrary. However, they may be taken to be open or closed, and will yield the same measure, although the approximations formula_12 may be different . If \"formula_6\" is a normed space the sets may be taken to be convex. However, the restriction of the covering families to balls gives a different, yet comparable, measure.\n\nNote that if \"d\" is a positive integer, the \"d\" dimensional Hausdorff measure of R is a rescaling of usual \"d\"-dimensional Lebesgue measure formula_24 which is normalized so that the Lebesgue measure of the unit cube [0,1] is 1. In fact, for any Borel set \"E\",\nwhere α is the volume of the unit \"d\"-ball; it can be expressed using Euler's gamma function\n\nRemark. Some authors adopt a definition of Hausdorff measure slightly different from the one chosen here, the difference being that it is normalized in such a way that Hausdorff \"d\"-dimensional measure in the case of Euclidean space coincides exactly with Lebesgue measure.\n\nOne of several possible equivalent definitions of the Hausdorff dimension is\n\nwhere we take\n\nIn geometric measure theory and related fields, the Minkowski content is often used to measure the size of a subset of a metric measure space. For suitable domains in Euclidean space, the two notions of size coincide, up to overall normalizations depending on conventions. More precisely, a subset of formula_29 is said to be \"formula_30\"-rectifiable if it is the image of a bounded set in formula_31 under a Lipschitz function. If formula_32, then the \"formula_30\"-dimensional Minkowski content of a closed \"formula_30\"-rectifiable subset of formula_29 is equal to formula_36 times the \"formula_30\"-dimensional Hausdorff measure .\n\nIn fractal geometry, some fractals with Hausdorff dimension formula_18 have zero or infinite formula_18-dimensional Hausdorff measure. For example, almost surely the image of planar Brownian motion has Hausdorff dimension 2 and its two-dimensional Hausdoff measure is zero. In order to “measure” the “size” of such sets, mathematicians have considered the following variation on the notion of the Hausdorff measure:\n\nThis is the Hausdorff measure of formula_5 with gauge function formula_42, or formula_42-Hausdorff measure. A formula_18-dimensional set formula_5 may satisfy formula_49, but formula_50 with an appropriate formula_51 Examples of gauge functions include formula_52 or formula_53. The former gives almost surely positive and formula_54-finite measure to the Brownian path in formula_29 when formula_56, and the latter when formula_57.\n\n\n\n"}
{"id": "45857", "url": "https://en.wikipedia.org/wiki?curid=45857", "title": "Hurwitz polynomial", "text": "Hurwitz polynomial\n\nIn mathematics, a Hurwitz polynomial, named after Adolf Hurwitz, is a polynomial whose roots (zeros) are located in the left half-plane of the complex plane or on the imaginary axis, that is, the real part of every root is zero or negative. Such a polynomial must have coefficients that are positive real numbers. The term is sometimes restricted to polynomials whose roots have real parts that are strictly negative, excluding the axis (i.e., a Hurwitz stable polynomial).\n\nA polynomial function \"P\"(\"s\") of a complex variable \"s\" is said to be Hurwitz if the following conditions are satisfied:\n\nHurwitz polynomials are important in control systems theory, because they represent the characteristic equations of stable linear systems. Whether a polynomial is Hurwitz can be determined by solving the equation to find the roots, or from the coefficients without solving the equation by the Routh–Hurwitz stability criterion.\n\nA simple example of a Hurwitz polynomial is the following:\n\nThe only real solution is −1, as it factors to\n\nIn general, all second-degree polynomials with positive coefficients are Hurwitz.\nThis follows directly from the quadratic formula:\nwhere, if the determinant \"b^2-4ac\" is less than zero, then the polynomial will have two complex-conjugate solutions with real part \"-b/2a\", which is negative for positive \"a\" and \"b\".\nIf it is equal to zero, there will be two coinciding real solutions at \"-b/2a\". Finally, if the determinant is greater than zero, there will be two real negative solutions,\nbecause <math>\\sqrt{b^2-4ac} for positive \"a\", \"b\" and \"c\".\n\nFor a polynomial to be Hurwitz, it is necessary but not sufficient that all of its coefficients be positive (except for second-degree polynomials, which also doesn't imply sufficiency). A necessary and sufficient condition that a polynomial is Hurwitz is that it passes the Routh–Hurwitz stability criterion. A given polynomial can be efficiently tested to be Hurwitz or not by using the Routh continued fraction expansion technique.\n\nThe properties of Hurwitz polynomials are:\n\n\n"}
{"id": "3699637", "url": "https://en.wikipedia.org/wiki?curid=3699637", "title": "Inductive data type", "text": "Inductive data type\n\nInductive data type may refer to:\n\n\n"}
{"id": "7204363", "url": "https://en.wikipedia.org/wiki?curid=7204363", "title": "Interchange of limiting operations", "text": "Interchange of limiting operations\n\nIn mathematics, the study of interchange of limiting operations is one of the major concerns of mathematical analysis, in that two given limiting operations, say \"L\" and \"M\", cannot be \"assumed\" to give the same result when applied in either order. One of the historical sources for this theory is the study of trigonometric series.\n\nIn symbols, the assumption\n\nwhere the left-hand side means that \"M\" is applied first, then \"L\", and \"vice versa\" on the right-hand side, is not a valid equation between mathematical operators, under all circumstances and for all operands. An algebraist would say that the operations do not commute. The approach taken in analysis is somewhat different. Conclusions that assume limiting operations do 'commute' are called \"formal\". The analyst tries to delineate conditions under which such conclusions are valid; in other words mathematical rigour is established by the specification of some set of sufficient conditions for the formal analysis to hold good. This approach justifies, for example, the notion of uniform convergence. It is relatively rare for such sufficient conditions to be also necessary, so that a sharper piece of analysis may extend the domain of validity of formal results. \n\nProfessionally speaking, therefore, analysts push the envelope of techniques, and expand the meaning of \"well-behaved\" for a given context. G. H. Hardy wrote that \"The problem of deciding whether two given limit operations are commutative is one of the most important in mathematics\". An opinion apparently not in favour of the piece-wise approach, but of leaving analysis at the level of heuristic, was that of Richard Courant.\n\nExamples abound, one of the simplest being that for a double sequence \"a\": it is not necessarily the case that the operations of taking the limits as \"m\" → ∞ and as \"n\" → ∞ can be freely interchanged. For example take \n\nin which taking the limit first with respect to \"n\" gives 0, and with respect to \"m\" gives ∞.\n\nMany of the fundamental results of infinitesimal calculus also fall into this category: the symmetry of partial derivatives, differentiation under the integral sign, and Fubini's theorem deal with the interchange of differentiation and integration operators. One of the major reasons why the Lebesgue integral is used is that theorems exist, such as the dominated convergence theorem, that give conditions under which integration and infinite summation can be interchanged.\n\n"}
{"id": "3735500", "url": "https://en.wikipedia.org/wiki?curid=3735500", "title": "Jacques-Louis Lions", "text": "Jacques-Louis Lions\n\nJacques-Louis Lions (; 3 May 1928 – 17 May 2001) was a French mathematician who made contributions to the theory of partial differential equations and to stochastic control, among other areas. He received the SIAM's John von Neumann Lecture prize in 1986 and numerous other distinctions. Lions is listed as an ISI highly cited researcher.\n\nAfter being part of the French Résistance in 1943 and 1944, J.-L. Lions entered the École Normale Supérieure in 1947.\nHe was a professor of mathematics at the Université of Nancy, the Faculty of Sciences of Paris, and the École polytechnique.\n\nIn 1966 he sent an invitation to Gury Marchuk, the soviet mathematician to visit Paris. This was hand delivered by General De Gaulle during his visit to Akademgorodok in June of that year.\n\nHe joined the prestigious Collège de France as well as the French Academy of Sciences in 1973.\nIn 1979, he was appointed director of the Institut National de la Recherche en Informatique et Automatique (INRIA), where he taught and promoted the use of numerical simulations using finite elements integration. Throughout his career, Lions insisted on the use of mathematics in industry, with a particular involvement in the French space program, as well as in domains such as energy and the environment.\nThis eventually led him to be appointed director of the Centre National d'Etudes Spatiales (CNES) from 1984 to 1992.\n\nLions was elected President of the International Mathematical Union in 1991 and also received the Japan Prize and the Harvey Prize that same year. In 1992, the University of Houston awarded him an honorary doctoral degree. He was elected president of the French Academy of Sciences in 1996 and was also a Foreign Member of the Royal Society (ForMemRS) and numerous other foreign academies.\n\nHe has left a considerable body of work, among this more than 400 scientific articles, 20 volumes of mathematics that were translated into English and Russian, and major contributions to several collective works, including the 4000 pages of the monumental \"Mathematical analysis and numerical methods for science and technology\" (in collaboration with Robert Dautray), as well as the \"Handbook of numerical analysis\" in 7 volumes (with Philippe G. Ciarlet).\n\nHis son Pierre-Louis Lions is also a well-known mathematician who was awarded a Fields Medal in 1994. In fact both Father and Son have also both received recognition in the form of Honorary Doctorates from Heriot-Watt University in 1986 and 1995 respectively.\n\n\n"}
{"id": "42923391", "url": "https://en.wikipedia.org/wiki?curid=42923391", "title": "Kleene's algorithm", "text": "Kleene's algorithm\n\nIn theoretical computer science, in particular in formal language theory, Kleene's algorithm transforms a given deterministic finite automaton (DFA) into a regular expression. \nTogether with other conversion algorithms, it establishes the equivalence of several description formats for regular languages.\n\nAccording to Gross and Yellen (2004), the algorithm can be traced back to Kleene (1956).\n\nThis description follows Hopcroft and Ullman (1979).\nGiven a deterministic finite automaton \"M\" = (\"Q\", Σ, δ, \"q\", \"F\"), with \"Q\" = { \"q\"...,\"q\" } its set of states, the algorithm computes \nHere, \"going through a state\" means entering \"and\" leaving it, so both \"i\" and \"j\" may be higher than \"k\", but no intermediate state may.\nEach set \"R\" is represented by a regular expression; the algorithm computes them step by step for \"k\" = -1, 0, ..., \"n\". Since there is no state numbered higher than \"n\", the regular expression \"R\" represents the set of all strings that take \"M\" from its start state \"q\" to \"q\". If \"F\" = { \"q\"...,\"q\" } is the set of accept states, the regular expression \"R\" | ... | \"R\" represents the language accepted by \"M\".\n\nThe initial regular expressions, for \"k\" = -1, are computed as\n\nAfter that, in each step the expressions \"R\" are computed from the previous ones by\n\nBy induction on \"k\", it can be shown that the length of each expression \"R\" is at most symbols, where \"s\" denotes the number of characters in Σ.\nTherefore, the length of the regular expression representing the language accepted by \"M\" is at most symbols, where \"f\" denotes the number of final states.\n\nThe automaton shown in the picture can be described as \"M\" = (\"Q\", Σ, δ, \"q\", \"F\") with\n\nKleene's algorithm computes the initial regular expressions as\n\nAfter that, the \"R\" are computed from the \"R\" step by step for \"k\" = 0, 1, 2.\nKleene algebra equalities are used to simplify the regular expressions as much as possible.\n\n\n\n\nSince \"q\" is the start state and \"q\" is the only accept state, the regular expression \"R\" denotes the set of all strings accepted by the automaton.\n\n"}
{"id": "1731131", "url": "https://en.wikipedia.org/wiki?curid=1731131", "title": "KnownSafe", "text": "KnownSafe\n\nKnownSafe, Inc. was a cryptographic services company founded in April 2000 by Bruce Perens, Len Sassaman, and Rodney Thayer. The company aimed to provide novel cryptographic assurance capabilities to consumers based on privacy-preserving PKI techniques, but failed to secure necessary funding following the collapse of the Dot-com bubble.\n"}
{"id": "23007058", "url": "https://en.wikipedia.org/wiki?curid=23007058", "title": "Krasner's lemma", "text": "Krasner's lemma\n\nIn number theory, more specifically in \"p\"-adic analysis, Krasner's lemma is a basic result relating the topology of a complete non-archimedean field to its algebraic extensions.\n\nLet \"K\" be a complete non-archimedean field and let be a separable closure of \"K\". Given an element α in , denote its Galois conjugates by \"α\", ..., \"α\". Krasner's lemma states:\n\n\nKrasner's lemma has the following generalization.\nConsider a monic polynomial \nof degree \"n\" > 1\nwith coefficients in a Henselian field (\"K\", \"v\") and roots in the\nalgebraic closure . Let \"I\" and \"J\" be two disjoint,\nnon-empty sets with union {1...,\"n\"}. Moreover, consider a\npolynomial \nwith coefficients and roots in . Assume\nThen the coefficients of the polynomials\nare contained in the field extension of \"K\" generated by the\ncoefficients of \"g\". (The original Krasner's lemma corresponds to the situation where \"g\" has degree 1.)\n\n"}
{"id": "23600625", "url": "https://en.wikipedia.org/wiki?curid=23600625", "title": "Lawson topology", "text": "Lawson topology\n\nIn mathematics and theoretical computer science the Lawson topology, named after J. D. Lawson, is a topology on partially ordered sets used in the study of domain theory. The lower topology on a poset \"P\" is generated by the subbasis consisting of all complements of principal filters on \"P\". The Lawson topology on \"P\" is the smallest common refinement of the lower topology and the Scott topology on \"P\".\n\n\n\n\n"}
{"id": "15012850", "url": "https://en.wikipedia.org/wiki?curid=15012850", "title": "Leonardo number", "text": "Leonardo number\n\nThe Leonardo numbers are a sequence of numbers given by the recurrence:\n\nEdsger W. Dijkstra used them as an integral part of his smoothsort algorithm, and also analyzed them in some detail.\n\nThe first few Leonardo numbers are\n\nThe Leonardo numbers are related to the Fibonacci numbers by the relation formula_3.\n\nFrom this relation it is straightforward to derive a closed-form expression for the Leonardo numbers, analogous to Binet's formula for the Fibonacci numbers:\n\nwhere the golden ratio formula_5 and formula_6 are the roots of the quadratic polynomial formula_7.\n"}
{"id": "17368856", "url": "https://en.wikipedia.org/wiki?curid=17368856", "title": "Linear continuum", "text": "Linear continuum\n\nIn the mathematical field of order theory, a continuum or linear continuum is a generalization of the real line.\nFormally, a linear continuum is a linearly ordered set \"S\" of more than one element that is densely ordered, i.e., between any two distinct elements there is another (and hence infinitely many others), and which \"lacks gaps\" in the sense that every non-empty subset with an upper bound has a least upper bound. More symbolically:\n\nA set has the least upper bound property, if every nonempty subset of the set that is bounded above has a least upper bound. Linear continua are particularly important in the field of topology where they can be used to verify whether an ordered set given the order topology is connected or not.\n\nUnlike the standard real line, a linear continuum may be bounded on either side: for example, any (real) closed interval is a linear continuum.\n\n\nExamples in addition to the real numbers:\n\nThis map is known as the projection map. The projection map is continuous (with respect to the product topology on \"I\" × \"I\") and is surjective. Let \"A\" be a nonempty subset of \"I\" × \"I\" which is bounded above. Consider \"π\"(\"A\"). Since \"A\" is bounded above, \"π\"(\"A\") must also be bounded above. Since, \"π\"(\"A\") is a subset of \"I\", it must have a least upper bound (since \"I\" has the least upper bound property). Therefore, we may let \"b\" be the least upper bound of \"π\"(\"A\"). If \"b\" belongs to \"π\"(\"A\"), then \"b\" × \"I\" will intersect \"A\" at say \"b\" × \"c\" for some \"c\" ∈ \"I\". Notice that since \"b\" × \"I\" has the same order type of \"I\", the set (\"b\" × \"I\") ∩ \"A\" will indeed have a least upper bound \"b\" × \"c\"', which is the desired least upper bound for \"A\".\n\nIf \"b\" does not belong to \"π\"(\"A\"), then \"b\" × 0 is the least upper bound of \"A\", for if \"d\" < \"b\", and \"d\" × \"e\" is an upper bound of \"A\", then \"d\" would be a smaller upper bound of \"π\"(\"A\") than \"b\", contradicting the unique property of \"b\".\n\n\n\n\nEven though linear continua are important in the study of ordered sets, they do have applications in the mathematical field of topology. In fact, we will prove that an ordered set in the order topology is connected if and only if it is a linear continuum (notice the 'if and only if' part). We will prove one implication, and leave the other one as an exercise. (Munkres explains the second part of the proof )\n\nTheorem\n\nLet \"X\" be an ordered set in the order topology. If \"X\" is connected, then \"X\" is a linear continuum.\n\n\"Proof:\"\n\nSuppose, x is in X and y is in X where x < y. If there exists no z in X such that x < z < y, consider the sets:\n\nA = (−∞, y)\n\nB = (x, +∞)\n\nThese sets are disjoint (If a is in A, a < y so that if a is in B, a > x and a < y which is impossible by hypothesis), nonempty (x is in A and y is in B) and open (in the order topology) and their union is X. This contradicts the connectedness of X.\n\nNow we prove the least upper bound property. If C is a subset of X that is bounded above and has no least upper bound, let D be the union of all open rays of the form (b, +∞) where b is an upper bound for C. Then D is open (since it is the union of open sets), and closed (if 'a' is not in D, then a < b for all upper bounds b of C so that we may choose q > a such that q is in C (if no such q exists, a is the least upper bound of C), then an open interval containing a, may be chosen that doesn't intersect D). Since D is nonempty (there is more than one upper bound of D for if there was exactly one upper bound s, s would be the least upper bound. Then if b and b are two upper bounds of D with b < b, b will belong to D), D and its complement together form a separation on X. This contradicts the connectedness of X.\n\n1. Since the ordered set:\n\nA = (−∞, 0) U (0,+∞)\n\nis not a linear continuum, it is disconnected.\n\n2. By applying the theorem just proved, the fact that R is connected follows. In fact any interval (or ray) in R is also connected.\n\n3. The set of integers is not a linear continuum and therefore cannot be connected.\n\n4. In fact, if an ordered set in the order topology is a linear continuum, it must be connected. Since any interval in this set is also a linear continuum, it follows that this space is locally connected since it has a basis consisting entirely of connected sets.\n\n5. For an example of a topological space that is a linear continuum, see long line.\n\n"}
{"id": "56353", "url": "https://en.wikipedia.org/wiki?curid=56353", "title": "Linear span", "text": "Linear span\n\nIn linear algebra, the linear span (also called the linear hull or just span) of a set of vectors in a vector space is the intersection of all linear subspaces which each contain every vector in that set. The linear span of a set of vectors is therefore a vector space. Spans can be generalized to matroids and modules.\n\nFor expressing that a vector space is a span of a set , one commonly uses the following phrases: spans ; is spanned by ; is a spanning set of ; is a generating set of .\n\nGiven a vector space \"V\" over a field \"K\", the span of a set \"S\" of vectors (not necessarily infinite) is defined to be the intersection \"W\" of all subspaces of \"V\" that contain \"S\". \"W\" is referred to as the subspace \"spanned by\" \"S\", or by the vectors in \"S\". Conversely, \"S\" is called a \"spanning set\" of \"W\", and we say that \"S\" \"spans\" \"W\".\n\nAlternatively, the span of \"S\" may be defined as the set of all finite linear combinations of elements of \"S\", which follows from the above definition.\n\nIn particular, if \"S\" is a finite subset of \"V\", then the span of \"S\" is the set of all linear combinations of the elements of \"S\". In the case of infinite \"S\", infinite linear combinations (i.e. where a combination may involve an infinite sum, assuming such sums are defined somehow, e.g. if \"V\" is a Banach space) are excluded by the definition; a generalization that allows these is not equivalent.\n\nThe real vector space R has {(-1,0,0), (0,1,0), (0,0,1)} as a spanning set. This particular spanning set is also a basis. If (-1,0,0) were replaced by (1,0,0), it would also form the canonical basis of R.\n\nAnother spanning set for the same space is given by {(1,2,3), (0,1,2), (−1,1/2,3), (1,1,1)}, but this set is not a basis, because it is linearly dependent.\n\nThe set {(1,0,0), (0,1,0), (1,1,0)} is not a spanning set of R; instead its span is the space of all vectors in R whose last component is zero. That space (the space of all vectors in R whose last component is zero) is also spanned by the set {(1,0,0), (0,1,0)}, as (1,1,0) is a linear combination of (1,0,0) and (0,1,0). It does, however, span R.\n\nThe empty set is a spanning set of {(0, 0, 0)} since the empty set is a subset of all possible vector spaces in R, and {(0, 0, 0)} is the intersection of all of these vector spaces.\n\nThe set of functions \"x\" where \"n\" is a non-negative integer spans the space of polynomials.\n\nTheorem 1: The subspace spanned by a non-empty subset \"S\" of a vector space \"V\" is the set of all linear combinations of vectors in \"S\".\n\nThis theorem is so well known that at times it is referred to as the definition of span of a set.\n\nTheorem 2: Every spanning set \"S\" of a vector space \"V\" must contain at least as many elements as any linearly independent set of vectors from \"V\".\n\nTheorem 3: Let \"V\" be a finite-dimensional vector space. Any set of vectors that spans \"V\" can be reduced to a basis for \"V\" by discarding vectors if necessary (i.e. if there are linearly dependent vectors in the set). If the axiom of choice holds, this is true without the assumption that \"V\" has finite dimension.\n\nThis also indicates that a basis is a minimal spanning set when \"V\" is finite-dimensional.\n\nGeneralizing the definition of the span of points in space, a subset \"X\" of the ground set of a matroid is called a \"spanning set\" if the rank of \"X\" equals the rank of the entire ground set.\n\nThe vector space definition can also be generalized to modules. Given an \"R\"-module \"A\" and any collection of elements a,…,a of A, then the sum of cyclic modules,\n\nconsisting of all \"R\"-linear combinations of the given elements a, is called the submodule of \"A\" spanned by a,…,a As with the case of vector spaces, the submodule of A spanned by any subset of A is the intersection of all the submodules containing that subset.\n\nIn functional analysis, a closed linear span of a set of vectors is the minimal closed set which contains the linear span of that set.\n\nSuppose that \"X\" is a normed vector space and let \"E\" be any non-empty subset of \"X\". The closed linear span of \"E\", denoted by formula_3 or formula_4, is the intersection of all the closed linear subspaces of \"X\" which contain \"E\".\n\nOne mathematical formulation of this is\n\nThe closed linear span of the set of functions \"x\" on the interval [0, 1], where \"n\" is a non-negative integer, depends on the norm used. If the \"L\" norm is used, then the closed linear span is the Hilbert space of square-integrable functions on the interval. But if the maximum norm is used, the closed linear span will be the space of continuous functions on the interval. In either case, the closed linear span contains functions that are not polynomials, and so are not in the linear span itself. However, the cardinality of the set of functions in the closed linear span is the cardinality of the continuum, which is the same cardinality as for the set of polynomials.\n\nThe linear span of a set is dense in the closed linear span. Moreover, as stated in the lemma below, the closed linear span is indeed the closure of the linear span.\n\nClosed linear spans are important when dealing with closed linear subspaces (which are themselves highly important, consider Riesz's lemma).\n\nLet \"X\" be a normed space and let \"E\" be any non-empty subset of \"X\". Then\n\n(a) formula_3 is a closed linear subspace of \"X\" which contains \"E\",\n\n(b) formula_7, viz. formula_3 is the closure of formula_9,\n\n(c) formula_10\n\n\n\n"}
{"id": "394008", "url": "https://en.wikipedia.org/wiki?curid=394008", "title": "Logical possibility", "text": "Logical possibility\n\nLogically possible refers to a proposition which can be the logical consequence of another, based on the axioms of a given system of logic. The logical possibility of a proposition will depend on the system of logic being considered, rather than on the violation of any single rule. Some systems of logic restrict inferences from inconsistent propositions or even allow for true contradictions. Other logical systems have more than two truth-values instead of a binary of such values. However, when talking about logical possibility it is often assumed that the system in question is classical propositional logic. Similarly, the criterion for logical possibility is often based on whether or not a proposition is contradictory and as such is often thought of as the broadest type of possibility.\n\nLogical possibility should be distinguished from other sorts of subjunctive possibilities. But the relationship between modalities (if there is any) is the subject of debate and may depend on how one views logic, as well as the relationship between logic and metaphysics. For example, many philosophers following Saul Kripke have held that discovered identities such as \"Hesperus = Phosphorus\" are metaphysically necessary because they pick out the same object in all possible worlds where the terms have a referent. However, it is nonetheless \"logically\" possible for “Hesperus = Phosphorus” to be false, since denying it doesn't violate a logical rule such as consistency. Other philosophers are of the view that logical possibility is broader than metaphysical possibility, so that anything which is metaphysically possible is also logically possible.\n\n\n"}
{"id": "976666", "url": "https://en.wikipedia.org/wiki?curid=976666", "title": "Monomial basis", "text": "Monomial basis\n\nIn mathematics the monomial basis of a polynomial ring is its basis (as vector space or free module over the field or ring of coefficients) that consists in the set of all monomials. The monomials form a basis because every polynomial may be uniquely written as a finite linear combination of monomials (this is an immediate consequence of the definition of a polynomial).\n\nThe polynomial ring of the univariate polynomial over a field is a -vector space, which has \nas an (infinite) basis. More generally, if is a ring, is a free module, which has the same basis.\n\nThe polynomials of degree at most form also a vector space (or a free module in the case of a ring of coefficients), which has \n\nas a basis\n\nThe canonical form of a polynomial is its expression on this basis:\n\nor, using the shorter sigma notation:\n\nThe monomial basis is naturally totally ordered, either by increasing degrees\nor by decreasing degrees\n\nIn the case of several indeterminates formula_7 a monomial is a product\nwhere the formula_9 are non-negative integers. Note that, as formula_10 an exponent equal to zero means that the corresponding indeterminate does not appear in the monomial; in particular\nformula_11\nis a monomial.\n\nSimilar to the case of univariate polynomials, the polynomials in formula_12 form a vector space (if the coefficients belong to a field) or a free module (if the coefficients belong to a ring), which has the set of all monomials as a basis, called the monomial basis\n\nThe homogeneous polynomials of degree formula_13 form a subspace which has the monomials of degree formula_14 as a basis. The dimension of this subspace is the number of monomials of degree formula_13, which is \nwhere formula_17 denotes a binomial coefficient.\n\nThe polynomials of degree at most formula_13 form also a subspace, which has the monomials of degree at most formula_13 as a basis. The number of these monomials is the dimension of this subspace, equal to\n\nDespite the univariate case, there is no natural total order of the monomial basis. For problem which require to choose a total order, such Gröbner basis computation, one generally chooses an \"admissible\" monomial order that is a total order on the set of monomials such that\nand\nfor every monomials formula_23\n\nA polynomial can always be converted into monomial form by calculating its Taylor expansion around 0. For example, a polynomial in formula_24:\n\n"}
{"id": "34260152", "url": "https://en.wikipedia.org/wiki?curid=34260152", "title": "Neat submanifold", "text": "Neat submanifold\n\nIn differential topology, an area of mathematics, a neat submanifold of a manifold with boundary is a kind of \"well-behaved\" submanifold. More precisely, let formula_1 be a manifold with boundary, and formula_2 a submanifold of formula_1. A is said to be a neat submanifold of formula_1 if it meets the following two conditions:\n\n"}
{"id": "35208985", "url": "https://en.wikipedia.org/wiki?curid=35208985", "title": "Negativity (quantum mechanics)", "text": "Negativity (quantum mechanics)\n\nIn quantum mechanics, negativity is a measure of quantum entanglement which is easy to compute. It is a measure deriving from the PPT criterion for separability. It has shown to be an entanglement monotone and hence a proper measure of entanglement.\n\nThe negativity of a subsystem formula_1 can be defined in terms of a density matrix formula_2 as: \n\nwhere:\n\nAn alternative and equivalent definition is the absolute sum of the negative eigenvalues of formula_9:\nwhere formula_11 are all of the eigenvalues.\n\nwhere formula_15 is an arbitrary LOCC operation over formula_2\n\nThe logarithmic negativity is an entanglement measure which is easily computable and an upper bound to the distillable entanglement.\nIt is defined as\nwhere formula_18 is the partial transpose operation and formula_19 denotes the trace norm.\n\nIt relates to the negativity as follows:\n\nThe logarithmic negativity \n\n"}
{"id": "2091495", "url": "https://en.wikipedia.org/wiki?curid=2091495", "title": "Nucleic acid double helix", "text": "Nucleic acid double helix\n\nIn molecular biology, the term double helix refers to the structure formed by double-stranded molecules of nucleic acids such as DNA. The double helical structure of a nucleic acid complex arises as a consequence of its secondary structure, and is a fundamental component in determining its tertiary structure. The term entered popular culture with the publication in 1968 of \"The Double Helix: A Personal Account of the Discovery of the Structure of DNA, by James Watson\"\n\nThe DNA double helix polymer of nucleic acid, held together by nucleotides which base pair together. In B-DNA, the most common double helical structure found in nature, the double helix is right-handed with about 10–10.5 base pairs per turn. The double helix structure of DNA contains a \"major groove\" and \"minor groove\". In B-DNA the major groove is wider than the minor groove. Given the difference in widths of the major groove and minor groove, many proteins which bind to B-DNA do so through the wider major groove.\n\nThe double-helix model of DNA structure was first published in the journal \"Nature\" by James Watson and Francis Crick in 1953, (X,Y,Z coordinates in 1954) based upon the crucial X-ray diffraction image of DNA labeled as \"Photo 51\", from Rosalind Franklin in 1952, followed by her more clarified DNA image with Raymond Gosling, Maurice Wilkins, Alexander Stokes, and Herbert Wilson, and base-pairing chemical and biochemical information by Erwin Chargaff. The prior model was triple-stranded DNA.\n\nThe realization that the structure of DNA is that of a double-helix elucidated the mechanism of base pairing by which genetic information is stored and copied in living organisms and is widely considered one of the most important scientific discoveries of the 20th century. Crick, Wilkins, and Watson each received one third of the 1962 Nobel Prize in Physiology or Medicine for their contributions to the discovery. (Franklin, whose breakthrough X-ray diffraction data was used to formulate the DNA structure, died in 1958, and thus was ineligible to be nominated for a Nobel Prize.)\n\nHybridization is the process of complementary base pairs binding to form a double helix. Melting is the process by which the interactions between the strands of the double helix are broken, separating the two nucleic acid strands. These bonds are weak, easily separated by gentle heating, enzymes, or mechanical force. Melting occurs preferentially at certain points in the nucleic acid. \"T\" and \"A\" rich regions are more easily melted than \"C\" and \"G\" rich regions. Some base steps (pairs) are also susceptible to DNA melting, such as \"T A\" and \"T G\". These mechanical features are reflected by the use of sequences such as \"TATA\" at the start of many genes to assist RNA polymerase in melting the DNA for transcription.\n\nStrand separation by gentle heating, as used in polymerase chain reaction (PCR), is simple, providing the molecules have fewer than about 10,000 base pairs (10 kilobase pairs, or 10 kbp). The intertwining of the DNA strands makes long segments difficult to separate. The cell avoids this problem by allowing its DNA-melting enzymes (helicases) to work concurrently with topoisomerases, which can chemically cleave the phosphate backbone of one of the strands so that it can swivel around the other. Helicases unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase.\n\nThe geometry of a base, or base pair step can be characterized by 6 coordinates: shift, slide, rise, tilt, roll, and twist. These values precisely define the location and orientation in space of every base or base pair in a nucleic acid molecule relative to its predecessor along the axis of the helix. Together, they characterize the helical structure of the molecule. In regions of DNA or RNA where the \"normal\" structure is disrupted, the change in these values can be used to describe such disruption.\n\nFor each base pair, considered relative to its predecessor, there are the following base pair geometries to consider:\n\n\nRise and twist determine the handedness and pitch of the helix. The other coordinates, by contrast, can be zero. Slide and shift are typically small in B-DNA, but are substantial in A- and Z-DNA. Roll and tilt make successive base pairs less parallel, and are typically small.\n\nNote that \"tilt\" has often been used differently in the scientific literature, referring to the deviation of the first, inter-strand base-pair axis from perpendicularity to the helix axis. This corresponds to slide between a succession of base pairs, and in helix-based coordinates is properly termed \"inclination\".\n\nAt least three DNA conformations are believed to be found in nature, A-DNA, B-DNA, and Z-DNA. The \"B\" form described by James Watson and Francis Crick is believed to predominate in cells. It is 23.7 Å wide and extends 34 Å per 10 bp of sequence. The double helix makes one complete turn about its axis every 10.4–10.5 base pairs in solution. This frequency of twist (termed the helical \"pitch\") depends largely on stacking forces that each base exerts on its neighbours in the chain. The absolute configuration of the bases determines the direction of the helical curve for a given conformation.\n\nA-DNA and Z-DNA differ significantly in their geometry and dimensions to B-DNA, although still form helical structures. It was long thought that the A form only occurs in dehydrated samples of DNA in the laboratory, such as those used in crystallographic experiments, and in hybrid pairings of DNA and RNA strands, but DNA dehydration does occur in vivo, and A-DNA is now known to have biological functions. Segments of DNA that cells have been methylated for regulatory purposes may adopt the Z geometry, in which the strands turn about the helical axis the opposite way to A-DNA and B-DNA. There is also evidence of protein-DNA complexes forming Z-DNA structures.\nOther conformations are possible; A-DNA, B-DNA, C-DNA, E-DNA, -DNA (the enantiomeric form of -DNA), P-DNA, S-DNA, Z-DNA, etc. have been described so far. In fact, only the letters F, Q, U, V, and Y are available to describe any new DNA structure that may appear in the future. However, most of these forms have been created synthetically and have not been observed in naturally occurring biological systems. There are also triple-stranded DNA forms and quadruplex forms such as the G-quadruplex and the i-motif.\n\nTwin helical strands form the DNA backbone. Another double helix may be found by tracing the spaces, or grooves, between the strands. These voids are adjacent to the base pairs and may provide a binding site. As the strands are not directly opposite each other, the grooves are unequally sized. One groove, the major groove, is 22 Å wide and the other, the minor groove, is 12 Å wide. The narrowness of the minor groove means that the edges of the bases are more accessible in the major groove. As a result, proteins like transcription factors that can bind to specific sequences in double-stranded DNA usually make contacts to the sides of the bases exposed in the major groove. This situation varies in unusual conformations of DNA within the cell \"(see below)\", but the major and minor grooves are always named to reflect the differences in size that would be seen if the DNA is twisted back into the ordinary B form.\n\nAlternative non-helical models were briefly considered in the late 1970s as a potential solution to problems in DNA replication in plasmids and chromatin. However, the models were set aside in favor of the double-helical model due to subsequent experimental advances such as X-ray crystallography of DNA duplexes and later the nucleosome core particle, and the discovery of topoisomerases. Also, the non-double-helical models are not currently accepted by the mainstream scientific community.\n\nSingle-stranded nucleic acids (ssDNA) do not adopt a helical formation, and are described by models such as the random coil or worm-like chain.\n\nDNA is a relatively rigid polymer, typically modelled as a worm-like chain. It has three significant degrees of freedom; bending, twisting, and compression, each of which cause certain limits on what is possible with DNA within a cell. Twisting-torsional stiffness is important for the circularisation of DNA and the orientation of DNA bound proteins relative to each other and bending-axial stiffness is important for DNA wrapping and circularisation and protein interactions. Compression-extension is relatively unimportant in the absence of high tension.\n\nDNA in solution does not take a rigid structure but is continually changing conformation due to thermal vibration and collisions with water molecules, which makes classical measures of rigidity impossible to apply. Hence, the bending stiffness of DNA is measured by the persistence length, defined as:\n"}
{"id": "1687416", "url": "https://en.wikipedia.org/wiki?curid=1687416", "title": "Porism", "text": "Porism\n\nA porism is a mathematical proposition or corollary. In particular, the term porism has been used to refer to a direct result of a proof, analogous to how a corollary refers to a direct result of a theorem.\nIn modern usage, a porism is a relation that holds for an infinite range of values but only if a certain condition is assumed, for example Steiner's porism.\nThe term originates from three books of Euclid with porism, that have been lost.\nNote that a proposition may not have been proven, so a porism may not be a theorem, or for that matter, it may not be true.\n\nThe treatise which has given rise to this subject is the \"Porisms\" of Euclid, the author of the \"Elements\". As much as is known of this lost treatise is due to the \"Collection\" of Pappus of Alexandria, who mentions it along with other geometrical treatises, and gives a number of lemmas necessary for understanding it. Pappus states:\n\nPappus goes on to say that this last definition was changed by certain later geometers, who defined a porism on the ground of an accidental characteristic as\n\" (\"to leîpon hypothései topikoû theōrḗmatos\"), that which falls short of a locus-theorem by a (or in its) hypothesis. Proclus points out that the word \"porism\" was used in two senses. One sense is that of \"corollary\", as a result unsought, as it were, but seen to follow from a theorem. On the \"porism\" in the other sense he adds nothing to the definition of \"the older geometers\" except to say that the finding of the center of a circle and the finding of the greatest common measure are porisms.\n\nPappus gave a complete enunciation of a porism derived from Euclid, and an extension of it to a more general case. This porism, expressed in modern language, asserts the following: Given four straight lines of which three turn about the points in which they meet the fourth, if two of the points of intersection of these lines lie each on a fixed straight line, the remaining point of intersection will also lie on another straight line. The general enunciation applies to any number of straight lines, say \"n\" + 1, of which \"n\" can turn about as many points fixed on the (\"n\" + 1)th. These \"n\" straight lines cut, two and two, in 1/2\"n\"(\"n\" − 1) points, 1/2\"n\"(\"n\" − 1) being a triangular number whose side is \"n\" − 1. If, then, they are made to turn about the \"n\" fixed points so that any \"n\" − 1 of their 1/2\"n\"(\"n\" − 1) points of intersection, chosen subject to a certain limitation, lie on \"n\" − 1 given fixed straight lines, then each of the remaining points of intersection, 1/2\"n\"(\"n\" − 1)(\"n\" − 2) in number, describes a straight line. Pappus gives also a complete enunciation of one porism of the first book of Euclid's treatise.\n\nThis may be expressed thus: If about two fixed points P, Q we make turn two straight lines meeting on a given straight line L, and if one of them cut off a segment AM from a fixed straight line AX, given in position, we can determine another fixed straight line BY, and a point B fixed on it, such that the segment BM' made by the second moving line on this second fixed line measured from B has a given ratio X to the first segment AM. The rest of the enunciations given by Pappus are incomplete, and he merely says that he gives thirty-eight lemmas for the three books of porisms; and these include 171 theorems. The lemmas which Pappus gives in connexion with the porisms are interesting historically, because he gives:\n\nFrom the 17th to the 19th centuries this subject seems to have had great fascination for mathematicians, and many geometers have attempted to restore the lost porisms. Thus Albert Girard says in his \"Traité de trigonometrie\" (1626) that he hopes to publish a restoration. About the same time Pierre de Fermat wrote a short work under the title \"Porismatum euclidaeorum renovata doctrina et sub forma isagoges recentioribus geometeis exhibita\" (see \"Œuvres de Fermat\", i., Paris, 1891); but two at least of the five examples of porisms which he gives do not fall within the classes indicated by Pappus.\n\nRobert Simson was the first to throw real light upon the subject. He first succeeded in explaining the only three propositions which Pappus indicates with any completeness. This explanation was published in the \"Philosophical Transactions\" in 1723. Later he investigated the subject of porisms generally in a work entitled \"De porismatibus traclatus; quo doctrinam porisrnatum satis explicatam, et in posterum ab oblivion tutam fore sperat auctor\", and published after his death in a volume, \"Roberti Simson opera quaedam reliqua\" (Glasgow, 1776).\n\nSimson's treatise, \"De porismatibus\", begins with definitions of theorem, problem, datum, porism and locus. Respecting the porism Simson says that Pappus's definition is too general, and therefore he will substitute for it the following:\n\n\"Porisma est propositio in qua proponitur demonstrare rem aliquam, vel plures datas esse, cui, vel quibus, ut et cuilibet ex rebus innumeris, non quidem datis, sed quae ad ea quae data sunt eandem habent rationem, convenire ostendendum est affectionem quandam communem in propositione descriptam. Porisma etiam in forma problematis enuntiari potest, si nimirum ex quibus data demonstranda sunt, invenienda proponantur.\"\n\nA locus (says Simson) is a species of porism. Then follows a Latin translation of Pappus's note on the porisms, and the propositions which form the bulk of the treatise. These are Pappus's thirty-eight lemmas relating to the porisms, ten cases of the proposition concerning four straight lines, twenty-nine porisms, two problems in illustration and some preliminary lemmas.\n\nJohn Playfair's memoir (\"Trans. Roy. Soc. Edin.\", 1794, vol. iii.), a sort of sequel to Simson's treatise, had for its special object the inquiry into the probable origin of porisms, that is, into the steps which led the ancient geometers to the discovery of them. Playfair remarked that the careful investigation of all possible particular cases of a proposition would show that (1) under certain conditions a problem becomes impossible; (2) under certain other conditions, indeterminate or capable of an infinite number of solutions. These cases could be enunciated separately, were in a manner intermediate between theorems and problems, and were called \"porisms.\" Playfair accordingly defined a porism thus: \"A proposition affirming the possibility of finding such conditions as will render a certain problem indeterminate or capable of innumerable solutions.\"\n\nThough this definition of a porism appears to be most favoured in England, Simson's view has been most generally accepted abroad, and had the support of Michel Chasles. However, in Liouville's \"Journal de mathematiques pures et appliquées\" (vol. xx., July, 1855), P. Breton published \"Recherches nouvelles sur les porismes d'Euclide\", in which he gave a new translation of the text of Pappus, and sought to base thereon a view of the nature of a porism more closely conforming to the definitions in Pappus. This was followed in the same journal and in \"La Science\" by a controversy between Breton and A. J. H. Vincent, who disputed the interpretation given by the former of the text of Pappus, and declared himself in favour of the idea of Schooten, put forward in his \"Mathematicae exercitationes\" (1657), in which he gives the name of \"porism\" to one section. According to Frans van Schooten, if the various relations between straight lines in a figure are written down in the form of equations or proportions, then the combination of these equations in all possible ways, and of new equations thus derived from them leads to the discovery of innumerable new properties of the figure, and here we have \"porisms.\"\n\nThe discussions, however, between Breton and Vincent, in which C. Housel also joined, did not carry forward the work of restoring Euclid's Porisms, which was left for Chasles. His work (\"Les Trois livres de porismes d'Euclide\", Paris, 1860) makes full use of all the material found in Pappus. But we may doubt its being a successful reproduction of Euclid's actual work. Thus, in view of the ancillary relation in which Pappus's lemmas generally stand to the works to which they refer, it seems incredible that the first seven out of thirty-eight lemmas should be really equivalent (as Chasles makes them) to Euclid's first seven Porisms. Again, Chasles seems to have been wrong in making the ten cases of the four-line Porism begin the book, instead of the intercept-Porism fully enunciated by Pappus, to which the \"lemma to the first Porism\" relates intelligibly, being a particular case of it.\n\nAn interesting hypothesis as to the Porisms was put forward by H. G. Zeuthen (\"Die Lehre von den Kegelschnitten im Altertum\", 1886, ch. viii.). Observing, e.g., that the intercept-Porism is still true if the two fixed points are points on a conic, and the straight lines drawn through them intersect on the conic instead of on a fixed straight line, Zeuthen conjectures that the Porisms were a by-product of a fully developed projective geometry of conics. It is a fact that Lemma 31 (though it makes no mention of a conic) corresponds exactly to Apollonius's method of determining the foci of a central conic (Conics, iii. 4547 with 42). The three porisms stated by Diophantus in his \"Arithmetica\" are propositions in the theory of numbers which can all be enunciated in the form \"we can find numbers satisfying such and such conditions\"; they are sufficiently analogous therefore to the geometrical porism as defined in Pappus and Proclus.\n\n\n"}
{"id": "26309566", "url": "https://en.wikipedia.org/wiki?curid=26309566", "title": "QuantLib", "text": "QuantLib\n\nQuantLib is an open-source software library which provides tools for software developers and practitioners interested in financial instrument valuation and related subjects. QuantLib is written in C++.\n\nThe QuantLib project was started by a few quantitative analysts who worked at RiskMap (currently StatPro Italia). The first e-mail announcing QuantLib to the world was sent on December 11, 2000, and signed by Ferdinando Ametrano, Luigi Ballabio and Marco Marchioro. RiskMap was founded by Dario Cintioli, Ferdinando Ametrano, Luigi Ballabio, Adolfo Benin, and Marco Marchioro. The people at RiskMap faced the problem, not for the first time in their life, to build a financial library from scratch. It was Ferdinando's idea to build an open source library that could be used by quants all over the world when starting to build a new quantitative library. Currently, the QuantLib project is headed by Luigi Ballabio and Ferdinando Ametrano.\n\nQuantLib is available as C++ source code which is compiled into a library. It is known to work on Windows, Mac OS X, Linux and other Unix-like operation systems.\n\nIt can be linked with other languages via SWIG, the Python extension is popular and can be installed via pip.\n\nMuch of QuantLib's functionality can be used in Excel via the add-in QuantlibXL.\n\nQuantLib is released under a modified BSD license known as the XFree86-type license. It is GPL compatible.\n\nThe software provides various facilities for computing values of financial instruments and related calculations. It is a major example of Mathematical finance. Its main use is in quantitative analysis.\n\nThe financial instruments and derivatives it can evaluate include\n\nIt has models for \n\nIt can compute derivative prices using methods including:\n\n\n"}
{"id": "20131133", "url": "https://en.wikipedia.org/wiki?curid=20131133", "title": "Quartic reciprocity", "text": "Quartic reciprocity\n\nQuartic or biquadratic reciprocity is a collection of theorems in elementary and algebraic number theory that state conditions under which the congruence \"x\" ≡ \"p\" (mod \"q\") is solvable; the word \"reciprocity\" comes from the form of some of these theorems, in that they relate the solvability of the congruence \"x\" ≡ \"p\" (mod \"q\") to that of \"x\" ≡ \"q\" (mod \"p\").\n\nEuler made the first conjectures about biquadratic reciprocity. Gauss published two monographs on biquadratic reciprocity. In the first one (1828) he proved Euler's conjecture about the biquadratic character of 2. In the second one (1832) he stated the biquadratic reciprocity law for the Gaussian integers and proved the supplementary formulas. He said that a third monograph would be forthcoming with the proof of the general theorem, but it never appeared. Jacobi presented proofs in his Königsberg lectures of 1836–37. The first published proofs were by Eisenstein.\n\nSince then a number of other proofs of the classical (Gaussian) version have been found, as well as alternate statements. Lemmermeyer states that there has been an explosion of interest in the rational reciprocity laws since the 1970s.\n\nA quartic or biquadratic residue (mod \"p\") is any number congruent to the fourth power of an integer (mod \"p\"). If \"x\" ≡ \"a\" (mod \"p\") does not have an integer solution, \"a\" is a quartic or biquadratic nonresidue (mod \"p\").\n\nAs is often the case in number theory, it is easiest to work modulo prime numbers, so in this section all moduli \"p\", \"q\", etc., are assumed to positive, odd primes.\n\nThe first thing to notice when working within the ring Z of integers is that if the prime number \"q\" is ≡ 3 (mod 4) then a residue \"b\" is a quadratic residue (mod \"q\") if and only if it is a biquadratic residue (mod \"q\"). Indeed, the first supplement of quadratic reciprocity states that −1 is a quadratic nonresidue (mod \"q\"), so that for any integer \"x\", one of \"x\" and −\"x\" is a quadratic residue and the other one is a nonresidue. Thus, if \"r\" ≡ \"a\" (mod \"q\") is a quadratic residue, then if \"a\" ≡ \"b\" is a residue, \"r\" ≡ \"a\" ≡ \"b\" (mod \"q\") is a biquadratic residue, and if \"a\" is a nonresidue, −\"a\" is a residue, −\"a\" ≡ \"b\", and again, \"r\" ≡ (−\"a\") ≡ \"b\" (mod \"q\") is a biquadratic residue.\n\nTherefore, the only interesting case is when the modulus \"p\" ≡ 1 (mod 4).\n\nGauss proved that if \"p\" ≡ 1 (mod 4) then the nonzero residue classes (mod \"p\") can be divided into four sets, each containing (\"p\"−1)/4 numbers. Let \"e\" be a quadratic nonresidue. The first set is the quartic residues; the second one is \"e\" times the numbers in the first set, the third is \"e\" times the numbers in the first set, and the fourth one is \"e\" times the numbers in the first set. Another way to describe this division is to let \"g\" be a primitive root (mod \"p\"); then the first set is all the numbers whose indices with respect to this root are ≡ 0 (mod 4), the second set is all those whose indices are ≡ 1 (mod 4), etc. In the vocabulary of group theory, the first set is a subgroup of index 4 (of the multiplicative group Z/pZ), and the other three are its cosets.\n\nThe first set is the biquadratic residues, the third set is the quadratic residues that are not quartic residues, and the second and fourth sets are the quadratic nonresidues. Gauss proved that −1 is a biquadratic residue if \"p\" ≡ 1 (mod 8) and a quadratic, but not biquadratic, residue, when \"p\" ≡ 5 (mod 8).\n\n2 is a quadratic residue mod \"p\" if and only if \"p\" ≡ ±1 (mod 8). Since \"p\" is also ≡ 1 (mod 4), this means \"p\" ≡ 1 (mod 8). Every such prime is the sum of a square and twice a square.\n\nGauss proved\n\nLet \"q\" = \"a\" + 2\"b\" ≡ 1 (mod 8) be a prime number. Then <br>\n\nEvery prime \"p\" ≡ 1 (mod 4) is the sum of two squares. If \"p\" = \"a\" + \"b\" where \"a\" is odd and \"b\" is even, Gauss proved that\n\n2 belongs to the first (respectively second, third, or fourth) class defined above if and only if \"b\" ≡ 0 (resp. 2, 4, or 6) (mod 8). The first case of this is one of Euler's conjectures:\n\nFor an odd prime number \"p\" and a quadratic residue \"a\" (mod \"p\"), Euler's criterion states that formula_1 so if \"p\" ≡ 1 (mod 4), formula_2\n\nDefine the rational quartic residue symbol for prime \"p\" ≡ 1 (mod 4) and quadratic residue \"a\" (mod \"p\") as formula_3 It is easy to prove that \"a\" is a biquadratic residue (mod \"p\") if and only if formula_4\n\nDirichlet simplified Gauss's proof of the biquadratic character of 2 (his proof only requires quadratic reciprocity for the integers) and put the result in the following form:\n\nLet \"p\" = \"a\" + \"b\" ≡ 1 (mod 4) be prime, and let \"i\" ≡ \"b\"/\"a\" (mod \"p\"). Then\n\nIn fact, let \"p\" = \"a\" + \"b\" = \"c\" + 2\"d\" = \"e\" − 2\"f\" ≡ 1 (mod 8) be prime, and assume \"a\" is odd. Then\n\nGoing beyond the character of 2, let the prime \"p\" = \"a\" + \"b\" where \"b\" is even, and let \"q\" be a prime such that formula_8 Quadratic reciprocity says that formula_9 where formula_10 Let σ ≡ \"p\" (mod \"q\"). Then\n\nThe first few examples are:\n\nEuler had conjectured the rules for 2, −3 and 5, but did not prove any of them.\n\nDirichlet also proved that if \"p\" ≡ 1 (mod 4) is prime and formula_14 then\n\nThis has been extended from 17 to 17, 73, 97, and 193 by Brown and Lehmer.\n\nThere are a number of equivalent ways of stating Burde's rational biquadratic reciprocity law.\n\nThey all assume that \"p\" = \"a\" + \"b\" and \"q\" = \"c\" + \"d\" are primes where \"b\" and \"d\" are even, and that formula_16\n\nGosset's version is\n\nLetting \"i\" ≡ −1 (mod \"p\") and \"j\" ≡ −1 (mod \"q\"), Frölich's law is\n\nBurde stated his in the form:\n\nNote that\n\nLet \"p\" ≡ \"q\" ≡ 1 (mod 4) be primes and assume formula_21. Then \"e\" = \"p f\" + \"q g\" has non-trivial integer solutions, and\n\nLet \"p\" ≡ \"q\" ≡ 1 (mod 4) be primes and assume \"p\" = \"r\" + \"q s\". Then\n\nLet \"p\" = 1 + 4\"x\" be prime, let \"a\" be any odd number that divides \"x\", and let formula_24 Then \"a\" is a biquadratic residue (mod \"p\").\n\nLet \"p\" = \"a\" + 4\"b\" = \"c\" + 2\"d\" ≡ 1 (mod 8) be prime. Then all the divisors of \"c\" − \"p a\" are biquadratic residues (mod \"p\"). The same is true for all the divisors of \"d\" − \"p b\".\n\nIn his second monograph on biquadratic reciprocity Gauss displays some examples and makes conjectures that imply the theorems listed above for the biquadratic character of small primes. He makes some general remarks, and admits there is no obvious general rule at work. He goes on to say\n\nThe theorems on biquadratic residues gleam with the greatest simplicity and genuine beauty only when the field of arithmetic is extended to imaginary numbers, so that without restriction, the numbers of the form \"a\" + \"bi\" constitute the object of study ... we call such numbers integral complex numbers. [bold in the original]\n\nThese numbers are now called the ring of Gaussian integers, denoted by Z[\"i\"]. Note that \"i\" is a fourth root of 1.\n\nIn a footnote he adds\n\nThe theory of cubic residues must be based in a similar way on a consideration of numbers of the form \"a\" + \"bh\" where \"h\" is an imaginary root of the equation \"h\" = 1 ... and similarly the theory of residues of higher powers leads to the introduction of other imaginary quantities.\n\nThe numbers built up from a cube root of unity are now called the ring of Eisenstein integers. The \"other imaginary quantities\" needed for the \"theory of residues of higher powers\" are the rings of integers of the cyclotomic number fields; the Gaussian and Eisenstein integers are the simplest examples of these.\n\nGauss develops the arithmetic theory of the \"integral complex numbers\" and shows that it is quite similar to the arithmetic of ordinary integers. This is where the terms unit, associate, norm, and primary were introduced into mathematics.\n\nThe units are the numbers that divide 1. They are 1, \"i\", −1, and −\"i\". They are similar to 1 and −1 in the ordinary integers, in that they divide every number. The units are the powers of \"i\".\n\nGiven a number λ = \"a\" + \"bi\", its conjugate is \"a\" − \"bi\" and its associates are the four numbers\n\nIf λ = \"a\" + \"bi\", the norm of λ, written Nλ, is the number \"a\" + \"b\". If λ and μ are two Gaussian integers, Nλμ = Nλ Nμ; in other words, the norm is multiplicative. The norm of zero is zero, the norm of any other number is a positive integer. ε is a unit if and only if Nε = 1. The square root of the norm of λ, a nonnegative real number which may not be a Gaussian integer, is the absolute value of lambda.\n\nGauss proves that Z[\"i\"] is a unique factorization domain and shows that the primes fall into three classes:\n\nThus, inert primes are 3, 7, 11, 19, ... and a factorization of the split primes is\n\nThe associates and conjugate of a prime are also primes.\n\nNote that the norm of an inert prime \"q\" is N\"q\" = \"q\" ≡ 1 (mod 4); thus the norm of all primes other than 1 + \"i\" and its associates is ≡ 1 (mod 4).\n\nGauss calls a number in Z[\"i\"] odd if its norm is an odd integer. Thus all primes except 1 + \"i\" and its associates are odd. The product of two odd numbers is odd and the conjugate and associates of an odd number are odd.\n\nIn order to state the unique factorization theorem, it is necessary to have a way of distinguishing one of the associates of a number. Gauss defines an odd number to be primary if it is ≡ 1 (mod (1 + \"i\")). It is straightforward to show that every odd number has exactly one primary associate. An odd number λ = \"a\" + \"bi\" is primary if \"a\" + \"b\" ≡ \"a\" − \"b\" ≡ 1 (mod 4); i.e., \"a\" ≡ 1 and \"b\" ≡ 0, or \"a\" ≡ 3 and \"b\" ≡ 2 (mod 4). The product of two primary numbers is primary and the conjugate of a primary number is also primary.\n\nThe unique factorization theorem for Z[\"i\"] is: if λ ≠ 0, then\nwhere 0 ≤ μ ≤ 3, ν ≥ 0, the πs are primary primes and the αs ≥ 1, and this representation is unique, up to the order of the factors.\n\nThe notions of congruence and greatest common divisor are defined the same way in Z[\"i\"] as they are for the ordinary integers Z. Because the units divide all numbers, a congruence (mod λ) is also true modulo any associate of λ, and any associate of a GCD is also a GCD.\n\nGauss proves the analogue of Fermat's theorem: if α is not divisible by an odd prime π, then\nSince Nπ ≡ 1 (mod 4), formula_27 makes sense, and formula_28 for a unique unit \"i\".\n\nThis unit is called the quartic or biquadratic residue character of α (mod π) and is denoted by\n\nIt has formal properties similar to those of the Legendre symbol.\n\nThe biquadratic character can be extended to odd composite numbers in the \"denominator\" in the same way the Legendre symbol is generalized into the Jacobi symbol. As in that case, if the \"denominator\" is composite, the symbol can equal one without the congruence being solvable:\n\nGauss stated the law of biquadratic reciprocity in this form:\n\nLet π and θ be distinct primary primes of Z[\"i\"]. Then\n\nJust as the quadratic reciprocity law for the Legendre symbol is also true for the Jacobi symbol, the requirement that the numbers be prime is not needed; it suffices that they be odd relatively prime nonunits. Probably the most well-known statement is:\n\nLet π and θ be primary relatively prime nonunits. Then\n\nThere are supplementary theorems for the units and the half-even prime 1 + \"i\".\n\nif π = \"a\" + \"bi\" is a primary prime, then\n\nand thus\n\nAlso, if π = \"a\" + \"bi\" is a primary prime, and \"b\" ≠ 0 then\n\nJacobi defined π = \"a\" + \"bi\" to be primary if \"a\" ≡ 1 (mod 4). With this normalization, the law takes the form\n\nLet α = \"a\" + \"bi\" and β = \"c\" + \"di\" where \"a\" ≡ \"c\" ≡ 1 (mod 4) and \"b\" and \"d\" are even be relatively prime nonunits. Then\n\nThe following version was found in Gauss's unpublished manuscripts.\n\nLet α = \"a\" + 2\"bi\" and β = \"c\" + 2\"di\" where \"a\" and \"c\" are odd be relatively prime nonunits. Then\n\nThe law can be stated without using the concept of primary:\n\nIf λ is odd, let ε(λ) be the unique unit congruent to λ (mod (1 + \"i\")); i.e., ε(λ) = \"i\" ≡ λ (mod 2 + 2\"i\"), where 0 ≤ \"k\" ≤ 3. Then for odd and relatively prime α and β, neither one a unit,\n\nFor odd λ, let formula_48 Then if λ and μ are relatively prime nonunits, Eisenstein proved\n\n\n\nThe references to the original papers of Euler, Dirichlet, and Eisenstein were copied from the bibliographies in Lemmermeyer and Cox, and were not used in the preparation of this article.\n\nThis was actually written 1748–1750, but was only published posthumously; It is in Vol V, pp. 182–283 of\n\nThe two monographs Gauss published on biquadratic reciprocity have consecutively numbered sections: the first contains §§ 1–23 and the second §§ 24–76. Footnotes referencing these are of the form \"Gauss, BQ, § \"n\"\". Footnotes referencing the \"Disquisitiones Arithmeticae\" are of the form \"Gauss, DA, Art. \"n\"\".\n\nThese are in Gauss's \"Werke\", Vol II, pp. 65–92 and 93–148\n\nGerman translations are in pp. 511–533 and 534–586 of the following, which also has the Disquisitiones Arithmeticae and Gauss's other papers on number theory.\n\nThese papers are all in Vol I of his \"Werke\".\n\nboth of these are in Vol I of his \"Werke\".\n\nThese two papers by Franz Lemmermeyer contain proofs of Burde's law and related results:\n"}
{"id": "1202168", "url": "https://en.wikipedia.org/wiki?curid=1202168", "title": "Relational operator", "text": "Relational operator\n\nIn computer science, a relational operator is a programming language construct or operator that tests or defines some kind of relation between two entities. These include numerical equality (\"e.g.\", ) and inequalities (\"e.g.\", ).\n\nIn programming languages that include a distinct boolean data type in their type system, like Pascal, Ada, or Java, these operators usually evaluate to true or false, depending on if the conditional relationship between the two operands holds or not. In languages such as C, relational operators return the integers 0 or 1, where 0 stands for false and any non-zero value stands for true.\n\nAn expression created using a relational operator forms what is termed a \"relational expression\" or a \"condition\". Relational operators can be seen as special cases of logical predicates.\n\nEquality is being used in many programming-language constructs and data types. It is used to test if an element already exists in a set, or to access to a value through a key. It is used in switch statements to dispatch the control flow to the correct branch, and during the unification process in logic programming.\n\nOne of the possible meaning of equality is that \"if a equals to b, then we can use either a or b interchangeably in any context without noticing any difference\". But this statement does not necessarily hold, particularly when taking into account mutability together with content equality.\n\nSometimes, particularly in object-oriented programming, the comparison raises questions of data types and inheritance, equality, and identity. It is often necessary to distinguish between:\n\nIn many modern programming languages, objects and data structures are accessed through references. In such languages, there becomes a need to test for two different types of equality:\n\nThe first type of equality usually implies the second (except for things like \"not a number\" (NaN) which are unequal to themselves), but the converse is not necessarily true. For example, two string objects may be distinct objects (unequal in the first sense) but contain the same sequence of characters (equal in the second sense). See identity for more of this issue.\n\nReal numbers, including many simple fractions, cannot be represented exactly in floating-point arithmetic, and it may be necessary to test for equality within a given tolerance. Such tolerance, however, can easily break desired properties such as transitivity, whereas reflexivity breaks too: the IEEE floating point standard requires that codice_1 holds.\n\nOther programming elements such as computable functions, may either have no sense of equality, or an equality that is uncomputable. For these reasons, some languages define an explicit notion of \"comparable\", in the form of a base class, an interface, a trait or a protocol, which is used either explicitly, by declaration in source code, or implicitly, via the structure of the type involved.\n\nIn JavaScript, PHP, VBScript and a few other dynamically typed languages, the standard equality operator evaluates to \"true\" if two values are equal, even if they have different types, making the number 4 compare equal to the text string \"4\", for instance. A typed equality operator is often available also, in such languages, returning true only for values with identical or equivalent types (in PHP 5, codice_2 is false although codice_3 is true). For languages where the number 0 may be interpreted as \"false\", this operator may simplify things such as checking for zero (as codice_4 would be true for x being either 0 or \"0\" using the type agnostic equality operator).\n\n\"Greater than\" and \"less than\" comparison of non-numeric data is performed according to a sort convention (such as, for text strings, lexicographical order) which may be built into the programming language and/or configurable by a programmer.\n\nWhen it is desired to associate a numeric value with the result of a comparison between two data items, say \"a\" and \"b\", the usual convention is to assign −1 if a < b, 0 if a = b and 1 if a > b. For example, the C function codice_5 performs a three-way comparison and returns −1, 0, or 1 according to this convention, and qsort expects the comparison function to return values according to this convention. In sorting algorithms, the efficiency of comparison code is critical since it is one of the major factors contributing to sorting performance.\n\nComparison of programmer-defined data types (data types for which the programming language has no in-built understanding) may be carried out by custom-written or library functions (such as codice_5 mentioned above), or, in some languages, by \"overloading\" a comparison operator – that is, assigning a programmer-defined meaning that depends on the data types being compared. Another alternative is using some convention such as memberwise comparison.\n\nThough perhaps unobvious at first, like the boolean logical operators XOR, AND, OR, and NOT, relational operators can be designed to have logical equivalence, such that they can all be defined in terms of one another. The following four conditional statements all have the same logical equivalence \"E\" (either all true or all false) for any given \"x\" and \"y\" values:\n\nThis relies on the domain being well ordered.\n\nThe most common numerical relational operators used in programming languages are shown below.\n\nOther conventions are less common: Common Lisp and Macsyma/Maxima use Basic-like operators except for inequality, which is codice_7 in Common Lisp and codice_8 in Macsyma/Maxima. Older Lisps used codice_9, codice_10, and codice_11; and negated them using codice_12 for the remaining operators.\n\nRelational operators are also used in technical literature instead of words. Relational operators are usually written in infix notation, if supported by the programming language, which means that they appear between their operands (the two expressions being related). For example, an expression in Python will print the message if the \"x\" is less than \"y\":\nOther programming languages, such as Lisp, use prefix notation, as follows:\nIn mathematics, it is common practice to chain relational operators, such as in 3 < x < y < 20 (meaning 3 < x \"and\" x < y \"and\" y < 20). The syntax is clear since these relational operators in mathematics are transitive.\n\nHowever, many recent programming languages would see an expression like 3 < x < y as consisting of two left (or right-) associative operators, interpreting it as something like codice_13. If we say that x=4, we then get codice_14, and evaluation will give codice_15 which generally does not make sense. However, it does compile in C/C++ and some other languages, yielding surprising result (as \"true\" would be represented by the number 1 here).\n\nIt is possible to give the expression codice_16 its familiar mathematical meaning, and some programming languages such as Python and Perl 6 do that. Others, such as C# and Java, do not, partly because it would differ from the way most other infix operators work in C-like languages. The D programming language do not do that since it maintains some compatibility with C, and \"Allowing C expressions but with subtly different semantics (albeit arguably in the right direction) would add more confusion than convenience\".\n\nSome languages, like Common Lisp, use multiple argument predicates for this. In Lisp codice_17 is true when x is between 1 and 10.\n\nEarly FORTRAN (1956–57) was bounded by heavily restricted character sets where codice_18 was the only relational operator available. There were no codice_19 or codice_20 (and certainly no codice_21 or codice_22). This forced the designers to define symbols such as codice_23, codice_24, codice_25, codice_26 etc. and subsequently made it tempting to use the remaining codice_18 character for copying, despite the obvious incoherence with mathematical usage (codice_28 should be impossible).\n\nInternational Algebraic Language (IAL, ALGOL 58) and ALGOL (1958 and 1960) thus introduced codice_29 for assignment, leaving the standard codice_18 available for equality, a convention followed by CPL, ALGOL W, ALGOL 68, Basic Combined Programming Language (BCPL), Simula, SET Language (SETL), Pascal, Smalltalk, Modula-2, Ada, Standard ML, OCaml, Eiffel, Object Pascal (Delphi), Oberon, Dylan, VHSIC Hardware Description Language (VHDL), and several other languages.\n\nThis uniform de facto standard among most programming languages was eventually changed, indirectly, by a minimalist compiled language named B. Its sole intended application was as a vehicle for a first port of (a then very primitive) Unix, but it also evolved into the very influential C language.\n\nB started off as a syntactically changed variant of the systems programming language BCPL, a simplified (and typeless) version of CPL. In what has been described as a \"strip-down\" process, the codice_31 and codice_32 operators of BCPL were replaced with codice_33 and codice_34 (which would later become codice_35 and codice_36, respectively.). In the same process, the ALGOL style codice_29 of BCPL was replaced by codice_18 in B. The reason for all this being unknown. As variable updates had no special syntax in B (such as codice_39 or similar) and were allowed in expressions, this non standard meaning of the equal sign meant that the traditional semantics of the equal sign now had to be associated with another symbol. Ken Thompson used the ad hoc codice_40 combination for this.\n\nAs a small type system was later introduced, B then became C. The popularity of this language along with its association with Unix, led to Java, C#, and many other languages following suit, syntactically, despite this needless conflict with the mathematical meaning of the equal sign.\n\nAssignments in C have a value and since any non-zero scalar value is interpreted as \"true\" in conditional expressions, the code codice_41 is legal, but has a very different meaning from codice_42. The former code fragment means \"assign \"y\" to \"x\", and if the new value of \"x\" is not zero, execute the following statement\". The latter fragment means \"if and only if \"x\" is equal to \"y\", execute the following statement\".\nThough Java and C# have the same operators as C, this mistake usually causes a compile error in these languages instead, because the if-condition must be of type codice_43, and there is no implicit way to convert from other types (\"e.g.\", numbers) into codice_43s. So unless the variable that is assigned to has type codice_43 (or wrapper type codice_46), there will be a compile error.\n\nIn ALGOL-like languages such as Pascal, Delphi, and Ada (in the sense that they allow nested function definitions), and in Python, and many functional languages, among others, assignment operators cannot appear in an expression (including codice_47 clauses), thus precluding this class of error. Some compilers, such as GNU Compiler Collection (GCC), provide a warning when compiling code containing an assignment operator inside an if statement, though there are some legitimate uses of an assignment inside an if-condition. In such cases, the assignment must be wrapped in an extra pair of parentheses explicitly, to avoid the warning.\n\nSimilarly, some languages, such as BASIC use just the codice_18 symbol for both assignment \"and\" equality, as they are syntactically separate (as with Pascal, Ada, Python, etc., assignment operators cannot appear in expressions).\n\nSome programmers get in the habit of writing comparisons against a constant in the reverse of the usual order:\n\nIf codice_18 is used accidentally, the resulting code is invalid because 2 is not a variable. The compiler will generate an error message, on which the proper operator can be substituted. This coding style is termed left-hand comparison, or Yoda conditions.\n\nThis table lists the different mechanisms to test for these two types of equality in various languages:\n\nRuby uses codice_50 to mean \"b is a member of the set a\", though the details of what it means to be a member vary considerably depending on the data types involved. codice_51 is here known as the \"case equality\" or \"case subsumption\" operator.\n\n"}
{"id": "12744687", "url": "https://en.wikipedia.org/wiki?curid=12744687", "title": "Right half-plane", "text": "Right half-plane\n\nIn complex variables, the right half plane is the set\n\nof all points in the complex plane whose real part is positive,\n"}
{"id": "1594286", "url": "https://en.wikipedia.org/wiki?curid=1594286", "title": "Rule of product", "text": "Rule of product\n\nIn combinatorics, the rule of product or multiplication principle is a basic counting principle (a.k.a. the fundamental principle of counting). Stated simply, it is the idea that if there are a ways of doing something and b ways of doing another thing, then there are a · b ways of performing both actions.\n\nIn this example, the rule says: multiply 3 by 2, getting 6.\n\nThe sets {\"A\", \"B\", \"C\"} and {\"X\", \"Y\"} in this example are disjoint sets, but that is not necessary. The number of ways to choose a member of {\"A\", \"B\", \"C\"}, and then to do so again, in effect choosing an ordered pair each of whose components is in {\"A\", \"B\", \"C\"}, is 3 × 3 = 9.\n\nAs another example, when you decide to order pizza, you must first choose the type of crust: thin or deep dish (2 choices). Next, you choose one topping: cheese, pepperoni, or sausage (3 choices). \n\nUsing the rule of product, you know that there are 2 × 3 = 6 possible combinations of ordering a pizza.\n\nIn set theory, this multiplication principle is often taken to be the definition of the product of cardinal numbers. We have\n\nwhere formula_4 is the Cartesian product operator. These sets need not be finite, nor is it necessary to have only finitely many factors in the product; see cardinal number.\n\nThe rule of sum is another basic counting principle. Stated simply, it is the idea that if we have \"a\" ways of doing something and \"b\" ways of doing another thing and we can not do both at the same time, then there are \"a\" + \"b\" ways to choose one of the actions.\n\n"}
{"id": "286550", "url": "https://en.wikipedia.org/wiki?curid=286550", "title": "Safety-critical system", "text": "Safety-critical system\n\nA safety-critical system or life-critical system is a system whose failure or malfunction may result in one (or more) of the following outcomes:\n\n\nA safety-related system (or sometimes safety-involved system) comprises everything (hardware, software, and human aspects) needed to perform one or more safety functions, in which failure would cause a significant increase in the safety risk for the people and/or environment involved. Safety-related systems are those that do not have full responsibility for controlling hazards such as loss of life, severe injury or severe environmental damage. The malfunction of a safety-involved system would only be that hazardous in conjunction with the failure of other systems or human error. Some safety organizations provide guidance on safety-related systems, for example the Health and Safety Executive (HSE) in the United Kingdom.\n\nRisks of this sort are usually managed with the methods and tools of safety engineering. A safety-critical system is designed to lose less than one life per billion (10) hours of operation. Typical design methods include probabilistic risk assessment, a method that combines failure mode and effects analysis (FMEA) with fault tree ana look\n\nlysis. Safety-critical systems are increasingly computer-based.\n\nSeveral reliability regimes for safety-critical systems exist: \n\n\nSoftware engineering for safety-critical systems is particularly difficult. There are three aspects which can be applied to aid the engineering software for life-critical systems. First is process engineering and management. Secondly, selecting the appropriate tools and environment for the system. This allows the system developer to effectively test the system by emulation and observe its effectiveness. Thirdly, address any legal and regulatory requirements, such as FAA requirements for aviation. By setting a standard for which a system is required to be developed under, it forces the designers to stick to the requirements. The avionics industry has succeeded in producing standard methods for producing life-critical avionics software. Similar standards exist for automotive (ISO 26262), Medical (IEC 62304) and nuclear (IEC 61513) industries. The standard approach is to carefully code, inspect, document, test, verify and analyze the system. Another approach is to certify a production system, a compiler, and then generate the system's code from specifications. Another approach uses formal methods to generate proofs that the code meets requirements. All of these approaches improve the software quality in safety-critical systems by testing or eliminating manual steps in the development process, because people make mistakes, and these mistakes are the most common cause of potential life-threatening errors.\n\n\nThe technology requirements can go beyond avoidance of failure, and can even facilitate medical \"intensive care\" (which deals with healing patients), and also \"life support\" (which is for stabilizing patients).\n\n\n\n\n\n\n\n\n"}
{"id": "25340011", "url": "https://en.wikipedia.org/wiki?curid=25340011", "title": "Semi-membership", "text": "Semi-membership\n\nIn mathematics and theoretical computer science, the semi-membership problem for a set is the problem of deciding which of two possible elements is logically more likely to belong to that set; alternatively, given two elements of which at least one is in the set, to distinguish the member from the non-member.\n\nThe semi-membership problem may be significantly easier than the membership problem. For example, consider the set \"S\"(\"x\") of finite-length binary strings representing the dyadic rationals less than some fixed real number \"x\". The semi-membership problem for a pair of strings is solved by taking the string representing the smaller dyadic rational, since if exactly one of the strings is an element, it must be the smaller, irrespective of the value of \"x\". However, the language \"S\"(\"x\") may not even be a recursive language, since there are uncountably many such \"x\", but only countably many recursive languages.\n\nA function \"f\" on ordered pairs (\"x\",\"y\") is a \"selector\" for a set \"S\" if \"f\"(\"x\",\"y\") is equal to either \"x\" or \"y\" and if \"f\"(\"x\",\"y\") is in \"S\" whenever at least one of \"x\", \"y\" is in \"S\". A set is semi-recursive if it has a recursive selector, and is P-selective or semi-feasible if it is semi-recursive with a polynomial time selector.\n\nSemi-feasible sets have small circuits; they are in the extended low hierarchy; and cannot be NP-complete unless P=NP.\n\n"}
{"id": "220089", "url": "https://en.wikipedia.org/wiki?curid=220089", "title": "Set-builder notation", "text": "Set-builder notation\n\nIn set theory and its applications to logic, mathematics, and computer science, set-builder notation is a mathematical notation for describing a set by enumerating its elements or stating the properties that its members must satisfy.\n\nDefining sets by properties is also known as set comprehension, set abstraction or as defining a set's intension.\n\nSet-builder notation is sometimes simply referred to as \"set notation\", although this phrase may be better reserved for the broader class of means of denoting sets.\n\nA set is an unordered collection of \"elements\". (An \"element\" may also be referred to as a \"member\".) An element may be any mathematical entity.\n\nA set can be described directly by enumerating all of its elements between curly brackets, as in the following two examples:\n\n\nThis is sometimes called the \"roster method\" for specifying a set.\n\nWhen it is desired to denote a set that contains elements from a regular sequence an ellipses notation may be employed, as shown in the next examples:\n\n\nThere is no order among the elements of a set (this explains and validates the equality of the last example), but with the ellipses notation we show an ordered sequence before (or after) the ellipsis as a convenient notational vehicle for explaining to a reader which elements are in a set. The first few elements of the sequence are shown then the ellipses indicate that the simplest interpretation should be applied for continuing the sequence. Should no terminating value appear to the right of the ellipses then the sequence is considered to be unbounded.\n\nIn each preceding example, each set is described by enumerating its elements. Not all sets can be described in this way, or if they can, their enumeration may be too long or too complicated to be useful. Therefore, many sets are defined by a property that characterizes their elements. This characterization may be done informally using general prose, as in the following example.\n\n\nHowever, the prose approach may lack accuracy or be ambiguous. Thus, set builder notation is often used with a predicate characterizing the elements of the set being defined, as described in the following section.\n\nSet builder notation can be used to describe sets that are defined by a predicate, rather than explicitly enumerated. In this form, set builder notation has three parts: a variable, a colon or vertical bar separator, and a logical predicate. Thus there is a variable on the left of the separator, and a rule on the right of it. These three parts are contained in curly brackets:\nor\nThe vertical bar, which can also be written as a colon, is a separator that can be read as \"such that\", \"for which\", or \"with the property that\". The formula is said to be the \"rule\" or the \"predicate\". All values of \"x\" for which the predicate holds (is true) belong to the set being defined. All values of for which the predicate does not hold do not belong to the set. Thus formula_8 is the set of all values of that satisfy the formula . It may be the empty set, if no value of satisfies the formula.\n\nA domain can appear on the left of the vertical bar: \nor by adjoining it to the predicate:\nThe ∈ symbol here denotes set membership, while the formula_13 symbol denotes the logical \"and\" operator, known as logical conjunction. This notation represents the set of all values of that belong to some given set for which the predicate is true. (see \"Set existence axiom\" below)\n\nIn general, it is not a good idea to consider sets without defining a domain, as this would represent the subset of \"all possible things that may exist\" for which the predicate is true. This can easily lead to contradictions and paradoxes. For example, Russell's paradox shows that the expression formula_14 although seemingly well formed as a set builder expression, can not define a set without producing a contradiction.\n\nIn cases where the set \"E\" is clear from context, it may be not explicitly specified. It is common in the literature for an author to state the domain ahead of time, and then not specify it in the set builder notation. For example, an author may say something such as, \"Unless otherwise stated, variables are to be taken to be natural numbers.\"\n\nThe following examples illustrate particular sets defined by set builder notation via predicates. In each case, the domain is specified on the left side of the vertical bar, while the rule is specified on the right side. \n\n\n\n\n\n\nAn extension of set-builder notation replaces the single variable with a term that may include one or more variables, combined with functions acting on them. So instead of formula_30, we may have formula_31 which should be read\n\nFor example:\n\nWhen inverse functions can be explicitly stated, the expression on the left can be eliminated through simple substitution. Consider the example set formula_37. Make the substitution formula_40, which is to say formula_41, then replace \"t\" in the set builder notation to find \n\nTwo sets are equal if and only if they have the same elements. Sets defined by set builder notation are equal if and only if their set builder rules, including the domain specifiers, are equivalent. That is \nif and only if \nTherefore, in order to prove the equality of two sets defined by set builder notation, it suffices to prove the equivalence of their predicates, including the domain qualifiers.\n\nFor example,\nbecause the two rule predicates are logically equivalent:\nThis equivalence holds because, for any real number \"x\", we have formula_47 if and only if \"x\" is a rational number with formula_48. In particular, both sets are equal to the set formula_49.\n\nIn many formal set theories, such as Zermelo–Fraenkel set theory, set builder notation is not part of the formal syntax of the theory. Instead, there is a set existence axiom scheme, which states that if \"E\" is a set and Φ(x) is a formula in the language of set theory, then there is a set \"Y\" whose members are exactly the elements of \"E\" that satisfy Φ:\nThe set \"Y\" obtained from this axiom is exactly the set described in set builder notation as formula_51.\n\nIn Z notation, the set of all \"x\" in a universe of discourse \"A\" that satisfy the condition \"P\"(\"x\") is written\nIn Z, the set membership of an element \"x\" in set \"A\" is written as formula_53 instead of formula_54. Versions of set builder notation are also available in Z which allow for terms more complicated than a single variable, using a bullet to indicate the form of members of the set. For example,\ndenotes the set of all values \"F\"(\"x\"), where \"x\" is in \"A\" and \"P\"(\"x\") holds.\n\nA similar notation available in a number of programming languages (notably Python and Haskell) is the list comprehension, which combines map and filter operations over one or more lists.\n\nIn Python, the set-builder's braces are replaced with square brackets, parentheses, or curly braces, giving list, generator, and set objects, respectively. Python uses an English-based syntax. Haskell replaces the set-builder's braces with square brackets and uses symbols, including the standard set-builder vertical bar.\n\nThe same can be achieved in Scala using Sequence Comprehensions, where the \"for\" keyword returns a list of the yielded variables using the \"yield\" keyword.\n\nConsider these set-builder notation examples in some programming languages:\nThe set builder notation and list comprehension notation are both instances of a more general notation known as \"monad comprehensions\", which permits map/filter-like operations over any monad with a zero element.\n\n"}
{"id": "22667049", "url": "https://en.wikipedia.org/wiki?curid=22667049", "title": "Transversality theorem", "text": "Transversality theorem\n\nIn differential topology, the transversality theorem, also known as the Thom transversality theorem after French mathematician René Thom, is a major result that describes the transverse intersection properties of a smooth family of smooth maps. It says that transversality is a generic property: any smooth map formula_1, may be deformed by an arbitrary small amount into a map that is transverse to a given submanifold formula_2. Together with the Pontryagin–Thom construction, it is the technical heart of cobordism theory, and the starting point for surgery theory. The finite-dimensional version of the transversality theorem is also a very useful tool for establishing the genericity of a property which is dependent on a finite number of real parameters and which is expressible using a system of nonlinear equations. This can be extended to an infinite-dimensional parametrization using the infinite-dimensional version of the transversality theorem.\n\nLet formula_1 be a smooth map between smooth manifolds, and let formula_4 be a submanifold of formula_5. We say that formula_6 is transverse to formula_4, denoted as formula_8, if and only if for every formula_9 we have that \n\nAn important result about transversality states that if a smooth map formula_6 is transverse to formula_4, then formula_13 is a regular submanifold of formula_14.\n\nIf formula_14 is a manifold with boundary, then we can define the restriction of the map formula_6 to the boundary, as formula_17. The map formula_18 is smooth, and it allows us to state an extension of the previous result: if both formula_8 and formula_20, then formula_13 is a regular submanifold of formula_14 with boundary, and \n\nConsider the map formula_24 and define formula_25. This generates a family of mappings formula_26. We require that the family vary smoothly by assuming formula_27 to be a (smooth) manifold and formula_28 to be smooth.\n\nThe statement of the \"parametric transversality theorem\" is:\n\nSuppose that formula_29 is a smooth map of manifolds, where only formula_14 has boundary, and let formula_4 be any submanifold of formula_5 without boundary. If both formula_28 and formula_34 are transverse to formula_4, then for almost every formula_36, both formula_37 and formula_38 are transverse to formula_4.\n\nThe parametric transversality theorem above is sufficient for many elementary applications (see the book by Guillemin and Pollack).\n\nThere are more powerful statements (collectively known as \"transversality theorems\") that imply the parametric transversality theorem and are needed for more advanced applications.\n\nInformally, the \"transversality theorem\" states that the set of mappings that are transverse to a given submanifold is a dense open (or, in some cases, only a dense formula_40) subset of the set of mappings. To make such a statement precise, it is necessary to define the space of mappings under consideration, and what is the topology in it. There are several possibilities; see the book by Hirsch.\n\nWhat is usually understood by \"Thom's transversality theorem\" is a more powerful statement about jet transversality. See the books by Hirsch and by Golubitsky and Guillemin. The original reference is Thom, Bol. Soc. Mat. Mexicana (2) 1 (1956), pp. 59–71.\n\nJohn Mather proved in the 1970s an even more general result called the \"multijet transversality theorem\". See the book by Golubitsky and Guillemin.\n\nThe infinite-dimensional version of the transversality theorem takes into account that the manifolds may be modeled in Banach spaces. \n\nSuppose that formula_29 is a formula_42 map of formula_43-Banach manifolds. Assume that\n\ni) formula_14, formula_27 and formula_5 are nonempty, metrizable formula_43-Banach manifolds with chart spaces over a field formula_48.\n\nii) The formula_42-map formula_50 with formula_51 has formula_52 as a regular value.\n\niii) For each parameter formula_36, the map formula_25 is a Fredholm map, where formula_55 for every formula_56.\n\niv) The convergence formula_57 on formula_27 as formula_59 and formula_60 for all formula_61 implies the existence of a convergent subsequence formula_62 as formula_59 with formula_64.\n\nIf Assumptions i-iv hold, then there exists an open, dense subset formula_65 of formula_27 such that formula_52 is a regular value of formula_37 for each parameter formula_69.\n\nNow, fix an element formula_69. If there exists a number formula_71 with formula_72 for all solutions formula_73 of formula_74, then the solution set formula_75 consists of an formula_61-dimensional formula_42-Banach manifold or the solution set is empty.\n\nNote that if formula_78 for all the solutions of formula_74, then there exists an open dense subset formula_65 of formula_27 such that there are at most finitely many solutions for each fixed parameter formula_69. In addition, all these solutions are regular.\n\n"}
{"id": "2971303", "url": "https://en.wikipedia.org/wiki?curid=2971303", "title": "Trudinger's theorem", "text": "Trudinger's theorem\n\nIn mathematical analysis, Trudinger's theorem or the Trudinger inequality (also sometimes called the Moser–Trudinger inequality) is a result of functional analysis on Sobolev spaces. It is named after Neil Trudinger (and Jürgen Moser).\n\nIt provides an inequality between a certain Sobolev space norm and an Orlicz space norm of a function. The inequality is a limiting case of Sobolev imbedding and can be stated as the following theorem:\n\nLet formula_1 be a bounded domain in formula_2 satisfying the cone condition. Let formula_3 and formula_4. Set\n\nThen there exists the embedding\n\nwhere \n\nThe space \n\nis an example of an Orlicz space.\n\n"}
{"id": "40811195", "url": "https://en.wikipedia.org/wiki?curid=40811195", "title": "Urania Propitia", "text": "Urania Propitia\n\nUrania Propitia is a book of astronomical tables written by Maria Cunitz and published in 1650. As Maria Cunitz was the daughter of both a physician and mathematician, it was her ability to grasp complex mathematics quickly and transcribe her findings as a polyglot that allowed her to do what not many women had done before her.\n\nUrania Propitia was a simplification of the Rudolphine Tables written by Johannes Kepler in 1627. Kepler's dedication to Emperor Ferdinand II which was originally dedicated to Rudolf II was filled with complex and tedious logarithms. It was because of Kepler's ingenious yet tiresome use of logarithms that led Cunitz to simplify the Rudolphine Tables and make Kepler's work more accessible to the public.\nThe tables are mostly astrological, but the instructions are completely astronomical. Written in both German for \"the fatherland\" and Latin to make it more accessible, the instructions are more practical in German and technical in Latin. Beyond the instructions, Maria Cunitz's book is split into three parts.\n\nThe first part is the mathematical starting point. These include \"sexagesimal sines, solutions of small right triangles in minutes and seconds, and tables for spherical astronomy for degrees of the ecliptic of: declination, right ascension, oblique ascension for latitudes 0 degrees to 72 degrees at 2 degree intervals...\"\n\nIt is the second part that the heart of Maria Cunitz's simplification is brought forward. Using the geometry and spherical astronomy from part one, Cunitz brings the rotational motions of the planets and moons into light using various mathematical formulas. One of the formulas from the Rudolphine Tables,\n\nwhere \"e\", \"M\" and \"E\" denote the orbital eccentricity, the mean anomaly and the eccentric anomaly. This equation is known as \"Kepler's equation\" which normally has no \"geometrical or algebraic solution for \"E\".\" However, when \"M\" is given it becomes more possible to but find \"\"E\" from \"M\" to any degree of precision by iteration or interpolation.\" The major accomplishment Cunitz brought was the ability to compute formula_2 (the true anomaly) from \"M\" without the necessity to use \"\"E\" as a coefficient of interpolation\". Thus, Cunitz was able to simplify the Rudolphine Tables and determine the position of a planet in its orbit as a function of time.\n\nThese tables were used for both the location of eclipses and the time of eclipses. This includes the use of the \"golden astronomical number\", the parallax of the moon and sun in a variety in longitude, latitude, altitude, etc..., and a catalog of other fixed stars in the universe.\n\nCunitz's cosmology has variations of both Tycho Brahe and Johannes Kepler. While the basic structure of her cosmology is like Tycho's with the sun and moon orbiting around the Earth while the rest of the planets orbit around the sun, the physics within the cosmos involves ellipticals and \"aphelions.\"\n\nBeyond the rewards that came from a simplification of the \"Rudolphine Tables\", a scientific advance written by a woman in the seventeenth century was an accomplishment in itself. It was described by Noel Swerdlow as \"the earliest surviving scientific work by a woman on the highest technical level of its age.\" It was common for male scientists before Maria Cunitz to attribute their discoveries to muses. For Urania Propitia\", Urania in Greek mythology was the muse of Astronomy and \"Propitia\" translates to favoring in Latin. This suggests that Maria Cunitz both saw Urania as her muse while also making strides for women as scientists because she could be so easily compared to the ancient Greek astronomer.\n"}
{"id": "34757331", "url": "https://en.wikipedia.org/wiki?curid=34757331", "title": "Viennot's geometric construction", "text": "Viennot's geometric construction\n\nIn mathematics, Viennot's geometric construction (named after Xavier Gérard Viennot) gives a diagrammatic interpretation of the Robinson–Schensted correspondence in terms of shadow lines. It has a generalization to the Robinson–Schensted–Knuth correspondence, which is known as the matrix-ball construction.\n\nStarting with a permutation formula_1, written in two-line notation, say:\n\none can apply the Robinson–Schensted correspondence to this permutation, yielding two standard Young tableaux of the same shape, \"P\" and \"Q\". \"P\" is obtained by performing a sequence of insertions, and \"Q\" is the recording tableau, indicating in which order the boxes were filled.\n\nViennot's construction starts by plotting the points formula_3 in the plane, and imagining there is a light that shines from the origin, casting shadows straight up and to the right. This allows consideration of the points which are not shadowed by any other point; the boundary of their shadows then forms the first shadow line. Removing these points and repeating the procedure, one obtains all the shadow lines for this permutation. Viennot's insight is then that these shadow lines read off the first rows of \"P\" and \"Q\" (in fact, even more than that; these shadow lines form a \"timeline\", indicating which elements formed the first rows of \"P\" and \"Q\" after the successive insertions). One can then repeat the construction, using as new points the previous unlabelled corners, which allows to read off the other rows of \"P\" and \"Q\".\n\nFor example consider the permutation\n\nThen Viennot's construction goes as follows:\n\nOne can use Viennot's geometric construction to prove that if formula_5 corresponds to the pair of tableaux \"P\",\"Q\" under the Robinson–Schensted correspondence, then formula_6 corresponds to the switched pair \"Q\",\"P\". Indeed, taking formula_5 to formula_6 reflects Viennot's construction in the formula_9-axis, and this precisely switches the roles of \"P\" and \"Q\".\n\n\n"}
