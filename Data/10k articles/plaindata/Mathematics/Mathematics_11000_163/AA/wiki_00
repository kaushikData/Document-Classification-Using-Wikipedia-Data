{"id": "2867825", "url": "https://en.wikipedia.org/wiki?curid=2867825", "title": "237 (number)", "text": "237 (number)\n\n237 (two hundred [and] thirty-seven) is the natural number following 236 and preceding 238.\n237 is a lucky number, and one of the numbers in Aronson's sequence.\n\nThe 237th square pyramidal number, 4465475, is also a sum of two smaller square pyramidal numbers. There are only four smaller numbers (55, 70, 147, and 226) with the same property.\n\n237 is the number of a haunted room in the Overlook Hotel in the Stanley Kubrick's film The Shining, and part of a network of interrelated numbers within the film (see The Shining (film)#Room number and the documentary Room 237).\n"}
{"id": "15239331", "url": "https://en.wikipedia.org/wiki?curid=15239331", "title": "Arithmetic hyperbolic 3-manifold", "text": "Arithmetic hyperbolic 3-manifold\n\nIn mathematics, more precisely in group theory and hyperbolic geometry, Arithmetic Kleinian groups are a special class of Kleinian groups constructed using orders in quaternion algebras. They are particular instances of arithmetic groups. An arithmetic hyperbolic three-manifold is the quotient of hyperbolic space formula_1 by an arithmetic Kleinian group. These manifolds include some particularly beautiful or remarkable examples.\n\nA quaternion algebra over a field formula_2 is a four-dimensional central simple formula_2-algebra. A quaternion algebra has a basis formula_4 where formula_5 and formula_6.\n\nA quaternion algebra is said to be split over formula_2 if it is isomorphic as an formula_2-algebra to the algebra of matrices formula_9; a quaternion algebra over an algebraically closed field is always split.\n\nIf formula_10 is an embedding of formula_2 into a field formula_12 we shall denote by formula_13 the algebra obtained by extending scalars from formula_2 to formula_12 where we view formula_2 as a subfield of formula_12 via formula_10.\n\nA subgroup of formula_19 is said to be \"derived from a quaternion algebra\" if it can be obtained through the following construction. Let formula_2 be a number field which has exactly two embeddings into formula_21 whose image is not contained in formula_22 (one conjugate to the other). Let formula_23 be a quaternion algebra over formula_2 such that for any embedding formula_25 the algebra formula_26 is isomorphic to the Hamilton quaternions. Next we need an order formula_27 in formula_23. Let formula_29 be the group of elements in formula_27 of reduced norm 1 and let formula_31 be its image in formula_32 via formula_33. We then consider the Kleinian group obtained as the image in formula_19 of formula_35.\n\nThe main fact about these groups is that they are discrete subgroups and they have finite covolume for the Haar measure on formula_19. Moreover, the construction above yields a cocompact subgroup if and only if the algebra formula_23 is not split over formula_2. The discreteness is a rather immediate consequence of the fact that formula_23 is only split at its complex embeddings. The finiteness of covolume is harder to prove.\n\nAn \"arithmetic Kleinian group\" is any subgroup of formula_40 which is commensurable to a group derived from a quaternion algebra. It follows immediately from this definition that arithmetic Kleinian groups are discrete and of finite covolume (this means that they are lattices in formula_40).\n\nExamples are provided by taking formula_2 to be an imaginary quadratic field, formula_43 and formula_44 where formula_45 is the ring of integers of formula_2 (for example formula_47 and formula_48). The groups thus obtained are the Bianchi groups. They are not cocompact, and any arithmetic Kleinian group which is not commensurable to a conjugate of a Bianchi group is cocompact.\n\nIf formula_23 is any quaternion algebra over an imaginary quadratic number field formula_2 which is not isomorphic to a matrix algebra then the unit groups of orders in formula_23 are cocompact.\n\nThe invariant trace field of a Kleinian group (or, through the monodromy image of the fundamental group, of an hyperbolic manifold) is the field generated by the traces of the squares of its elements. In the case of an arithmetic manifold whose fundamental groups is commensurable with that of a manifold derived from a quaternion algebra over a number field formula_2 the invariant trace field equals formula_2.\n\nOne can in fact characterise arithmetic manifolds through the traces of the elements of their fundamental group. A Kleinian group is an arithmetic group if and only if the following three conditions are realised:\n\nFor the volume an arithmetic three manifold formula_59 derived from a maximal order in a quaternion algebra formula_23 over a number field formula_61 we have the expression:\n\nformula_62\n\nwhere formula_63 are the discriminants of formula_64 respectively, formula_65 is the Dedekind zeta function of formula_2 and formula_67.\n\nA consequence of the volume formula in the previous paragraph is that\n\nThis is in contrast with the fact that hyperbolic Dehn surgery can be used to produce infinitely many non-isometric hyperbolic 3–manifolds with bounded volume. In particular, a corollary is that given a cusped hyperbolic manifold, at most finitely many Dehn surgeries on it can yield an arithmetic hyperbolic manifold.\n\nThe Weeks manifold is the hyperbolic three-manifold of smallest volume and the Meyerhoff manifold is the one of next smallest volume.\n\nThe complement in the three—sphere of the figure-eight knot is an arithmetic hyperbolic three—manifold and attains the smallest volume among all cusped hyperbolic three-manifolds.\n\nThe Ramanujan conjecture for automorphic forms on formula_70 over a number field would imply that for any congruence cover of an arithmetic three–manifold (derived from a quaternion algebra) the spectrum of the Laplace operator is contained in formula_71.\n\nMany of Thurston's conjectures (for example the virtually Haken conjecture), now all known to be true following the work of Ian Agol, were checked first for arithmetic manifolds by using specific methods. In some arithmetic cases the Virtual Haken conjecture is known by general means but it is not known if its solution can be arrived at by purely arithmetic means (i.e. by finding a congruence subgroup with positive first Betti number).\n\nArithmetic manifolds can be used to give examples of manifolds with large injectivity radius whose first Betti number vanishes.\n\nA remark by William Thurston is that arithmetic manifolds \"...often seem to have special beauty.\" This can be substantiated by results showing that the relation between topology and geometry for these manifolds is much more predictable than in general. For example:\n"}
{"id": "20459000", "url": "https://en.wikipedia.org/wiki?curid=20459000", "title": "Ars inveniendi", "text": "Ars inveniendi\n\nArs inveniendi (Latin for \"art of invention\") is a chief notion of mathesis universalis and implies ascertaining truth through the use of mathematics.\n"}
{"id": "8923815", "url": "https://en.wikipedia.org/wiki?curid=8923815", "title": "Ascendency", "text": "Ascendency\n\nAscendency is a quantitative attribute of an ecosystem, defined as a function of the ecosystem's trophic network. Ascendency is derived using mathematical tools from information theory. It is intended to capture in a single index the ability of an ecosystem to prevail against disturbance by virtue of its combined organization and size.\n\nOne way of depicting ascendency is to regard it as \"organized power\", because the index represents the magnitude of the power that is flowing within the system towards particular ends, as distinct from power that is dissipated willy-nilly. Almost half a century earlier, Alfred J. Lotka (1922) had suggested that a system's capacity to prevail in evolution was related to its ability to capture useful power. Ascendency can thus be regarded as a refinement of Lotka's supposition that also takes into account how power is actually being channeled within a system.\n\nIn mathematical terms, ascendency is the product of the aggregate amount of material or energy being transferred in an ecosystem times the coherency with which the outputs from the members of the system relate to the set of inputs to the same components (Ulanowicz 1986). Coherence is gauged by the average mutual information shared between inputs and outputs (Rutledge et al. 1976).\n\nOriginally, it was thought that ecosystems increase uniformly in ascendency as they developed, but subsequent empirical observation has suggested that all sustainable ecosystems are confined to a narrow \"window of vitality\" (Ulanowicz 2002). Systems with relative values of ascendency plotting below the window tend to fall apart due to lack of significant internal constraints, whereas systems above the window tend to be so \"brittle\" that they become vulnerable to external perturbations.\n\nSensitivity analysis on the components of the ascendency reveals the controlling transfers within the system in the sense of Liebig (Ulanowicz and Baird 1999). That is, ascendency can be used to identify which resource is limiting the functioning of each component of the ecosystem.\n\nIt is thought that autocatalytic feedback is the primary route by which systems increase and maintain their ascendencies (Ulanowicz 1997.)\n\n"}
{"id": "20041308", "url": "https://en.wikipedia.org/wiki?curid=20041308", "title": "Berezin integral", "text": "Berezin integral\n\nIn mathematical physics, a Berezin integral, named after Felix Berezin, (or Grassmann integral, after Hermann Grassmann) is a way to define integration of elements of the exterior algebra (Hermann Grassmann 1844). It is called integral because it is used in physics as a sum over histories for fermions, an extension of the path integral.\n\nLet formula_1 be the exterior algebra of polynomials in anticommuting elements formula_2 over the field of complex numbers. (The ordering of the generators formula_3 is fixed and defines the orientation of the exterior algebra.) The Berezin integral on formula_4 is the linear functional formula_5 with the following properties:\n\nfor any formula_8 where formula_9 means the left or the right partial derivative. These properties define the integral uniquely. The formula\n\nexpresses the Fubini law. On the right-hand side, the interior integral of a monomial formula_11 is set to be formula_12 where formula_13; the integral of formula_14 vanishes. The integral with respect to formula_15 is calculated in the similar way and so on.\n\nLet formula_16 be odd polynomials in some antisymmetric variables formula_17. The Jacobian is the matrix\n\nwhere the left and the right derivatives coincide and are even polynomials. The formula for the coordinate change reads\n\nConsider now the algebra formula_20 of functions of real commuting variables formula_21 and of anticommuting variables formula_22 (which is called the free superalgebra of dimension formula_23). This means that an element formula_24 is a function of the argument formula_25 that varies in an open set formula_26 with values in the algebra formula_27 Suppose that this function is continuousformula_28and vanishes in the complement of a compact set formula_29 The Berezin integral is the number\n\nLet a coordinate transformation be given by formula_31, where formula_32 are even and formula_33 are odd polynomials of formula_34 depending on even variables formula_35 The Jacobian matrix of this transformation has the block form:\n\nwhere each even derivative formula_37 commutes with all elements of the algebra formula_20; the odd derivatives commute with even elements and anticommute with odd elements. The entries of the diagonal blocks formula_39 and formula_40 are even and the entries of the offdiagonal blocks formula_41 are odd functions, where formula_42 mean right derivatives. The Berezinian (or the superdeterminant) of the matrix formula_43 is the even function\n\ndefined when the function formula_45 is invertible in formula_46 Suppose that the real functions formula_47 define a smooth invertible map formula_48 of open sets formula_49 in formula_50 and the linear part of the map formula_51 is invertible for each formula_52 The general transformation law for the Berezin integral reads\n\nwhere formula_55 is the sign of the orientation of the map formula_56 The superposition formula_57 is defined in the obvious way, if the functions formula_58 do not depend on formula_59 In the general case, we write formula_60 where formula_61 are even nilpotent elements of formula_20 and set\n\nwhere the Taylor series is finite.\n\nThe mathematical theory of the integral with commuting and anticommuting variables was invented and developed by Felix Berezin. Some important earlier insights were made by David John Candlin. Other authors contributed to these developments, including the physicists Khalatnikov (although his paper contains mistakes), Matthews and Salam, and Martin.\n\n"}
{"id": "47699360", "url": "https://en.wikipedia.org/wiki?curid=47699360", "title": "Bernstein's theorem (polynomials)", "text": "Bernstein's theorem (polynomials)\n\nBernstein's theorem is an inequality relating the maximum modulus of a complex polynomial function on the unit disk with the maximum modulus of its derivative on the unit disk. It was proven by Sergei Bernstein while he was working on approximation theory.\n\nLet formula_1 denote the maximum modulus of an arbitrary\nfunction formula_2 on formula_3, and let formula_4 denote its derivative.\nThen for every polynomial formula_5 of degree formula_6 we have\n\nThe inequality is best possible with equality holding if and only if\n\nLet formula_5 be a polynomial of degree formula_6, and let formula_11 be another polynomial of the same degree with no zeros in formula_12. We show first that if formula_13 on formula_14, then formula_15 on formula_12. \n\nBy Rouché's theorem, formula_17 with formula_18 has all\nits zeros in formula_19. By virtue of the Gauss–Lucas theorem,\nformula_20 has all its zeros in formula_19 as well.\nIt follows that formula_15 on formula_23,\notherwise we could choose an formula_24 with formula_18 such that\nformula_26 has a zero in formula_27.\n\nFor an arbitrary polynomial formula_5 of degree formula_6, we obtain Bernstein's Theorem by applying the above result to the polynomials formula_30, where formula_31 is an arbitrary constant exceeding formula_32.\n\nPaul Erdős conjectured that if formula_5 has no zeros in formula_34, then formula_35. This was proved by Peter Lax.\n\nM. A. Malik showed that if formula_5 has no zeros in formula_37 for a given formula_38, then formula_39.\n"}
{"id": "18542594", "url": "https://en.wikipedia.org/wiki?curid=18542594", "title": "Besov space", "text": "Besov space\n\nIn mathematics, the Besov space (named after Oleg Vladimirovich Besov) formula_1 is a complete quasinormed space which is a Banach space when . These spaces, as well as the similarly defined Triebel–Lizorkin spaces, serve to generalize more elementary function spaces such as Sobolev spaces and are effective at measuring regularity properties of functions.\n\nSeveral equivalent definitions exist. One of them is given below.\n\nLet\n\nand define the modulus of continuity by\n\nLet be a non-negative integer and define: with . The Besov space formula_1 contains all functions such that\n\nThe Besov space formula_1 is equipped with the norm\n\nThe Besov spaces formula_8 coincide with the more classical Sobolev spaces formula_9.\n\nIf formula_10 and formula_11 is not an integer, then formula_12, where formula_13 denotes the Sobolev–Slobodeckij space.\n\n"}
{"id": "56687309", "url": "https://en.wikipedia.org/wiki?curid=56687309", "title": "Catherine Greenhill", "text": "Catherine Greenhill\n\nCatherine Greenhill is an Australian mathematician known for her research on random graphs, combinatorial enumeration and Markov chains. She is an associate professor of mathematics in the School of Mathematics and Statistics at the University of New South Wales,\nand an editor-in-chief of the \"Electronic Journal of Combinatorics\".\n\nGreenhill did her undergraduate studies at the University of Queensland, and remained there for a master's degree, working with Anne Penfold Street there. She earned her Ph.D. in 1996 at the University of Oxford, under the supervision of Peter M. Neumann. Her dissertation was \"From Multisets to Matrix Groups: Some Algorithms Related to the Exterior Square\".\nAfter postdoctoral research with Martin Dyer at the University of Leeds and Nick Wormald at the University of Melbourne, Greenhill joined the University of New South Wales in 2003.\nShe was promoted to associate professor in 2014, becoming the first female mathematician to earn such a promotion at UNSW.\n\nGreenhill was the 2010 winner of the Hall Medal of the Institute of Combinatorics and its Applications.\nShe was president of the Combinatorial Mathematics Society of Australasia for 2011–2013.\nIn 2015 the Australian Academy of Science awarded her their Christopher Heyde Medal for distinguished research in the mathematical sciences.\n"}
{"id": "43161091", "url": "https://en.wikipedia.org/wiki?curid=43161091", "title": "Central polynomial", "text": "Central polynomial\n\nIn algebra, a central polynomial for \"n\"-by-\"n\" matrices is a polynomial in non-commuting variables that is non-constant but yields a scalar matrix whenever it is evaluated at \"n\"-by-\"n\" matrices. That such polynomials exist for any square matrices was discovered in 1970 independently by Formanek and Razmyslov. The term \"central\" is because the evaluation of a central polynomial has the image lying in the center of the matrix ring over any commutative ring. The notion has an application to the theory of polynomial identity rings.\n\nExample: formula_1 is a central polynomial for 2-by-2-matrices. Indeed, by the Cayley–Hamilton theorem, one has that formula_2 for any 2-by-2-matrices \"x\", \"y\".\n\n\n"}
{"id": "58157092", "url": "https://en.wikipedia.org/wiki?curid=58157092", "title": "Claudia Sagastizábal", "text": "Claudia Sagastizábal\n\nClaudia Alejandra Sagastizábal is an applied mathematician known for her research in convex optimization and energy management, and for her co-authorship of the book \"Numerical Optimization: Theoretical and Practical Aspects\". She is a researcher at the University of Campinas in Brazil. Since 2015 she has been editor-in-chief of the journal \"Set-Valued and Variational Analysis\".\n\nSagastizábal earned a degree in mathematics, astronomy and physics from the National University of Córdoba in Argentina in 1984. She completed a Ph.D. in 1993 at Pantheon-Sorbonne University in France; her dissertation, \"Quelques methodes numeriques d'optimization: Application en gestion de stocks\", was supervised by Claude Lemaréchal.\n\nWhile in France, she worked with Électricité de France on optimization problems involving electricity generation, a topic that has continued in her research since that time.\nShe moved to Brazil in 1997. Before joining the University of Campinas in 2017, she has also been affiliated with the Instituto Nacional de Matemática Pura e Aplicada and French Institute for Research in Computer Science and Automation, among other institutions.\n\nSagastizábal was an invited speaker at the 8th International Congress on Industrial and Applied Mathematics in 2015.\nShe was also an invited speaker on control theory and mathematical optimization at the 2018 International Congress of Mathematicians.\n\n"}
{"id": "7948184", "url": "https://en.wikipedia.org/wiki?curid=7948184", "title": "Computational engineering", "text": "Computational engineering\n\n\"Not to be confused with computer engineering.\"\n\nComputational science and engineering (CSE) is a relatively new discipline that deals with the development and application of computational models and simulations, often coupled with high-performance computing, to solve complex physical problems arising in engineering analysis and design (computational engineering) as well as natural phenomena (computational science). CSE has been described as the \"third mode of discovery\" (next to theory and experimentation). In many fields, computer simulation is integral and therefore essential to business and research. Computer simulation provides the capability to enter fields that are either inaccessible to traditional experimentation or where carrying out traditional empirical inquiries is prohibitively expensive. CSE should neither be confused with pure computer science, nor with computer engineering, although a wide domain in the former is used in CSE (e.g., certain algorithms, data structures, parallel programming, high performance computing) and some problems in the latter can be modeled and solved with CSE methods (as an application area).\n\nIt is typically offered as a masters or doctorate program at several institutions.\n\nComputational Science and Engineering methods and frameworks include:\nWith regard to computing, computer programming, algorithms, and parallel computing play a major role in CSE. The most widely used programming language in the scientific community is FORTRAN. Recently, C++ and C have increased in popularity over FORTRAN. Due to the wealth of legacy code in FORTRAN and its simpler syntax, the scientific computing community has been slow in completely adopting C++ as the lingua franca. Because of its very natural way of expressing mathematical computations, and its built-in visualization capacities, the proprietary language/environment MATLAB is also widely used, especially for rapid application development and model verification. Python along with external libraries (such as NumPy, SciPy, Matplotlib) has gain some popularity as a free and Copycenter alternative to MATLAB.\n\nComputational Science and Engineering finds diverse applications, including in:\n\n\n"}
{"id": "32212763", "url": "https://en.wikipedia.org/wiki?curid=32212763", "title": "Critical pair (logic)", "text": "Critical pair (logic)\n\nIn mathematical logic, a critical pair arises in term rewriting systems where rewrite rules overlap to yield two different terms. In more detail, (\"t\", \"t\") is a critical pair if there is a term \"t\" for which two different applications of a rewrite rule (either the same rule applied differently, or two different rules) yield the terms \"t\" and \"t\".\n\nFor example, in the term rewriting system with rules\nthe only critical pair is ⟨\"g\"(\"x\",\"z\"), \"f\"(\"x\",\"z\")⟩. Both of these terms can be derived from the term \"f\"(\"g\"(\"x\",\"y\"),\"z\") by applying a single rewrite rule.\n\nAs another example, consider the term rewriting system with the single rule\nBy applying this rule in two different ways to the term \"f\"(\"f\"(\"x\",\"x\"),\"x\"), we see that (\"f\"(\"x\",\"x\"), \"f\"(\"x\",\"x\")) is a (trivial) critical pair.\n\nWhen both sides of the critical pair can reduce to the same term, the critical pair is called \"convergent\". Where one side of the critical pair is identical to the other, the critical pair is called \"trivial\".\n\nIf the term rewriting system is not confluent, the critical pair may not converge, so critical pairs are potential sources where confluence will fail. In fact, the critical pair lemma states that a term rewriting system is weakly (a.k.a. locally) confluent if all critical pairs are convergent. Thus, to find out if a term rewriting system is weakly confluent, it suffices to test all critical pairs and see if they are convergent. This makes it possible to find out algorithmically if a term rewriting system is weakly confluent or not, given that one can algorithmically check if two terms converge.\n\nWeak confluence clearly implies convergent critical pairs: if any critical pair ⟨\"a\", \"b\"⟩ arises, then \"a\" and \"b\" have common reduct and thus the critical pair is convergent.\n\n\n"}
{"id": "5991396", "url": "https://en.wikipedia.org/wiki?curid=5991396", "title": "Cyclotomic unit", "text": "Cyclotomic unit\n\nIn mathematics, a cyclotomic unit (or circular unit) is a unit of an algebraic number field which is the product of numbers of the form (ζ − 1) for ζ an \"n\" root of unity and 0 < \"a\" < \"n\". Note that if \"n\" is the power of a prime ζ − 1 itself is not a unit; however the numbers (ζ − 1)/(ζ − 1) for (\"a\", \"n\") = 1, and ±ζ generate the group of cyclotomic units in this case (\"n\" power of a prime). \n\nThe cyclotomic units form a subgroup of finite index in the group of units of a cyclotomic field. The index of this subgroup of \"real\" cyclotomic units (those cyclotomic units in the maximal real subfield) within the full real unit group is equal to the class number of the maximal real subfield of the cyclotomic field. \n\nNote also that if \"n\" is a composite number, the subgroup of cyclotomic units generated by (ζ − 1)/(ζ − 1)with (\"a\", \"n\") = 1 is not of finite index in general. \n\nThe cyclotomic units satisfy \"distribution relations\". Let \"a\" be a rational number prime to \"p\" and let \"g\" denote exp(2πi\"a\")−1. Then for \"a\"≠ 0 we have formula_1.\n\nUsing these distribution relations and the symmetry relation ζ − 1 = -ζ (ζ − 1) a basis \"B\" of the cyclotomic units can be constructed with the property that \n\"B\" ⊆ \"B\" for \"d\" | \"n\". \n\n\n"}
{"id": "18355895", "url": "https://en.wikipedia.org/wiki?curid=18355895", "title": "Davenport–Schmidt theorem", "text": "Davenport–Schmidt theorem\n\nIn mathematics, specifically the area of Diophantine approximation, the Davenport–Schmidt theorem tells us how well a certain kind of real number can be approximated by another kind. Specifically it tells us that we can get a good approximation to irrational numbers that are not quadratic by using either quadratic irrationals or simply rational numbers. It is named after Harold Davenport and Wolfgang M. Schmidt.\n\nGiven a number α which is either rational or a quadratic irrational, we can find unique integers \"x\", \"y\", and \"z\" such that \"x\", \"y\", and \"z\" are not all zero, the first non-zero one among them is positive, they are relatively prime, and we have\n\nIf α is a quadratic irrational we can take \"x\", \"y\", and \"z\" to be the coefficients of its minimal polynomial. If α is rational we will have \"x\" = 0. With these integers uniquely determined for each such α we can define the \"height\" of α to be\n\nThe theorem then says that for any real number ξ which is neither rational nor a quadratic irrational, we can find infinitely many real numbers α which \"are\" rational or quadratic irrationals and which satisfy\n\nwhere \"C\" is any real number satisfying \"C\" > 160/9.\n\nWhile the theorem is related to Roth's theorem, its real use lies in the fact that it is effective, in the sense that the constant \"C\" can be worked out for any given ξ.\n\n"}
{"id": "29843595", "url": "https://en.wikipedia.org/wiki?curid=29843595", "title": "DexNet", "text": "DexNet\n\nDex-net is a robotic manipulator. It uses a Grasp Quality Convolutional Neural Network to learn how to grasp unusually shaped objects.\n\nDex-net was developed by University of California, Berkeley professor Ken Goldberg and graduate student Jeff Mahler.\n\nDex-net includes a high-resolution 3-D sensor and two arms, each controlled by a different neural network. One arm is equipped with a conventional robot gripper and another with a suction system. The robot’s software scans an object and then asks both neural networks to decide, on the fly, whether to grab or suck a particular object. It runs on an off-the-shelf industrial machine made by Swiss robotics company ABB.\n\nThe software learns by attempting to pick up objects in a virtual environment. Dex-Net can generalize from an object it has seen before to a new one. The robot can \"nudge\" such virtual objects to examine it if it is unsure how to grasp it. The trial data set was 6.7 million point clouds, grasps and analytic grasp metrics generated from thousands of 3D models. Grasps are defined as a gripper's planar position, angle and depth relative to an RGB-D sensor.\n\nA metric called \"mean picks per hour\" (MPPH) is calculated by multiplying the average time per pick and the average probability of success for a specific set of objects. The new metric allows labs working on picking robots to compare their results.\n\nHumans are capable of between 400 and 600 MPPH. In a contest organized by Amazon recently, the best robots were capable of between 70 and 95. Dex-net has achieved 200 to 300.\n"}
{"id": "221519", "url": "https://en.wikipedia.org/wiki?curid=221519", "title": "Differential form", "text": "Differential form\n\nIn the mathematical fields of differential geometry and tensor calculus, differential forms are an approach to multivariable calculus that is independent of coordinates. Differential forms provide a unified approach to define integrands over curves, surfaces, volumes, and higher-dimensional manifolds. The modern notion of differential forms was pioneered by Élie Cartan. It has many applications, especially in geometry, topology and physics.\n\nFor instance, the expression from one-variable calculus is an example of a -form, and can be integrated over an interval in the domain of :\nSimilarly, the expression is a -form that has a surface integral over an oriented surface :\nThe symbol denotes the exterior product, sometimes called the \"wedge product\", of two differential forms. Likewise, a -form represents a volume element that can be integrated over a region of space. In general, a -form is an object that may be integrated over -dimensional sets, and is homogeneous of degree in the coordinate differentials.\n\nThe algebra of differential forms is organized in a way that naturally reflects the orientation of the domain of integration. There is an operation on differential forms known as the exterior derivative that, when acting on a -form, produces a -form. This operation extends the differential of a function, and is directly related to the divergence and the curl of a vector field in a manner that makes the fundamental theorem of calculus, the divergence theorem, Green's theorem, and Stokes' theorem special cases of the same general result, known in this context also as the generalized Stokes' theorem. In a deeper way, this theorem relates the topology of the domain of integration to the structure of the differential forms themselves; the precise connection is known as de Rham's theorem.\n\nThe general setting for the study of differential forms is on a differentiable manifold. Differential -forms are naturally dual to vector fields on a manifold, and the pairing between vector fields and -forms is extended to arbitrary differential forms by the interior product. The algebra of differential forms along with the exterior derivative defined on it is preserved by the pullback under smooth functions between two manifolds. This feature allows geometrically invariant information to be moved from one space to another via the pullback, provided that the information is expressed in terms of differential forms. As an example, the change of variables formula for integration becomes a simple statement that an integral is preserved under pullback.\n\nDifferential forms are part of the field of differential geometry, influenced by linear algebra. Although the notion of a differential is quite old, the initial attempt at an algebraic organization of differential forms is usually credited to Élie Cartan with reference to his 1899 paper. Some aspects of the exterior algebra of differential forms appears in Hermann Grassmann's 1844 work, \"Die Lineale Ausdehnungslehre, ein neuer Zweig der Mathematik\" [The Theory of Linear Extension, a New Branch of Mathematics]\n\nDifferential forms provide an approach to multivariable calculus that is independent of coordinates.\n\nA differential -form can be integrated over a manifold of dimension . A differential one-form can be thought of as measuring an infinitesimal (oriented) length, or one-dimensional density. A differential two-form can be thought of as measuring an infinitesimal (oriented) area, or two-dimensional density. And so on.\n\nIntegration of differential forms is well-defined only on oriented manifolds. An example of a one dimensional manifold is an interval , and intervals can be given an orientation: they are positively oriented if , and negatively oriented otherwise. If then the integral of the differential one-form over the interval (with its natural positive orientation) is\nwhich is the negative of the integral of the same differential form over the same interval, when equipped with the opposite orientation. That is:\nThis gives a geometrical context to the conventions for one-dimensional integrals, that the sign changes when the orientation of the interval is reversed. A standard explanation of this in one-variable integration theory is that, when the limits of integration are in the opposite order (), the increment is negative. The integrals are negatives of one another because the oriented lengths \"dx\" have opposite directions.\n\nMore generally, an -form is an oriented density that can be integrated over an -dimensional oriented manifold. (For example, a -form can be integrated over an oriented curve, a -form can be integrated over an oriented surface, etc.) If is an oriented -dimensional manifold, and is the same manifold with opposed orientation and is an -form, then one has:\nThese conventions correspond to interpreting the integrand as a differential form, integrated over a chain. In measure theory, by contrast, one interprets the integrand as a function with respect to a measure and integrates over a subset , without any notion of orientation; one writes formula_6 to indicate integration over a subset . This is a minor distinction in one dimension, but becomes subtler on higher-dimensional manifolds; see below for details.\n\nMaking the notion of an oriented density precise, and thus of a differential form, involves the exterior algebra. The basic -forms are the differentials of the coordinates: , ..., . Each of these represents a covector that measures a small displacement in the corresponding coordinate direction. A general -form is a linear combination of these differentials\nwhere the formula_8 are functions of the coordinates. A differential -form is integrated along an oriented curve as a line integral.\n\nThe basic two-forms are expressions , where . This represents an infinitesimal oriented square parallel to the –-plane. A general two-form is a linear combination of these, and it is integrated just like a surface integral.\n\nA fundamental operation defined on differential forms is the exterior product (the symbol is the wedge ). This is similar to the cross product from vector calculus, in that it is an alternating product. For instance,\nbecause the square whose first side is and second side is is to be regarded as having the opposite orientation as the square whose first side is and whose second side is . The exterior product allows higher dimensional differential forms to be built out of lower-dimensional ones, in much the same way that the cross product in vector calculus allows one to compute the area vector of a parallelogram from vectors pointing up the two sides.\n\nIn addition to the exterior product, there is also the exterior derivative operator . Like the differential of a function, the exterior derivative gives a way of quantifying a differential form's sensitivity to change. In , if is a -form, then is a -form defined by\n\nwith extension to general -forms occurring linearly.\n\nThis more general approach allows for a more natural coordinate-free approach to integration on manifolds. It also allows for a natural generalization of the fundamental theorem of calculus (see ).\n\nLet be an open set in . A differential -form (\"zero-form\") is defined to be a smooth function on . If is any vector in , then has a directional derivative , which is another function on whose value at a point is the rate of change (at ) of in the direction:\n\nIn particular, if is the th coordinate vector then is the partial derivative of with respect to the th coordinate function, i.e., , where , , ..., are the coordinate functions on . By their very definition, partial derivatives depend upon the choice of coordinates: if new coordinates , , ..., are introduced, then\n\nThe first idea leading to differential forms is the observation that is a linear function of :\n\nfor any vectors , and any real number . This linear map from to is denoted and called the derivative of at . Thus . The object can be viewed as a function on , whose value at is not a real number, but the linear map . This is just the usual Fréchet derivative – an example of a differential -form.\n\nSince any vector is a linear combination of its components, is uniquely determined by for each and each , which are just the partial derivatives of on . Thus provides a way of encoding the partial derivatives of . It can be decoded by noticing that the coordinates , , ..., are themselves functions on , and so define differential -forms , , ..., . Let . Since , the Kronecker delta function, it follows that\n\nThe meaning of this expression is given by evaluating both sides at an arbitrary point : on the right hand side, the sum is defined \"pointwise\", so that\nApplying both sides to , the result on each side is the th partial derivative of at . Since and were arbitrary, this proves the formula .\n\nMore generally, for any smooth functions and on , we define the differential -form pointwise by\n\nfor each . Any differential -form arises this way, and by using it follows that any differential -form on may be expressed in coordinates as\n\nfor some smooth functions on .\n\nThe second idea leading to differential forms arises from the following question: given a differential -form on , when does there exist a function on such that ? The above expansion reduces this question to the search for a function whose partial derivatives are equal to given functions . For , such a function does not always exist: any smooth function satisfies\n\nso it will be impossible to find such an unless\n\nfor all and .\n\nThe skew-symmetry of the left hand side in and suggests introducing an antisymmetric product on differential -forms, the exterior product, so that these equations can be combined into a single condition\n\nwhere is defined so that:\n\nThis is an example of a differential -form. This -form is called the exterior derivative of . It is given by\n\nTo summarize: is a necessary condition for the existence of a function with .\n\nDifferential -forms, -forms, and -forms are special cases of differential forms. For each , there is a space of differential -forms, which can be expressed in terms of the coordinates as\n\nfor a collection of functions . Antisymmetry, which was already present for -forms, makes it possible to restrict the sum to those sets of indices for which .\n\nDifferential forms can be multiplied together using the exterior product, and for any differential -form , there is a differential -form called the exterior derivative of .\n\nDifferential forms, the exterior product and the exterior derivative are independent of a choice of coordinates. Consequently, they may be defined on any smooth manifold . One way to do this is cover with coordinate charts and define a differential -form on to be a family of differential -forms on each chart which agree on the overlaps. However, there are more intrinsic definitions which make the independence of coordinates manifest.\n\nLet be a smooth manifold. A smooth differential form of degree is a smooth section of the th exterior power of the cotangent bundle of . The set of all differential -forms on a manifold is a vector space, often denoted .\n\nThe definition of a differential form may be restated as follows. At any point , a -form defines an element\nwhere is the tangent space to at and is its dual space. This space is naturally isomorphic to the fiber at of the dual bundle of the th exterior power of the tangent bundle of . That is, is also a linear functional\n\nBy the universal property of exterior powers, this is equivalently an alternating multilinear map\nConsequently, a differential -form may be evaluated against any -tuple of tangent vectors to the same point of . For example, a differential -form assigns to each point a linear functional on . In the presence of an inner product on (induced by a Riemannian metric on ), may be represented as the inner product with a tangent vector . Differential -forms are sometimes called covariant vector fields, covector fields, or \"dual vector fields\", particularly within physics.\n\nThe exterior algebra may be embedded in the tensor algebra by means of the alternation map. The alternation map is defined as a mapping \nFor a tensor at a point ,\nwhere is the symmetric group on elements. The alternation map is constant on the cosets of the ideal in the tensor algebra generated by the symmetric 2-forms, and therefore descends to an embedding\n\nThis map exhibits as a totally antisymmetric covariant tensor field of rank . The differential forms on are in one-to-one correspondence with such tensor fields.\n\nAs well as the addition and multiplication by scalar operations which arise from the vector space structure, there are several other standard operations defined on differential forms. The most important operations are the exterior product of two differential forms, the exterior derivative of a single differential form, the interior product of a differential form and a vector field, the Lie derivative of a differential form with respect to a vector field and the covariant derivative of a differential form with respect to a vector field on a manifold with a defined connection.\n\nThe exterior product of a -form and an -form is a ()-form denoted . At each point of the manifold , the forms and are elements of an exterior power of the tangent space at . When the exterior algebra is viewed as a quotient of the tensor algebra, the exterior product corresponds to the tensor product (modulo the equivalence relation defining the exterior algebra).\n\nThe antisymmetry inherent in the exterior algebra means that when is viewed as a multilinear functional, it is alternating. However, when the exterior algebra embedded a subspace of the tensor algebra by means of the alternation map, the tensor product is not alternating. There is an explicit formula which describes the exterior product in this situation. The exterior product is\nThis description is useful for explicit computations. For example, if , then is the -form whose value at a point is the alternating bilinear form defined by\nfor .\n\nThe exterior product is bilinear: If , , and are any differential forms, and if is any smooth function, then\n\nIt is \"skew commutative\" (also known as \"graded commutative\"), meaning that it satisfies a variant of anticommutativity that depends on the degrees of the forms: if is a -form and is an -form, then\n\nOn a Riemannian manifold, or more generally a pseudo-Riemannian manifold, the metric defines a fibre-wise isomorphism of the tangent and cotangent spaces. This makes it possible to convert vector fields to covector fields and vice versa. It also enables the definition of additional operations such as the Hodge star operator formula_34 and the codifferential formula_35, which has degree and is adjoint to the exterior differential .\n\nOn a pseudo-Riemannian manifold, -forms can be identified with vector fields; vector fields have additional distinct algebraic structures, which are listed here for context and to avoid confusion.\n\nFirstly, each (co)tangent space generates a Clifford algebra, where the product of a (co)vector with itself is given by the value of a quadratic form – in this case, the natural one induced by the metric. This algebra is \"distinct\" from the exterior algebra of differential forms, which can be viewed as a Clifford algebra where the quadratic form vanishes (since the exterior product of any vector with itself is zero). Clifford algebras are thus non-anti-commutative (\"quantum\") deformations of the exterior algebra. They are studied in geometric algebra.\n\nAnother alternative is to consider vector fields as derivations. The (noncommutative) algebra of differential operators they generate is the Weyl algebra and is a noncommutative (\"quantum\") deformation of the \"symmetric\" algebra in the vector fields.\n\nOne important property of the exterior derivative is that . This means that the exterior derivative defines a cochain complex:\n\nThis complex is called the de Rham complex, and its cohomology is by definition the de Rham cohomology of . By the Poincaré lemma, the de Rham complex is locally exact except at . The kernel at is the space of locally constant functions on . Therefore, the complex is a resolution of the constant sheaf formula_37, which in turn implies a form of de Rham's theorem: de Rham cohomology computes the sheaf cohomology of formula_37.\n\nSuppose that is smooth. The differential of is a smooth map between the tangent bundles of and . This map is also denoted and called the pushforward. For any point and any , there is a well-defined pushforward vector in . However, the same is not true of a vector field. If is not injective, say because has two or more preimages, then the vector field may determine two or more distinct vectors in . If is not surjective, then will be a point at which does not determine any tangent vector at all. Since a vector field on determines, by definition, a unique tangent vector at every point of , the pushforward of a vector field does not always exist.\n\nBy contrast, it is always possible to pull back a differential form. A differential form on may be viewed as a linear functional on each tangent space. Precomposing this functional with the differential defines a linear functional on each tangent space of and therefore a differential form on . The existence of pullbacks is one of the key features of the theory of differential forms. It leads to the existence of pullback maps in other situations, such as pullback homomorphisms in de Rham cohomology.\n\nFormally, let be smooth, and let be a smooth -form on . Then there is a differential form on , called the pullback of , which captures the behavior of as seen relative to . To define the pullback, fix a point of and tangent vectors , ..., to at . The pullback of is defined by the formula\n\nThere are several more abstract ways to view this definition. If is a -form on , then it may be viewed as a section of the cotangent bundle of . Using to denote a dual map, the dual to the differential of is . The pullback of may be defined to be the composite\nThis is a section of the cotangent bundle of and hence a differential -form on . In full generality, let formula_41 denote the th exterior power of the dual map to the differential. Then the pullback of a -form is the composite\n\nAnother abstract way to view the pullback comes from viewing a -form as a linear functional on tangent spaces. From this point of view, is a morphism of vector bundles\nwhere is the trivial rank one bundle on . The composite map\ndefines a linear functional on each tangent space of , and therefore it factors through the trivial bundle . The vector bundle morphism formula_45 defined in this way is .\n\nPullback respects all of the basic operations on forms. If and are forms and is a real number, then\n\nThe pullback of a form can also be written in coordinates. Assume that , ..., are coordinates on , that , ..., are coordinates on , and that these coordinate systems are related by the formulas for all . Locally on , can be written as\n\nwhere, for each choice of , ..., , is a real-valued function of , ..., . Using the linearity of pullback and its compatibility with exterior product, the pullback of has the formula\n\nEach exterior derivative can be expanded in terms of , ..., . The resulting -form can be written using Jacobian matrices:\n\nHere, formula_50 denotes the determinant of the matrix whose entries are formula_51, formula_52.\n\nA differential -form can be integrated over an oriented -dimensional manifold. When the -form is defined on an -dimensional manifold with , then the -form can be integrated over oriented -dimensional submanifolds. If , this is just evaluation of a function at points. Other values of correspond to line integrals, surface integrals, volume integrals, and so on. There are several equivalent ways to formally define the integral of a differential form, all of which depend on reducing to the case of Euclidean space.\n\nLet be an open subset of . Give its standard orientation and the restriction of that orientation. Every smooth -form on has the form\nfor some smooth function . Such a function has an integral in the usual Riemann or Lebesgue sense. This allows us to define the integral of to be the integral of :\nFixing an orientation is necessary for this to be well-defined. The skew-symmetry of differential forms means that the integral of, say, must be the negative of the integral of . Riemann and Lebesgue integrals cannot see this dependence on the ordering of the coordinates, so they leave the sign of the integral undetermined. The orientation resolves this ambiguity.\n\nLet be an -manifold and an -form on . First, assume that there is a parametrization of by an open subset of Euclidean space. That is, assume that there exists a diffeomorphism\nwhere . Give the orientation induced by . Then defines the integral of over to be the integral of over . In coordinates, this has the following expression. Fix a chart on with coordinates . Then\nSuppose that is defined by\nThen the integral may be written in coordinates as\nwhere\nis the determinant of the Jacobian. The Jacobian exists because is differentiable.\n\nIn general, an -manifold cannot be parametrized by an open subset of . But such a parametrization is always possible locally, so it is possible to define integrals over arbitrary manifolds by defining them as sums of integrals over collections of local parametrizations. Moreover, it is also possible to define parametrizations of -dimensional subsets for , and this makes it possible to define integrals of -forms. To make this precise, it is convenient to fix a standard domain in , usually a cube or a simplex. A -chain is a formal sum of smooth embeddings . That is, it is a collection of smooth embeddings, each of which is assigned an integer multiplicity. Each smooth embedding determines a -dimensional submanifold of . If the chain is\nthen the integral of a -form over is defined to be the sum of the integrals over the terms of :\n\nThis approach to defining integration does not assign a direct meaning to integration over the whole manifold . However, it is still possible to assign such a meaning indirectly because every smooth manifold may be smoothly triangulated in an essentially unique way, and the integral over may be defined to be the integral over the chain determined by a triangulation.\n\nThere is another approach, expounded in , which does directly assign a meaning to integration over , but this approach requires fixing an orientation of . The integral of an -form on an -dimensional manifold is defined by working in charts. Suppose first that is supported on a single positively oriented chart. On this chart, it may be pulled back to an -form on an open subset of . Here, the form has a well-defined Riemann or Lebesgue integral as before. The change of variables formula and the assumption that the chart is positively oriented together ensure that the integral of is independent of the chosen chart. In the general case, use a partition of unity to write as a sum of -forms, each of which is supported in a single positively oriented chart, and define the integral of to be the sum of the integrals of each term in the partition of unity.\n\nIt is also possible to integrate -forms on oriented -dimensional submanifolds using this more intrinsic approach. The form is pulled back to the submanifold, where the integral is defined using charts as before. For example, given a path , integrating a -form on the path is simply pulling back the form to a form on , and this integral is the integral of the function on the interval.\n\nFubini's theorem states that the integral over a set that is a product may be computed as an iterated integral over the two factors in the product. This suggests that the integral of a differential form over a product ought to be computable as an iterated integral as well. The geometric flexibility of differential forms ensures that this is possible not just for products, but in more general situations as well. Under some hypotheses, it is possible to integrate along the fibers of a smooth map, and the analog of Fubini's theorem is the case where this map is the projection from a product to one of its factors.\n\nBecause integrating a differential form over a submanifold requires fixing an orientation, a prerequisite to integration along fibers is the existence of a well-defined orientation on those fibers. Let and be two orientable manifolds of pure dimensions and , respectively. Suppose that is a surjective submersion. This implies that each fiber is -dimensional and that, around each point of , there is a chart on which looks like the projection from a product onto one of its factors. Fix and set . Suppose that\nand that does not vanish. Following , there is a unique\nwhich may be thought of as the fibral part of with respect to . More precisely, define to be the inclusion. Then is defined by the property that,\nwhere\nis any -covector for which\nThe form may also be notated .\n\nMoreover, for fixed , varies smoothly with respect to . That is, suppose that\nis a smooth section of the projection map; we say that is a smooth differential -form on along . Then there is a smooth differential -form on such that, at each ,\nThis form is denoted . The same construction works if is an -form in a neighborhood of the fiber, and the same notation is used. A consequence is that each fiber is orientable. In particular, a choice of orientation forms on and defines an orientation of every fiber of .\n\nThe analog of Fubini's theorem is as follows. As before, and are two orientable manifolds of pure dimensions and , and is a surjective submersion. Fix orientations of and , and give each fiber of the induced orientation. Let be an -form on , and let be an -form on that is almost everywhere positive with respect to the orientation of . Then, for almost every , the form is a well-defined integrable form on . Moreover, there is an integrable -form on defined by\nDenote this form by\nThen proves the generalized Fubini formula\n\nIt is also possible to integrate forms of other degrees along the fibers of a submersion. Assume the same hypotheses as before, and let be a compactly supported -form on . Then there is a -form on which is the result of integrating along the fibers of . The form is defined by specifying, at each , how pairs against each -vector at , and the value of that pairing is an integral over that depends only on , , and the orientations of and . More precisely, at each , there is an isomorphism\ndefined by the interior product\nIf , then a -vector at determines an -covector at by pullback:\nEach of these covectors has an exterior product against , so there is an -form on along defined by\nThis form depends on the orientation of but not the choice of . Then the -form is uniquely defined by the property\nand is smooth . This form also denoted and called the integral of along the fibers of \"f\". Integration along fibers is important for the construction of Gysin maps in de Rham cohomology.\n\nIntegration along fibers satisfies the projection formula . If is any -form on , then\n\nThe fundamental relationship between the exterior derivative and integration is given by the Stokes' theorem: If is an ()-form with compact support on and denotes the boundary of with its induced orientation, then\n\nA key consequence of this is that \"the integral of a closed form over homologous chains is equal\": If is a closed -form and and are -chains that are homologous (such that is the boundary of a ()-chain ), then formula_79, since the difference is the integral formula_80.\n\nFor example, if is the derivative of a potential function on the plane or , then the integral of over a path from to does not depend on the choice of path (the integral is ), since different paths with given endpoints are homotopic, hence homologous (a weaker condition). This case is called the gradient theorem, and generalizes the fundamental theorem of calculus. This path independence is very useful in contour integration.\n\nThis theorem also underlies the duality between de Rham cohomology and the homology of chains.\n\nOn a \"general\" differentiable manifold (without additional structure), differential forms \"cannot\" be integrated over subsets of the manifold; this distinction is key to the distinction between differential forms, which are integrated over chains or oriented submanifolds, and measures, which are integrated over subsets. The simplest example is attempting to integrate the -form over the interval . Assuming the usual distance (and thus measure) on the real line, this integral is either or , depending on \"orientation:\" formula_81, while formula_82. By contrast, the integral of the \"measure\" on the interval is unambiguously (formally, the integral of the constant function with respect to this measure is ). Similarly, under a change of coordinates a differential -form changes by the Jacobian determinant , while a measure changes by the \"absolute value\" of the Jacobian determinant, , which further reflects the issue of orientation. For example, under the map on the line, the differential form pulls back to ; orientation has reversed; while the Lebesgue measure, which here we denote , pulls back to ; it does not change.\n\nIn the presence of the additional data of an \"orientation\", it is possible to integrate -forms (top-dimensional forms) over the entire manifold or over compact subsets; integration over the entire manifold corresponds to integrating the form over the fundamental class of the manifold, . Formally, in the presence of an orientation, one may identify -forms with densities on a manifold; densities in turn define a measure, and thus can be integrated .\n\nOn an orientable but not oriented manifold, there are two choices of orientation; either choice allows one to integrate -forms over compact subsets, with the two choices differing by a sign. On non-orientable manifold, -forms and densities cannot be identified —notably, any top-dimensional form must vanish somewhere (there are no volume forms on non-orientable manifolds), but there are nowhere-vanishing densities— thus while one can integrate densities over compact subsets, one cannot integrate -forms. One can instead identify densities with top-dimensional pseudoforms.\n\nEven in the presence of an orientation, there is in general no meaningful way to integrate -forms over subsets for because there is no consistent way to use the ambient orientation to orient -dimensional subsets. Geometrically, a -dimensional subset can be turned around in place, yielding the same subset with the reserve orientation; for example, the horizontal axis in a plane can be rotated by a half-circle. Compare the Gram determinant of a set of vectors in an -dimensional space, which, unlike the determinant of vectors, is always positive, corresponding to a squared number. An orientation of a -submanifold is therefore extra data not derivable from the ambient manifold.\n\nOn a Riemannian manifold, one may define a -dimensional Hausdorff measure for any (integer or real), which may be integrated over -dimensional subsets of the manifold. A function times this Hausdorff measure can then be integrated over -dimensional subsets, providing a measure-theoretic analog to integration of -forms. The -dimensional Hausdorff measure yields a density, as above.\n\nThe differential form analog of a distribution or generalized function is called a current. The space of -currents on is the dual space to an appropriate space of differential -forms. Currents play the role of generalized domains of integration, similar to but even more flexible than chains.\n\nDifferential forms arise in some important physical contexts. For example, in Maxwell's theory of electromagnetism, the Faraday 2-form, or electromagnetic field strength, is\n\nwhere the are formed from the electromagnetic fields formula_84 and formula_85; e.g., , , or equivalent definitions.\n\nThis form is a special case of the curvature form on the principal bundle on which both electromagnetism and general gauge theories may be described. The connection form for the principal bundle is the vector potential, typically denoted by , when represented in some gauge. One then has\n\nThe current -form is\n\nwhere are the four components of the current density. (Here it is a matter of convention to write instead of , i.e. to use capital letters, and to write instead of . However, the vector rsp. tensor components and the above-mentioned forms have different physical dimensions. Moreover, by decision of an international commission of the International Union of Pure and Applied Physics, the magnetic polarization vector is called formula_88 since several decades, and by some publishers , i.e. the same name is used for different quantities.)\n\nUsing the above-mentioned definitions, Maxwell's equations can be written very compactly in geometrized units as\n\nwhere formula_90 denotes the Hodge star operator. Similar considerations describe the geometry of gauge theories in general.\n\nThe -form formula_91, which is dual to the Faraday form, is also called Maxwell 2-form.\n\nElectromagnetism is an example of a gauge theory. Here the Lie group is , the one-dimensional unitary group, which is in particular abelian. There are gauge theories, such as Yang–Mills theory, in which the Lie group is not abelian. In that case, one gets relations which are similar to those described here. The analog of the field in such theories is the curvature form of the connection, which is represented in a gauge by a Lie algebra-valued one-form . The Yang–Mills field is then defined by\n\nIn the abelian case, such as electromagnetism, , but this does not hold in general. Likewise the field equations are modified by additional terms involving exterior products of and , owing to the structure equations of the gauge group.\n\nNumerous minimality results for complex analytic manifolds are based on the Wirtinger inequality for 2-forms. A succinct proof may be found in Herbert Federer's classic text \"Geometric Measure Theory\". The Wirtinger inequality is also a key ingredient in Gromov's inequality for complex projective space in systolic geometry.\n\n\n\n"}
{"id": "9754647", "url": "https://en.wikipedia.org/wiki?curid=9754647", "title": "Distributive homomorphism", "text": "Distributive homomorphism\n\nA congruence θ of a join-semilattice \"S\" is \"monomial\", if the θ-equivalence class of any element of \"S\" has a largest element. We say that θ is \"distributive\", if it is a join, in the congruence lattice Con \"S\" of \"S\", of monomial join-congruences of \"S\".\n\nThe following definition originates in Schmidt's 1968 work and was subsequently adjusted by Wehrung.\n\nDefinition (weakly distributive homomorphisms). A homomorphism \n\"μ : S → T\" between join-semilattices \"S\" and \"T\" is \"weakly distributive\", if for all \"a, b\" in \"S\" and all \"c\" in \"T\" such that \"μ(c)≤ a ∨ b\", there are elements \"x\" and \"y\" of \"S\" such that \"c≤ x ∨ y\", \"μ(x)≤ a\", and \"μ(y)≤ b\".\n\nExamples:\n\n(1) For an algebra \"B\" and a \"reduct\" \"A\" of \"B\" (that is, an algebra with same underlying set as \"B\" but whose set of operations is a subset of the one of \"B\"), the canonical (∨, 0)-homomorphism from Con A to Con B is weakly distributive. Here, Con A denotes the (∨, 0)-semilattice of all compact congruences of \"A\".\n\n(2) For a convex sublattice \"K\" of a lattice \"L\", the canonical (∨, 0)-homomorphism from Con \"K\" to Con \"L\" is weakly distributive.\n\nE.T. Schmidt, \"Zur Charakterisierung der Kongruenzverbände der Verbände\", Mat. Casopis Sloven. Akad. Vied. 18 (1968), 3--20.\n\nF. Wehrung, \"A uniform refinement property for congruence lattices\", Proc. Amer. Math. Soc. 127, no. 2 (1999), 363–370.\n\nF. Wehrung, \"A solution to Dilworth's congruence lattice problem\", preprint 2006.\n"}
{"id": "4725226", "url": "https://en.wikipedia.org/wiki?curid=4725226", "title": "Frege's theorem", "text": "Frege's theorem\n\nIn metalogic and metamathematics, Frege's theorem is a metatheorem that states that the Peano axioms of arithmetic can be derived in second-order logic from Hume's principle. It was first proven, informally, by Gottlob Frege in his \"Die Grundlagen der Arithmetik\" (\"The Foundations of Arithmetic\"), published in 1884, and proven more formally in his \"Grundgesetze der Arithmetik\" (\"Basic Laws of Arithmetic\"), published in two volumes, in 1893 and 1903. The theorem was re-discovered by Crispin Wright in the early 1980s and has since been the focus of significant work. It is at the core of the philosophy of mathematics known as neo-logicism (at least of the Scottish School variety).\n\nIn \"The Foundations of Arithmetic\" (1884), and later, in \"Basic Laws of Arithmetic\" (vol. 1, 1893; vol. 2, 1903), Frege attempted to derive all of the laws of arithmetic from axioms he asserted as logical (see logicism). Most of these axioms were carried over from his \"Begriffsschrift\"; the one truly new principle was one he called the Basic Law V (now known as the axiom schema of unrestricted comprehension): the \"value-range\" of the function \"f\"(\"x\") is the same as the \"value-range\" of the function \"g\"(\"x\") if and only if ∀\"x\"[\"f\"(\"x\") = \"g\"(\"x\")]. However, not only did Basic Law V fail to be a logical proposition, but the resulting system proved to be inconsistent, because it was subject to Russell's paradox. The inconsistency in Frege's \"Grundgesetze\" overshadowed Frege's achievement: according to Edward Zalta, the \"Grundgesetze\" \"contains all the essential steps of a valid proof (in second-order logic) of the fundamental propositions of arithmetic from a single consistent principle.\" This achievement has become known as Frege's theorem.\n\nIn propositional logic, Frege's theorems refers to this tautology:\n\nThe truth table to the right gives a proof. For all possible assignments of \"false\" () or \"true\" () to \"P\", \"Q\", and \"R\" (columns 1, 3, 5), each subformula is evaluated according to the rules for material conditional, the result being shown below its main operator. Column 6 shows that the whole formula evaluates to \"true\" in every case, i.e. that it is a tautology. In fact, its antecedent (column 2) and its consequent (column 10) are even equivalent.\n\n"}
{"id": "271143", "url": "https://en.wikipedia.org/wiki?curid=271143", "title": "Fresnel integral", "text": "Fresnel integral\n\nFresnel integrals, \"S\"(\"x\") and \"C\"(\"x\"), are two transcendental functions named after Augustin-Jean Fresnel that are used in optics, which are closely related to the error function (erf). They arise in the description of near-field Fresnel diffraction phenomena and are defined through the following integral representations:\n\nThe simultaneous parametric plot of \"S\"(\"x\") and \"C\"(\"x\") is the Euler spiral (also known as the Cornu spiral or clothoid). Recently, they have been used in the design of highways and other engineering projects.\n\nThe Fresnel integrals admit the following power series expansions that converge for all \"x\":\n\nSome authors, including Abramowitz and Stegun, (eqs 7.3.1 – 7.3.2) use formula_4 for the argument of the integrals defining \"S\"(\"x\") and \"C\"(\"x\"), which changes their limits to 0.5 and the arc length for the first spiral turn formula_5 to 2 (at formula_6), all smaller by a factor formula_7. The alternative functions are also called \"Normalized Fresnel integrals\".\n\nThe Euler spiral, also known as Cornu spiral or clothoid, is the curve generated by a parametric plot of formula_8 against formula_9. The Cornu spiral was created by Marie Alfred Cornu as a nomogram for diffraction computations in science and engineering.\n\nFrom the definitions of Fresnel integrals, the infinitesimals formula_10 and formula_11 are thus:\n\nThus the length of the spiral measured from the origin can be expressed as\n\nThat is, the parameter formula_15 is the curve length measured from the origin formula_16, and the Euler spiral has infinite length. The vector formula_17 also expresses the unit tangent vector along the spiral, giving formula_18. Since \"t\" is the curve length, the curvature formula_19 can be expressed as\n\nAnd the rate of change of curvature with respect to the curve length is\n\nAn Euler spiral has the property that its curvature at any point is proportional to the distance along the spiral, measured from the origin. This property makes it useful as a transition curve in highway and railway engineering: If a vehicle follows the spiral at unit speed, the parameter formula_15 in the above derivatives also represents the time. That is, a vehicle following the spiral at constant speed will have a constant rate of angular acceleration.\n\nSections from Euler spirals are commonly incorporated into the shape of roller-coaster loops to make what are known as clothoid loops.\n\n\n\n\nThe integrals defining \"C\"(\"x\") and \"S\"(\"x\") cannot be evaluated in the closed form in terms of elementary functions, except in special cases. The limits of these functions as \"x\" goes to infinity are known:\n\nThe limits of and as the argument tends to infinity can be found by the methods of complex analysis. This uses the contour integral of the function\n\naround the boundary of the sector-shaped region in the complex plane formed by the positive -axis, the bisector of the first quadrant with , and a circular arc of radius centered at the origin.\n\nAs goes to infinity, the integral along the circular arc tends to , the integral along the real axis tends to the half Gaussian integral\n\nNote too that because the integrand is an entire function on the complex plane, its integral along the whole contour is zero. Overall, we must have\n\nwhere formula_31 denotes the bisector of the first quadrant, as in the diagram. To evaluate the right hand side, parametrize the bisector as formula_32 where r ranges from 0 to formula_33. Note that the square of this expression is just formula_34. Therefore, substitution gives the right hand side as\n\nUsing Euler's formula to take real and imaginary parts of formula_36 gives this as\n\nwhere we have written formula_38 to emphasize that the original Gaussian integral's value is completely real with zero imaginary part. Letting formula_39 and then equating real and imaginary parts produces the following system of two equations in the two unknowns formula_40:\n\nSolving this for formula_42 and formula_43 gives the desired result.\n\nThe integral\n\nis a confluent hypergeometric function and also an incomplete gamma function \n\nwhich reduces to Fresnel integrals if real or imaginary parts are taken:\n\nThe leading term in the asymptotic expansion is\n\nand therefore\n\nFor \"m\" = 0, the imaginary part of this equation in particular is\n\nwith the left-hand side converging for \"a\" > 1 and the right-hand side being its analytical extension to the whole plane less where lie the poles of formula_50.\n\nThe Kummer transformation of the confluent hypergeometric function is\n\nwith\n\nThe Fresnel integrals were originally used in the calculation of the electromagnetic field intensity in an environment where light bends around opaque objects. More recently, they have been used in the design of highways and railways, specifically their curvature transition zones, see track transition curve. Other applications are roller coasters or calculating the transitions on a velodrome track to allow rapid entry to the bends and gradual exit.\n\n\n\n"}
{"id": "26452145", "url": "https://en.wikipedia.org/wiki?curid=26452145", "title": "Future of mathematics", "text": "Future of mathematics\n\nThe future of mathematics is a topic that has been written about by many notable mathematicians. Typically, they are motivated by a desire to set a research agenda to direct efforts to specific problems, or a wish to clarify, update and extrapolate the way that subdisciplines relate to the general discipline of mathematics and its possibilities. Examples historical and recent include Felix Klein's Erlangen program, Hilbert's problems, Langlands program, and the Millennium Prize Problems. In the Mathematics Subject Classification section 01Axx History of mathematics and mathematicians, the subsection 01A67 is titled Future prospectives.\n\nAccording to Henri Poincaré writing in 1908 (English translation), \"The true method of forecasting the future of mathematics lies in the study of its history and its present state\".\nThe historical approach can consist of the study of earlier predictions, and comparing them to the present state of the art to see how the predictions have fared, e.g. monitoring the progress of Hilbert's problems. A subject survey of mathematics itself however is now problematic: the sheer expansion of the subject gives rise to issues of mathematical knowledge management.\n\nGiven the support of research by governments and other funding bodies, concerns about the future form part of the rationale of the distribution of funding. Mathematical education must also consider changes that are happening in the mathematical requirements of the workplace; course design will be influenced both by current and by possible future areas of application of mathematics. László Lovász, in \"Trends in Mathematics: How they could Change Education?\" describes how the mathematics community and mathematical research activity is growing and states that this will mean changes in the way things are done: larger organisations mean more resources are spent on overheads (coordination and communication); in mathematics this would equate to more time engaged in survey and expository writing.\n\nSteven G. Krantz writes in \"The Proof is in the Pudding. A Look at the Changing Nature of Mathematical Proof\": \"It is becoming increasingly evident that the delineations among “engineer” and “mathematician” and “physicist” are becoming ever more vague. It seems plausible that in 100 years we will no longer speak of mathematicians as such but rather of mathematical scientists. It would not be at all surprising if the notion of “Department of Mathematics” at the college and university level gives way to “Division of Mathematical Sciences”.\"\n\nExperimental mathematics is the use of computers to generate large data sets within which to automate the discovery of patterns which can then form the basis of conjectures and eventually new theory. The paper \"Experimental Mathematics: Recent Developments and Future Outlook\" describes expected increases in computer capabilities: better hardware in terms of speed and memory capacity; better software in terms of increasing sophistication of algorithms; more advanced visualization facilities; the mixing of numerical and symbolic methods.\n\nDoron Zeilberger considers a time when computers become so powerful that the predominant questions in mathematics change from proving things to determining how much it would cost: \"As wider classes of identities, and perhaps even other kinds of classes of theorems, become routinely provable, we might witness many results for which we would know how to find a proof (or refutation), but we would be unable, or unwilling, to pay for finding such proofs, since “almost certainty” can be bought so much cheaper. I can envision an abstract of a paper, c. 2100, that reads : “We show, in a certain precise sense, that the Goldbach conjecture is true with probability larger than 0.99999, and that its complete truth could be determined with a budget of $10B.”\" Some people strongly disagree with Zeilberger's prediction, for example it has been described as provocative and quite wrongheaded, whereas it has also been stated that choosing which theorems are interesting enough to pay for, already happens as a result of funding bodies making decisions as to which areas of research to invest in.\n\nIn \"Rough structure and classification\", Timothy Gowers writes about three stages: 1) at the moment computers are just slaves doing boring calculations, 2) soon databases of mathematical concepts and proof methods will lead to an intermediate stage where computers are very helpful with theorem proving but unthreatening, and 3) within a century computers will be better than humans at theorem proving.\n\nOn combinatorics: In 2001, Peter Cameron in \"Combinatorics entering the third millennium\" attempts to \"throw some light on present trends and future directions. I have divided the causes into four groups: the influence of the computer; the growing sophistication of combinatorics; its strengthening links with the rest of mathematics; and wider changes in society.\" He makes the prediction that \"What is clear, though, is that combinatorics will continue to elude attempts at formal specification.\" Béla Bollobás writes: \"Hilbert, I think, said that a subject is alive only if it has an abundance of problems. It is exactly this that makes combinatorics very much alive. I have no doubt that combinatorics will be around in a hundred years from now. It will be a completely different subject but it will still flourish simply because it still has many, many problems\".\n\nOn numerical analysis and scientific computing: In 2000, Lloyd N. Trefethen wrote \"Predictions for scientific computing 50 years from now\", which concluded with the theme that \"Human beings will be removed from the loop\" and writing in 2008 in \"The Princeton Companion to Mathematics\" predicted that by 2050 most numerical programs will be 99% intelligent wrapper and only 1% algorithm, and that the distinction between linear and non-linear problems, and between forward problems (one step) and inverse problems (iteration), and between algebraic and analytic problems, will fade as everything becomes solved by iterative methods inside adaptive intelligent systems that mix and match and combine algorithms as required.\n\nOn data analysis: In 1998, Mikhail Gromov in \"Possible Trends in Mathematics in the Coming Decades\", says that traditional probability theory applies where global structure such as the Gauss Law emerges when there is a lack of structure between individual data points, but that one of today's problems is to develop methods for analyzing structured data where classical probability does not apply. Such methods might include advances in wavelet analysis, higher-dimensional methods and inverse scattering.\n\nA list of grand challenges for control theory is outlined in \"Future Directions in Control, Dynamics, and Systems: Overview, Grand Challenges, and New Courses\".\n\nMathematical logic is discussed in \"The Prospects For Mathematical Logic In The Twenty-First Century\".\n\nMathematical biology is one of the fastest expanding areas of mathematics at the beginning of the 21st century. \"Mathematics Is Biology's Next Microscope, Only Better; Biology Is Mathematics' Next Physics, Only Better\" is an essay by Joel E. Cohen.\n\nMathematical physics is an enormous and diverse subject. Some indications of future research directions are given in \"New Trends in Mathematical Physics: Selected Contributions of the XVth International Congress on Mathematical Physics\".\n\n\n\n"}
{"id": "23270711", "url": "https://en.wikipedia.org/wiki?curid=23270711", "title": "George Szekeres Medal", "text": "George Szekeres Medal\n\nThe George Szekeres Medal is awarded by the Australian Mathematical Society for outstanding research contributions over a fifteen-year period. This award, established in 2001, is given biennially in even-numbered years for work that has been carried out primarily in Australia.\n\nThis medal commemorates the work of the late George Szekeres, FAA, for his achievements in number theory, combinatorics, analysis, and relativity.\n"}
{"id": "8637946", "url": "https://en.wikipedia.org/wiki?curid=8637946", "title": "George W. Hart", "text": "George W. Hart\n\nGeorge William Hart (born 1955) is an American geometer who expresses himself both artistically and academically. He is also an interdepartmental research professor at the State University of New York in Stony Brook, New York.\n\nHis artistic work includes sculpture, computer images, toys (e.g. Zome) and puzzles. His sculptures have been featured in articles in \"The New York Times\", \"Games\", \"Science News\", \"Science\", \"Tiede\" (Finnish), \"Ars et Mathesis\" (Dutch), \"Наука и жизнь\" (Russian) and other publications around the world.\n\nHis academic work includes the online publication Encyclopedia of Polyhedra, the textbook \"Multidimensional Analysis\", and the instruction book \"Zome Geometry\". He has also published over sixty academic articles.\n\nHart is a co-founder of North America's only Museum of Mathematics, MoMath, in New York City. As chief of content, he set the \"Math is Cool!\" tone of the museum and spent five years designing original exhibits and workshop activities for it. \n\nHart is a coinventor on two US patents, \"Digital ac monitor\" and \"Non-intrusive appliance monitor apparatus\". These patents cover, in part, an improved electrical meter for homes called nonintrusive load monitors. These meters track changes in voltage and current usage by a given household and then deduce which appliances are using how much electricity and when.\n\nHart received a B.S. in Mathematics from MIT (1977), an M.A. in Linguistics from Indiana University (1979), and a Ph.D. in Electrical Engineering and Computer Science from MIT (1987).\n\n\nThe Incompatible Food Triad is a puzzle to find three foods for which any pair will taste good together, but all three together will not. The puzzle is believed to have originated with the philosopher Wilfrid Sellars, and has been spread by some of his former colleagues and students, including Nuel Belnap and George W. Hart. The puzzle was also featured on WNYC's \"The Brian Lehrer Show\".\n\nGiven three foods that do not go together, it is usually because two of them don't go together. For example, Richard Feynman's famous example of accidentally requesting milk and lemon in his tea is not a solution. While tea and lemon \"do\" go together, and tea and milk \"do\" go together, milk and lemon do \"not\" go together. For this solution to work, milk and lemon would have to go together as well.\n\nAccording to Hart, most attempted solutions tend to overlook one of the three pairs. Issues of personal taste and preparation complicate the issue, as combinations some consider acceptable sound unpalatable to others, and problems such as milk curdling with the addition of lemon juice can potentially be overcome if a cheesemaking process is employed.\n\nIn a posting on its website after the puzzle was aired on the WNYC radio show in New York; Beer, 7Up, and Whiskey was given as a solution with the statement that beer with 7Up makes shandy, beer with whiskey makes a boilermaker and whiskey with 7Up is a 7 & 7, but the three together would \"make you sick\". Other possible solutions from viewers included:\n\nA few of the \"classic\" solutions are:\n\n\n"}
{"id": "352714", "url": "https://en.wikipedia.org/wiki?curid=352714", "title": "Germ (mathematics)", "text": "Germ (mathematics)\n\nIn mathematics, the notion of a germ of an object in/on a topological space is an equivalence class of that object and others of the same kind which captures their shared local properties. In particular, the objects in question are mostly functions (or maps) and subsets. In specific implementations of this idea, the sets or maps in question will have some property, such as being analytic or smooth, but in general this is not needed (the maps or functions in question need not even be continuous); it is however necessary that the space on/in which the object is defined is a topological space, in order that the word \"local\" have some sense.\n\nThe name is derived from \"cereal germ\" in a continuation of the sheaf metaphor, as a germ is (locally) the \"heart\" of a function, as it is for a grain.\n\nGiven a point \"x\" of a topological space X, and two maps formula_1 (where \"Y\" is any set), then formula_2 and formula_3 define the same germ at \"x\" if there is a neighbourhood \"U\" of \"x\" such that restricted to \"U\", \"f\" and \"g\" are equal; meaning that formula_4 for all \"u\" in \"U\".\n\nSimilarly, if \"S\" and \"T\" are any two subsets of X, then they define the same germ at \"x\" if there is again a neighbourhood \"U\" of \"x\" such that\n\nIt is straightforward to see that \"defining the same germ\" at \"x\" is an equivalence relation (be it on maps or sets), and the equivalence classes are called germs (map-germs, or set-germs accordingly). The equivalence relation is usually written\n\nGiven a map \"f\" on \"X\", then its germ at \"x\" is usually denoted [\"f\" ]. Similarly, the germ at \"x\" of a set \"S\" is written [\"S\"]. Thus,\n\nA map germ at \"x\" in \"X\" which maps the point \"x\" in \"X\" to the point \"y\" in \"Y\" is denoted as\n\nWhen using this notation, \"f\" is then intended as an entire equivalence class of maps, using the same letter \"f\" for any representative map.\n\nNotice that two sets are germ-equivalent at \"x\" if and only if their characteristic functions are germ-equivalent at \"x\":\n\nMaps need not be defined on all of \"X\", and in particular they don't need to have the same domain. However, if \"f\" has domain \"S\" and \"g\" has domain \"T\", both subsets of \"X\", then \"f\" and \"g\" are germ equivalent at \"x\" in \"X\" if first \"S\" and \"T\" are germ equivalent at \"x\", say formula_10 and then moreover formula_11, for some smaller neighbourhood \"V\" with formula_12. This is particularly relevant in two settings: \n\nIf \"f\" and \"g\" are germ equivalent at \"x\", then they share all local properties, such as continuity, differentiability etc., so it makes sense to talk about a \"differentiable or analytic germ\", etc. Similarly for subsets: if one representative of a germ is an analytic set then so are all representatives, at least on some neighbourhood of \"x\".\n\nAlgebraic structures on the target \"Y\" are inherited by the set of germs with values in \"Y\". For instance, if the target \"Y\" is a group (mathematics), then it makes sense to multiply germs: to define [\"f\"][\"g\"], first take representatives \"f\" and \"g\", defined on neighbourhoods \"U\" and \"V\" respectively, and define [\"f\"][\"g\"] to be the germ at \"x\" of the map \"fg\" (which is defined on formula_13). In the same way, if \"Y\" is an abelian group, vector space, or ring, then so is the set of germs.\n\nThe set of germs at \"x\" of maps from \"X\" to \"Y\" does not have a useful topology, except for the discrete one. It therefore makes little or no sense to talk of a convergent sequence of germs. However, if \"X\" and \"Y\" are manifolds, then the spaces of jets formula_14 (finite order Taylor series at \"x\" of map(-germs)) do have topologies as they can be identified with finite-dimensional vector spaces.\n\nThe idea of germ is behind the definition of sheaves and presheaves. A presheaf formula_15 of abelian groups on a topological space \"X\" assigns an abelian group formula_16 to each open set \"U\" in \"X\". Typical examples of abelian groups here are: real valued functions on \"U\", differential forms on \"U\", vector fields on \"U\", holomorphic functions on \"U\" (when \"X\" is a complex space), constant functions on \"U\" and differential operators on \"U\".\n\nIf formula_17 then there is a restriction map formula_18 satisfying certain compatibility conditions. For a fixed \"x\", one says that elements formula_19 and formula_20 are equivalent at \"x\" if there is a neighbourhood formula_21 of \"x\" with res(\"f\") = res(\"g\") (both elements of formula_22). The equivalence classes form the stalk formula_23 at \"x\" of the presheaf formula_15. This equivalence relation is an abstraction of the germ equivalence described above.\n\nInterpreting germs through sheaves also gives a general explanation for the presence of algebraic structures on sets of germs. The reason is because formation of stalks preserves finite limits. This implies that if \"T\" is a Lawvere theory and a sheaf \"F\" is a \"T\"-algebra, then any stalk \"F\" is also a \"T\"-algebra.\n\nIf formula_25 and formula_26 have additional structure, it is possible to define subsets of the set of all maps from \"X\" to \"Y\" or more generally sub-presheaves of a given presheaf formula_15 and corresponding germs: \"some notable examples follow\".\n\n\n\n\n\n\nThe stalk of a sheaf formula_15 on a topological space formula_25 at a point formula_44 of formula_25 is commonly denoted by formula_46 As a consequence germs, being stalks of sheaves of various kind of functions, borrow this scheme of notation:\n\nFor germs of sets and varieties, the notation is not so well established: some notations found in literature include:\n\n\nThe key word in the applications of germs is locality: \"all local properties of a function at a point can be studied by analyzing its germ\". They are a generalization of Taylor series, and indeed the Taylor series of a germ (of a differentiable function) is defined: you only need local information to compute derivatives.\n\nGerms are useful in determining the properties of dynamical systems near chosen points of their phase space: they are one of the main tools in singularity theory and catastrophe theory.\n\nWhen the topological spaces considered are Riemann surfaces or more generally analytic varieties, germs of holomorphic functions on them can be viewed as power series, and thus the set of germs can be considered to be the analytic continuation of an analytic function.\n\nAs noted earlier, sets of germs may have algebraic structures such as being rings. In many situations, rings of germs are not arbitrary rings but instead have quite specific properties.\n\nSuppose that \"X\" is a space of some sort. It is often the case that, at each \"x\" ∈ \"X\", the ring of germs of functions at \"x\" is a local ring. This is the case, for example, for continuous functions on a topological space; for \"k\" times differentiable, smooth, or analytic functions on a real manifold (when such functions are defined); for holomorphic functions on complex manifold; and for regular functions on an algebraic variety. The property that rings of germs are local rings is axiomatized by the theory of locally ringed spaces.\n\nThe types of local rings that arise, however, depend closely on the theory under consideration. The Weierstrass preparation theorem implies that rings of germs of holomorphic functions are Noetherian rings. It can also be shown that these are regular rings. On the other hand, let formula_69 be the ring of germs at the origin of smooth functions on R. This ring is local but not Noetherian. To see why, observe that the maximal ideal \"m\" of this ring consists of all germs which vanish at the origin, and the power \"m\" consists of those germs whose first \"k\" − 1 derivatives vanish. If this ring were Noetherian, then the Krull intersection theorem would imply that a smooth function whose Taylor series vanished would be the zero function. But this is false, as can be seen by considering\nThis ring is also not a unique factorization domain. This is because all UFDs satisfy the ascending chain condition on principal ideals, but there is an infinite ascending chain of principal ideals\nThe inclusions are strict because \"x\" is in the maximal ideal \"m\".\n\nThe ring formula_72 of germs at the origin of continuous functions on R even has the property that its maximal ideal \"m\" satisfies \"m\" = \"m\". Any germ \"f\" ∈ \"m\" can be written as\nwhere sgn is the sign function. Since |\"f\"| vanishes at the origin, this expresses \"f\" as the product of two functions in \"m\", whence the conclusion. This is related to the setup of almost ring theory.\n\n\n\n"}
{"id": "5791910", "url": "https://en.wikipedia.org/wiki?curid=5791910", "title": "Grosshans subgroup", "text": "Grosshans subgroup\n\nIn mathematics, in the representation theory of algebraic groups, a Grosshans subgroup, named after Frank Grosshans, is an algebraic subgroup of an algebraic group that is an observable subgroup for which the ring of functions on the quotient variety is finitely generated.\n\n"}
{"id": "57460109", "url": "https://en.wikipedia.org/wiki?curid=57460109", "title": "Haya Freedman", "text": "Haya Freedman\n\nHaya Freedman (1923–2005) was a Polish-born Israeli mathematician known for her research on the Tamari lattice and on ring theory, and as \"an exceptionally gifted teacher\" of mathematics at the London School of Economics.\n\nHaya Freedman was born in Lvov, which at that time was part of Poland, and at the age of ten moved to Mandatory Palestine. She earned a master's degree from the Hebrew University of Jerusalem, studying abstract algebra there under the supervision of Jacob Levitzki. She began doctoral studies under Dov Tamari in the early 1950s, doing research on the Tamari lattice that she would much later publish with Tamari. However, at that time her husband wanted to shift his own research from mathematics to computer science, and as part of that shift decided to move to England. Freedman moved with him in 1956, breaking off her studies.\nInstead, she completed a Ph.D. at Queen Mary College in 1960, under the supervision of Kurt Hirsch.\n\nIn 1965, Freedman became a faculty member in mathematics in Birkbeck College. In 1966, Cyril Offord founded the sub-department of mathematics at the London School of Economics, and she became one of the founding faculty members there.\n\nIn her honour, the London School of Economics offers an annual prize, the Haya Freedman Prize, for the best dissertation in applied mathematics.\n"}
{"id": "51429", "url": "https://en.wikipedia.org/wiki?curid=51429", "title": "Hyperreal number", "text": "Hyperreal number\n\nThe system of hyperreal numbers is a way of treating infinite and infinitesimal quantities. The hyperreals, or nonstandard reals, *R, are an extension of the real numbers R that contains numbers greater than anything of the form\n\nSuch numbers are infinite, and their reciprocals are infinitesimals. The term \"hyper-real\" was introduced by Edwin Hewitt in 1948.\n\nThe hyperreal numbers satisfy the transfer principle, a rigorous version of Leibniz's heuristic Law of Continuity. The transfer principle states that true first order statements about R are also valid in *R. For example, the commutative law of addition, \"x\" + \"y\" = \"y\" + \"x\", holds for the hyperreals just as it does for the reals; since R is a real closed field, so is *R. Since formula_2 for all integers \"n\", one also has formula_3 for all hyperintegers \"H\". The transfer principle for ultrapowers is a consequence of Łoś' theorem of 1955.\n\nConcerns about the soundness of arguments involving infinitesimals date back to ancient Greek mathematics, with Archimedes replacing such proofs with ones using other techniques such as the method of exhaustion. In the 1960s, Abraham Robinson proved that the hyperreals were logically consistent if and only if the reals were. This put to rest the fear that any proof involving infinitesimals might be unsound, provided that they were manipulated according to the logical rules that Robinson delineated.\n\nThe application of hyperreal numbers and in particular the transfer principle to problems of analysis is called non-standard analysis. One immediate application is the definition of the basic concepts of analysis such as derivative and integral in a direct fashion, without passing via logical complications of multiple quantifiers. Thus, the derivative of \"f(x)\" becomes formula_4 for an infinitesimal formula_5, where \"st(·)\" denotes the standard part function, which \"rounds off\" each finite hyperreal to the nearest real. Similarly, the integral is defined as the standard part of a suitable infinite sum.\n\nThe idea of the hyperreal system is to extend the real numbers R to form a system *R that includes infinitesimal and infinite numbers, but without changing any of the elementary axioms of algebra. Any statement of the form \"for any number x...\" that is true for the reals is also true for the hyperreals. For example, the axiom that states \"for any number \"x\", \"x\" + 0 = \"x\"\" still applies. The same is true for quantification over several numbers, e.g., \"for any numbers \"x\" and \"y\", \"xy\" = \"yx\".\" This ability to carry over statements from the reals to the hyperreals is called the transfer principle. However, statements of the form \"for any \"set\" of numbers S ...\" may not carry over. The only properties that differ between the reals and the hyperreals are those that rely on quantification over sets, or other higher-level structures such as functions and relations, which are typically constructed out of sets. Each real set, function, and relation has its natural hyperreal extension, satisfying the same first-order properties. The kinds of logical sentences that obey this restriction on quantification are referred to as statements in first-order logic.\n\nThe transfer principle, however, doesn't mean that R and *R have identical behavior. For instance, in *R there exists an element \"ω\" such that\n\nbut there is no such number in R. (In other words, *R is not Archimedean.) This is possible because the nonexistence of \"ω\" cannot be expressed as a first order statement.\n\nInformal notations for non-real quantities have historically appeared in calculus in two contexts: as infinitesimals like \"dx\" and as the symbol ∞, used, for example, in limits of integration of improper integrals.\n\nAs an example of the transfer principle, the statement that for any nonzero number \"x\", \"2x\" ≠ \"x\", is true for the real numbers, and it is in the form required by the transfer principle, so it is also true for the hyperreal numbers. This shows that it is not possible to use a generic symbol such as ∞ for all the infinite quantities in the hyperreal system; infinite quantities differ in magnitude from other infinite quantities, and infinitesimals from other infinitesimals.\n\nSimilarly, the casual use of 1/0 = ∞ is invalid, since the transfer principle applies to the statement that division by zero is undefined. The rigorous counterpart of such a calculation would be that if ε is a non-zero infinitesimal, then 1/ε is infinite.\n\nFor any finite hyperreal number \"x\", its standard part, st \"x\", is defined as the unique real number that differs from it only infinitesimally. The derivative of a function \"y\"(\"x\") is defined not as \"dy/dx\" but as the standard part of \"dy/dx\".\n\nFor example, to find the derivative \"f′\"(\"x\") of the function \"f\"(\"x\") = \"x\", let \"dx\" be a non-zero infinitesimal. Then,\n\nThe use of the standard part in the definition of the derivative is a rigorous alternative to the traditional practice of neglecting the square of an infinitesimal quantity. Dual numbers are a number system based this idea. After the third line of the differentiation above, the typical method from Newton through the 19th century would have been simply to discard the \"dx\" term. In the hyperreal system,\n\"dx\" ≠ 0, since \"dx\" is nonzero, and the transfer principle can be applied to the statement that the square of any nonzero number is nonzero. However, the quantity \"dx\" is infinitesimally small compared to \"dx\"; that is, the hyperreal system contains a hierarchy of infinitesimal quantities.\n\nOne way of defining a definite integral in the hyperreal system is as the standard part of an infinite sum on a hyperfinite lattice defined as \"a\", \"a + dx\", \"a + 2dx\", ... \"a + ndx\", where \"dx\" is infinitesimal, n is an infinite hypernatural, and the lower and upper bounds of integration are \"a\" and \"b\" = \"a\" + \"n\" \"dx.\"\n\nThe hyperreals *R form an ordered field containing the reals R as a subfield. Unlike the reals, the hyperreals do not form a standard metric space, but by virtue of their order they carry an order topology.\n\nThe use of the definite article \"the\" in the phrase \"the hyperreal numbers\" is somewhat misleading in that there is not a unique ordered field that is referred to in most treatments.\nHowever, a 2003 paper by Vladimir Kanovei and Saharon Shelah shows that there is a definable, countably saturated (meaning ω-saturated, but not, of course, countable) elementary extension of the reals, which therefore has a good claim to the title of \"the\" hyperreal numbers. Furthermore, the field obtained by the ultrapower construction from the space of all real sequences, is unique up to isomorphism if one assumes the continuum hypothesis.\n\nThe condition of being a hyperreal field is a stronger one than that of being a real closed field strictly containing R. It is also stronger than that of being a superreal field in the sense of Dales and Woodin.\n\nThe hyperreals can be developed either axiomatically or by more constructively oriented methods. The essence of the axiomatic approach is to assert (1) the existence of at least one infinitesimal number, and (2) the validity of the transfer principle. In the following subsection we give a detailed outline of a more constructive approach. This method allows one to construct the hyperreals if given a set-theoretic object called an ultrafilter, but the ultrafilter itself cannot be explicitly constructed.\n\nWhen Newton and (more explicitly) Leibniz introduced differentials, they used infinitesimals and these were still regarded as useful by later mathematicians such as Euler and Cauchy. Nonetheless these concepts were from the beginning seen as suspect, notably by George Berkeley. Berkeley's criticism centered on a perceived shift in hypothesis in the definition of the derivative in terms of infinitesimals (or fluxions), where \"dx\" is assumed to be nonzero at the beginning of the calculation, and to vanish at its conclusion (see Ghosts of departed quantities for details). When in the 1800s calculus was put on a firm footing through the development of the (ε, δ)-definition of limit by Bolzano, Cauchy, Weierstrass, and others, infinitesimals were largely abandoned, though research in non-Archimedean fields continued (Ehrlich 2006).\n\nHowever, in the 1960s Abraham Robinson showed how infinitely large and infinitesimal numbers can be rigorously defined and used to develop the field of non-standard analysis. Robinson developed his theory nonconstructively, using model theory; however it is possible to proceed using only algebra and topology, and proving the transfer principle as a consequence of the definitions. In other words hyperreal numbers \"per se\", aside from their use in nonstandard analysis, have no necessary relationship to model theory or first order logic, although they were discovered by the application of model theoretic techniques from logic. Hyper-real fields were in fact originally introduced by Hewitt (1948) by purely algebraic techniques, using an ultrapower construction.\n\nWe are going to construct a hyperreal field via sequences of reals. In fact we can add and multiply sequences componentwise; for example:\n\nand analogously for multiplication.\nThis turns the set of such sequences into a commutative ring, which is in fact a real algebra A. We have a natural embedding of R in A by identifying the real number \"r\" with the sequence (\"r\", \"r\", \"r\", …) and this identification preserves the corresponding algebraic operations of the reals. The intuitive motivation is, for example, to represent an infinitesimal number using a sequence that approaches zero. The inverse of such a sequence would represent an infinite number. As we will see below, the difficulties arise because of the need to define rules for comparing such sequences in a manner that, although inevitably somewhat arbitrary, must be self-consistent and well defined. For example, we may have two sequences that differ in their first \"n\" members, but are equal after that; such sequences should clearly be considered as representing the same hyperreal number. Similarly, most sequences oscillate randomly forever, and we must find some way of taking such a sequence and interpreting it as, say, formula_8, where formula_9 is a certain infinitesimal number.\n\nComparing sequences is thus a delicate matter. We could, for example, try to define a relation between sequences in a componentwise fashion:\n\nbut here we run into trouble, since some entries of the first sequence may be bigger than the corresponding entries of the second sequence, and some others may be smaller. It follows that the relation defined in this way is only a partial order. To get around this, we have to specify which positions matter. Since there are infinitely many indices, we don't want finite sets of indices to matter. A consistent choice of index sets that matter is given by any free ultrafilter \"U\" on the natural numbers; these can be characterized as ultrafilters that do not contain any finite sets. (The good news is that Zorn's lemma guarantees the existence of many such \"U\"; the bad news is that they cannot be explicitly constructed.) We think of \"U\" as singling out those sets of indices that \"matter\": We write (\"a\", \"a\", \"a\", ...) ≤ (\"b\", \"b\", \"b\", ...) if and only if the set of natural numbers { \"n\" : \"a\" ≤ \"b\" } is in \"U\".\n\nThis is a total preorder and it turns into a total order if we agree not to distinguish between two sequences \"a\" and \"b\" if \"a\"≤\"b\" and \"b\"≤\"a\". With this identification, the ordered field *R of hyperreals is constructed. From an algebraic point of view, \"U\" allows us to define a corresponding maximal ideal I in the commutative ring A (namely, the set of the sequences that vanish in some element of \"U\"), and then to define *R as A/I; as the quotient of a commutative ring by a maximal ideal, *R is a field. This is also notated A/\"U\", directly in terms of the free ultrafilter \"U\"; the two are equivalent. The maximality of I follows from the possibility of, given a sequence \"a\", constructing a sequence \"b\" inverting the non-null elements of \"a\" and not altering its null entries. If the set on which \"a\" vanishes is not in \"U\", the product \"ab\" is identified with the number 1, and any ideal containing 1 must be \"A\". In the resulting field, these \"a\" and \"b\" are inverses.\n\nThe field A/\"U\" is an ultrapower of R.\nSince this field contains R it has cardinality at least that of the continuum. Since A has cardinality\n\nit is also no larger than formula_12, and hence has the same cardinality as R.\n\nOne question we might ask is whether, if we had chosen a different free ultrafilter \"V\", the quotient field A/\"U\" would be isomorphic as an ordered field to A/\"V\". This question turns out to be equivalent to the continuum hypothesis; in ZFC with the continuum hypothesis we can prove this field is unique up to order isomorphism, and in ZFC with the negation of continuum hypothesis we can prove that there are non-order-isomorphic pairs of fields that are both countably indexed ultrapowers of the reals.\n\nFor more information about this method of construction, see ultraproduct.\n\nThe following is an intuitive way of understanding the hyperreal numbers. The approach taken here is very close to the one in the book by Goldblatt. Recall that the sequences converging to zero are sometimes called infinitely small. These are almost the infinitesimals in a sense; the true infinitesimals include certain classes of sequences that contain a sequence converging to zero.\n\nLet us see where these classes come from. Consider first the sequences of real numbers. They form a ring, that is, one can multiply, add and subtract them, but not always divide by a non-zero element. The real numbers are considered as the constant sequences, the sequence is zero if it is identically zero, that is, \"a\" = 0 for all \"n\".\n\nIn our ring of sequences one can get \"ab\" = 0 with neither \"a\" = 0 nor \"b\" = 0. Thus, if for two sequences formula_13 one has \"ab\" = 0, at least one of them should be declared zero. Surprisingly enough, there is a consistent way to do it. As a result, the equivalence classes of sequences that differ by some sequence declared zero will form a field, which is called a hyperreal field. It will contain the infinitesimals in addition to the ordinary real numbers, as well as infinitely large numbers (the reciprocals of infinitesimals, including those represented by sequences diverging to infinity). Also every hyperreal that is not infinitely large will be infinitely close to an ordinary real, in other words, it will be the sum of an ordinary real and an infinitesimal.\n\nThis construction is parallel to the construction of the reals from the rationals given by Cantor. He started with the ring of the Cauchy sequences of rationals and declared all the sequences that converge to zero to be zero. The result is the reals. To continue the construction of hyperreals, let us consider the zero sets of our sequences, that is, the formula_14, that is, formula_15 is the set of indexes formula_16 for which formula_17. It is clear that if formula_18, then the union of formula_15 and formula_20 is \"N\" (the set of all natural numbers), so:\nNow the idea is to single out a bunch \"U\" of subsets \"X\" of \"N\" and to declare that formula_27 if and only if formula_15 belongs to \"U\". From the above conditions one can see that:\n\nAny family of sets that satisfies (2–4) is called a filter (an example: the complements to the finite sets, it is called the Fréchet filter and it is used in the usual limit theory). If (1) also holds, U is called an ultrafilter (because you can add no more sets to it without breaking it). The only explicitly known example of an ultrafilter is the family of sets containing a given element (in our case, say, the number 10). Such ultrafilters are called trivial, and if we use it in our construction, we come back to the ordinary real numbers. Any ultrafilter containing a finite set is trivial. It is known that any filter can be extended to an ultrafilter, but the proof uses the axiom of choice. The existence of a nontrivial ultrafilter (the ultrafilter lemma) can be added as an extra axiom, as it is weaker than the axiom of choice.\n\nNow if we take a nontrivial ultrafilter (which is an extension of the Fréchet filter) and do our construction, we get the hyperreal numbers as a result.\n\nIf formula_29 is a real function of a real variable formula_30 then formula_29 naturally extends to a hyperreal function of a hyperreal variable by composition:\nwhere formula_33 means \"the equivalence class of the sequence formula_34 relative to our ultrafilter\", two sequences being in the same class if and only if the zero set of their difference belongs to our ultrafilter.\n\nAll the arithmetical expressions and formulas make sense for hyperreals and hold true if they are true for the ordinary reals. It turns out that any finite (that is, such that formula_35 for some ordinary real formula_21) hyperreal formula_30 will be of the form formula_38 where formula_39 is an ordinary (called standard) real and formula_40 is an infinitesimal. It can be proven by bisection method used in proving the Bolzano-Weierstrass theorem, the property (1) of ultrafilters turns out to be crucial.\nNow one can see that formula_29 is continuous means that formula_42 is infinitely small whenever formula_43 is, and formula_29 is differentiable means that\nis infinitely small whenever formula_43 is. Remarkably, if one allows formula_21 to be hyperreal, the derivative will be automatically continuous (because, formula_29 being differentiable at formula_30,\nis infinitely small when formula_43 is, therefore formula_52 is also infinitely small when formula_43 is).\n\nThe finite elements F of *R form a local ring, and in fact a valuation ring, with the unique maximal ideal S being the infinitesimals; the quotient F/S is isomorphic to the reals. Hence we have a homomorphic mapping, st(\"x\"), from F to R whose kernel consists of the infinitesimals and which sends every element \"x\" of F to a unique real number whose difference from x is in S; which is to say, is infinitesimal. Put another way, every \"finite\" nonstandard real number is \"very close\" to a unique real number, in the sense that if \"x\" is a finite nonstandard real, then there exists one and only one real number st(\"x\") such that \"x\" – st(\"x\") is infinitesimal. This number st(\"x\") is called the standard part of \"x\", conceptually the same as \"x\" \"to the nearest real number\". This operation is an order-preserving homomorphism and hence is well-behaved both algebraically and order theoretically. It is order-preserving though not isotonic; i.e. formula_54 implies formula_55, but formula_56 does not imply formula_57.\n\nThe map st is continuous with respect to the order topology on the finite hyperreals; in fact it is locally constant.\n\nSuppose \"X\" is a Tychonoff space, also called a T space, and C(\"X\") is the algebra of continuous real-valued functions on \"X\". Suppose M is a maximal ideal in C(\"X\"). Then the factor algebra A = C(\"X\")/M is a totally ordered field F containing the reals. If F strictly contains R then M is called a hyperreal ideal (terminology due to Hewitt (1948)) and F a hyperreal field. Note that no assumption is being made that the cardinality of F is greater than R; it can in fact have the same cardinality.\n\nAn important special case is where the topology on \"X\" is the discrete topology; in this case \"X\" can be identified with a cardinal number κ and C(\"X\") with the real algebra formula_62 of functions from κ to R. The hyperreal fields we obtain in this case are called ultrapowers of R and are identical to the ultrapowers constructed via free ultrafilters in model theory.\n\n\n\n"}
{"id": "23574889", "url": "https://en.wikipedia.org/wiki?curid=23574889", "title": "Index of combinatorics articles", "text": "Index of combinatorics articles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "26382006", "url": "https://en.wikipedia.org/wiki?curid=26382006", "title": "Infinite product", "text": "Infinite product\n\nIn mathematics, for a sequence of complex numbers \"a\", \"a\", \"a\", ... the infinite product\n\nis defined to be the limit of the partial products \"a\"\"a\"...\"a\" as \"n\" increases without bound. The product is said to \"converge\" when the limit exists and is not zero. Otherwise the product is said to \"diverge\". A limit of zero is treated specially in order to obtain results analogous to those for infinite sums. Some sources allow convergence to 0 if there are only a finite number of zero factors and the product of the non-zero factors is non-zero, but for simplicity we will not allow that here. If the product converges, then the limit of the sequence \"a\" as \"n\" increases without bound must be 1, while the converse is in general not true.\n\nThe best known examples of infinite products are probably some of the formulae for π, such as the following two products, respectively by Viète (Viète's formula, the first published infinite product in mathematics) and John Wallis (Wallis product):\n\nThe product of positive real numbers\nconverges to a nonzero real number if and only if the sum\nconverges. This allows the translation of convergence criteria for infinite sums into convergence criteria for infinite products. The same criterion applies to products of arbitrary complex numbers (including negative reals) if the logarithm is understood as a fixed branch of logarithm which satisfies ln(1) = 0, with the proviso that the infinite product diverges when infinitely many \"a\" fall outside the domain of ln, whereas finitely many such \"a\" can be ignored in the sum.\n\nFor products of reals in which each formula_6, written as, for instance, formula_7 where formula_8, the bounds\n\nshow that the infinite product converges if the infinite sum of the \"p\" converges. This relies on the Monotone convergence theorem. We can show the converse by observing that, if formula_10, then \n\nand by the limit comparison test it follows that the two series \n\nare equivalent meaning that either they both converge or they both diverge.\n\nThe same proof also shows that if formula_13 for some formula_14 then formula_15 converges to a non-zero number if and only if formula_16 converges.\n\nIf the series formula_5 diverges to formula_18, then the sequence of partial products of the \"a\" converges to zero. The infinite product is said to diverge to zero.\n\nOne important result concerning infinite products is that every entire function \"f\"(\"z\") (that is, every function that is holomorphic over the entire complex plane) can be factored into an infinite product of entire functions, each with at most a single root. In general, if \"f\" has a root of order \"m\" at the origin and has other complex roots at \"u\", \"u\", \"u\", ... (listed with multiplicities equal to their orders), then\n\nwhere \"λ\" are non-negative integers that can be chosen to make the product converge, and \"φ\"(\"z\") is some entire function (which means the term before the product will have no roots in the complex plane). The above factorization is not unique, since it depends on the choice of values for \"λ\". However, for most functions, there will be some minimum non-negative integer \"p\" such that \"λ\" = \"p\" gives a convergent product, called the canonical product representation. This \"p\" is called the \"rank\" of the canonical product. In the event that \"p\" = 0, this takes the form\n\nThis can be regarded as a generalization of the fundamental theorem of algebra, since for polynomials, the product becomes finite and \"φ\"(\"z\") is constant.\n\nIn addition to these examples, the following representations are of special note:\n\nThe last of these is not a product representation of the same sort discussed above, as \"ζ\" is not entire. Rather, the above product representation of \"ζ\"(\"z\") converges precisely for Re(\"z\") > 1, where it is an analytic function. By techniques of analytic continuation, this function can be extended uniquely to an analytic function (still denoted \"ζ\"(\"z\")) on the whole complex plane except at the point \"z\" = 1, where it has a simple pole.\n\n\n\n"}
{"id": "44145", "url": "https://en.wikipedia.org/wiki?curid=44145", "title": "Interquartile mean", "text": "Interquartile mean\n\nThe interquartile mean (IQM) (or midmean) is a statistical measure of central tendency based on the truncated mean of the interquartile range. The IQM is very similar to the scoring method used in sports that are evaluated by a panel of judges: \"discard the lowest and the highest scores; calculate the mean value of the remaining scores\".\n\nIn calculation of the IQM, only the data in the second and third quartiles is used (as in the interquartile range), and the lowest 25% and the highest 25% of the scores are discarded. These points are called the first and third quartiles, hence the name of the IQM. (Note that the \"second\" quartile is also called the median).\n\nassuming the values have been ordered.\n\nThe method is best explained with an example. Consider the following dataset:\n\nFirst sort the list from lowest-to-highest:\n\nThere are 12 observations (datapoints) in the dataset, thus we have 4 quartiles of 3 numbers. Discard the lowest and the highest 3 values:\n\nWe now have 6 of the 12 observations remaining; next, we calculate the arithmetic mean of these numbers:\n\nThis is the interquartile mean.\n\nFor comparison, the arithmetic mean of the original dataset is\n\ndue to the strong influence of the outlier, 38.\n\nThe above example consisted of 12 observations in the dataset, which made the determination of the quartiles very easy. Of course, not all datasets have a number of observations that is divisible by 4. We can adjust the method of calculating the IQM to accommodate this. So ideally we want to have the IQM equal to the mean for symmetric distributions, e.g.:\n\nhas a mean value \"x\" = 3, and since it is a symmetric distribution, \"x\" = 3 would be desired.\n\nWe can solve this by using a weighted average of the quartiles and the interquartile dataset:\n\nConsider the following dataset of 9 observations:\n\nThere are 9/4 = 2.25 observations in each quartile, and 4.5 observations in the interquartile range. Truncate the fractional quartile size, and remove this number from the 1st and 4th quartiles (2.25 observations in each quartile, thus the lowest 2 and the highest 2 are removed).\n\nThus, there are 3 \"full\" observations in the interquartile range, and 2 fractional observations. Since we have a total of 4.5 observations in the interquartile range, the two fractional observations each count for 0.75 (and thus 3×1 + 2×0.75 = 4.5 observations).\n\nThe IQM is now calculated as follows:\n\nIn the above example, the mean has a value x = 9. The same as the IQM, as was expected. The method of calculating the IQM for any number of observations is analogous; the fractional contributions to the IQM can be either 0, 0.25, 0.50, or 0.75.\n\nThe interquartile mean shares some properties of both the mean and the median:\n\n\n\n"}
{"id": "24006693", "url": "https://en.wikipedia.org/wiki?curid=24006693", "title": "Inverse bundle", "text": "Inverse bundle\n\nIn mathematics, the inverse bundle of a fibre bundle is its inverse with respect to the Whitney sum operation.\n\nLet formula_1 be a fibre bundle. A bundle formula_2 is called the \"inverse bundle\" of formula_3 if their Whitney sum is a trivial bundle, namely if \n\nAny vector bundle over a compact Hausdorff base has an inverse bundle.\n"}
{"id": "4495817", "url": "https://en.wikipedia.org/wiki?curid=4495817", "title": "LR-attributed grammar", "text": "LR-attributed grammar\n\nLR-attributed grammars are a special type of attribute grammars. They allow the attributes to be evaluated on LR parsing. As a result, attribute evaluation in LR-attributed grammars can be incorporated conveniently in bottom-up parsing. zyacc is based on LR-attributed grammars. They are a subset of the L-attributed grammars, where the attributes can be evaluated in one left-to-right traversal of the abstract syntax tree. They are a superset of the S-attributed grammars, which allow only synthesized attributes. In yacc, a common hack is to use global variables to simulate some kind of inherited attributes and thus LR-attribution.\n\n"}
{"id": "28975424", "url": "https://en.wikipedia.org/wiki?curid=28975424", "title": "Lee–Carter model", "text": "Lee–Carter model\n\nThe Lee–Carter model is a numerical algorithm used in mortality forecasting and life expectancy forecasting. The input to the model is a matrix of age specific mortality rates ordered monotonically by time, usually with ages in columns and years in rows. The output is another forecasted matrix of mortality rates.\n\nThe model uses the singular value decomposition (SVD) to find a univariate time series vector \"k\" that captures 80–90% of the mortality trend (here the subscript \"t\" refers to time), a vector \"b\" that describes the amount of mortality change at a given age for a unit of yearly total mortality change (here the subscript \"x\" refers to age), and a scaling constant (referred to here as s but unnamed in the literature). Surprisingly, k is usually linear, implying that gains to life expectancy are fairly constant year after year in most populations. Before being input to the SVD, age specific mortality rates are transformed into \"a\", by taking their logarithms, and then centering them by subtracting their age-specific means (calculated over time). (The subscript \"x,t\" refers to the fact that a spans both age and time.) Many researchers adjust the k vector by fitting it to empirical life expectancies for each year, using the a and b just generated with the SVD; when adjusted using this approach, changes to k are usually small.\n\nTo forecast mortality, the above k (either adjusted or not) is projected into the future using ARIMA time series methods, the corresponding future a is recovered by multiplying k by b and the appropriate diagonal element of S (when [U S V] = svd(mort)), and the actual mortality rates are recovered by taking exponentials of this vector. Because of the linearity of k, it is generally modeled as a random walk with trend. Life expectancy and other life table measures can be calculated from this forecasted matrix after adding back the means and taking exponentials to yield regular mortality rates.\n\nIn most implementations, confidence intervals for the forecasts are generated by simulating multiple mortality forecasts using Monte-Carlo methods; a band of mortality between 5% and 95% percentiles of the simulated results is considered to be a valid forecast. These simulations are done by extending k into the future using randomization based on the standard error of k derived from the input data.\n\nIn outline and Matlab-style pseudocode, the algorithm is as follows:\n\nWithout applying SVD or some other method of dimension reduction the table of mortality data is a highly correlated multivariate data series; the complexity of these multidimensional time series makes such them almost impossible to forecast. SVD has become widely used as a method of dimension reduction in many disparate fields, including by Google in their page rank algorithm.\n\nThe Lee–Carter model was introduced by Ronald D. Lee and Lawrence Carter in 1992 with the article \"Modeling and Forecasting the Time Series of U.S. Mortality,\" (Journal of the American Statistical Association 87 (September): 659–671). The model grew out of their work in the late 1980s and early 1990s attempting to use inverse projection to infer rates in historical demography. The model has been used by the United States Social Security Administration, the US Census Bureau, and the United Nations. It has become the most widely used mortality forecasting technique in the world today.\n\nThere have been extensions to the Lee–Carter, most notably to account for missing years, correlated male and female populations, and large scale coherency in populations that share a mortality regime (western Europe, for example). Many related papers can be found on Professor Ronald Lee's website.\n\nThere are surprisingly few software packages for forecasting with the Lee-Carter Model. LCFIT is a web-based package with interactive forms. Professor Rob J. Hyndman provides an R package for demography that includes routines for creating and forecasting a Lee-Carter Model. Professor German Rodriguez provides code for the Lee-Carter Model using Stata. Using Matlab, Professor Eric Jondeau and Professor Michael Rockinger have put together the Longevity Toolbox for parameter estimation.\n"}
{"id": "44172803", "url": "https://en.wikipedia.org/wiki?curid=44172803", "title": "Lieb–Thirring inequality", "text": "Lieb–Thirring inequality\n\nIn mathematics and physics, Lieb–Thirring inequalities provide an upper bound on the sums of powers of the negative eigenvalues of a Schrödinger operator in terms of integrals of the potential. They are named after E. H. Lieb and W. E. Thirring.\n\nThe inequalities are useful in studies of quantum mechanics and differential equations and imply, as a corollary, a lower bound on the kinetic energy of formula_1 quantum mechanical particles that plays an important role in the proof of stability of matter.\n\nFor the Schrödinger operator formula_2 on formula_3 with real-valued potential formula_4, the numbers formula_5 denote the (not necessarily finite) sequence of negative eigenvalues. Then, for formula_6 and formula_7 satisfying one of the conditions\n\nthere exists a constant formula_9, which only depends on formula_6 and formula_7, such that\n\nwhere formula_12 is the negative part of the potential formula_13. The cases formula_14 as well as formula_15 were proven by E. H. Lieb and W. E. Thirring in 1976 and used in their proof of stability of matter. \nIn the case formula_16 the left-hand side is simply the number of negative eigenvalues, and proofs were given independently by M. Cwikel., E. H. Lieb and G. V. Rozenbljum. The resulting formula_17 inequality is thus also called the Cwikel–Lieb–Rosenbljum bound. The remaining critical case formula_18 was proven to hold by T. Weidl \nThe conditions on formula_6 and formula_7 are necessary and cannot be relaxed.\n\nThe Lieb–Thirring inequalities can be compared to the semi-classical limit. \nThe classical phase space consists of pairs formula_21. Identifying the momentum operator formula_22 with formula_23 and assuming that every quantum state is contained in a volume formula_24 in the formula_25-dimensional phase space, the semi-classical approximation\n\nis derived with the constant\n\nWhile the semi-classical approximation does not need any assumptions on formula_28, the Lieb–Thirring inequalities only hold for suitable formula_6.\n\nNumerous results have been published about the best possible constant formula_9 in () but this problem is still partly open.\nThe semiclassical approximation becomes exact in the limit of large coupling, that is for potentials formula_31 the Weyl asymptotics\n\nhold. This implies that formula_33. \nLieb and Thirring were able to show that formula_34 for formula_35. M. Aizenman and E. H. Lieb \nproved that for fixed dimension formula_7 the ratio formula_37 is a monotonic, non-increasing function of formula_6. Subsequently formula_39 was also shown to hold for all formula_7 when formula_41 by A. Laptev and T. Weidl. \nFor formula_42 D. Hundertmark, E. H. Lieb and L. E. Thomas proved that the best constant is given by formula_43.\n\nOn the other hand, it is known that formula_44 for formula_45 and for formula_46. \nIn the former case Lieb and Thirring conjectured that the sharp constant is given by\n\nThe best known value for the physical relevant constant formula_48 is formula_49 and the smallest known constant in the Cwikel–Lieb–Rosenbljum inequality is formula_50. \nA complete survey of the presently best known values for formula_9 can be found in the literature.\n\nThe Lieb–Thirring inequality for formula_52 is equivalent to a lower bound on the kinetic energy of a given normalised formula_1-particle wave function formula_54 in terms of the one-body density. For an anti-symmetric wave function such that\n\nfor all formula_56, the one-body density is defined as\n\nThe Lieb–Thirring inequality () for formula_52 is equivalent to the statement that\n\n\\mathrm{d}^n x\n\nwhere the sharp constant formula_59 is defined via\n\nThe inequality can be extended to particles with spin states by replacing the one-body density by the spin-summed one-body density. The constant formula_59 then has to be replaced by formula_62 where formula_63 is the number of quantum spin states available to each particle (formula_64 for electrons). If the wave function is symmetric, instead of anti-symmetric, such that\n\nfor all formula_56, the constant formula_59 has to be replaced by formula_68. \nInequality () describes the minimum kinetic energy necessary to achieve a given density formula_69 with formula_1 particles in formula_7 dimensions. \nIf formula_72 was proven to hold, the right-hand side of () for formula_73 would be precisely the kinetic energy term in Thomas–Fermi theory.\n\nThe inequality can be compared to the Sobolev inequality. M. Rumin derived the kinetic energy inequality () (with a smaller constant) directly without the use of the Lieb–Thirring inequality.\n\nThe kinetic energy inequality plays an important role in the proof of stability of matter as presented by Lieb and Thirring. The Hamiltonian under consideration describes a system of formula_1 particles with formula_63 spin states and formula_76 fixed nuclei at locations formula_77 with charges formula_78. The particles and nuclei interact with each other through the electrostatic Coulomb force and an arbitrary magnetic field can be introduced. If the particles under consideration are fermions (i.e. the wave function formula_79 is antisymmetric), then the kinetic energy inequality () holds with the constant formula_62 (not formula_68). This is a crucial ingredient in the proof of stability of matter for a system of fermions. It ensures that the ground state energy formula_82 of the system can be bounded from below by a constant depending only on the maximum of the nuclei charges, formula_83, times the number of particles,\n\nThe system is then stable of the first kind since the ground-state energy is bounded from below and also stable of the second kind, i.e. the energy of decreases linearly with the number of particles and nuclei. In comparison, if the particles are assumed to be bosons (i.e. the wave function formula_79 is symmetric), then the kinetic energy inequality () holds only with the constant formula_68 and for the ground state energy only a bound of the form formula_87 holds. Since the power formula_88 can be shown to be optimal, a system of bosons is stable of the first kind but unstable of the second kind.\n\nIf the Laplacian formula_89 is replaced by formula_90, where formula_91 is a magnetic field vector potential in formula_3, the Lieb–Thirring inequality () remains true. The proof of this statement uses the diamagnetic inequality. Although all presently known constants formula_9 remain unchanged, it is not known whether this is true in general for the best possible constant.\n\nThe Laplacian can also be replaced by other powers of formula_94. In particular for the operator formula_95, a Lieb–Thirring inequality similar to () holds with a different constant formula_9 and with the power on the right-hand side replaced by formula_97. Analogously a kinetic inequality similar to () holds, with formula_98 replaced by formula_99, which can be used to prove stability of matter for the relativistic Schrödinger operator under additional assumptions on the charges formula_100.\n\nIn essence, the Lieb–Thirring inequality () gives an upper bound on the distances of the eigenvalues formula_101 to the essential spectrum formula_102 in terms of the perturbation formula_13. Similar inequalities can be proved for Jacobi operators.\n\n"}
{"id": "662781", "url": "https://en.wikipedia.org/wiki?curid=662781", "title": "List of harmonic analysis topics", "text": "List of harmonic analysis topics\n\nThis is a list of harmonic analysis topics. See also list of Fourier analysis topics and list of Fourier-related transforms, which are more directed towards the classical Fourier series and Fourier transform of mathematical analysis, mathematical physics and engineering.\n\n\n\n\n\n\n"}
{"id": "408108", "url": "https://en.wikipedia.org/wiki?curid=408108", "title": "List of probability topics", "text": "List of probability topics\n\nThis is a list of probability topics, by Wikipedia page.\nIt overlaps with the (alphabetical) list of statistical topics. There are also the outline of probability and catalog of articles in probability theory. For distributions, see List of probability distributions. For journals, see list of probability journals. For contributors to the field, see list of mathematical probabilists and list of statisticians.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "3647249", "url": "https://en.wikipedia.org/wiki?curid=3647249", "title": "Logical graph", "text": "Logical graph\n\nA logical graph is a special type of diagramatic structure in any one of several systems of graphical syntax that Charles Sanders Peirce developed for logic.\n\nIn his papers on \"qualitative logic\", \"entitative graphs\", and \"existential graphs\", Peirce developed several versions of a graphical formalism, or a graph-theoretic formal language, designed to be interpreted for logic.\n\nIn the century since Peirce initiated this line of development, a variety of formal systems have branched out from what is abstractly the same formal base of graph-theoretic structures.\n\n\n"}
{"id": "24187952", "url": "https://en.wikipedia.org/wiki?curid=24187952", "title": "Lukacs's proportion-sum independence theorem", "text": "Lukacs's proportion-sum independence theorem\n\nIn statistics, Lukacs's proportion-sum independence theorem is a result that is used when studying proportions, in particular the Dirichlet distribution. It is named for Eugene Lukacs.\n\nIf \"Y\" and \"Y\" are non-degenerate, independent random variables, then the random variables\n\nare independently distributed if and only if both \"Y\" and \"Y\" have gamma distributions with the same scale parameter.\n\nSuppose \"Y\", \"i\" = 1, ..., \"k\" be non-degenerate, independent, positive random variables. Then each of \"k\" − 1 random variables\n\nis independent of\n\nif and only if all the \"Y\" have gamma distributions with the same scale parameter.\n\n"}
{"id": "44577560", "url": "https://en.wikipedia.org/wiki?curid=44577560", "title": "Occam learning", "text": "Occam learning\n\nIn computational learning theory, Occam learning is a model of algorithmic learning where the objective of the learner is to output a succinct representation of received training data. This is closely related to probably approximately correct (PAC) learning, where the learner is evaluated on its predictive power of a test set.\n\nOccam learnability implies PAC learning, and for a wide variety of concept classes, the converse is also true: PAC learnability implies Occam learnability.\n\nOccam Learning is named after Occam's razor, which is a principle stating that, given all other things being equal, a shorter explanation for observed data should be favored over a lengthier explanation. The theory of Occam learning is a formal and mathematical justification for this principle. It was first shown by Blumer, et al. that Occam learning implies PAC learning, which is the standard model of learning in computational learning theory. In other words, \"parsimony\" (of the output hypothesis) implies \"predictive power\".\n\nThe succinctness of a concept formula_1 in concept class formula_2 can be expressed by the length formula_3 of the shortest bit string that can represent formula_1 in formula_2. Occam learning connects the succinctness of a learning algorithm's output to its predictive power on unseen data.\n\nLet formula_2 and formula_7 be concept classes containing target concepts and hypotheses respectively. Then, for constants formula_8 and formula_9, a learning algorithm formula_10 is an formula_11-Occam algorithm for formula_2 using formula_7 iff, given a set formula_14 of formula_15 samples labeled according to a concept formula_16, formula_10 outputs a hypothesis formula_18 such that\nwhere formula_24 is the maximum length of any sample formula_25. An Occam algorithm is called \"efficient\" if it runs in time polynomial in formula_24, formula_15, and formula_28 We say a concept class formula_2 is \"Occam learnable\" with respect to a hypothesis class formula_7 if there exists an efficient Occam algorithm for formula_2 using formula_32\n\nOccam learnability implies PAC learnability, as the following theorem of Blumer, et al. shows:\n\nLet formula_10 be an efficient formula_11-Occam algorithm for formula_2 using formula_7. Then there exists a constant formula_37 such that for any formula_38, for any distribution formula_39, given formula_40 samples drawn from formula_39 and labelled according to a concept formula_42 of length formula_24 bits each, the algorithm formula_10 will output a hypothesis formula_45 such that formula_46 with probability at least formula_47 .Here, formula_48 is with respect to the concept formula_1 and distribution formula_39. This implies that the algorithm formula_10 is also a PAC learner for the concept class formula_2 using hypothesis class formula_7. A slightly more general formulation is as follows:\n\nLet formula_38. Let formula_10 be an algorithm such that, given formula_15 samples drawn from a fixed but unknown distribution formula_57 and labeled according to a concept formula_42 of length formula_24 bits each, outputs a hypothesis formula_60 that is consistent with the labeled samples. Then, there exists a constant formula_61 such that if formula_62, then formula_10 is guaranteed to output a hypothesis formula_60 such that formula_46 with probability at least formula_47.\n\nWhile the above theorems show that Occam learning is sufficient for PAC learning, it doesn't say anything about \"necessity.\" Board and Pitt show that, for a wide variety of concept classes, Occam learning is in fact necessary for PAC learning. They proved that for any concept class that is \"polynomially closed under exception lists,\" PAC learnability implies the existence of an Occam algorithm for that concept class. Concept classes that are polynomially closed under exception lists include Boolean formulas, circuits, deterministic finite automata, decision-lists, decision-trees, and other geometrically-defined concept classes.\n\nA concept class formula_2 is polynomially closed under exception lists if there exists a polynomial-time algorithm formula_68 such that, when given the representation of a concept formula_42 and a finite list formula_70 of \"exceptions\", outputs a representation of a concept formula_71 such that the concepts formula_1 and formula_73 agree except on the set formula_70.\n\nWe first prove the Cardinality version. Call a hypothesis formula_75 \"bad\" if formula_76, where again formula_48 is with respect to the true concept formula_1 and the underlying distribution formula_57. The probability that a set of samples formula_21 is consistent with formula_19 is at most formula_82, by the independence of the samples. By the union bound, the probability that there exists a bad hypothesis in formula_83 is at most formula_84, which is less than formula_85 if formula_86. This concludes the proof of the second theorem above.\n\nUsing the second theorem, we can prove the first theorem. Since we have a formula_11-Occam algorithm, this means that any hypothesis output by formula_10 can be represented by at most formula_89 bits, and thus formula_90. This is less than formula_91 if we set formula_92 for some constant formula_37. Thus, by the Cardinality version Theorem, formula_10 will output a consistent hypothesis formula_19 with probability at least formula_96. This concludes the proof of the first theorem above.\n\nThough Occam and PAC learnability are equivalent, the Occam framework can be used to produce tighter bounds on the sample complexity of classical problems including conjunctions, conjunctions with few relevant variables, and decision lists.\n\nOccam algorithms have also been shown to be successful for PAC learning in the presence of errors, probabilistic concepts, function learning and Markovian non-independent examples.\n\n"}
{"id": "37440786", "url": "https://en.wikipedia.org/wiki?curid=37440786", "title": "Paul A. Catlin", "text": "Paul A. Catlin\n\nPaul Allen Catlin ( – ) was a mathematician, professor of mathematics and Doctor of Mathematics, known for his valuable contributions to graph theory and number theory. He wrote one of the most cited papers in the series of chromatic numbers and Brooks' theorem, titled \" Hajós graph coloring conjecture: variations and counterexamples\".\n\nHe held a Doctorate in Mathematics degree from Ohio State University, authored over fifty academic papers in number theory and graph theory. Many of his contributions and collaborations have been published in \"The Fibonacci Quarterly\", in \"The Journal of Number Theory\", in the \"Journal of Discrete Mathematics\", and many other academic publications. He co-authored scholarly papers with Arthur M. Hobbs, Béla Bollobás and Paul Erdős, Hong-Jian Lai, Zheng-Yiao Han, and Yehong Shao, among others. He also published papers with G. Neil Robertson, with whom he also completed his dissertation thesis in 1976.\n\nOriginally from Bridgeport, Connecticut, he majored in Mathematics with a B.A. degree from Carnegie Mellon University in 1970.\n\nFrom 1972 to 1973, he was a research and teaching assistant at Ohio State University, where he earned the Master of Science degree in Mathematics.\n\nIn 1976, he went to work at Wayne State University, where he concentrated the research on chromatic numbers and Brooks' theorem. As a result, Paul A. Catlin published one of the most cited papers in that series: \"Hajós graph coloring conjecture: variations and counterexamples.\", which showed that the conjecture raised by Hugo Hadwiger is further strengthened not only by formula_1 but also by formula_2, which led to the joint paper written with Paul Erdős and Béla Bollobás titled \"Hadwiger's conjecture is true for almost every graph\".\n\n"}
{"id": "40765261", "url": "https://en.wikipedia.org/wiki?curid=40765261", "title": "Point process notation", "text": "Point process notation\n\nIn probability and statistics, point process notation comprises the range of mathematical notation used to symbolically represent random objects known as point processes, which are used in related fields such as stochastic geometry, spatial statistics and continuum percolation theory and frequently serve as mathematical models of random phenomena, representable as points, in time, space or both.\n\nThe notation varies due to the histories of certain mathematical fields and the different interpretations of point processes, and borrows notation from mathematical areas of study such as measure theory and set theory.\n\nThe notation, as well as the terminology, of point processes depends on their setting and interpretation as mathematical objects which under certain assumptions can be interpreted as random sequences of points, random sets of points or random counting measures.\n\nIn some mathematical frameworks, a given point process may be considered as a sequence of points with each point randomly positioned in \"d\"-dimensional Euclidean space R as well as some other more abstract mathematical spaces. In general, whether or not a random sequence is equivalent to the other interpretations of a point process depends on the underlying mathematical space, but this holds true for the setting of finite-dimensional Euclidean space R.\n\nA point process is called \"simple\" if no two (or more points) coincide in location with probability one. Given that often point processes are simple and the order of the points does not matter, a collection of random points can be considered as a random set of points The theory of random sets was independently developed by David Kendall and Georges Matheron. In terms of being considered as a random set, a sequence of random points is a random closed set if the sequence has no accumulation points with probability one\n\nA point process is often denoted by a single letter, for example formula_1, and if the point process is considered as a random set, then the corresponding notation:\n\nis used to denote that a random point formula_3 is an element of (or belongs to) the point process formula_1. The theory of random sets can be applied to point processes owing to this interpretation, which alongside the random sequence interpretation has resulted in a point process being written as:\n\nwhich highlights its interpretation as either a random sequence or random closed set of points. Furthermore, sometimes an uppercase letter denotes the point process, while a lowercase denotes a point from the process, so, for example, the point formula_6 (or formula_7) belongs to or is a point of the point process formula_8, or with set notation, formula_9.\n\nTo denote the number of points of formula_1 located in some Borel set formula_11, it is sometimes written \n\nwhere formula_13 is a random variable and formula_14 is a counting measure, which gives the number of points in some set. In this mathematical expression the point process is denoted by:\n\nformula_1.\n\nOn the other hand, the symbol:\n\nformula_16\n\nrepresents the number of points of formula_1 in formula_11. In the context of random measures, one can write:\n\nformula_19\n\nto denote that there is the set formula_11 that contains formula_21 points of formula_22. In other words, a point process can be considered as a random measure that assigns some non-negative integer-valued measure to sets. This interpretation has motivated a point process being considered just another name for a \"random counting measure\" and the techniques of random measure theory offering another way to study point processes, which also induces the use of the various notations used in integration and measure theory. \n\nThe different interpretations of point processes as random sets and counting measures is captured with the often used notation in which:\n\n\nDenoting the counting measure again with formula_14, this dual notation implies:\n\nIf formula_29 is some measurable function on R, then the sum of formula_30 over all the points formula_31 in formula_32 can be written in a number of ways such as:\n\nwhich has the random sequence appearance, or with set notation as:\n\nor, equivalently, with integration notation as:\n\nwhere formula_36 is the space of all possible counting measures, hence putting an emphasis on the interpretation of formula_1 as a random counting measure. An alternative integration notation may be used to write this integral as:\n\nThe dual interpretation of point processes is illustrated when writing the number of formula_1 points in a set formula_11 as:\n\nwhere the indicator function formula_42 if the point formula_31 is exists in formula_11 and zero otherwise, which in this setting is also known as a Dirac measure. In this expression the random measure interpretation is on the left-hand side while the random set notation is used is on the right-hand side.\n\nThe average or expected value of a sum of functions over a point process is written as:\n\nwhere (in the random measure sense) formula_46 is an appropriate probability measure defined on the space of counting measures formula_36. The expected value of formula_48 can be written as:\n\nwhich is also known as the first moment measure of formula_1. The expectation of such a random sum, known as a \"shot noise process\" in the theory of point processes, can be calculated with .\n\nPoint processes are employed in other mathematical and statistical disciplines, hence the notation may be used in fields such stochastic geometry, spatial statistics or continuum percolation theory, and areas which use the methods and theory from these fields.\n\n"}
{"id": "14841405", "url": "https://en.wikipedia.org/wiki?curid=14841405", "title": "Pseudo-zero set", "text": "Pseudo-zero set\n\nIn complex analysis, the pseudo-zero set or root neighborhood of a degree-\"m\" polynomial \"p\"(\"z\") is the set of all complex numbers that are roots of polynomials whose coefficients differ from those of \"p\" by a small amount. Namely, given a norm on the space formula_1 of polynomial coefficients, the pseudo-zero set is the set of all zeros of all degree-\"m\" polynomials \"q\" such that (as vectors of coefficients) is less than a given \"ε\".\n\n"}
{"id": "11149717", "url": "https://en.wikipedia.org/wiki?curid=11149717", "title": "Q-Pochhammer symbol", "text": "Q-Pochhammer symbol\n\nIn mathematics, in the area of combinatorics, a q\"-Pochhammer symbol, also called a q\"-shifted factorial, is a \"q\"-analog of the Pochhammer symbol. It is defined as\n\nwith\n\nby definition. The \"q\"-Pochhammer symbol is a major building block in the construction of \"q\"-analogs; for instance, in the theory of basic hypergeometric series, it plays the role that the ordinary Pochhammer symbol plays in the theory of generalized hypergeometric series.\n\nUnlike the ordinary Pochhammer symbol, the \"q\"-Pochhammer symbol can be extended to an infinite product:\n\nThis is an analytic function of \"q\" in the interior of the unit disk, and can also be considered as a formal power series in \"q\". The special case\n\nis known as Euler's function, and is important in combinatorics, number theory, and the theory of modular forms.\n\nThe finite product can be expressed in terms of the infinite product:\n\nwhich extends the definition to negative integers \"n\". Thus, for nonnegative \"n\", one has\n\nand\n\nThe \"q\"-Pochhammer symbol is the subject of a number of \"q\"-series identities, particularly the infinite series expansions\n\nand\n\nwhich are both special cases of the q-binomial theorem:\n\nFridrikh Karpelevich found the following identity (see for the proof):\n\nThe \"q\"-Pochhammer symbol is closely related to the enumerative combinatorics of partitions. The coefficient of formula_12 in\nis the number of partitions of \"m\" into at most \"n\" parts.\n\nSince, by conjugation of partitions, this is the same as the number of partitions of \"m\" into parts of size at most \"n\", by identification of generating series we obtain the identity:\n\nas in the above section.\n\nWe also have that the coefficient of formula_12 in\nis the number of partitions of \"m\" into \"n\" or \"n\"-1 distinct parts.\n\nBy removing a triangular partition with \"n\" − 1 parts from such a partition, we are left with an arbitrary partition with at most \"n\" parts. This gives a weight-preserving bijection between the set of partitions into \"n\" or \"n\" − 1 distinct parts and the set of pairs consisting of a triangular partition having \"n\" − 1 parts and a partition with at most \"n\" parts. By identifying generating series, this leads to the identity:\n\nalso described in the above section. \nThe reciprocal of the function formula_18 similarly arises as the generating function for the partition function, formula_19, which is also expanded by the second two q-series expansions given below:\n\nThe q-binomial theorem itself can also be handled by a slightly more involved combinatorial argument of a similar flavor (see also the expansions given in the next subsection) .\n\nSince identities involving \"q\"-Pochhammer symbols so frequently involve products of many symbols, the standard convention is to write a product as a single symbol of multiple arguments:\n\nA \"q\"-series is a series in which the coefficients are functions of \"q\", typically expressions of formula_22. Early results are due to Euler, Gauss, and Cauchy. The systematic study begins with Eduard Heine (1843).\n\nThe \"q\"-analog of \"n\", also known as the q\"-bracket or q\"-number of \"n\", is defined to be\n\nFrom this one can define the \"q\"-analog of the factorial, the \"q\"-factorial, as\n\nThese numbers are analogues in the sense that \n\nand so also \n\nThe limit value \"n\"! counts permutations of an \"n\"-element set \"S\". Equivalently, it counts the number of sequences of nested sets formula_26 such that formula_27 contains exactly \"i\" elements. By comparison, when \"q\" is a prime power and \"V\" is an \"n\"-dimensional vector space over the field with \"q\" elements, the \"q\"-analogue formula_28 is the number of complete flags in \"V\", that is, it is the number of sequences formula_29 of subspaces such that formula_30 has dimension \"i\". The preceding considerations suggest that one can regard a sequence of nested sets as a flag over a conjectural field with one element.\n\nA product of negative integer \"q\"-brackets can be expressed in terms of the \"q\"-factorial as\n\nFrom the \"q\"-factorials, one can move on to define the \"q\"-binomial coefficients, also known as the Gaussian binomial coefficients, as\n\nwhere it is easy to see that the triangle of these coefficients is symmetric in the sense that formula_33 for all formula_34.\n\nOne can check that\n\nOne can also see from the previous recurrence relations that the next variants of the formula_36-binomial theorem are expanded in terms of these coefficients as follows:\n\nOne may further define the \"q\"-multinomial coefficients\nwhere the arguments formula_39 are nonnegative integers that satisfy formula_40. The coefficient above counts the number of flags\nformula_41 \nof subspaces in an \"n\"-dimensional vector space over the field with \"q\" elements such that formula_42.\n\nThe limit formula_43 gives the usual multinomial coefficient formula_44, which counts words in \"n\" different symbols formula_45 such that each formula_46 appears formula_47 times. \n\nOne also obtains a \"q\"-analog of the Gamma function, called the q-gamma function, and defined as\n\nThis converges to the usual Gamma function as \"q\" approaches 1 from inside the unit disc. Note that\n\nfor any \"x\" and\n\nfor non-negative integer values of \"n\". Alternatively, this may be taken as an extension of the \"q\"-factorial function to the real number system.\n\n\n\n"}
{"id": "510629", "url": "https://en.wikipedia.org/wiki?curid=510629", "title": "Quantitative analyst", "text": "Quantitative analyst\n\nA quantitative analyst (or, in financial jargon, a quant) is a person who specializes in the application of mathematical and statistical methods – such as numerical or quantitative techniques – to financial and risk management problems. The occupation is similar to those in industrial mathematics in other industries.\n\nAlthough the original quantitative analysts were \"sell side quants\" from market maker firms, concerned with derivatives pricing and risk management, the meaning of the term has expanded over time to include those individuals involved in almost any application of mathematics in finance, including the buy side. Examples include statistical arbitrage, quantitative investment management, algorithmic trading, and electronic market making. \n\nQuantitative finance started in 1900 with Louis Bachelier's doctoral thesis \"Theory of Speculation\", which provided a model to price options under a Normal Distribution.\n\nHarry Markowitz's 1952 doctoral thesis \"Portfolio Selection\" and its published version was one of the first efforts in economics journals to formally adapt mathematical concepts to finance (mathematics was until then confined to mathematics, statistics or specialized economics journals). Markowitz formalized a notion of mean return and covariances for common stocks which allowed him to quantify the concept of \"diversification\" in a market. He showed how to compute the mean return and variance for a given portfolio and argued that investors should hold only those portfolios whose variance is minimal among all portfolios with a given mean return. Although the language of finance now involves Itō calculus, management of risk in a quantifiable manner underlies much of the modern theory.\n\nIn 1965 Paul Samuelson introduced stochastic calculus into the study of finance. In 1969 Robert Merton promoted continuous stochastic calculus and continuous-time processes. Merton was motivated by the desire to understand how prices are set in financial markets, which is the classical economics question of \"equilibrium,\" and in later papers he used the machinery of stochastic calculus to begin investigation of this issue.\n\nAt the same time as Merton's work and with Merton's assistance, Fischer Black and Myron Scholes developed the Black–Scholes model, which was awarded the 1997 Nobel Memorial Prize in Economic Sciences. It provided a solution for a practical problem, that of finding a fair price for a European call option, i.e., the right to buy one share of a given stock at a specified price and time. Such options are frequently purchased by investors as a risk-hedging device. In 1981, Harrison and Pliska used the general theory of continuous-time stochastic processes to put the Black–Scholes model on a solid theoretical basis, and showed how to price numerous other derivative securities.\n\nEmanuel Derman's 2004 book \"My Life as a Quant\" helped to both make the role of a quantitative analyst better known outside of finance, and to popularize the abbreviation \"quant\" for a quantitative analyst.\n\nQuantitative analysts often come from applied mathematics, physics or engineering backgrounds rather than economics-related fields, and quantitative analysis is a major source of employment for people with mathematics and physics PhD degrees, or with financial mathematics DEA degrees in the French education system. Typically, a quantitative analyst will also need extensive skills in computer programming, most commonly C, C++, Java, R, MATLAB, Mathematica, Python.\n\nThis demand for quantitative analysts has led to a resurgence in demand for actuarial qualifications as well as creation of specialized Masters and PhD courses in financial engineering, mathematical finance, computational finance, and/or financial reinsurance. In particular, Master's degrees in mathematical finance, financial engineering, operations research, computational statistics, machine learning, and financial analysis are becoming more popular with students and with employers. See Master of Quantitative Finance; Master of Financial Economics.\n\nData science and machine learning analysis and modelling methods are being increasingly employed in portfolio performance and portfolio risk modelling, and as such data science and machine learning Master's graduates are also in demand as quantitative analysts.\n\nIn sales & trading, quantitative analysts work to determine prices, manage risk, and identify profitable opportunities. Historically this was a distinct activity from trading but the boundary between a desk quantitative analyst and a quantitative trader is increasingly blurred, and it is now difficult to enter trading as a profession without at least some quantitative analysis education. In the field of algorithmic trading it has reached the point where there is little meaningful difference. Front office work favours a higher speed to quality ratio, with a greater emphasis on solutions to specific problems than detailed modeling. FOQs typically are significantly better paid than those in back office, risk, and model validation. Although highly skilled analysts, FOQs frequently lack software engineering experience or formal training, and bound by time constraints and business pressures tactical solutions are often adopted.\n\nQuantitative analysis is used extensively by asset managers. Some, such as FQ, AQR or Barclays, rely almost exclusively on quantitative strategies while others, such as Pimco, Blackrock or Citadel use a mix of quantitative and fundamental methods.\n\nMajor firms invest large sums in an attempt to produce standard methods of evaluating prices and risk. These differ from front office tools in that Excel is very rare, with most development being in C++, though Java and C# are sometimes used in non-performance critical tasks. LQs spend more time modeling ensuring the analytics are both efficient and correct, though there is tension between LQs and FOQs on the validity of their results. LQs are required to understand techniques such as Monte Carlo methods and finite difference methods, as well as the nature of the products being modeled.\n\nOften the highest paid form of Quant, ATQs make use of methods taken from signal processing, game theory, gambling Kelly criterion, market microstructure, econometrics, and time series analysis. Algorithmic trading includes statistical arbitrage, but includes techniques largely based upon speed of response, to the extent that some ATQs modify hardware and Linux kernels to achieve ultra low latency.\n\nThis has grown in importance in recent years, as the credit crisis exposed holes in the mechanisms used to ensure that positions were correctly hedged, though in no bank does the pay in risk approach that in front office. A core technique is value at risk, and this is backed up with various forms of stress test (financial), economic capital analysis and direct analysis of the positions and models used by various bank's divisions.\n\nIn the aftermath of the financial crisis, there surfaced the recognition that quantitative valuation methods were generally too narrow in their approach. An agreed upon fix adopted by numerous financial institutions has been to improve collaboration.\n\nModel validation (MV) takes the models and methods developed by front office, library, and modeling quantitative analysts and determines their validity and correctness. The MV group might well be seen as a superset of the quantitative operations in a financial institution, since it must deal with new and advanced models and trading techniques from across the firm. Before the crisis however, the pay structure in all firms was such that MV groups struggle to attract and retain adequate staff, often with talented quantitative analysts leaving at the first opportunity. This gravely impacted corporate ability to manage model risk, or to ensure that the positions being held were correctly valued. An MV quantitative analyst would typically earn a fraction of quantitative analysts in other groups with similar length of experience. In the years following the crisis, this has changed. Regulators now typically talk directly to the quants in the middle office such as the model validators, and since profits highly depend of the regulatory infrastructure, model validation has gained in weight and importance with respect to the quants in the front office.\n\nQuantitative developers are computer specialists that assist, implement and maintain the quantitative models. They tend to be highly specialised language technicians that bridge the gap between software developer and quantitative analysts.\n\nBecause of their backgrounds, quantitative analysts draw from various forms of mathematics: statistics and probability, calculus centered around partial differential equations, linear algebra, discrete mathematics, and econometrics. Some on the buy side may use machine learning. The\nmajority of quantitative analysts have received little formal education in mainstream economics, and often apply a mindset drawn from the physical sciences. Quants use mathematical skills learned from diverse fields such as computer science, physics and engineering. These skills include (but are not limited to) advanced statistics, linear algebra and partial differential equations as well as solutions to these based upon numerical analysis.\n\nCommonly used numerical methods are:\n\nA typical problem for a mathematically oriented quantitative analyst would be to develop a model for pricing, hedging, and risk-managing a complex derivative product. These quantitative analysts tend to rely more on numerical analysis than statistics and econometrics. The mindset is to prefer a deterministically \"correct\" answer, as once there is agreement on input values and market variable dynamics, there is only one correct price for any given security (which can be demonstrated, albeit often inefficiently, through a large volume of Monte Carlo simulations).\n\nA typical problem for a statistically oriented quantitative analyst would be to develop a model for deciding which stocks are relatively expensive and which stocks are relatively cheap. The model might include a company's book value to price ratio, its trailing earnings to price ratio, and other accounting factors. An investment manager might implement this analysis by buying the underpriced stocks, selling the overpriced stocks, or both. Statistically oriented quantitative analysts tend to have more of a reliance on statistics and econometrics, and less of a reliance on sophisticated numerical techniques and object-oriented programming. These quantitative analysts tend to be of the psychology that enjoys trying to find the best approach to modeling data, and can accept that there is no \"right answer\" until time has passed and we can retrospectively see how the model performed. Both types of quantitative analysts demand a strong knowledge of sophisticated mathematics and computer programming proficiency.\n\nOne of the principal mathematical tools of quantitative finance is stochastic calculus.\n\n\n\n\n\n\n"}
{"id": "59545", "url": "https://en.wikipedia.org/wiki?curid=59545", "title": "Sagrada Família", "text": "Sagrada Família\n\nThe (; ; ) is a large unfinished Roman Catholic church in Barcelona, designed by Catalan architect Antoni Gaudí (1852–1926). Gaudí's work on the building is part of a UNESCO World Heritage Site, and in November 2010 Pope Benedict XVI consecrated and proclaimed it a minor basilica, as distinct from a cathedral, which must be the seat of a bishop.\n\nIn 1882, construction of Sagrada Família started under architect Francisco de Paula del Villar. In 1883, when Villar resigned, Gaudí took over as chief architect, transforming the project with his architectural and engineering style, combining Gothic and curvilinear Art Nouveau forms. Gaudí devoted the remainder of his life to the project, and he is buried in the crypt. At the time of his death at age 73 in 1926, when he was run down by a streetcar, less than a quarter of the project was complete.\n\nRelying solely on private donations, Sagrada Familia's construction progressed slowly and was interrupted by the Spanish Civil War, only to resume intermittent progress in the 1950s. Since commencing construction in 1882, advancements in technologies such as computer aided design and computerised numerical control (CNC) have enabled faster progress and construction passed the midpoint in 2010. However, some of the project's greatest challenges remain, including the construction of ten more spires, each symbolising an important Biblical figure in the New Testament. It is anticipated that the building can be completed by 2026—the centenary of Gaudí's death. \n\nThe basilica has a long history of dividing the citizens of Barcelona: over the initial possibility it might compete with Barcelona's cathedral, over Gaudí's design itself, over the possibility that work after Gaudí's death disregarded his design, and the 2007 proposal to build an underground tunnel of Spain's high-speed rail link to France which could disturb its stability. Describing Sagrada Família, art critic Rainer Zerbst said \"it is probably impossible to find a church building anything like it in the entire history of art\", and Paul Goldberger describes it as \"the most extraordinary personal interpretation of Gothic architecture since the Middle Ages\".\n\nThe Basilica of the Sagrada Família was the inspiration of a bookseller, Josep Maria Bocabella, founder of Asociación Espiritual de Devotos de San José (Spiritual Association of Devotees of St. Joseph).\n\nAfter a visit to the Vatican in 1872, Bocabella returned from Italy with the intention of building a church inspired by the basilica at Loreto. The apse crypt of the church, funded by donations, was begun 19 March 1882, on the festival of St. Joseph, to the design of the architect Francisco de Paula del Villar, whose plan was for a Gothic revival church of a standard form. The apse crypt was completed before Villar's resignation on 18 March 1883, when Gaudí assumed responsibility for its design, which he changed radically. Antoni Gaudí began work on the church in 1883 but was not appointed Architect Director until 1884.\n\nOn the subject of the extremely long construction period, Gaudí is said to have remarked: \"My client is not in a hurry.\" When Gaudí died in 1926, the basilica was between 15 and 25 percent complete. After Gaudí's death, work continued under the direction of Domènec Sugrañes i Gras until interrupted by the Spanish Civil War in 1936.\n\nParts of the unfinished basilica and Gaudí's models and workshop were destroyed during the war by Catalan anarchists. The present design is based on reconstructed versions of the plans that were burned in a fire as well as on modern adaptations. Since 1940 the architects Francesc Quintana, Isidre Puig Boada, Lluís Bonet i Gari and Francesc Cardoner have carried on the work. The illumination was designed by Carles Buïgas.\nThe current director and son of Lluís Bonet, Jordi Bonet i Armengol, has been introducing computers into the design and construction process since the 1980s. Mark Burry of New Zealand serves as Executive Architect and Researcher. Sculptures by J. Busquets, Etsuro Sotoo and the controversial Josep Maria Subirachs decorate the fantastical façades. Barcelona-born Jordi Fauli took over as chief architect in 2012.\n\nThe central nave vaulting was completed in 2000 and the main tasks since then have been the construction of the transept vaults and apse. , work concentrated on the crossing and supporting structure for the main tower of Jesus Christ as well as the southern enclosure of the central nave, which will become the Glory façade.\n\nThe church shares its site with the Sagrada Família Schools building, a school originally designed by Gaudí in 1909 for the children of the construction workers. Relocated in 2002 from the eastern corner of the site to the southern corner, the building now houses an exhibition.\n\nChief architect Jordi Fauli announced in October 2015 that construction is 70 percent complete and has entered its final phase of raising six immense towers. The towers and most of the church's structure are to be completed by 2026, the centennial of Gaudí's death; decorative elements should be complete by 2030 or 2032. Visitor entrance fees of 15–20 euros finance the annual construction budget of 25million euros .\n\nComputer-aided design technology has been used to accelerate construction of the building. Current technology allows stone to be shaped off-site by a CNC milling machine, whereas in the 20th century the stone was carved by hand.\n\nIn 2008, some renowned Catalan architects advocated halting construction, to respect Gaudí's original designs, which although they were not exhaustive and were partially destroyed, have been partially reconstructed in recent years.\n\nSince 2013, AVE high-speed trains have passed near the Sagrada Família through an underground tunnel that runs beneath the centre of Barcelona.\n\nThe tunnel's construction, which began on 26 March 2010, was controversial. The Ministry of Public Works of Spain (\"Ministerio de Fomento\") claimed the project posed no risk to the church. Sagrada Família engineers and architects disagreed, saying there was no guarantee that the tunnel would not affect the stability of the building. The Board of the Sagrada Família (\"Patronat de la Sagrada Família\") and the neighborhood association \"AVE pel Litoral\" (AVE by the Coast) had led a campaign against this route for the AVE, without success.\n\nIn October 2010, the tunnel boring machine reached the church underground under the location of the building's principal façade. Service through the tunnel was inaugurated on 8 January 2013. Track in the tunnel makes use of a system by Edilon Sedra in which the rails are embedded in an elastic material to dampen vibrations. No damage to the Sagrada Família has been reported to date.\n\nThe main nave was covered and an organ installed in mid-2010, allowing the still-unfinished building to be used for religious services. The church was consecrated by Pope Benedict XVI on 7 November 2010 in front of a congregation of 6,500 people. A further 50,000 people followed the consecration Mass from outside the basilica, where more than 100 bishops and 300 priests were on hand to offer Holy Communion. Starting on 9 July 2017, there is an international mass celebrated at the basilica on every Sunday and holy day of obligation, at 9 a.m, open to the public (until the church is full). Occasionally, Mass is celebrated at other times, where attendance requires an invitation. When masses are scheduled, instructions to obtain an invitation are posted on the basilica's website. In addition, visitors may pray in the chapel of the Blessed Sacrament and Penitence.\n\nOn 19 April 2011, an arsonist started a small fire in the sacristy which forced the evacuation of tourists and construction workers; the sacristy was damaged, and the fire took 45 minutes to contain.\n\nThe style of la Sagrada Família is variously likened to Spanish Late Gothic, Catalan Modernism and to Art Nouveau or Catalan Noucentisme. While the Sagrada Família falls within the Art Nouveau period, Nikolaus Pevsner points out that, along with Charles Rennie Mackintosh in Glasgow, Gaudí carried the Art Nouveau style far beyond its usual application as a surface decoration.\n\nWhile never intended to be a cathedral (seat of a bishop), the Sagrada Família was planned from the outset to be a cathedral-sized building. Its ground-plan has obvious links to earlier Spanish cathedrals such as Burgos Cathedral, León Cathedral and Seville Cathedral. In common with Catalan and many other European Gothic cathedrals, the Sagrada Família is short in comparison to its width, and has a great complexity of parts, which include double aisles, an ambulatory with a chevet of seven apsidal chapels, a multitude of towers and three portals, each widely different in structure as well as ornament. Where it is common for cathedrals in Spain to be surrounded by numerous chapels and ecclesiastical buildings, the plan of this church has an unusual feature: a covered passage or cloister which forms a rectangle enclosing the church and passing through the narthex of each of its three portals. With this peculiarity aside, the plan, influenced by Villar's crypt, barely hints at the complexity of Gaudí's design or its deviations from traditional church architecture. There are no exact right angles to be seen inside or outside the church, and few straight lines in the design.\n\nGaudí's original design calls for a total of eighteen spires, representing in ascending order of height the Twelve Apostles, the Virgin Mary, the four Evangelists and, tallest of all, Jesus Christ. Eight spires have been built , corresponding to four apostles at the Nativity façade and four apostles at the Passion façade.\n\nAccording to the 2005 \"Works Report\" of the project's official website, drawings signed by Gaudí and recently found in the Municipal Archives, indicate that the spire of the Virgin was in fact intended by Gaudí to be shorter than those of the evangelists. The spire height will follow Gaudí's intention, which according to the report will work with the existing foundation. \n\nThe Evangelists' spires will be surmounted by sculptures of their traditional symbols: a winged bull (Saint Luke), a winged man (Saint Matthew), an eagle (Saint John), and a winged lion (Saint Mark). The central spire of Jesus Christ is to be surmounted by a giant cross; its total height () will be one metre less than that of Montjuïc hill in Barcelona as Gaudí believed that his creation should not surpass God's. The lower spires are surmounted by communion hosts with sheaves of wheat and chalices with bunches of grapes, representing the Eucharist. Plans call for tubular bells to be placed within the spires, driven by the force of the wind, and driving sound down into the interior of the church. Gaudí performed acoustic studies to achieve the appropriate acoustic results inside the temple. However, only one bell is currently in place.\n\nThe completion of the spires will make Sagrada Família the tallest church building in the world.\n\nThe Church will have three grand façades: the Nativity façade to the East, the Passion façade to the West, and the Glory façade to the South (yet to be completed). The Nativity Façade was built before work was interrupted in 1935 and bears the most direct Gaudí influence. The Passion façade was built according to the design that Gaudi created in 1917. The construction began in 1954, and the towers, built over the elliptical plan, were finished in 1976. It is especially striking for its spare, gaunt, tormented characters, including emaciated figures of Christ being scourged at the pillar; and Christ on the Cross. These controversial designs are the work of Josep Maria Subirachs. The Glory façade, on which construction began in 2002, will be the largest and most monumental of the three and will represent one's ascension to God. It will also depict various scenes such as Hell, Purgatory, and will include elements such as the Seven deadly sins and the Seven heavenly virtues.\n\nConstructed between 1894 and 1930, the Nativity façade was the first façade to be completed. Dedicated to the birth of Jesus, it is decorated with scenes reminiscent of elements of life. Characteristic of Gaudí's naturalistic style, the sculptures are ornately arranged and decorated with scenes and images from nature, each a symbol in its own manner. For instance, the three porticos are separated by two large columns, and at the base of each lies a turtle or a tortoise (one to represent the land and the other the sea; each are symbols of time as something set in stone and unchangeable). In contrast to the figures of turtles and their symbolism, two chameleons can be found at either side of the façade, and are symbolic of change.\n\nThe façade faces the rising sun to the northeast, a symbol for the birth of Christ. It is divided into three porticos, each of which represents a theological virtue (Hope, Faith and Charity). The Tree of Life rises above the door of Jesus in the portico of Charity. Four towers complete the façade and are each dedicated to a Saint (Matthias, Barnabas, Jude the Apostle, and Simon the Zealot).\n\nOriginally, Gaudí intended for this façade to be polychromed, for each archivolt to be painted with a wide array of colours. He wanted every statue and figure to be painted. In this way the figures of humans would appear as much alive as the figures of plants and animals.\n\nGaudí chose this façade to embody the structure and decoration of the whole church. He was well aware that he would not finish the church and that he would need to set an artistic and architectural example for others to follow. He also chose for this façade to be the first on which to begin construction and for it to be, in his opinion, the most attractive and accessible to the public. He believed that if he had begun construction with the Passion Façade, one that would be hard and bare (as if made of bones), before the Nativity Façade, people would have withdrawn at the sight of it. Some of the statues were destroyed in 1936 during the Spanish Civil War, and subsequently were reconstructed by the Japanese artist Etsuro Sotoo.\n\nIn contrast to the highly decorated Nativity Façade, the Passion Façade is austere, plain and simple, with ample bare stone, and is carved with harsh straight lines to resemble the bones of a skeleton. Dedicated to the Passion of Christ, the suffering of Jesus during his crucifixion, the façade was intended to portray the sins of man. Construction began in 1954, following the drawings and instructions left by Gaudí for future architects and sculptors. The towers were completed in 1976, and in 1987 a team of sculptors, headed by Josep Maria Subirachs, began work sculpting the various scenes and details of the façade. They aimed to give a rigid, angular form to provoke a dramatic effect. Gaudí intended for this façade to strike fear into the onlooker. He wanted to \"break\" arcs and \"cut\" columns, and to use the effect of chiaroscuro (dark angular shadows contrasted by harsh rigid light) to further show the severity and brutality of Christ's sacrifice.\n\nFacing the setting sun, indicative and symbolic of the death of Christ, the Passion Façade is supported by six large and inclined columns, designed to resemble Sequoia trunks. Above there is a pyramidal pediment, made up of eighteen bone-shaped columns, which culminate in a large cross with a crown of thorns. Each of the four towers is dedicated to an apostle (James, Thomas, Philip, and Bartholomew) and, like the Nativity Façade, there are three porticos, each representing the theological virtues, though in a much different light.\n\nThe scenes sculpted into the façade may be divided into three levels, which ascend in an \"S\" form and reproduce the stations of the Cross (Via Crucis of Christ). The lowest level depicts scenes from Jesus' last night before the crucifixion, including the Last Supper, Kiss of Judas, Ecce homo, and the Sanhedrin trial of Jesus. The middle level portrays the Calvary, or Golgotha, of Christ, and includes The Three Marys, Saint Longinus, Saint Veronica, and a hollow-face illusion of Christ on the Veil of Veronica. In the third and final level the Death, Burial and the Resurrection of Christ can be seen. A bronze figure situated on a bridge creating a link between the towers of Saint Bartholomew and Saint Thomas represents the Ascension of Jesus.\n\nThe largest and most striking of the façades will be the Glory Façade, on which construction began in 2002. It will be the principal façade and will offer access to the central nave. Dedicated to the Celestial Glory of Jesus, it represents the road to God: Death, Final Judgment, and Glory, while Hell is left for those who deviate from God's will. Aware that he would not live long enough to see this façade completed, Gaudí made a model which was demolished in 1936, whose original fragments were base for the development of the design for the façade. The completion of this façade may require the partial demolition of the block with buildings across the Carrer de Mallorca.\nTo reach the Glory Portico the large staircase will lead over the underground passage built over Carrer de Mallorca with the decoration representing Hell and vice. On other projects Carrer de Mallorca will have to go underground. It will be decorated with demons, idols, false gods, heresy and schisms, etc. Purgatory and death will also be depicted, the latter using tombs along the ground. The portico will have seven large columns dedicated to gifts of the Holy Spirit. At the base of the columns there will be representations of the Seven Deadly Sins, and at the top, The Seven Virtues.\n\nThis facade will have five doors corresponding to the five naves of the temple, with the central one having a triple entrance, that will give the Glory Façade a total seven doors representing the sacraments:\n\n\nIn September 2008, the doors of the Glory façade, by Josep Maria Subirachs, were installed. Inscribed with the Lord's prayer, these central doors are inscribed with the words \"Give us our daily bread\" in fifty different languages. The handles of the door are the letters \"A\" and \"G\" that form the initials of Antoni Gaudí within the phrase \"lead us not into temptation\".\n\nThe church plan is that of a Latin cross with five aisles. The central nave vaults reach while the side nave vaults reach . The transept has three aisles. The columns are on a 7.5metre (25 ft) grid. However, the columns of the apse, resting on del Villar's foundation, do not adhere to the grid, requiring a section of columns of the ambulatory to transition to the grid thus creating a horseshoe pattern to the layout of those columns. The crossing rests on the four central columns of porphyry supporting a great hyperboloid surrounded by two rings of twelve hyperboloids (currently under construction). The central vault reaches . The apse is capped by a hyperboloid vault reaching . Gaudí intended that a visitor standing at the main entrance be able to see the vaults of the nave, crossing, and apse; thus the graduated increase in vault loft.\n\nThere are gaps in the floor of the apse, providing a view down into the crypt below.\n\nThe columns of the interior are a unique Gaudí design. Besides branching to support their load, their ever-changing surfaces are the result of the intersection of various geometric forms. The simplest example is that of a square base evolving into an octagon as the column rises, then a sixteen-sided form, and eventually to a circle. This effect is the result of a three-dimensional intersection of helicoidal columns (for example a square cross-section column twisting clockwise and a similar one twisting counter-clockwise).\n\nEssentially none of the interior surfaces are flat; the ornamentation is comprehensive and rich, consisting in large part of abstract shapes which combine smooth curves and jagged points. Even detail-level work such as the iron railings for balconies and stairways are full of curvaceous elaboration.\n\nIn 2010 an organ was installed in the chancel by the Blancafort Orgueners de Montserrat organ builders. The instrument has 26 stops (1,492 pipes) on two manuals and a pedalboard.\n\nTo overcome the unique acoustical challenges posed by the church's architecture and vast size, several additional organs will be installed at various points within the building. These instruments will be playable separately (from their own individual consoles) and simultaneously (from a single mobile console), yielding an organ of some 8000 pipes when completed.\n\nThe towers on the Nativity façade are crowned with geometrically shaped tops that are reminiscent of Cubism (they were finished around 1930), and the intricate decoration is contemporary to the style of Art Nouveau, but Gaudí's unique style drew primarily from nature, not other artists or architects, and resists categorization.\n\nGaudí used hyperboloid structures in later designs of the Sagrada Família (more obviously after 1914), however there are a few places on the nativity façade—a design not equated with Gaudí's ruled-surface design—where the hyperboloid crops up. For example, all around the scene with the pelican there are numerous examples (including the basket held by one of the figures). There is a hyperboloid adding structural stability to the cypress tree (by connecting it to the bridge). And finally, the \"bishop's mitre\" spires are capped with hyperboloid structures. In his later designs, ruled surfaces are prominent in the nave's vaults and windows and the surfaces of the Passion façade.\n\nThemes throughout the decoration include words from the liturgy. The towers are decorated with words such as \"Hosanna\", \"Excelsis\", and \"Sanctus\"; the great doors of the Passion façade reproduce excerpts of the Passion of Jesus from the New Testament in various languages, mainly Catalan; and the Glory façade is to be decorated with the words from the Apostles' Creed, while its main door reproduce the entire Lord's Prayer in Catalan, surrounded by multiple variations of \"Give us this day our daily bread\" in other languages. The three entrances symbolize the three virtues: Faith, Hope and Love. Each of them is also dedicated to a part of Christ's life. The Nativity Façade is dedicated to his birth; it also has a cypress tree which symbolizes the tree of life. The Glory façade is dedicated to his glory period. The Passion façade is symbolic of his suffering. The apse tower bears Latin text of Hail Mary. All in all, the Sagrada Família is symbolic of the lifetime of Christ.\n\nAreas of the sanctuary will be designated to represent various concepts, such as saints, virtues and sins, and secular concepts such as regions, presumably with decoration to match.\n\n\nThe art historian Nikolaus Pevsner, writing in the 1960s, referred to Gaudí's buildings as growing \"like sugar loaves and anthills\" and describes the ornamenting of buildings with shards of broken pottery as possibly \"bad taste\" but handled with vitality and \"ruthless audacity\".\n\nThe building's design itself has been polarizing. Assessments by Gaudí's fellow architects were generally\npositive; Louis Sullivan greatly admired it, describing Sagrada Família as the\n\"greatest piece of creative architecture in the last twenty-five years. It is spirit symbolised\nin stone!\"\nWalter Gropius also praised the Sagrada Família, describing the building's walls as \"a marvel of\ntechnical perfection\".\nTime Magazine called it \"sensual, spiritual, whimsical, exuberant\", George Orwell called it \"one of the most hideous buildings in the world\", James A. Michener called it \"one of the strangest-looking serious buildings in the world\" and British historian Gerald Brenan stated about\nthe building \"Not even in the European architecture of the period can one discover anything so vulgar\nor pretentious.\" The building's distinctive silhouette has nevertheless become symbolic of Barcelona itself, drawing an estimated 2.5 million visitors annually.\n\nTogether with six other Gaudí buildings in Barcelona, part of la Sagrada Família is a UNESCO World Heritage Site, as testifying \"to Gaudí's exceptional creative contribution to the development of architecture and building technology\", \"having represented el Modernisme of Catalonia\" and \"anticipated and influenced many of the forms and techniques that were relevant to the development of modern construction in the 20th century\". The inscription only includes the Crypt and the Nativity Façade.\n\nVisitors can access the Nave, Crypt, Museum, Shop, and the Passion and Nativity towers. Entrance to either of the towers requires a reservation and advance purchase of a ticket. Access is possible only by lift (elevator) and a short walk up the remainder of the towers to the bridge between the towers. Descent is via a very narrow spiral staircase of over 300 steps. There is a posted caution for those with medical conditions.\n\nAs of June 2017, on-line ticket purchase has been available. As of August 2010, there had been a service whereby visitors could buy an entry code either at Servicaixa ATM kiosks (part of \"La Caixa\") or online. During the peak season, May to October, reservation delays for entrance of up to a few days are not unusual.\n\nConstruction on Sagrada Família is not supported by any government or official church sources. Private patrons funded the initial stages. Money from tickets purchased by tourists is now used to pay for the work, and private donations are accepted through the Friends of the Sagrada Família.\n\nThe construction budget for 2009 was €18 million.\n\nIn October 2018, Sagrada Família trustees agreed to pay €36 million in payments to the city authorities, to land a building permit after 136 years of construction. Most of the funds would be directed to improve the access between the church and Barcelona's metro system.\n\n\n\n"}
{"id": "20506374", "url": "https://en.wikipedia.org/wiki?curid=20506374", "title": "Steinitz exchange lemma", "text": "Steinitz exchange lemma\n\nThe Steinitz exchange lemma is a basic theorem in linear algebra used, for example, to show that any two bases for a finite-dimensional vector space have the same number of elements. The result is named after the German mathematician Ernst Steinitz. The result is often called the Steinitz–Mac Lane exchange lemma, also recognizing the generalization\nby Saunders Mac Lane\nof Steinitz's lemma to matroids.\n\nIf formula_1 is a set of formula_2 linearly independent vectors in a vector space formula_3, and formula_4 span formula_3, then:\n\n1. formula_6;\n\n2. Possibly after reordering the formula_7, the set formula_8 spans formula_3.\n\nSuppose that we have the indicated sets of vectors. We wish to show that for each formula_10, we have that formula_11, and that the set formula_12 spans formula_3 (where the formula_14 have possibly been reordered, and the reordering depends on formula_15). We proceed by mathematical induction on formula_15.\n\nFor the base case, suppose formula_15 is zero.\nIn this case, the claim holds because there are no vectors formula_18, and the set formula_19 spans formula_3 by hypothesis.\n\nFor the inductive step, assume the proposition is true for some formula_21. Since formula_22, and formula_23 spans formula_3 (by the induction hypothesis), there exist coefficients formula_25 such that\nAt least one of formula_27 must be non-zero, since otherwise this equality would contradict the linear independence of formula_28; note that this additionally implies that formula_29. By reordering the formula_30, we may assume that formula_31 is not zero. Therefore, we have\nIn other words, formula_33 is in the span of formula_34. The latter span therefore contains each of the vectors formula_35, and hence must contain the span of these latter vectors as a subset. But since the latter span is formula_3 (by the induction hypothesis), this simply means that the span of formula_34 contains formula_3 as a subset (thus is formula_3). We have therefore shown that our claim is true of formula_40, completing the inductive step.\n\nThe Steinitz exchange lemma is a basic result in computational mathematics, especially in linear algebra and in combinatorial algorithms.\n\n\n"}
{"id": "37921130", "url": "https://en.wikipedia.org/wiki?curid=37921130", "title": "Tutte homotopy theorem", "text": "Tutte homotopy theorem\n\nIn mathematics, the Tutte homotopy theorem, introduced by , generalises the concept of \"path\" from graphs to matroids, and states roughly that closed paths can be written as compositions of elementary closed paths, so that in some sense they are homotopic to the trivial closed path.\n\nA matroid on a set \"Q\" is specified by a class of non-empty subsets \"M\" of \"Q\", called circuits, such that no element of \"M\" contains another, and if \"X\" and \"Y\" are in \"M\", \"a\" is in \"X\" and \"Y\", \"b\" is in \"X\" but not in \"Y\", then there is some \"Z\" in \"M\" containing \"b\" but not \"a\" and contained in \"X\"∪\"Y\".\n\nThe subsets of \"Q\" that are unions of circuits are called flats. The elements of \"M\" are called 0-flats, the minimal non-empty flats that are not 0-flats are called 1-flats, the minimal nonempty flats that are not 0-flats or 1-flats are called 2-flats, and so on.\n\nA path is a finite sequence of 0-flats such that any two consecutive elements of the path lie in some 1-flat.\n\nAn elementary path is one of the form (\"X\",\"Y\",\"X\"), or (\"X\",\"Y\",\"Z\",\"X\") with \"X\",\"Y\",\"Z\" all lying in some 2-flat.\n\nTwo paths \"P\" and \"Q\" such that the last 0-flat of \"P\" is the same as the first 0-flat of \"Q\" can be composed in the obvious way to give a path \"PQ\".\n\nTwo paths are called homotopic if one can be obtained from the other by the operations of adding or removing elementary paths inside a path, in other words changing a path \"PR\" to \"PQR\" or vice versa, where \"Q\" is elementary.\n\nA weak form of Tutte's homotopy theorem states that any closed path is homotopic to the trivial path. A stronger form states a similar result for paths not meeting certain \"convex\" subsets.\n\n"}
{"id": "33458", "url": "https://en.wikipedia.org/wiki?curid=33458", "title": "Well-ordering theorem", "text": "Well-ordering theorem\n\nIn mathematics, the well-ordering theorem states that every set can be well-ordered. A set \"X\" is \"well-ordered\" by a strict total order if every non-empty subset of \"X\" has a least element under the ordering. This is also known as Zermelo's theorem and is equivalent to the axiom of choice (see also ). Ernst Zermelo introduced the axiom of choice as an \"unobjectionable logical principle\" to prove the well-ordering theorem. This is important because it makes every set susceptible to the powerful technique of transfinite induction. The well-ordering theorem has consequences that may seem paradoxical, such as the Banach–Tarski paradox.\n\nGeorg Cantor considered the well-ordering theorem to be a \"fundamental principle of thought\". Most mathematicians however find it difficult to visualize a well-ordering of, for example, the set R of real numbers. In 1904, Gyula Kőnig claimed to have proven that such a well-ordering cannot exist. A few weeks later, Felix Hausdorff found a mistake in the proof. It turned out, though, that the well-ordering theorem is equivalent to the axiom of choice, in the sense that either one together with the Zermelo–Fraenkel axioms is sufficient to prove the other, in first order logic (the same applies to Zorn's Lemma). In second order logic, however, the well-ordering theorem is strictly stronger than the axiom of choice: from the well-ordering theorem one may deduce the axiom of choice, but from the axiom of choice one cannot deduce the well-ordering theorem.\n\nThe well-ordering theorem follows from Zorn's lemma. Take the set \"A\" of all well-orderings of subsets of \"X\": an element of \"A\" is an ordered pair (\"a\",\"b\") where \"a\" is a subset of \"X\" and \"b\" is a well-ordering of \"a\". \"A\" can be partially ordered by continuation. That means, define \"E\" ≤ \"F\" if \"E\" is an initial segment of \"F\" and the ordering of the members of \"E\" is the same as their ordering in \"F\". If \"E\" is a chain in \"A\", then the union of the sets in \"E\" can be ordered in a way that makes it a continuation of any set in \"E\"; this ordering is a well-ordering, and therefore, an upper bound of \"E\" in \"A\". We may therefore apply Zorn's Lemma to conclude that \"A\" has a maximal element, say (\"M\",\"R\"). The set \"M\" must be equal to \"X\", for if \"X\" has an element \"x\" not in \"M\", then the set \"M\"∪{\"x\"} has a well-ordering that restricts to \"R\" on \"M\", and for which \"x\" is larger than all elements of \"M\". This well ordered set is a continuation of (\"M\",\"R\"), contradicting its maximality, therefore \"M\" = \"X\". Now \"R\" is a well-ordering of \"X\".\n\nThe Axiom of Choice can be proven from the well-ordering theorem as follows. To make a choice function for a collection of non-empty sets, \"E\", take the union of the sets in \"E\" and call it \"X\". There exists a well-ordering of \"X\"; let \"R\" be such an ordering. The function that to each set \"S\" of \"E\" associates the smallest element of \"S\", as ordered by (the restriction to \"S\" of) \"R\", is a choice function for the collection \"E\". An essential point of this proof is that it involves only a single arbitrary choice, that of \"R\"; applying the well-ordering theorem to each member \"S\" of \"E\" separately would not work, since the theorem only asserts the existence of a well-ordering, and choosing for each \"S\" a well-ordering would not be easier than choosing an element.\n\n\n"}
{"id": "14036131", "url": "https://en.wikipedia.org/wiki?curid=14036131", "title": "William McFadden Orr", "text": "William McFadden Orr\n\nWilliam McFadden Orr, FRS (2 May 1866 – 14 August 1934) was a British and Irish mathematician.\n\nHe was born in Comber, County Down and educated at Methodist College Belfast and Queen's College, Belfast under John Purser, before entering St John's College, Cambridge and graduating as Senior Wrangler in 1888. He was elected a fellow of his college, and became a Fellow of the Royal Society in 1909.\n\nHe was appointed professor of mathematics at the Royal College of Science for Ireland in 1892 and professor of pure mathematics and applied mathematics when the college merged with University College Dublin in 1926. He retired in 1933 and died in 1934, and is interred in Mount Jerome Cemetery, Dublin.\n\n"}
