{"id": "58753466", "url": "https://en.wikipedia.org/wiki?curid=58753466", "title": "Bendixson's inequality", "text": "Bendixson's inequality\n\nIn mathematics, Bendixson's inequality is a quantitative result in the field of matrices derived by Ivar Bendixson in 1902. The inequality puts limits on the imaginary parts of Characteristic roots (Eigen values) of real matrices. A special case of this inequality leads to the result that characteristic roots of a real matrix are always real.\n\nMathematically, the inequality is stated as:\n\nLet formula_1 be a real formula_2 matrix and formula_3. If formula_4 is any characteristic root of formula_5, then\n\nIf formula_5 is symmetric then formula_8 and consequently the inequality implies that formula_4 must be real.\n"}
{"id": "5147723", "url": "https://en.wikipedia.org/wiki?curid=5147723", "title": "Birch's theorem", "text": "Birch's theorem\n\nIn mathematics, Birch's theorem, named for Bryan John Birch, is a statement about the representability of zero by odd degree forms.\n\nLet \"K\" be an algebraic number field, \"k\", \"l\" and \"n\" be natural numbers, \"r\", . . . ,\"r\" be odd natural numbers, and \"f\", . . . ,\"f\" be homogeneous polynomials with coefficients in \"K\" of degrees \"r\", . . . ,\"r\" respectively in \"n\" variables, then there exists a number ψ(\"r\", . . . ,\"r\",\"l\",\"K\") such that\nimplies that there exists an \"l\"-dimensional vector subspace \"V\" of \"K\" such that\n\nThe proof of the theorem is by induction over the maximal degree of the forms \"f\", . . . ,\"f\". Essential to the proof is a special case, which can be proved by an application of the Hardy–Littlewood circle method, of the theorem which states that if \"n\" is sufficiently large and \"r\" is odd, then the equation\n\nhas a solution in integers \"x\", . . . ,\"x\", not all of which are 0.\n\nThe restriction to odd \"r\" is necessary, since even-degree forms, such as positive definite quadratic forms, may take the value 0 only at the origin.\n"}
{"id": "7087423", "url": "https://en.wikipedia.org/wiki?curid=7087423", "title": "Boolean circuit", "text": "Boolean circuit\n\nIn computational complexity theory and circuit complexity, a Boolean circuit is a mathematical model for digital logic circuits. A formal language can be decided by a family of Boolean circuits, one circuit for each possible input length. Boolean circuits are also used as a formal model for combinational logic in digital electronics.\n\nBoolean circuits are defined in terms of the logic gates they contain. For example, a circuit might contain binary AND and OR gates and unary NOT gates, or be entirely described by binary NAND gates. Each gate corresponds to some Boolean function that takes a fixed number of bits as input and outputs a single bit.\n\nBoolean circuits provide a model for many digital components used in computer engineering, including multiplexers, adders, and arithmetic logic units.\n\nIn giving a formal definition of Boolean circuits, Vollmer starts by defining a basis set \"B\" of Boolean functions, corresponding to the gates allowable in the circuit model. A Boolean circuit over a basis \"B\", with \"n\" inputs and \"m\" outputs, is then defined as a finite directed acyclic graph. Each vertex corresponds to either a basis function or one of the inputs, and there is a set of exactly \"m\" nodes which are labeled as the outputs. The edges must also have some ordering, to distinguish between different arguments to the same Boolean function.\n\nAs a special case, a propositional formula or Boolean expression is a Boolean circuit with a single output node in which every other node has fan-out of 1. Thus, a Boolean circuit can be regarded as a generalization that allows shared subformulas and multiple outputs.\n\nA common basis for Boolean circuits is the set {AND, OR, NOT}, from which all other Boolean functions can be constructed.\n\nThe Circuit Value Problem, the problem of computing the output of a given Boolean circuit on a given input string, is a P-complete decision problem. Therefore, this problem is considered to be \"inherently sequential\" in the sense that there is likely no efficient, highly parallel algorithm that solves the problem.\n\nSeveral important complexity measures can be defined on Boolean circuits, including circuit depth, circuit size, and number of alternations between AND gates and OR gates. For example, the size complexity of a Boolean circuit is the number of gates.\n\nSeveral important complexity classes are defined in terms of Boolean circuits, including NC. NC is defined to be the set of Boolean functions that can be decided by uniform Boolean circuits of polynomial size and polylogarithmic depth. Here, the word \"uniform\" means that there must be some condition on the circuit family so that a description of a circuit can be computed from only the number of inputs to the circuit.\n\n"}
{"id": "1028158", "url": "https://en.wikipedia.org/wiki?curid=1028158", "title": "Canonical basis", "text": "Canonical basis\n\nIn mathematics, a canonical basis is a basis of an algebraic structure that is canonical in a sense that depends on the precise context:\n\n\nIn representation theory there are several bases that are called \"canonical\", for example, Lusztig's canonical basis and closely related Kashiwara's crystal basis in quantum groups and their representations. There is a general concept underlying these basis:\n\nConsider the ring of integral Laurent polynomials formula_3 with its two subrings formula_4 and the automorphism formula_5 defined by formula_6.\n\nA \"precanonical structure\" on a free formula_7-module formula_8 consists of\n\nIf a precanonical structure is given, then one can define the formula_17 submodule formula_18 of formula_8.\n\nA \"canonical basis at formula_20\" of the precanonical structure is then a formula_7-basis formula_22 of formula_8 that satisfies:\nfor all formula_13. A \"canonical basis at formula_27\" is analogously defined to be a basis formula_28 that satisfies\nfor all formula_13. The naming \"at formula_27\" alludes to the fact formula_33 and hence the \"specialization\" formula_34 corresponds to quotienting out the relation formula_35.\n\nOne can show that there exists at most one canonical basis at \"v\" = 0 (and at most one at formula_27) for each precanonical structure. A sufficient condition for existence is that the polynomials formula_37 defined by formula_38 satisfy formula_39 and formula_40.\n\nA canonical basis at \"v\" = 0 (formula_27) induces an isomorphism from formula_42 to formula_43 (formula_44 respectively).\n\nThe canonical basis of quantum groups in the sense of Lusztig and Kashiwara are canonical basis at formula_20.\n\nLet formula_46 be a Coxeter group. The corresponding Iwahori-Hecke algebra formula_47 has the standard basis formula_48, the group is partially ordered by the Bruhat order which is interval finite and has a dualization operation defined by formula_49. This is a precanonical structure on formula_47 that satisfies the sufficient condition above and the corresponding canonical basis of formula_47 at formula_20 is the Kazhdan–Lusztig basis\n\nwith formula_54 being the Kazhdan–Lusztig polynomials.\n\nIf we are given an \"n\" × \"n\" matrix formula_2 and wish to find a matrix formula_56 in Jordan normal form, similar to formula_2, we are interested only in sets of linearly independent generalized eigenvectors. A matrix in Jordan normal form is an \"almost diagonal matrix,\" that is, as close to diagonal as possible. A diagonal matrix formula_58 is a special case of a matrix in Jordan normal form. An ordinary eigenvector is a special case of a generalized eigenvector.\n\nEvery \"n\" × \"n\" matrix formula_2 possesses \"n\" linearly independent generalized eigenvectors. Generalized eigenvectors corresponding to distinct eigenvalues are linearly independent. If formula_60 is an eigenvalue of formula_2 of algebraic multiplicity formula_62, then formula_2 will have formula_62 linearly independent generalized eigenvectors corresponding to formula_60.\n\nFor any given \"n\" × \"n\" matrix formula_2, there are infinitely many ways to pick the \"n\" linearly independent generalized eigenvectors. If they are chosen in a particularly judicious manner, we can use these vectors to show that formula_2 is similar to a matrix in Jordan normal form. In particular,\n\nDefinition: A set of \"n\" linearly independent generalized eigenvectors is a canonical basis if it is composed entirely of Jordan chains.\n\nThus, once we have determined that a generalized eigenvector of rank \"m\" is in a canonical basis, it follows that the \"m\" − 1 vectors formula_68 that are in the Jordan chain generated by formula_69 are also in the canonical basis.\n\nLet formula_70 be an eigenvalue of formula_2 of algebraic multiplicity formula_72. First, find the ranks (matrix ranks) of the matrices formula_73. The integer formula_74 is determined to be the \"first integer\" for which formula_75 has rank formula_76 (\"n\" being the number of rows or columns of formula_2, that is, formula_2 is \"n\" × \"n\").\n\nNow define\n\nThe variable formula_80 designates the number of linearly independent generalized eigenvectors of rank \"k\" (generalized eigenvector rank; see generalized eigenvector) corresponding to the eigenvalue formula_70 that will appear in a canonical basis for formula_2. Note that\n\nOnce we have determined the number of generalized eigenvectors of each rank that a canonical basis has, we can obtain the vectors explicitly (see generalized eigenvector).\n\nThis example illustrates a canonical basis with two Jordan chains. Unfortunately, it is a little difficult to construct an interesting example of low order.\nThe matrix\n\nhas eigenvalues formula_85 and formula_86 with algebraic multiplicities formula_87 and formula_88, but geometric multiplicities formula_89 and formula_90.\n\nFor formula_91 we have formula_92\n\nTherefore formula_97\n\nThus, a canonical basis for formula_2 will have, corresponding to formula_91 one generalized eigenvector each of ranks 4, 3, 2 and 1.\n\nFor formula_104 we have formula_105\n\nTherefore formula_108\n\nThus, a canonical basis for formula_2 will have, corresponding to formula_104 one generalized eigenvector each of ranks 2 and 1.\n\nA canonical basis for formula_2 is\n\nformula_115 is the ordinary eigenvector associated with formula_116. \nformula_117 and formula_118 are generalized eigenvectors associated with formula_116. \nformula_120 is the ordinary eigenvector associated with formula_121. \nformula_122 is a generalized eigenvector associated with formula_121.\n\nA matrix formula_56 in Jordan normal form, similar to formula_2 is obtained as follows:\n\nwhere the matrix formula_128 is a generalized modal matrix for formula_2 and formula_130.\n\n\n"}
{"id": "42392488", "url": "https://en.wikipedia.org/wiki?curid=42392488", "title": "Chasles' theorem (gravitation)", "text": "Chasles' theorem (gravitation)\n\nIn gravitation, Chasles' theorem says that the Newtonian gravitational attraction of a spherical shell, outside of that shell, is equivalent mathematically to the attraction of a point mass.\n\nThe theorem is attributed to Michel Chasles (1793–1880).\n\nBenjamin Peirce followed Chasles work on that developed an analogy between conduction of heat and gravitational attraction:\nChaslesian shell is the figure that Peirce exploits:\nThe Chasles theorem as expressed by Peirce:\nThe ellipsoid is recruited to bound the Chaslesian shells:\n"}
{"id": "21059", "url": "https://en.wikipedia.org/wiki?curid=21059", "title": "Constructivism (philosophy of mathematics)", "text": "Constructivism (philosophy of mathematics)\n\nIn the philosophy of mathematics, constructivism asserts that it is necessary to find (or \"construct\") a mathematical object to prove that it exists. In standard mathematics, one can prove the existence of a mathematical object without \"finding\" that object explicitly, by assuming its non-existence and then deriving a contradiction from that assumption. This proof by contradiction is not constructively valid. The constructive viewpoint involves a verificational interpretation of the existential quantifier, which is at odds with its classical interpretation.\n\nThere are many forms of constructivism. These include the program of intuitionism founded by Brouwer, the finitism of Hilbert and Bernays, the constructive recursive mathematics of Shanin and Markov, and Bishop's program of constructive analysis. Constructivism also includes the study of constructive set theories such as CZF and the study of topos theory.\n\nConstructivism is often identified with intuitionism, although intuitionism is only one constructivist program. Intuitionism maintains that the foundations of mathematics lie in the individual mathematician's intuition, thereby making mathematics into an intrinsically subjective activity. Other forms of constructivism are not based on this viewpoint of intuition, and are compatible with an objective viewpoint on mathematics.\n\nMuch constructive mathematics uses intuitionistic logic, which is essentially classical logic without the law of the excluded middle. This law states that, for any proposition, either that proposition is true or its negation is. This is not to say that the law of the excluded middle is denied entirely; special cases of the law will be provable. It is just that the general law is not assumed as an axiom. The law of non-contradiction (which states that contradictory statements cannot both at the same time be true) is still valid.\n\nFor instance, in Heyting arithmetic, one can prove that for any proposition \"p\" that \"does not contain quantifiers\", formula_1 is a theorem (where \"x\", \"y\", \"z\" ... are the free variables in the proposition \"p\"). In this sense, propositions restricted to the finite are still regarded as being either true or false, as they are in classical mathematics, but this bivalence does not extend to propositions that refer to infinite collections.\n\nIn fact, L.E.J. Brouwer, founder of the intuitionist school, viewed the law of the excluded middle as abstracted from finite experience, and then applied to the infinite without justification. For instance, Goldbach's conjecture is the assertion that every even number (greater than 2) is the sum of two prime numbers. It is possible to test for any particular even number whether or not it is the sum of two primes (for instance by exhaustive search), so any one of them is either the sum of two primes or it is not. And so far, every one thus tested has in fact been the sum of two primes.\n\nBut there is no known proof that all of them are so, nor any known proof that not all of them are so. Thus to Brouwer, we are not justified in asserting \"either Goldbach's conjecture is true, or it is not.\" And while the conjecture may one day be solved, the argument applies to similar unsolved problems; to Brouwer, the law of the excluded middle was tantamount to assuming that \"every\" mathematical problem has a solution.\n\nWith the omission of the law of the excluded middle as an axiom, the remaining logical system has an existence property that classical logic does not have: whenever formula_2 is proven constructively, then in fact formula_3 is proven constructively for (at least) one particular formula_4, often called a witness. Thus the proof of the existence of a mathematical object is tied to the possibility of its construction.\n\nIn classical real analysis, one way to define a real number is as an equivalence class of Cauchy sequences of rational numbers.\n\nIn constructive mathematics, one way to construct a real number is as a function \"ƒ\" that takes a positive integer formula_5 and outputs a rational \"ƒ\"(\"n\"), together with a function \"g\" that takes a positive integer \"n\" and outputs a positive integer \"g\"(\"n\") such that\n\nso that as \"n\" increases, the values of \"ƒ\"(\"n\") get closer and closer together. We can use \"ƒ\" and \"g\" together to compute as close a rational approximation as we like to the real number they represent.\n\nUnder this definition, a simple representation of the real number \"e\" is:\n\nThis definition corresponds to the classical definition using Cauchy sequences, except with a constructive twist: for a classical Cauchy sequence, it is required that, for any given distance, there exists (in a classical sense) a member in the sequence after which all members are closer together than that distance. In the constructive version, it is required that, for any given distance, it is possible to actually specify a point in the sequence where this happens (this required specification is often called the modulus of convergence). In fact, the standard constructive interpretation of the mathematical statement\n\nis precisely the existence of the function computing the modulus of convergence. Thus the difference between the two definitions of real numbers can be thought of as the difference in the interpretation of the statement \"for all... there exists...\"\n\nThis then opens the question as to what sort of function from a countable set to a countable set, such as \"f\" and \"g\" above, can actually be constructed. Different versions of constructivism diverge on this point. Constructions can be defined as broadly as free choice sequences, which is the intuitionistic view, or as narrowly as algorithms (or more technically, the computable functions), or even left unspecified. If, for instance, the algorithmic view is taken, then the reals as constructed here are essentially what classically would be called the computable numbers.\n\nTo take the algorithmic interpretation above would seem at odds with classical notions of cardinality. By enumerating algorithms, we can show classically that the computable numbers are countable. And yet Cantor's diagonal argument shows that real numbers have higher cardinality. Furthermore, the diagonal argument seems perfectly constructive. To identify the real numbers with the computable numbers would then be a contradiction.\n\nAnd in fact, Cantor's diagonal argument \"is\" constructive, in the sense that given a bijection between the real numbers and natural numbers, one constructs a real number that doesn't fit, and thereby proves a contradiction. We can indeed enumerate algorithms to construct a function \"T\", about which we initially assume that it is a function from the natural numbers onto the reals. But, to each algorithm, there may or may not correspond a real number, as the algorithm may fail to satisfy the constraints, or even be non-terminating (\"T\" is a partial function), so this fails to produce the required bijection. In short, one who takes the view that real numbers are (individually) effectively computable interprets Cantor's result as showing that the real numbers (collectively) are not recursively enumerable.\n\nStill, one might expect that since \"T\" is a partial function from the natural numbers onto the real numbers, that therefore the real numbers are \"no more than\" countable. And, since every natural number can be trivially represented as a real number, therefore the real numbers are \"no less than\" countable. They are, therefore \"exactly\" countable. However this reasoning is not constructive, as it still does not construct the required bijection. The classical theorem proving the existence of a bijection in such circumstances, namely the Cantor–Bernstein–Schroeder theorem, is non-constructive and no constructive proof of it is known.\n\nThe status of the axiom of choice in constructive mathematics is complicated by the different approaches of different constructivist programs. One trivial meaning of \"constructive\", used informally by mathematicians, is \"provable in ZF set theory without the axiom of choice.\" However, proponents of more limited forms of constructive mathematics would assert that ZF itself is not a constructive system.\n\nIn intuitionistic theories of type theory (especially higher-type arithmetic), many forms of the axiom of choice are permitted. For example, the axiom AC can be paraphrased to say that for any relation \"R\" on the set of real numbers, if you have proved that for each real number \"x\" there is a real number \"y\" such that \"R\"(\"x\",\"y\") holds, then there is actually a function \"F\" such that \"R\"(\"x\",\"F\"(\"x\")) holds for all real numbers. Similar choice principles are accepted for all finite types. The motivation for accepting these seemingly nonconstructive principles is the intuitionistic understanding of the proof that \"for each real number \"x\" there is a real number \"y\" such that \"R\"(\"x\",\"y\") holds\". According to the BHK interpretation, this proof itself is essentially the function \"F\" that is desired. The choice principles that intuitionists accept do not imply the law of the excluded middle.\n\nHowever, in certain axiom systems for constructive set theory, the axiom of choice does imply the law of the excluded middle (in the presence of other axioms), as shown by the Diaconescu-Goodman-Myhill theorem. Some constructive set theories include weaker forms of the axiom of choice, such as the axiom of dependent choice in Myhill's set theory.\n\nClassical measure theory is fundamentally non-constructive, since the classical definition of Lebesgue measure does not describe any way to compute the measure of a set or the integral of a function. In fact, if one thinks of a function just as a rule that \"inputs a real number and outputs a real number\" then there cannot be any algorithm to compute the integral of a function, since any algorithm would only be able to call finitely many values of the function at a time, and finitely many values are not enough to compute the integral to any nontrivial accuracy. The solution to this conundrum, carried out first in Bishop's 1967 book, is to consider only functions that are written as the pointwise limit of continuous functions (with known modulus of continuity), with information about the rate of convergence. An advantage of constructivizing measure theory is that if one can prove that a set is constructively of full measure, then there is an algorithm for finding a point in that set (again see Bishop's book). For example, this approach can be used to construct a real number that is normal to every base.\n\nTraditionally, some mathematicians have been suspicious, if not antagonistic, towards mathematical constructivism, largely because of limitations they believed it to pose for constructive analysis.\nThese views were forcefully expressed by David Hilbert in 1928, when he wrote in \"Grundlagen der Mathematik\", \"Taking the principle of excluded middle from the mathematician would be the same, say, as proscribing the telescope to the astronomer or to the boxer the use of his fists\".\n\nErrett Bishop, in his 1967 work \"Foundations of Constructive Analysis\", worked to dispel these fears by developing a great deal of traditional analysis in a constructive framework.\n\nEven though most mathematicians do not accept the constructivist's thesis that only mathematics done based on constructive methods is sound, constructive methods are increasingly of interest on non-ideological grounds. For example, constructive proofs in analysis may ensure witness extraction, in such a way that working within the constraints of the constructive methods may make finding witnesses to theories easier than using classical methods. Applications for constructive mathematics have also been found in typed lambda calculi, topos theory and categorical logic, which are notable subjects in foundational mathematics and computer science. In algebra, for such entities as toposes and Hopf algebras, the structure supports an internal language that is a constructive theory; working within the constraints of that language is often more intuitive and flexible than working externally by such means as reasoning about the set of possible concrete algebras and their homomorphisms.\n\nPhysicist Lee Smolin writes in \"Three Roads to Quantum Gravity\" that topos theory is \"the right form of logic for cosmology\" (page 30) and \"In its first forms it was called 'intuitionistic logic'\" (page 31). \"In this kind of logic, the statements an observer can make about the universe are divided into at least three groups: those that we can judge to be true, those that we can judge to be false and those whose truth we cannot decide upon at the present time\" (page 28).\n\n\n\n\n\n"}
{"id": "26013068", "url": "https://en.wikipedia.org/wiki?curid=26013068", "title": "Cousin's theorem", "text": "Cousin's theorem\n\nIn real analysis, a branch of mathematics, Cousin's theorem states that:\n\nThis result was proved and established by Pierre Cousin, a student of Henri Poincaré, in 1895, and it is an extension of the original Heine–Borel theorem on compactness for arbitrary covers of any compact subsets of formula_1. However, Pierre Cousin did not receive any credit. Cousin's theorem was generally attributed to Henri Lebesgue and renamed as Borel–Lebesgue theorem, who was aware of this result in 1898 and proved this in his dissertation in 1903.\n\nNowadays, it is stated as:\n\nFurther, Cousin's theorem is mainly only used in Henstock–Kurzweil integral and is often called Fineness Theorem or Cousin's lemma. It can be stated as:\n\n"}
{"id": "8846283", "url": "https://en.wikipedia.org/wiki?curid=8846283", "title": "Cyclic negation", "text": "Cyclic negation\n\nIn many-valued logic with linearly ordered truth values, cyclic negation is a unary truth function that takes a truth value \"n\" and returns \"n\" − 1 as value if \"n\" is not the lowest value; otherwise it returns the highest value.\n\nFor example, let the set of truth values be {0,1,2}, let ~ denote negation, and let \"p\" be a variable ranging over truth values. For these choices, if p = 0 then ~p = 2; and if p = 1 then ~p = 0.\n\nCyclic negation was originally introduced by the logician and mathematician Emil Post.\n\n"}
{"id": "17507355", "url": "https://en.wikipedia.org/wiki?curid=17507355", "title": "Dining cryptographers problem", "text": "Dining cryptographers problem\n\nIn cryptography, the dining cryptographers problem studies how to perform a secure multi-party computation of the boolean-OR function. David Chaum first proposed this problem in the early 1980s and used it as an illustrative example to show that it was possible to send anonymous messages with unconditional sender and recipient untraceability. Anonymous communication networks based on this problem are often referred to as DC-nets (where DC stands for \"dining cryptographers\").\n\nDespite the word \"dining\", the dining cryptographers problem is unrelated to the dining philosophers problem.\n\nThree cryptographers gather around a table for dinner. The waiter informs them that the meal has been paid for by someone, who could be one of the cryptographers or the National Security Agency (NSA). The cryptographers respect each other's right to make an anonymous payment, but want to find out whether the NSA paid. So they decide to execute a two-stage protocol.\n\nIn the first stage, every two cryptographers establish a shared one-bit secret, say by tossing a coin behind a menu so that only two cryptographers see the outcome in turn for each two cryptographers. Suppose, for example, that after the coin tossing, cryptographer A and B share a secret bit formula_1, A and C share formula_2, and B and C share formula_1.\n\nIn the second stage, each cryptographer publicly announces a bit, which is:\n\nSupposing none of the cryptographers paid, then A announces formula_4, B announces formula_5, and C announces formula_6. On the other hand, if A paid, she announces formula_7.\n\nThe three public announcements combined reveal the answer to their question. One simply computes the XOR of the three bits announced. If the result is 0, it implies that none of the cryptographers paid (so the NSA must have paid the bill). Otherwise, one of the cryptographers paid, but their identity remains unknown to the other cryptographers.\n\nDavid Chaum coined the term \"dining cryptographers network\", or DC-net, for this protocol.\n\nThe DC-net protocol is simple and elegant. It has several limitations, however, some solutions to which have been explored in follow-up research (see the References section below).\n\n\n\n\nA related anonymous veto network algorithm computes the logical OR of several users' inputs, rather than a logical XOR as in DC-nets, which may be useful in applications to which a logical OR combining operation is naturally suited.\n\nDavid Chaum first thought about this problem in the early 1980s. The first publication that outlines the basic underlying ideas is his. The journal version appeared in the very first issue of the Journal of Cryptology.\n\nDC-nets are readily generalized to allow for transmissions of more than one bit per round, for groups larger than three participants, and for arbitrary \"alphabets\" other than the binary digits 0 and 1, as described below.\n\nTo enable an anonymous sender to transmit more than one bit of information per DC-nets round, the group of cryptographers can simply repeat the protocol as many times as desired to create a desired number of bits worth of transmission bandwidth. These repetitions need not be performed serially. In practical DC-net systems, it is typical for pairs of participants to agree up-front on a single shared \"master\" secret, using Diffie–Hellman key exchange for example. Each participant then locally feeds this shared master secret into a pseudorandom number generator, in order to produce as many shared \"coin flips\" as desired to allow an anonymous sender to transmit multiple bits of information.\n\nThe protocol can be generalized to a group of formula_9 participants, each with a shared secret key in common with each other participant. In each round of the protocol, if a participant wants to transmit an untraceable message to the group, they invert their publicly announced bit. The participants can be visualized as a fully connected graph with the vertices representing the participants and the edges representing their shared secret keys.\n\nThe protocol may be run with less than fully connected secret sharing graphs, which can improve the performance and scalability of practical DC-net implementations, at the potential risk of reducing anonymity if colluding participants can split the secret sharing graph into separate connected components. For example, an intuitively appealing but less secure generalization to formula_10 participants using a ring topology, where each cryptographer sitting around a table shares a secret \"only\" with the cryptographer to their immediate left and right, and \"not\" with every other cryptographer. Such a topology is appealing because each cryptographer needs to coordinate two coin flips per round, rather than formula_9. However, if Adam and Charlie are actually NSA agents sitting immediately to the left and right of Bob, an innocent victim, and if Adam and Charlie secretly collude to reveal their secrets to each other, then they can determine with certainty whether or not Bob was the sender of a 1 bit in a DC-net run, regardless of how many participants there are in total. This is because the colluding participants Adam and Charlie effectively \"split\" the secret sharing graph into two separate disconnected components, one containing only Bob, the other containing all other honest participants.\n\nAnother compromise secret sharing DC-net topology, employed in the Dissent system for scalability, may be described as a \"client/server\" or \"user/trustee\" topology. In this variant, we assume there are two types of participants playing different roles: a potentially large number \"n\" of users who desire anonymity, and a much smaller number formula_12 of \"trustees\" whose role is to help the users obtain that anonymity. In this topology, each of the formula_9 users shares a secret with each of the formula_12 trustees—but users share no secrets directly with other users, and trustees share no secrets directly with other trustees—resulting in an formula_15 secret sharing matrix. If the number of trustees formula_12 is small, then each user needs to manage only a few shared secrets, improving efficiency for users in the same way the ring topology does. However, as long as \"at least one trustee\" behaves honestly and does not leak his or her secrets or collude with other participants, then that honest trustee forms a \"hub\" connecting all honest users into a single fully connected component, regardless of which or how many other users and/or trustees might be dishonestly colluding. Users need not know or guess which trustee is honest; their security depends only on the \"existence\" of at least one honest, non-colluding trustee.\n\nThough the simple DC-nets protocol uses binary digits as its transmission alphabet, and uses the XOR operator to combine cipher texts, the basic protocol generalizes to any alphabet and combining operator suitable for one-time pad encryption. This flexibility arises naturally from the fact that the secrets shared between the many pairs of participants are, in effect, merely one-time pads combined together symmetrically within a single DC-net round.\n\nOne useful alternate choice of DC-nets alphabet and combining operator is to use a finite group suitable for public-key cryptography as the alphabet—such as a Schnorr group or elliptic curve—and to use the associated group operator as the DC-net combining operator. Such a choice of alphabet and operator makes it possible for clients to use zero-knowledge proof techniques to prove correctness properties about the DC-net ciphertexts that they produce, such as that the participant is not \"jamming\" the transmission channel, without compromising the anonymity offered by the DC-net. This technique was first suggested by Golle and Juels, further developed by Franck, and later implemented in Verdict, a cryptographically verifiable implementation of the Dissent system.\n\nThe measure originally suggested by David Chaum to avoid collisions is to retransmit the message once a collision is detected, but the paper does not explain exactly how to arrange the retransmission.\n\nDissent avoids the possibility of unintentional collisions by using a verifiable shuffle to establish a DC-nets transmission schedule, such that each participant knows exactly which bits in the schedule correspond to his own transmission slot, but does not know who owns other transmission slots.\n\nHerbivore divides a large anonymity network into smaller DC-net groups, enabling participants to evade disruption attempts by leaving a disrupted group and joining another group, until the participant finds a group free of disruptors. This evasion approach introduces the risk that an adversary who owns many nodes could \"selectively\" disrupt only groups the adversary has not \"completely\" compromised, thereby \"herding\" participants toward groups that may be functional precisely because they are completely compromised.\n\nDissent implements several schemes to counter disruption. The original protocol used a verifiable cryptographic shuffle to form a DC-net transmission schedule and distribute \"transmission assignments\", allowing the correctness of subsequent DC-nets ciphertexts to be verified with a simple cryptographic hash check. This technique required a fresh verifiable before every DC-nets round, however, leading to high latencies. A later, more efficient scheme allows a series of DC-net rounds to proceed without intervening shuffles in the absence of disruption, but in response to a disruption event uses a shuffle to distribute anonymous \"accusations\" enabling a disruption victim to expose and prove the identity of the perpetrator. Finally, more recent versions support fully verifiable DC-nets - at substantial cost in computation efficiency due to the use of public-key cryptography in the DC-net - as well as a \"hybrid\" mode that uses efficient XOR-based DC-nets in the normal case and verifiable DC-nets only upon disruption, to distribute accusations more quickly than is feasible using verifiable shuffles.\n"}
{"id": "105622", "url": "https://en.wikipedia.org/wiki?curid=105622", "title": "Euler's criterion", "text": "Euler's criterion\n\nIn number theory Euler's criterion is a formula for determining whether an integer is a quadratic residue modulo a prime. Precisely,\n\nLet \"p\" be an odd prime and \"a\" an integer coprime to \"p\". Then\n\nEuler's criterion can be concisely reformulated using the Legendre symbol:\n\nThe criterion first appeared in a 1748 paper by Euler.\n\nThe proof uses the fact that the residue classes modulo a prime number are a field. See the article prime field for more details.\n\nBecause the modulus is prime, Lagrange's theorem applies: a polynomial of degree can only have at most roots. In particular, formula_3 has at most 2 roots for each . This immediately implies that besides 0 there are at least distinct quadratic residues (mod ): each of the possible can only be accompanied by one other to give the same residue.\n\nAs is coprime to , Fermat's little theorem says that\nwhich can be written as\nSince the integers mod form a field, for each one or the other of these factors must be zero.\n\nNow if is a quadratic residue, ,\nSo every quadratic residue (mod ) makes the first factor zero.\n\nApplying Lagrange's theorem again, we note that there can be no more than values of that make the first factor zero. But as we noted at the beginning, there are at least distinct quadratic residues (mod ) (besides 0). Therefore they are precisely the residue classes that make the first factor zero. The other residue classes, the nonresidues, must make the second factor zero, or they would not satisfy Fermat's little theorem. This is Euler's criterion.\n\nExample 1: Finding primes for which \"a\" is a residue\n\nLet \"a\" = 17. For which primes \"p\" is 17 a quadratic residue?\n\nWe can test prime \"p\"'s manually given the formula above.\n\nIn one case, testing \"p\" = 3, we have 17 = 17 ≡ 2 ≡ −1 (mod 3), therefore 17 is not a quadratic residue modulo 3.\n\nIn another case, testing \"p\" = 13, we have 17 = 17 ≡ 1 (mod 13), therefore 17 is a quadratic residue modulo 13. As confirmation, note that 17 ≡ 4 (mod 13), and 2 = 4.\n\nWe can do these calculations faster by using various modular arithmetic and Legendre symbol properties.\n\nIf we keep calculating the values, we find:\n\nExample 2: Finding residues given a prime modulus \"p\" \n\nWhich numbers are squares modulo 17 (quadratic residues modulo 17)?\n\nWe can manually calculate it as:\n\nSo the set of the quadratic residues modulo 17 is {1,2,4,8,9,13,15,16}. Note that we did not need to calculate squares for the values 9 through 16, as they are all negatives of the previously squared values (e.g. 9 ≡ −8 (mod 17), so 9 ≡ (−8) = 64 ≡ 13 (mod 17)).\n\nWe can find quadratic residues or verify them using the above formula. To test if 2 is a quadratic residue modulo 17, we calculate 2 = 2 ≡ 1 (mod 17), so it is a quadratic residue. To test if 3 is a quadratic residue modulo 17, we calculate 3 = 3 ≡ 16 ≡ −1 (mod 17), so it is not a quadratic residue.\n\nEuler's criterion is related to the Law of quadratic reciprocity and is used in a definition of Euler–Jacobi pseudoprimes.\n\nThe \"Disquisitiones Arithmeticae\" has been translated from Gauss's Ciceronian Latin into English and German. The German edition includes all of his papers on number theory: all the proofs of quadratic reciprocity, the determination of the sign of the Gauss sum, the investigations into biquadratic reciprocity, and unpublished notes.\n\n"}
{"id": "1963183", "url": "https://en.wikipedia.org/wiki?curid=1963183", "title": "Euro calculator", "text": "Euro calculator\n\nA euro calculator is a very popular type of calculator in European countries (see eurozone) that adopted the euro as their official monetary unit. It functions like any other normal calculator, but it also includes a special function which allows one to convert a value expressed in the previously official unit (the peseta in Spain, for example) to the new value in euros, or vice versa. Its use became very popular within the population and commerce of these countries especially during the first few months after adopting the euro.\n\nAs so many were produced, they are also found outside the eurozone to help staff with conversions at airports or railway stations where the euro has a strong presence.\n"}
{"id": "37810060", "url": "https://en.wikipedia.org/wiki?curid=37810060", "title": "Friedberg numbering", "text": "Friedberg numbering\n\nIn computability theory, a Friedberg numbering is a numbering (enumeration) of the set of all uniformly recursively enumerable sets that has no repetitions: each recursively enumerable set appears exactly once in the enumeration (Vereščagin and Shen 2003:30).\n\nThe existence of such numberings was established by Richard M. Friedberg in 1958 (Cutland 1980:78). \n\n\n"}
{"id": "49817168", "url": "https://en.wikipedia.org/wiki?curid=49817168", "title": "Germanium-vacancy center in diamond", "text": "Germanium-vacancy center in diamond\n\nThe germanium-vacancy center (Ge-V) is an optically active defect in diamond, which can be created by doping germanium into diamond during its growth or by implanting germanium ions into diamond after its growth. Its properties are similar to those of the silicon-vacancy center in diamond (SiV). Ge-V can behave as a single-photon source and shows potential for quantum and nanoscience applications due to its narrow zero-phonon line (ZPL) and minimal phononic-sideband (compared to that of the nitrogen-vacancy center (NV).\n\nGe-V is predicted to consist of one germanium atom situated between two adjacent lattice vacancies and have the same D point group symmetry as SiV. It has a single ZPL at 602 nm (2.059 eV) at room-temperature, which splits into two components separated by 0.67 meV at low-temperatures (10 K). The Ge-V has an excited state lifetime of 1.4–5.5 ns.\n\nGe-V can be created during the diamond growth, or by ion implantation and subsequent annealing at 800 °C. The former way results in lower lattice strain, as revealed by the spread in the position and width of the Ge-V ZPL.\n"}
{"id": "30654850", "url": "https://en.wikipedia.org/wiki?curid=30654850", "title": "Groups, Geometry, and Dynamics", "text": "Groups, Geometry, and Dynamics\n\nGroups, Geometry, and Dynamics is a quarterly peer-reviewed mathematics journal published quarterly by the European Mathematical Society. It was established in 2007 and covers all aspects of groups, group actions, geometry and dynamical systems. The journal is indexed by \"Mathematical Reviews\" and Zentralblatt MATH. Its 2009 MCQ was 0.65, and its 2012 impact factor is 0.867.\n"}
{"id": "7905578", "url": "https://en.wikipedia.org/wiki?curid=7905578", "title": "Guillermo Martínez (writer)", "text": "Guillermo Martínez (writer)\n\nGuillermo Martínez (born 29 July 1962) is an Argentine novelist and short story writer.\n\nMartínez was born in Bahía Blanca, Argentina. He gained a PhD in mathematical logic at the University of Buenos Aires.\n\nAfter his degree in Argentina, he worked for two years in a postdoctoral position at the Mathematical Institute, Oxford. His most successful novel has been Crímenes Imperceptibles (Imperceptible Crimes) known as \"The Oxford Murders\", written in 2003. In the same year, he was awarded the Planeta Prize for this novel, which has been translated into a number of languages. The book has appeared as a film in 2008, directed by Alex de la Iglesia, and starring John Hurt, Elijah Wood, Leonor Watling and Julie Cox.\n\n\n\n"}
{"id": "55789686", "url": "https://en.wikipedia.org/wiki?curid=55789686", "title": "Human information interaction", "text": "Human information interaction\n\nHuman-information interaction or HII is the formal term for information behavior research in archival science; the term was invented by Nahum Gershon in 1995. HII is not transferrable from analog to digital research because nonprofessional researchers greatly emphasize the need for further elaboration of context and scope finding aid elements. Researchers in HII take on many tasks, including helping to design information systems from a biological perspective that conform to the requirements of different segments of society, along with other behaviour intended to improve interaction between humans and information systems. HII is generally considered to be multi-disciplinary as different disciplines have different viewpoints on these interactions and their consequences. HII is considered especially important due to humanity's dependence on information and the technology needed to access it.\n"}
{"id": "48628786", "url": "https://en.wikipedia.org/wiki?curid=48628786", "title": "ILNumerics", "text": "ILNumerics\n\nILNumerics is a mathematical class library for Common Language Infrastructure (CLI) developers and a domain specific language (DSL) for the implementation of numerical algorithms on the .NET platform. While algebra systems with graphical user interfaces focus on prototyping of algorithms, implementation of such algorithms into distribution-ready applications is done using \ndevelopment environments and general purpose programming languages (GPL). ILNumerics is an extension to Visual Studio and aims at supporting the creation of technical applications based on .NET.\n\nILNumerics started in 2006 as an open source project, originating from the Technical University of Berlin. In 2007 ILNumerics won the BASTA! Innovation Awards 2007 as most innovative .NET project in Germany, Switzerland and Austria. After 6 years of open source development, the project added a closed source, proprietary license in 2011, aiming business and academic developers at the same time. The project quickly gained popularity (download numbers and engagement at stackoverflow.com, download counts from website not available).\nThe .NET framework was selected as a managed foundation, since earlier attempts on the Java platform had been abandoned due to technical limitations. Similarly, the .NET framework has not been designed with the focus on requirements of technical application development. ILNumerics added interfaces to popular codes (LAPACK, FFTW), complex numbers and generic mult-dimensional array classes. In 2010 graphical capabilities have been added. Efforts to increase the performance of the technology were introduced in 2011. At the same time, a company was founded to continue the development. The technological goal is to establish the .NET framework as a feasible alternative to unmanaged languages for numeric computing.\n\nILNumerics implements base functionality frequently needed for application development in technical areas: N-dimensional arrays, complex numbers, linear algebra, FFT and plotting controls (2D and 3D). The array classes are fully compatible with the array features of Matlab and numpy, including internal storage order, subarray creation, expansion, and advanced indexing. Higher level functionality is provided by toolboxes for interpolation, optimization, statistics, HDF5 and machine learning. The ILNumerics DSL is embedded into .NET. Computational algorithms are formulated using any CLI language. However, only C# and Visual Basic are officially supported. Due to the strong type system of the .NET framework algorithms created with ILNumerics are strongly typed. This deviates from the syntax of alternatives, which are often weakly typed and therefore easier to adopt.\n\nA scene graph is used in ILNumerics to realize graphical output. Interactive 2D and 3D plots are used in Windows Forms applications. Hardware accelerated drawing is available via OpenGL. A software renderer is provided for legacy hardware, based on GDI+ and SVG.\n\nILNumerics is distributed as an extension to Visual Studio. It adds a tool window to the IDE for the graphical inspection of mathematical objects while stepping through user code.\n\nSince ILNumerics comes as a CLI assembly, it targets Common Language Infrastructure (CLI) applications. Just like Java - those frameworks are often criticized for not being suitable for numerical computations. Reasons are the memory management by a garbage collector, the intermediate language execution and deficient optimizations by the compilers involved. ILNumerics approaches these limitations by performing loop unrolling, removal of bound checks on array accesses and cache optimizations. Further speed-up is gained by the auto-management of the memory of large array objects. Numerical operations are parallelized on multicore systems. Linear algebra routines rely on processor specific optimized versions of LAPACK and BLAS.\n\nILNumerics arrays utilize the unmanaged heap for storing data. This way, the size of ILNumerics arrays is not limited by the CLR and interoperability with 3rd party libraries is improved. \n\n\n"}
{"id": "57863097", "url": "https://en.wikipedia.org/wiki?curid=57863097", "title": "Icivil", "text": "Icivil\n\niCivil is a CRVS (Civil Registration and Vital Statistic System) that is in use in Burkina Faso since August 2015. It sequentially allows the declaration, recording, and addition of civil status certificates (birth, marriage, divorce) in a central place. It is not needed to travel far to register a birth or to obtain an extract of a birth certificate later.. \n\nThe system uses wristbands with bubble tags in order to protect the unique ID number given at birth, and an encrypted sms to transmit information to civil status where records are kept. \n\nAccording to UNICEF, there are almost 230-million children younger than five years old not registered, who are known as ghost children. Resolving the problem of ghost children is a challenge in Africa. iCivil permits help to solve the ghost children problem. \n"}
{"id": "235124", "url": "https://en.wikipedia.org/wiki?curid=235124", "title": "Index of cryptography articles", "text": "Index of cryptography articles\n\nArticles related to cryptography include:\n\n3-D Secure •\n3-subset meet-in-the-middle attack •\n3-Way •\n40-bit encryption •\n56-bit encryption •\n5-UCO \n\nA5/1 •\nA5/2 •\nABA digital signature guidelines •\nABC (stream cipher) •\nAbraham Sinkov •\nAcoustic cryptanalysis •\nAdaptive chosen-ciphertext attack •\nAdaptive chosen plaintext and chosen ciphertext attack •\nAdvantage (cryptography) •\nADFGVX cipher •\nAdi Shamir •\nAdvanced Access Content System •\nAdvanced Encryption Standard •\nAdvanced Encryption Standard process •\nAdversary •\nAEAD block cipher modes of operation •\nAffine cipher •\nAgnes Meyer Driscoll •\nAKA (security) •\nAkelarre (cipher) •\nAlan Turing •\nAlastair Denniston •\nAl Bhed language •\nAlex Biryukov •\nAlfred Menezes •\nAlgebraic Eraser •\nAlgorithmically random sequence •\nAlice and Bob •\nAll-or-nothing transform •\nAlphabetum Kaldeorum •\nAlternating step generator •\nAmerican Cryptogram Association •\nAN/CYZ-10 •\nAnonymous Internet banking •\nAnonymous publication •\nAnonymous remailer •\nAntoni Palluth •\nAnubis (cipher) •\nArgon2 •\nARIA (cipher) •\nArlington Hall •\nArne Beurling •\nArnold Cipher •\nArray controller based encryption •\nArthur Scherbius •\nArvid Gerhard Damm •\nAsiacrypt •\nAtbash •\nAttack model •\nAuguste Kerckhoffs •\nAuthenticated encryption •\nAuthentication •\nAuthorization certificate •\nAutokey cipher •\nAvalanche effect \n\nB-Dienst •\nBabington Plot •\nBaby-step giant-step •\nBacon's cipher •\nBanburismus •\nBart Preneel •\nBaseKing •\nBassOmatic •\nBATON •\nBB84 •\nBeale ciphers •\nBEAR and LION ciphers •\nBeaufort cipher •\nBeaumanor Hall •\nBent function •\nBerlekamp–Massey algorithm •\nBernstein v. United States •\nBestCrypt •\nBiclique attack •\nBID/60 •\nBID 770 •\nBifid cipher •\nBill Weisband •\nBinary Goppa code •\nBiometric word list •\nBirthday attack •\nBit-flipping attack •\nBitTorrent protocol encryption •\nBiuro Szyfrów •\nBlack Chamber •\nBlaise de Vigenère •\nBletchley Park •\nBlind credential •\nBlinding (cryptography) •\nBlind signature •\nBlock cipher •\nBlock cipher mode of operation •\nBlock size (cryptography) •\nBlowfish (cipher) •\nBlum Blum Shub •\nBlum–Goldwasser cryptosystem •\nBomba (cryptography) •\nBombe •\nBook cipher •\nBooks on cryptography •\nBoomerang attack •\nBoris Hagelin •\nBouncy Castle (cryptography) •\nBroadcast encryption •\nBruce Schneier •\nBrute-force attack •\nBurrows–Abadi–Needham logic •\nBurt Kaliski \n\nC2Net •\nC-36 (cipher machine) •\nC-52 (cipher machine) •\nCAcert.org •\nCaesar cipher •\nCamellia (cipher) •\nCAPICOM •\nCapstone (cryptography) •\nCardan grille •\nCard catalog (cryptology) •\nCarlisle Adams •\nCAST-128 •\nCAST-256 •\nCayley–Purser algorithm •\nCBC-MAC •\nCCM mode •\nCCMP •\nCD-57 •\nCDMF •\nCellular Message Encryption Algorithm •\nCentiban •\nCentral Security Service •\nCentre for Applied Cryptographic Research •\nCentral Bureau •\nCerticom •\nCertificate authority •\nCertificate-based encryption •\nCertificateless cryptography •\nCertificate revocation list •\nCertificate signing request •\nCertification path validation algorithm •\nChaffing and winnowing •\nChallenge-Handshake Authentication Protocol •\nChallenge–response authentication •\nChosen-ciphertext attack •\nChosen-plaintext attack •\nCIKS-1 •\nCipher disk •\nCipher runes •\nCipher security summary •\nCipherSaber •\nCiphertext expansion •\nCiphertext indistinguishability •\nCiphertext-only attack •\nCiphertext stealing •\nCIPHERUNICORN-A •\nCIPHERUNICORN-E •\nClassical cipher •\nClaude Shannon •\nClaw-free permutation •\nCleartext •\nCLEFIA •\nClifford Cocks •\nClipper chip •\nClock (cryptography) •\nClock drift •\nCMVP •\nCOCONUT98 •\nCodebook •\nCode (cryptography) •\nCode talker •\nCodress message •\nCold boot attack •\nCollision attack •\nCollision resistance •\nColossus computer •\nCombined Cipher Machine •\nCommitment scheme •\nCommon Scrambling Algorithm •\nCommunications security •\nCommunications Security Establishment •\nCommunication Theory of Secrecy Systems •\nComparison of disk encryption software •\nComparison of SSH clients •\nCompleteness (cryptography) •\nComplexity trap •\nComputational Diffie–Hellman assumption •\nComputational hardness assumption •\nComputer insecurity •\nComputer and network surveillance •\nCOMSEC equipment •\nConch (SSH) •\nConcrete security •\nConel Hugh O'Donel Alexander •\nConfidentiality •\nConfusion and diffusion •\nContent-scrambling system •\nControlled Cryptographic Item •\nCorkscrew (program) •\nCorrelation immunity •\nCOSIC •\nCovert channel •\nCover (telecommunications) •\nCrab (cipher) •\nCramer–Shoup cryptosystem •\nCRAM-MD5 •\nCRHF •\nCrib (cryptanalysis) •\nCrossCrypt •\nCrowds •\nCrypt (C) •\nCryptanalysis •\nCryptanalysis of the Enigma •\nCryptanalysis of the Lorenz cipher •\nCryptanalytic computer •\nCryptex •\nCryptico •\nCrypto AG •\nCrypto-anarchism •\nCrypto API (Linux) •\nMicrosoft CryptoAPI •\nCryptoBuddy •\nCryptochannel •\nCRYPTO (conference) •\nCryptogram •\nCryptographically Generated Address •\nCryptographically secure pseudorandom number generator •\nCryptographically strong •\nCryptographic Application Programming Interface •\nCryptographic engineering •\nCryptographic hash function •\nCryptographic key types •\nCryptographic Message Syntax •\nCryptographic primitive •\nCryptographic protocol •\nCryptographic Service Provider •\nCryptographie indéchiffrable •\nCryptography •\nCryptography in Japan •\nCryptography newsgroups •\nCryptography standards •\nCryptologia •\nCryptology ePrint Archive •\nCryptology Research Society of India •\nCryptomathic •\nCryptome •\nCryptomeria cipher •\nCryptonomicon •\nCrypTool •\nCrypto phone •\nCrypto-society •\nCryptosystem •\nCryptovirology •\nCRYPTREC •\nCS-Cipher •\nCurve25519 •\nCustom hardware attack •\nCycles per byte •\nCyclometer •\nCypherpunk •\nCyrillic Projector \n\nD'Agapeyeff cipher •\nDaniel J. Bernstein •\nData Authentication Algorithm •\nData Encryption Standard •\nDatagram Transport Layer Security •\nDavid Chaum •\nDavid Kahn •\nDavid Naccache •\nDavid Wagner •\nDavid Wheeler (computer scientist) •\nDavies attack •\nDavies–Meyer hash •\nDEAL •\nDecimal sequences for cryptography •\nDecipherment •\nDecisional Diffie–Hellman assumption •\nDecorrelation theory •\nDecrypt •\nDeCSS •\nDefence Signals Directorate •\nDegree of anonymity •\nDelegated Path Discovery •\nDelegated Path Validation •\nDeniable encryption •\nDerek Taunt •\nDerived unique key per transaction •\nDES Challenges •\nDES supplementary material •\nDES-X •\nDeterministic encryption •\nDFC (cipher) •\nDictionary attack •\nDifferential cryptanalysis •\nDifferential-linear attack •\nDifferential power analysis •\nDiffie–Hellman key exchange •\nDiffie–Hellman problem •\nDigiCipher 2 •\nDigital Fortress •\nDigital rights management •\nDigital signature •\nDigital Signature Algorithm •\nDigital signature forgery •\nDigital timestamping •\nDigital watermarking •\nDilly Knox •\nDining cryptographers problem •\nDiplomatic bag •\nDirect Anonymous Attestation •\nDiscrete logarithm •\nDisk encryption •\nDisk encryption hardware •\nDisk encryption software •\nDistance-bounding protocol •\nDistinguishing attack •\nDistributed.net •\nDMA attack •\ndm-crypt •\nDmitry Sklyarov •\nDomainKeys •\nDon Coppersmith •\nDorabella Cipher •\nDouble Ratchet Algorithm •\nDoug Stinson •\nDragon (cipher) •\nDRYAD •\nDual_EC_DRBG •\nDvorak encoding \n\nE0 (cipher) •\nE2 (cipher) •\nE4M •\nEAP-AKA •\nEAP-SIM •\nEAX mode •\nECC patents •\nECHELON •\nECRYPT •\nEdouard Fleissner von Wostrowitz •\nEdward Hebern •\nEdward Scheidt •\nEdward Travis •\nEFF DES cracker •\nEfficient Probabilistic Public-Key Encryption Scheme •\nEKMS •\nElectronic Communications Act 2000 •\nElectronic money •\nElectronic signature •\nElectronic voting •\nElGamal encryption •\nElGamal signature scheme •\nEli Biham •\nElizebeth Friedman •\nElliptic-curve cryptography •\nElliptic-curve Diffie–Hellman •\nElliptic Curve DSA •\nElliptic curve only hash •\nElonka Dunin •\nEncrypted function •\nEncrypted key exchange •\nEncrypting File System •\nEncryption •\nEncryption software •\nEnigmail •\nEnigma machine •\nEnigma rotor details •\nEntrust •\nErnst Fetterlein •\neSTREAM •\nÉtienne Bazeries •\nEurocrypt •\nEuroCrypt •\nExport of cryptography •\nExtensible Authentication Protocol \n\nFast Software Encryption •\nFast syndrome-based hash •\nFEA-M •\nFEAL •\nFeige–Fiat–Shamir identification scheme •\nFeistel cipher •\nFélix Delastelle •\nFialka •\nFilesystem-level encryption •\nFileVault •\nFill device •\nFinancial cryptography •\nFIPS 140 •\nFIPS 140-2 •\nFirefly (key exchange protocol) •\nFISH (cipher) •\nFish (cryptography) •\nFloradora •\nFluhrer, Mantin and Shamir attack •\nFormat-preserving encryption •\nFortezza •\nFort George G. Meade •\nFortuna (PRNG) •\nFour-square cipher •\nFranciszek Pokorny •\nFrank A. Stevenson •\nFrank Rowlett •\nFreenet •\nFreeOTFE •\nFreeS/WAN •\nFrequency analysis •\nFriedrich Kasiski •\nFritz-chip •\nFROG •\nFROSTBURG •\nFTP over SSH •\nFull disk encryption •\nFull Domain Hash •\nF. W. Winterbotham \n\nGalois/Counter Mode •\nGardening (cryptanalysis) •\nGCHQ Bude •\nGCHQ CSO Morwenstow •\nGDES •\nGeneric Security Services Application Program Interface •\nGeorge Blakley •\nGeorge Scovell •\nGGH encryption scheme •\nGGH signature scheme •\nGilbert Vernam •\nGMR (cryptography) •\nGNU Privacy Guard •\nGnuTLS •\nGoldwasser–Micali cryptosystem •\nGordon Welchman •\nGOST (block cipher) •\nGOST (hash function) •\nGovernment Communications Headquarters •\nGovernment Communications Security Bureau •\nGrain (cipher) •\nGrand Cru (cipher) •\nGreat Cipher •\nGrill (cryptology) •\nGrille (cryptography) •\nGroup-based cryptography •\nGroup signature •\nGrover's algorithm •\nGustave Bertrand •\nGwido Langer \n\nH.235 •\nHAIFA construction •\nHAIPE •\nHans Dobbertin •\nHans-Thilo Schmidt •\nHard-core predicate •\nHardware random number generator •\nHardware security module •\nHarold Keen •\nHarry Hinsley •\nHarvest (computer) •\nHAS-160 •\nHash-based cryptography •\nHashcash •\nHash chain •\nHash function security summary •\nHash list •\nHasty Pudding cipher •\nHAVAL •\nHC-256 •\nHC-9 •\nHeath Robinson (codebreaking machine) •\nHebern rotor machine •\nHenri Braquenié •\nHenryk Zygalski •\nHerbert Yardley •\nHidden Field Equations •\nHideki Imai •\nHierocrypt •\nHigh-bandwidth Digital Content Protection •\nHigher-order differential cryptanalysis •\nHill cipher •\nHistory of cryptography •\nHMAC •\nHMAC-based One-time Password algorithm (HOTP) •\nHorst Feistel •\nHoward Heys •\nHttps •\nHugo Hadwiger •\nHugo Koch •\nHushmail •\nHut 6 •\nHut 8 •\nHX-63 •\nHybrid cryptosystem •\nHyperelliptic curve cryptography •\nHyper-encryption \n\nIan Goldberg •\nIBM 4758 •\nICE (cipher) •\nID-based cryptography •\nIDEA NXT •\nIdentification friend or foe •\nIEEE 802.11i •\nIEEE P1363 •\nI. J. Good •\nIllegal prime •\nImpossible differential cryptanalysis •\nIndex of coincidence •\nIndifferent chosen-ciphertext attack •\nIndocrypt •\nInformation leakage •\nInformation Security Group •\nInformation-theoretic security •\nInitialization vector •\nInteger factorization •\nIntegral cryptanalysis •\nIntegrated Encryption Scheme •\nIntegrated Windows Authentication •\nInterlock protocol •\nIntermediate certificate authorities •\nInternational Association for Cryptologic Research •\nInternational Data Encryption Algorithm •\nInternet Key Exchange •\nInternet Security Association and Key Management Protocol •\nInterpolation attack •\nInvisible ink •\nIPsec •\nIraqi block cipher •\nISAAC (cipher) •\nISO 19092-2 •\nISO/IEC 9797 •\nIvan Damgård \n\nJacques Stern •\nJADE (cypher machine) •\nJames Gillogly •\nJames H. Ellis •\nJames Massey •\nJan Graliński •\nJan Kowalewski •\nJapanese naval codes •\nJava Cryptography Architecture •\nJefferson disk •\nJennifer Seberry •\nJerzy Różycki •\nJoan Daemen •\nJohannes Trithemius •\nJohn Herivel •\nJohn Kelsey (cryptanalyst) •\nJohn R. F. Jeffreys •\nJohn Tiltman •\nJon Lech Johansen •\nJosef Pieprzyk •\nJoseph Desch •\nJoseph Finnegan (cryptographer) •\nJoseph Mauborgne •\nJoseph Rochefort •\nJournal of Cryptology •\nJunger v. Daley \n\nKaisa Nyberg •\nKalyna (cipher) •\nKasiski examination •\nKASUMI •\nKCDSA •\nKeePass •\nKerberos (protocol) •\nKerckhoffs's principle •\nKevin McCurley (cryptographer) •\nKey-agreement protocol •\nKey authentication •\nKey clustering •\nKey (cryptography) •\nKey derivation function •\nKey distribution center •\nKey escrow •\nKey exchange •\nKeyfile •\nKey generation •\nKey generator •\nKey management •\nKeymat •\nKey-recovery attack •\nKey schedule •\nKey server (cryptographic) •\nKey signature (cryptography) •\nKeysigning •\nKey signing party •\nKey size •\nKey space (cryptography) •\nKeystream •\nKey stretching •\nKey whitening •\nKG-84 •\nKHAZAD •\nKhufu and Khafre •\nKiss (cryptanalysis) •\nKL-43 •\nKL-51 •\nKL-7 •\nKleptography •\nKN-Cipher •\nKnapsack problem •\nKnown-key distinguishing attack •\nKnown-plaintext attack •\nKnownSafe •\nKOI-18 •\nKOV-14 •\nKryha •\nKryptos •\nKSD-64 •\nKupyna •\nKuznyechik •\nKW-26 •\nKW-37 •\nKY-3 •\nKY-57 •\nKY-58 •\nKY-68 •\nKYK-13 \n\nLacida •\nLadder-DES •\nLamport signature •\nLars Knudsen •\nLattice-based cryptography •\nLaurance Safford •\nLawrie Brown •\nLCS35 •\nLeo Marks •\nLeonard Adleman •\nLeon Battista Alberti •\nLeo Rosen •\nLeslie Yoxall •\nLEVIATHAN (cipher) •\nLEX (cipher) •\nLibelle (cipher) •\nLinear cryptanalysis •\nLinear-feedback shift register •\nLink encryption •\nList of ciphertexts •\nList of cryptographers •\nList of cryptographic file systems •\nList of cryptographic key types •\nList of cryptology conferences •\nList of telecommunications encryption terms • List of people associated with Bletchley Park • \nList of SFTP server software •\nLOKI •\nLOKI97 •\nLorenz cipher •\nLouis W. Tordella •\nLsh •\nLucifer (cipher) •\nLyra2 \n\nM6 (cipher) •\nM8 (cipher) •\nM-209 •\nM-325 •\nM-94 •\nMacGuffin (cipher) •\nMadryga •\nMAGENTA •\nMagic (cryptography) •\nMaksymilian Ciężki •\nMalcolm J. Williamson •\nMalleability (cryptography) •\nMan-in-the-middle attack •\nMarian Rejewski •\nMARS (cryptography) •\nMartin Hellman •\nMaruTukku •\nMassey–Omura cryptosystem •\nMatt Blaze •\nMatt Robshaw •\nMax Newman •\nMcEliece cryptosystem •\nmcrypt •\nMD2 (cryptography) •\nMD4 •\nMD5 •\nMD5CRK •\nMDC-2 •\nMDS matrix •\nMean shortest distance •\nMeet-in-the-middle attack •\nMental poker •\nMercury (cipher machine) •\nMercy (cipher) •\nMeredith Gardner •\nMerkle signature scheme •\nMerkle–Damgård construction •\nMerkle–Hellman knapsack cryptosystem •\nMerkle's Puzzles •\nMerkle tree •\nMESH (cipher) •\nMessage authentication •\nMessage authentication code •\nMessage forgery •\nMI8 •\nMichael Luby •\nMICKEY •\nMicrodot •\nMilitary Cryptanalysis (book) (William F. Friedman) •\nMilitary Cryptanalytics •\nMimic function •\nMirror writing •\nMISTY1 •\nMitsuru Matsui •\nMMB (cipher) •\nMod n cryptanalysis •\nMQV •\nMS-CHAP •\nMUGI •\nMULTI-S01 •\nMultiSwap •\nMultivariate cryptography \n\nNational Communications Centre •\nNational Cryptologic Museum •\nNational Security Agency •\nNational Cipher Challenge •\nNavajo I •\nNeal Koblitz •\nNeedham–Schroeder protocol •\nNegligible function •\nNEMA (machine) •\nNESSIE •\nNetwork Security Services •\nNeural cryptography •\nNew Data Seal •\nNewDES •\nN-Hash •\nNicolas Courtois •\nNiederreiter cryptosystem •\nNiels Ferguson •\nNigel de Grey •\nNihilist cipher •\nNikita Borisov •\nNimbus (cipher) •\nNIST hash function competition •\nNonlinear-feedback shift register •\nNOEKEON •\nNon-malleable codes •\nNoreen •\nNothing up my sleeve number •\nNSA cryptography •\nNSA encryption systems •\nNSA in fiction •\nNSAKEY •\nNSA Suite A Cryptography •\nNSA Suite B Cryptography •\nNT LAN Manager •\nNTLMSSP •\nNTRU Cryptosystems, Inc. •\nNTRUEncrypt •\nNTRUSign •\nNull cipher •\nNumbers station •\nNUSH •\nNTRU \n\nOblivious transfer •\nOCB mode •\nOded Goldreich •\nOff-the-Record Messaging •\nOkamoto–Uchiyama cryptosystem •\nOMI cryptograph •\nOMNI (SCIP) •\nOne-key MAC •\nOne-time pad •\nOne-time password •\nOne-way compression function •\nOne-way function •\nOnion routing •\nOnline Certificate Status Protocol •\nOP-20-G •\nOpenPGP card •\nOpenSSH •\nOpenSSL •\nOpenswan •\nOpenVPN •\nOperation Ruthless •\nOptimal asymmetric encryption padding •\nOver the Air Rekeying (OTAR) •\nOTFE •\nOtway–Rees protocol \n\nPadding (cryptography) •\nPadding oracle attack •\nPaillier cryptosystem •\nPairing-based cryptography •\nPanama (cryptography) •\nPartitioning cryptanalysis •\nPassive attack •\nPassphrase •\nPassword •\nPassword-authenticated key agreement •\nPassword cracking •\nPassword Hashing Competition •\nPaul Kocher •\nPaulo Pancatuccio •\nPaulo S. L. M. Barreto •\nPaul van Oorschot •\nPBKDF2 •\nPC Bruno •\nPepper (cryptography) •\nPerfect forward secrecy •\nPerforated sheets •\nPermutation cipher •\nPeter Gutmann (computer scientist) •\nPeter Junger •\nPeter Twinn •\nPGP Corporation •\nPGPDisk •\nPGPfone •\nPhelix •\nPhil Zimmermann •\nPhoturis (protocol) •\nPhysical security •\nPhysical unclonable function •\nPig Latin •\nPigpen cipher •\nPike (cipher) •\nPiling-up lemma •\nPinwheel (cryptography) •\nPiotr Smoleński •\nPirate decryption •\nPKC (conference) •\nPKCS •\nPKCS 11 •\nPKCS 12 •\nPKIX •\nPlaintext •\nPlaintext-aware encryption •\nPlayfair cipher •\nPlugboard •\nPMAC (cryptography) •\nPoem code •\nPohlig–Hellman algorithm •\nPoint-to-Point Tunneling Protocol •\nPointcheval–Stern signature algorithm •\nPoly1305 •\nPolyalphabetic cipher •\nPolybius square •\nPortex •\nPost-quantum cryptography •\nPost-Quantum Cryptography Standardization •\nPower analysis •\nPreimage attack •\nPre-shared key •\nPretty Good Privacy •\nPrinter steganography •\nPrivacy-enhanced Electronic Mail •\nPrivate Communications Technology •\nPrivate information retrieval •\nProbabilistic encryption •\nProduct cipher •\nProof-of-work system •\nProtected Extensible Authentication Protocol •\nProvable security •\nProvably secure cryptographic hash function •\nProxy re-encryption •\nPseudo-Hadamard transform •\nPseudonymity •\nPseudorandom function •\nPseudorandom number generator •\nPseudorandom permutation •\nPublic key certificate •\nPublic-key cryptography •\nPublic key fingerprint •\nPublic key infrastructure •\nPURPLE •\nPuTTY •\nPy (cipher) \n\nQ (cipher) •\nQrpff •\nQUAD (cipher) •\nQuadratic sieve •\nQuantum coin flipping •\nQuantum cryptography •\nQuantum digital signature •\nQuantum fingerprinting •\nQuantum key distribution \n\nRabbit (cipher) •\nRabin cryptosystem •\nRabin–Williams encryption •\nRadioGatún •\nRail fence cipher •\nRainbow table •\nRalph Merkle •\nRambutan (cryptography) •\nRandom function •\nRandomness tests •\nRandom number generator attack •\nRandom oracle •\nRC2 •\nRC4 •\nRC5 •\nRC6 •\nRebound attack •\nReciprocal cipher •\nRed/black concept •\nREDOC •\nRed Pike (cipher) •\nReflector (cipher machine) •\nRegulation of Investigatory Powers Act 2000 •\nReihenschieber •\nRekeying (cryptography) •\nRelated-key attack •\nReplay attack •\nReservehandverfahren •\nResidual block termination •\nRijndael key schedule •\nRijndael S-box •\nRing signature •\nRIPEMD •\nRip van Winkle cipher •\nRobert Morris (cryptographer) •\nRobot certificate authority •\nRockex •\nRolf Noskwith •\nRon Rivest •\nRoom 40 •\nRoot certificate •\nRoss J. Anderson •\nRossignols •\nROT13 •\nRotor machine •\nRSA •\nRSA-100 •\nRSA-1024 •\nRSA-110 •\nRSA-120 •\nRSA-129 •\nRSA-130 •\nRSA-140 •\nRSA-150 •\nRSA-1536 •\nRSA-155 •\nRSA-160 •\nRSA-170 •\nRSA-180 •\nRSA-190 •\nRSA-200 •\nRSA-2048 •\nRSA-210 •\nRSA-220 •\nRSA-230 •\nRSA-232 •\nRSA-240 •\nRSA-250 •\nRSA-260 •\nRSA-270 •\nRSA-280 •\nRSA-290 •\nRSA-300 •\nRSA-309 •\nRSA-310 •\nRSA-320 •\nRSA-330 •\nRSA-340 •\nRSA-350 •\nRSA-360 •\nRSA-370 •\nRSA-380 •\nRSA-390 •\nRSA-400 •\nRSA-410 •\nRSA-420 •\nRSA-430 •\nRSA-440 •\nRSA-450 •\nRSA-460 •\nRSA-470 •\nRSA-480 •\nRSA-490 •\nRSA-500 •\nRSA-576 •\nRSA-617 •\nRSA-640 •\nRSA-704 •\nRSA-768 •\nRSA-896 •\nRSA-PSS •\nRSA Factoring Challenge •\nRSA problem •\nRSA Secret-Key Challenge •\nRSA Security •\nRubber-hose cryptanalysis •\nRunning key cipher •\nRussian copulation \n\nS-1 block cipher •\nSAFER •\nSalsa20 •\nSalt (cryptography) •\nSAM card •\nSecurity Support Provider Interface •\nSAML •\nSAVILLE •\nSC2000 •\nSchnorr group •\nSchnorr signature •\nSchoof–Elkies–Atkin algorithm •\nSCIP •\nScott Vanstone •\nScrambler •\nScramdisk •\nScream (cipher) •\nScrypt •\nScytale •\nSeahorse (software) •\nSEAL (cipher) •\nSean Murphy (cryptographer) •\nSECG •\nSecret broadcast •\nSecret decoder ring •\nSecrets and Lies (Schneier) •\nSecret sharing •\nSectéra Secure Module •\nSecure access module •\nSecure channel •\nSecure Communication based on Quantum Cryptography •\nSecure copy •\nSecure cryptoprocessor •\nSecure Electronic Transaction •\nSecure Hash Algorithms •\nSecure Hypertext Transfer Protocol •\nSecure key issuing cryptography •\nSecure multi-party computation •\nSecure Neighbor Discovery •\nSecure Real-time Transport Protocol •\nSecure remote password protocol •\nSecure Shell •\nSecure telephone •\nSecure Terminal Equipment •\nSecure voice •\nSecurID •\nSecurity association •\nSecurity engineering •\nSecurity level •\nSecurity parameter •\nSecurity protocol notation •\nSecurity through obscurity •\nSecurity token •\nSEED •\nSelected Areas in Cryptography •\nSelf-certifying File System •\nSelf-certifying key •\nSelf-shrinking generator •\nSelf-signed certificate •\nSemantic security •\nSerge Vaudenay •\nSerpent (cipher) •\nSession key •\nSHACAL •\nShafi Goldwasser •\nSHA-1 •\nSHA-2 •\nSHA-3 •\nShared secret •\nSHARK •\nShaun Wylie •\nShor's algorithm •\nShrinking generator •\nShugborough inscription •\nSide-channel attack •\nSiemens and Halske T52 •\nSIGABA •\nSIGCUM •\nSIGINT •\nSignal Protocol •\nSignal Intelligence Service •\nSigncryption •\nSIGSALY •\nSILC (protocol) •\nSilvio Micali •\nSimple Authentication and Security Layer •\nSimple public-key infrastructure •\nSimple XOR cipher •\nS/KEY •\nSkein (hash function) •\nSkipjack (cipher) •\nSlide attack •\nSlidex •\nSmall subgroup confinement attack •\nS/MIME •\nSM4 algorithm (formerly SMS4) •\nSnake oil (cryptography) •\nSnefru •\nSNOW •\nSnuffle •\nSOBER-128 •\nSolitaire (cipher) •\nSolomon Kullback •\nSOSEMANUK •\nSpecial Collection Service •\nSpectr-H64 •\nSPEKE (cryptography) •\nSponge function •\nSPNEGO •\nSquare (cipher) •\nSsh-agent •\nSSH File Transfer Protocol •\nSSLeay •\nStafford Tavares •\nStåle Schumacher Ytteborg •\nStandard model (cryptography) •\nStation CAST •\nStation HYPO •\nStation-to-Station protocol •\nStatistical cryptanalysis •\nStefan Lucks •\nSteganalysis •\nSteganography •\nStraddling checkerboard •\nStream cipher •\nStream cipher attacks •\nStrong cryptography •\nStrong RSA assumption •\nStuart Milner-Barry •\nSTU-II •\nSTU-III •\nStunnel •\nSubstitution box •\nSubstitution cipher •\nSubstitution–permutation network •\nSuperencryption •\nSupersingular isogeny key exchange •\nSwedish National Defence Radio Establishment •\nSWIFFT •\nSXAL/MBAL •\nSymmetric-key algorithm •\nSYSKEY \n\nTabula recta •\nTaher Elgamal •\nTamper resistance •\nTcpcrypt •\nTelevision encryption •\nTEMPEST •\nTemporal Key Integrity Protocol •\nTestery •\nThawte •\nThe Alphabet Cipher •\nThe Code Book •\nThe Codebreakers •\nThe Gold-Bug •\nThe Magic Words are Squeamish Ossifrage •\nTheory of Cryptography Conference •\nThe world wonders •\nThomas Jakobsen •\nThree-pass protocol •\nThreshold shadow scheme •\nTICOM •\nTiger (cryptography) •\nTimeline of cryptography •\nTime/memory/data tradeoff attack •\nTime-based One-time Password algorithm (TOTP) •\nTiming attack •\nTiny Encryption Algorithm •\nTom Berson •\nTommy Flowers •\nTopics in cryptography •\nTor (anonymity network) •\nTorus-based cryptography •\nTraffic analysis •\nTraffic-flow security •\nTraitor tracing •\nTransmission security •\nTransport Layer Security •\nTransposition cipher •\nTrapdoor function •\nTrench code •\nTreyfer •\nTrifid cipher •\nTriple DES •\nTrivium (cipher) •\nTrueCrypt •\nTruncated differential cryptanalysis •\nTrusted third party •\nTuring (cipher) •\nTWINKLE •\nTWIRL •\nTwofish •\nTwo-square cipher •\nType 1 encryption •\nType 2 encryption •\nType 3 encryption •\nType 4 encryption •\nTypex \n\nUES (cipher) •\nUltra •\nUMAC •\nUnbalanced Oil and Vinegar •\nUndeniable signature •\nUnicity distance •\nUniversal composability •\nUniversal one-way hash function (UOWHF)\n\nVenona project •\nVerifiable secret sharing •\nVerisign •\nVery smooth hash •\nVEST •\nVIC cipher •\nVideoCrypt •\nVigenère cipher •\nVincent Rijmen •\nVINSON •\nVirtual private network •\nVisual cryptography •\nVoynich manuscript \n\nWadsworth's cipher •\nWAKE •\nWLAN Authentication and Privacy Infrastructure •\nWatermark (data file) •\nWatermarking attack •\nWeak key •\nWeb of trust •\nWhirlpool (hash function) •\nWhitfield Diffie •\nWide Mouth Frog protocol •\nWi-Fi Protected Access •\nWilliam F. Friedman •\nWilliam Montgomery (cryptographer) •\nWinSCP •\nWired Equivalent Privacy •\nWireless Transport Layer Security •\nWitness-indistinguishable proof •\nWorkshop on Cryptographic Hardware and Embedded Systems •\nWorld War I cryptography •\nWorld War II cryptography •\nW. T. Tutte \n\nX.509 •\nXDH assumption •\nXenon (cipher) •\nXiaoyun Wang •\nXML Encryption •\nXML Signature •\nxmx •\nXSL attack •\nXTEA •\nXTR •\nXuejia Lai •\nXXTEA \n\nYarrow algorithm •\nY-stations •\nYuliang Zheng \n\nZeroisation •\nZero-knowledge password proof •\nZero-knowledge proof •\nZfone •\nZodiac (cipher) •\nZRTP •\nZimmermann–Sassaman key-signing protocol •\nZimmermann Telegram \n\n"}
{"id": "6247749", "url": "https://en.wikipedia.org/wiki?curid=6247749", "title": "John H. Smith (mathematician)", "text": "John H. Smith (mathematician)\n\nJohn Howard Smith is an American mathematician, a retired professor of mathematics at Boston College. He received his Ph.D. from the Massachusetts Institute of Technology in 1963, under the supervision of Kenkichi Iwasawa.\nIn voting theory, he is known for the Smith set, the smallest nonempty set of candidates such that, in every pairwise matchup between a member and a non-member, the member is the winner, and for the Smith criterion, a property of certain election systems in which the winner is guaranteed to belong to the Smith set. He has also made contributions to spectral graph theory and additive number theory.\n"}
{"id": "22780828", "url": "https://en.wikipedia.org/wiki?curid=22780828", "title": "K. R. Parthasarathy (graph theorist)", "text": "K. R. Parthasarathy (graph theorist)\n\nK. R. Parthasarathy is a professor emeritus of graph theory from the Department of Mathematics, Indian Institute of Technology Madras, Chennai. He received his Ph.D. (1966) in graph theory from the Indian Institute of Technology Kharagpur. Parthasarathy is known for his work (with his student G. Ravindra) on strong perfect graph conjecture. Parthasarathy guided and refereed Ph.D. students in graph theory, among them S. A. Choudum. Parthasarathy wrote a book on graph theory - \"Basic Graph Theory\", K. R. Parthasarathy - 1994 - Tata McGraw-Hill New York.\n"}
{"id": "47321473", "url": "https://en.wikipedia.org/wiki?curid=47321473", "title": "Kolmogorov–Arnold representation theorem", "text": "Kolmogorov–Arnold representation theorem\n\nIn real analysis and approximation theory, the Kolmogorov–Arnold representation theorem (or superposition theorem) states that every multivariate continuous function can be represented as a superposition of continuous functions of two variables. It solved a more general form of Hilbert's thirteenth problem.\n\nThe works of Andrey Kolmogorov and Vladimir Arnold established that if \"f\" is a multivariate continuous function, then \"f\" can be written as a finite composition of continuous functions of a single variable and the binary operation of addition.\n\nMore specifically \n\nConstructive proofs, and even more specific constructions can be found in .\n\nIn a sense, they showed that the only true multivariate function is the sum, since every other function can be written using univariate functions and summing.\n\nThe Kolmogorov–Arnold representation theorem is closely related to Hilbert's 13th problem. In his Paris lecture at the International Congress of Mathematicians in 1900, David Hilbert formulated 23 problems which in his opinion were important for the further development of mathematics. The 13th of these problems dealt with the solution of general equations of higher degrees. It is known that for algebraic equations of degree 4 the solution can be computed by formulae that only contain radicals and arithmetic operations. For higher orders, Galois theory shows us that the solutions of algebraic equations cannot be expressed in terms of basic algebraic operations. It follows from the so called Tschirnhaus transformation that the general algebraic equation formula_2 can be translated to the form formula_3. The Tschirnhaus transformation is given by a formula containing only radicals and arithmetic operations and transforms. Therefore, the solution of an algebraic equation of degree formula_4 can be represented as a superposition of functions of two variables if formula_5 and as a superposition of functions of formula_6 variables if formula_7. For formula_8 the solution is a superposition of arithmetic operations, radicals, and the solution of the equation formula_9. \n\nA further simplification with algebraic transformations seems to be impossible which led to Hilbert's conjecture that \"A solution of the general equation of degree 7 cannot be represented as a superposition of continuous functions of two variables\". This explains the relation of Hilbert's thirteenth problem to the representation of a higher-dimensional function as superposition of lower-dimensional functions. In this context, it has stimulated many studies in the theory of functions and other related problems by different authors.\n\nA variant of Kolmogorov's theorem that reduces the number of\nouter functions formula_10 is due to George Lorentz. He showed in 1962 that the outer functions formula_11 can be replaced by a single function formula_12. More precisely, Lorentz proved the existence of functions formula_13, formula_14 formula_15 such that \n\nSprecher replaced the inner functions formula_17 by one single inner function with an appropriate shift in its argument. He proved that there exist real values formula_18, a continuous function formula_19, and a real increasing continuous function formula_20 with formula_21, for formula_22, such that\n\nPhillip A. Ostrand generalized the Kolmogorov superposition theorem to compact metric spaces. For formula_24 let formula_25 be compact metric spaces of finite dimension formula_26 and let formula_27. Then there exists continuous functions formula_28 and continuous functions formula_29 such that any continuous function formula_30 is representable in the form \n\n\n"}
{"id": "44932655", "url": "https://en.wikipedia.org/wiki?curid=44932655", "title": "Kurzsignale", "text": "Kurzsignale\n\nThe Short Signal Code, also known as the Short Signal Book (), was a short code system used by the Kriegsmarine (German Navy) during World War II to minimize the transmission duration of messages.\n\nThe transmission of radio messages had the potential risks of revealing the submarine's presence and direction; if decoded the content was also revealed. Submarines need to provide information, mostly in standard form (position of convoy to attack and of submarine, weather information), to their bases. Initially Morse code transmissions could be used. To inhibit detection, the duration of messages needed to be minimised; for this, \"Kurzsignale\" short-coding was used. To prevent interception, messages needed to be encrypted by the Enigma machine. To shorten transmission even further, the message could be sent by a fast machine instead of a human radio operator. For example, the Kurier system – not implemented in time – decreased the time to send a Morse dot from around 50 milliseconds for a human to 1 millisecond.\n\nThe \"Kurzsignale\" code was intended to shorten transmission time to below the time required to get a directional fix. It was not primarily intended to hide signal contents; protection was intended to be achieved by encoding with the Enigma machine. A copy of the \"Kurzsignale\" code book was captured from on 9 May 1941. In August 1941, Dönitz began addressing U-boats by the names of their commanders, instead of boat numbers. The method of defining U-boat meeting points in the Short Signal Book was regarded as compromised, so a method was defined by B-Dienst cryptanalysts to disguise their positions on the Kriegsmarine German Naval Grid System (German:Gradnetzmeldeverfahren) was introduced and used until the end of the war\n\nAware of the danger presented by radio direction finding (RDF), the Kriegsmarine developed various systems to speed up broadcast. The \"Kurzsignale\" code system condensed messages into short codes consisting of short sequences for common terms such as \"convoy location\" so that additional descriptions would not be needed in the message. The resulting \"Kurzsignal\" was then encoded with the Enigma machine and subsequently transmitted as rapidly as possible, typically taking about 20 seconds. Typical length of an information or weather signal was about 25 characters.\n\nConventional RDF needed about a minute to fix the bearing of a radio signal, and the Kurzsignale protected against this. However, the huff-duff system which was in use by the Allies could cope with these short transmissions.\n\nThe fully automated burst transmission \"Kurier system\", in testing from August 1944, could send a \"Kurzsignal\" in not more than 460 milliseconds; this was short enough to prevent location even by huff-duff and, if deployed, would have been a serious setback for Allied anti-submarine and code-breaking activities. By late 1944 the \"Kurier\" program was a top priority, but the war ended before the system was operational.\n\nA similar coding system was used for weather reports from U-boats, the \"Wetterkurzschlüssel\" (Short Weather Cipher). Code books were captured from on 30 October 1942.\n"}
{"id": "45712630", "url": "https://en.wikipedia.org/wiki?curid=45712630", "title": "LINGO (mathematical modeling language)", "text": "LINGO (mathematical modeling language)\n\nLINGO is a mathematical modeling language designed for formulating and solving optimization problems, including linear, integer, and nonlinear programming problems.\n"}
{"id": "42158354", "url": "https://en.wikipedia.org/wiki?curid=42158354", "title": "LowerUnits", "text": "LowerUnits\n\nIn proof compression LowerUnits (LU) is an algorithm used to compress propositional logic resolution proofs. The main idea of LowerUnits is to exploit the following fact:\n\nThe algorithm targets exactly the class of global redundancy stemming from multiple resolutions with unit clauses. The algorithm takes its name from the fact that, when this rewriting is done and the resulting proof is displayed as a DAG (directed acyclic graph), the unit node formula_2 appears lower (i.e., closer to the root) than it used to appear in the original proof. \n\nA naive implementation exploiting theorem would require the proof to be traversed and fixed after each unit node is lowered. It is possible, however, to do better by first collecting and removing all the unit nodes in a single traversal, and afterwards fixing the whole proof in a single second traversal. Finally, the collected and fixed unit nodes have to be reinserted at the bottom of the proof.\n\nCare must be taken with cases when a unit node formula_6 occurs above in the subproof that derives another unit node formula_2. In such cases, formula_2 depends on formula_6. Let formula_10 be the single literal of the unit clause of formula_6. Then any occurrence of formula_12 in the subproof above formula_2 will not be cancelled by resolution inferences with formula_6 anymore. Consequently, formula_12 will be propagated downwards when the proof is fixed and will appear in the clause of formula_2. Difficulties with such dependencies can be easily avoided if we reinsert the upper unit node formula_6 after reinserting the unit node formula_2 (i.e. after reinsertion, formula_6 must appear below formula_2, to cancel the extra literal formula_12 from formula_2’s clause). This can be ensured by collecting the unit nodes in a queue during a bottom-up traversal of the proof and reinserting them in the order they were queued.\n\nThe algorithm for fixing a proof containing many roots performs a top-down traversal of the proof, recomputing the resolvents and replacing broken nodes (e.g. nodes having deletedNodeMarker as one of their parents) by their surviving parents (e.g. the other parent, in case one parent was deletedNodeMarker).\n\nWhen unit nodes are collected and removed from a proof of a clause formula_23 and the proof is fixed, the clause formula_24 in the root node of the new proof is not equal to formula_23 anymore, but contains (some of) the duals of the literals of the unit clauses that have been removed from the proof. The reinsertion of unit nodes at the bottom of the proof resolves formula_24 with the clauses of (some of) the collected unit nodes, in order to obtain a proof of formula_23 again.\n\nGeneral structure of the algorithm\n\nWe collect the unit clauses as follow\n\nThen we reinsert the units\n"}
{"id": "45366299", "url": "https://en.wikipedia.org/wiki?curid=45366299", "title": "Mark Ellingham", "text": "Mark Ellingham\n\nMark Norman Ellingham is a professor of mathematics at Vanderbilt University whose research concerns graph theory. With Joseph D. Horton, he is the discoverer and namesake of the Ellingham–Horton graphs, two cubic 3-vertex-connected bipartite graphs that have no Hamiltonian cycle.\n\nEllingham earned his Ph.D. in 1986 from the University of Waterloo under the supervision of Lawrence Bruce Richmond. In 2012, he became one of the inaugural fellows of the American Mathematical Society.\n"}
{"id": "11830372", "url": "https://en.wikipedia.org/wiki?curid=11830372", "title": "Menger curvature", "text": "Menger curvature\n\nIn mathematics, the Menger curvature of a triple of points in \"n\"-dimensional Euclidean space R is the reciprocal of the radius of the circle that passes through the three points. It is named after the Austrian-American mathematician Karl Menger.\n\nLet \"x\", \"y\" and \"z\" be three points in R; for simplicity, assume for the moment that all three points are distinct and do not lie on a single straight line. Let Π ⊆ R be the Euclidean plane spanned by \"x\", \"y\" and \"z\" and let \"C\" ⊆ Π be the unique Euclidean circle in Π that passes through \"x\", \"y\" and \"z\" (the circumcircle of \"x\", \"y\" and \"z\"). Let \"R\" be the radius of \"C\". Then the Menger curvature \"c\"(\"x\", \"y\", \"z\") of \"x\", \"y\" and \"z\" is defined by\n\nIf the three points are collinear, \"R\" can be informally considered to be +∞, and it makes rigorous sense to define \"c\"(\"x\", \"y\", \"z\") = 0. If any of the points \"x\", \"y\" and \"z\" are coincident, again define \"c\"(\"x\", \"y\", \"z\") = 0.\n\nUsing the well-known formula relating the side lengths of a triangle to its area, it follows that\n\nwhere \"A\" denotes the area of the triangle spanned by \"x\", \"y\" and \"z\".\n\nAnother way of computing Menger curvature is the identity\nwhere formula_4 is the angle made at the \"y\"-corner of the triangle spanned by \"x\",\"y\",\"z\".\n\nMenger curvature may also be defined on a general metric space. If \"X\" is a metric space and \"x\",\"y\", and \"z\" are distinct points, let \"f\" be an isometry from formula_5 into formula_6. Define the Menger curvature of these points to be\n\nNote that \"f\" need not be defined on all of \"X\", just on \"{x,y,z}\", and the value \"c\" \"(x,y,z)\" is independent of the choice of \"f\".\n\nMenger curvature can be used to give quantitative conditions for when sets in formula_8 may be rectifiable. For a Borel measure formula_9 on a Euclidean space formula_10 define\n\n\nThe basic intuition behind the result is that Menger curvature measures how straight a given triple of points are (the smaller formula_16 is, the closer x,y, and z are to being collinear), and this integral quantity being finite is saying that the set E is flat on most small scales. In particular, if the power in the integral is larger, our set is smoother than just being rectifiable\n\n\nAnalogous results hold in general metric spaces:\n\n\n"}
{"id": "1664427", "url": "https://en.wikipedia.org/wiki?curid=1664427", "title": "Mereotopology", "text": "Mereotopology\n\nIn formal ontology, a branch of metaphysics, and in ontological computer science, mereotopology is a first-order theory, embodying mereological and topological concepts, of the relations among wholes, parts, parts of parts, and the boundaries between parts. \n\nMereotopology begins in philosophy with theories articulated by A. N. Whitehead in several books and articles he published between 1916 and 1929, drawing in part on the mereogeometry of De Laguna (1922). The first to have proposed the idea of a point-free definition of the concept of topological space in mathematics was Karl Menger in his book \"Dimensionstheorie\" (1928) -- see also his (1940). The early historical background of mereotopology is documented in Bélanger and Marquis (2013) and Whitehead's early work is discussed in Kneebone (1963: chpt. 13.5) and Simons (1987: 2.9.1). The theory of Whitehead's 1929 \"Process and Reality\" augmented the part-whole relation with topological notions such as contiguity and connection. Despite Whitehead's acumen as a mathematician, his theories were insufficiently formal, even flawed. By showing how Whitehead's theories could be fully formalized and repaired, Clarke (1981, 1985) founded contemporary mereotopology. The theories of Clarke and Whitehead are discussed in Simons (1987: 2.10.2), and Lucas (2000: chpt. 10). The entry Whitehead's point-free geometry includes two contemporary treatments of Whitehead's theories, due to Giangiacomo Gerla, each different from the theory set out in the next section.\n\nAlthough mereotopology is a mathematical theory, we owe its subsequent development to logicians and theoretical computer scientists. Lucas (2000: chpt. 10) and Casati and Varzi (1999: chpts. 4,5) are introductions to mereotopology that can be read by anyone having done a course in first-order logic. More advanced treatments of mereotopology include Cohn and Varzi (2003) and, for the mathematically sophisticated, Roeper (1997). For a mathematical treatment of point-free geometry, see Gerla (1995). Lattice-theoretic (algebraic) treatments of mereotopology as contact algebras have been applied to separate the topological from the mereological structure, see Stell (2000), Düntsch and Winter (2004).\n\nBarry Smith (1996), Anthony Cohn, Achille Varzi and their co-authors have shown that mereotopology can be useful in formal ontology and computer science, by allowing the formalization of relations such as contact, connection, boundaries, interiors, holes, and so on. Mereotopology has been applied also as a tool for qualitative spatial-temporal reasoning, with constraint calculi such as the Region Connection Calculus (RCC). It provides the starting point for the theory of fiat boundaries developed by Smith and Varzi (2000), which grew out of the attempt to distinguish formally between \nMereotopology is being applied by Salustri in the domain of digital manufacturing (Salustri, 2002) and by Smith and Varzi to the formalization of basic notions of ecology and environmental biology (Smith and Varzi, 1999, 2002). It has been applied also to deal with vague boundaries in geography (Smith and Mark, 2003), in ecological psychology (Smith, 2000), and in the study of vagueness and granularity (Smith and Brogaard, 2002, Bittner and Smith, 2001, 2001a).\n\nCasati and Varzi (1999: chpt.4) set out a variety of mereotopological theories in a consistent notation. This section sets out several nested theories that culminate in their preferred theory GEMTC, and follows their exposition closely. The mereological part of GEMTC is the conventional theory GEM. Casati and Varzi do not say if the models of GEMTC include any conventional topological spaces.\n\nWe begin with some domain of discourse, whose elements are called individuals (a synonym for mereology is \"the calculus of individuals\"). Casati and Varzi prefer limiting the ontology to physical objects, but others freely employ mereotopology to reason about geometric figures and events, and to solve problems posed by research in machine intelligence.\n\nAn upper case Latin letter denotes both a relation and the predicate letter referring to that relation in first-order logic. Lower case letters from the end of the alphabet denote variables ranging over the domain; letters from the start of the alphabet are names of arbitrary individuals. If a formula begins with an atomic formula followed by the biconditional, the subformula to the right of the biconditional is a definition of the atomic formula, whose variables are unbound. Otherwise, variables not explicitly quantified are tacitly universally quantified. The axiom Cn below corresponds to axiom C.n in Casati and Varzi (1999: chpt. 4).\n\nWe begin with a topological primitive, a binary relation called \"connection\"; the atomic formula \"Cxy\" denotes that \"\"x\" is connected to \"y\".\" Connection is governed, at minimum, by the axioms:\n\nC1. formula_1 (reflexive)\n\nC2. formula_2 (symmetric)\n\nNow posit the binary relation \"E\", defined as:\n\nformula_3\n\n\"Exy\" is read as \"\"y\" encloses \"x\" and is also topological in nature. A consequence of C1-2 is that \"E\" is reflexive and transitive, and hence a preorder. If \"E\" is also assumed extensional, so that:\n\nformula_4\n\nthen \"E\" can be proved antisymmetric and thus becomes a partial order. Enclosure, notated \"xKy\", is the single primitive relation of the theories in Whitehead (1919, 1925), the starting point of mereotopology. \n\nLet \"parthood\" be the defining primitive binary relation of the underlying mereology, and let the atomic formula \"Pxy\" denote that \"x\" is part of \"y\". We assume that \"P\" is a partial order. Call the resulting minimalist mereological theory M. \n\nIf \"x\" is part of \"y\", we postulate that \"y\" encloses \"x\":\n\nC3. formula_5\n\nC3 nicely connects mereological parthood to topological enclosure.\n\nLet \"O\", the binary relation of mereological \"overlap\", be defined as:\n\nformula_6\n\nLet \"Oxy\" denote that \"x\" and \"y\" overlap.\" With \"O\" in hand, a consequence of C3 is:\n\nformula_7\n\nNote that the converse does not necessarily hold. While things that overlap are necessarily connected, connected things do not necessarily overlap. If this were not the case, topology would merely be a model of mereology (in which \"overlap\" is always either primitive or defined).\n\nGround mereotopology (MT) is the theory consisting of primitive \"C\" and \"P\", defined \"E\" and \"O\", the axioms C1-3, and axioms assuring that \"P\" is a partial order. Replacing the M in MT with the standard extensional mereology GEM results in the theory GEMT.\n\nLet \"IPxy\" denote that \"\"x\" is an internal part of \"y\".\" \"IP\" is defined as:\n\nformula_8\n\nLet σ\"x\" φ(\"x\") denote the mereological sum (fusion) of all individuals in the domain satisfying φ(\"x\"). σ is a variable binding prefix operator. The axioms of GEM assure that this sum exists if φ(\"x\") is a first-order formula. With σ and the relation \"IP\" in hand, we can define the interior of \"x\", formula_9 as the mereological sum of all interior parts \"z\" of \"x\", or:\n\nformula_10 formula_11\n\nTwo easy consequences of this definition are:\n\nformula_12\n\nwhere \"W\" is the universal individual, and\n\nC5. formula_13 (Inclusion)\n\nThe operator i has two more axiomatic properties:\n\nC6. formula_14 (Idempotence)\n\nC7. formula_15 \n\nwhere \"a\"×\"b\" is the mereological product of \"a\" and \"b\", not defined when \"Oab\" is false. i distributes over product.\n\nIt can now be seen that i is isomorphic to the interior operator of topology. Hence the dual of i, the topological closure operator c, can be defined in terms of i, and Kuratowski's axioms for c are theorems. Likewise, given an axiomatization of c that is analogous to C5-7, i may be defined in terms of c, and C5-7 become theorems. Adding C5-7 to GEMT results in Casati and Varzi's preferred mereotopological theory, GEMTC.\n\n\"x\" is \"self-connected\" if it satisfies the following predicate:\n\nformula_16\n\nNote that the primitive and defined predicates of MT alone suffice for this definition. The predicate \"SC\" enables formalizing the necessary condition given in Whitehead's \"Process and Reality\" for the mereological sum of two individuals to exist: they must be connected. Formally:\n\nC8. formula_17\n\nGiven some mereotopology X, adding C8 to X results in what Casati and Varzi call the \"Whiteheadian extension\" of X, denoted WX. Hence the theory whose axioms are C1-8 is WGEMTC.\n\nThe converse of C8 is a GEMTC theorem. Hence given the axioms of GEMTC, \"C\" is a defined predicate if \"O\" and \"SC\" are taken as primitive predicates.\n\nIf the underlying mereology is atomless and weaker than GEM, the axiom that assures the absence of atoms (P9 in Casati and Varzi 1999) may be replaced by C9, which postulates that no individual has a topological boundary:\n\nC9. formula_18\n\nWhen the domain consists of geometric figures, the boundaries can be points, curves, and surfaces. What boundaries could mean, given other ontologies, is not an easy matter and is discussed in Casati and Varzi (1999: chpt. 5).\n\n\n\n"}
{"id": "195795", "url": "https://en.wikipedia.org/wiki?curid=195795", "title": "Metric tensor", "text": "Metric tensor\n\nIn the mathematical field of differential geometry, a metric tensor is a type of function which takes as input a pair of tangent vectors and at a point of a surface (or higher dimensional differentiable manifold) and produces a real number scalar in a way that generalizes many of the familiar properties of the dot product of vectors in Euclidean space. In the same way as a dot product, metric tensors are used to define the length of and angle between tangent vectors. Through integration, the metric tensor allows one to define and compute the length of curves on the manifold.\n\nA metric tensor is called \"positive-definite\" if it assigns a positive value to every nonzero vector . A manifold equipped with a positive-definite metric tensor is known as a Riemannian manifold. On a Riemannian manifold, the curve connecting two points that (locally) has the smallest length is called a geodesic, and its length is the distance that a passenger in the manifold needs to traverse to go from one point to the other. Equipped with this notion of length, a Riemannian manifold is a metric space, meaning that it has a distance function whose value at a pair of points and is the distance from to . Conversely, the metric tensor itself is the derivative of the distance function (taken in a suitable manner). Thus the metric tensor gives the \"infinitesimal\" distance on the manifold.\n\nWhile the notion of a metric tensor was known in some sense to mathematicians such as Carl Gauss from the early 19th century, it was not until the early 20th century that its properties as a tensor were understood by, in particular, Gregorio Ricci-Curbastro and Tullio Levi-Civita, who first codified the notion of a tensor. The metric tensor is an example of a tensor field.\n\nThe components of a metric tensor in a coordinate basis take on the form of a symmetric matrix whose entries transform covariantly under changes to the coordinate system. Thus a metric tensor is a covariant symmetric tensor. From the coordinate-independent point of view, a metric tensor field is defined to be a nondegenerate symmetric bilinear form on each tangent space that varies smoothly from point to point.\n\nCarl Friedrich Gauss in his 1827 \"Disquisitiones generales circa superficies curvas\" (\"General investigations of curved surfaces\") considered a surface parametrically, with the Cartesian coordinates , , and of points on the surface depending on two auxiliary variables and . Thus a parametric surface is (in today's terms) a vector-valued function\n\ndepending on an ordered pair of real variables , and defined in an open set in the -plane. One of the chief aims of Gauss's investigations was to deduce those features of the surface which could be described by a function which would remain unchanged if the surface underwent a transformation in space (such as bending the surface without stretching it), or a change in the particular parametric form of the same geometrical surface.\n\nOne natural such invariant quantity is the length of a curve drawn along the surface. Another is the angle between a pair of curves drawn along the surface and meeting at a common point. A third such quantity is the area of a piece of the surface. The study of these invariants of a surface led Gauss to introduce the predecessor of the modern notion of the metric tensor.\n\nIf the variables and are taken to depend on a third variable, , taking values in an interval , then will trace out a parametric curve in parametric surface . The arc length of that curve is given by the integral\n\nwhere formula_3 represents the Euclidean norm. Here the chain rule has been applied, and the subscripts denote partial derivatives:\n\nThe integrand is the restriction to the curve of the square root of the (quadratic) differential\n\nwhere\n\nThe quantity in () is called the line element, while is called the first fundamental form of . Intuitively, it represents the principal part of the square of the displacement undergone by when is increased by units, and is increased by units.\n\nUsing matrix notation, the first fundamental form becomes\n\nSuppose now that a different parameterization is selected, by allowing and to depend on another pair of variables and . Then the analog of () for the new variables is\nThe chain rule relates , , and to , , and via the matrix equation\n\nwhere the superscript T denotes the matrix transpose. The matrix with the coefficients , , and arranged in this way therefore transforms by the Jacobian matrix of the coordinate change\n\nA matrix which transforms in this way is one kind of what is called a tensor. The matrix\n\nwith the transformation law () is known as the metric tensor of the surface.\n\n first observed the significance of a system of coefficients , , and , that transformed in this way on passing from one system of coordinates to another. The upshot is that the first fundamental form () is \"invariant\" under changes in the coordinate system, and that this follows exclusively from the transformation properties of , , and . Indeed, by the chain rule,\n\nso that\n\nAnother interpretation of the metric tensor, also considered by Gauss, is that it provides a way in which to compute the length of tangent vectors to the surface, as well as the angle between two tangent vectors. In contemporary terms, the metric tensor allows one to compute the dot product of tangent vectors in a manner independent of the parametric description of the surface. Any tangent vector at a point of the parametric surface can be written in the form\n\nfor suitable real numbers and . If two tangent vectors are given:\n\nthen using the bilinearity of the dot product,\n\nThis is plainly a function of the four variables , , , and . It is more profitably viewed, however, as a function that takes a pair of arguments and which are vectors in the -plane. That is, put\n\nThis is a symmetric function in and , meaning that\n\nIt is also bilinear, meaning that it is linear in each variable and separately. That is,\n\nfor any vectors , , , and in the plane, and any real numbers and .\n\nIn particular, the length of a tangent vector is given by\n\nand the angle between two vectors and is calculated by\n\nThe surface area is another numerical quantity which should depend only on the surface itself, and not on how it is parameterized. If the surface is parameterized by the function over the domain in the -plane, then the surface area of is given by the integral\n\nwhere denotes the cross product, and the absolute value denotes the length of a vector in Euclidean space. By Lagrange's identity for the cross product, the integral can be written\n\nwhere is the determinant.\n\nLet be a smooth manifold of dimension ; for instance a surface (in the case ) or hypersurface in the Cartesian space . At each point there is a vector space , called the tangent space, consisting of all tangent vectors to the manifold at the point . A metric tensor at is a function which takes as inputs a pair of tangent vectors and at , and produces as an output a real number (scalar), so that the following conditions are satisfied:\n\nA metric tensor field on assigns to each point of a metric tensor in the tangent space at in a way that varies smoothly with . More precisely, given any open subset of manifold and any (smooth) vector fields and on , the real function\n\nis a smooth function of .\n\nThe components of the metric in any basis of vector fields, or frame, are given by\n\nThe functions form the entries of an symmetric matrix, . If\nare two vectors at , then the value of the metric applied to and is determined by the coefficients () by bilinearity:\n\nDenoting the matrix by and arranging the components of the vectors and into column vectors and ,\n\nwhere and denote the transpose of the vectors and , respectively. Under a change of basis of the form\n\nfor some invertible matrix , the matrix of components of the metric changes by as well. That is,\n\nor, in terms of the entries of this matrix,\n\nFor this reason, the system of quantities is said to transform covariantly with respect to changes in the frame .\n\nA system of real-valued functions , giving a local coordinate system on an open set in , determines a basis of vector fields on \n\nThe metric has components relative to this frame given by\n\nRelative to a new system of local coordinates, say\n\nthe metric tensor will determine a different matrix of coefficients,\n\nThis new system of functions is related to the original by means of the chain rule\n\nso that\n\nOr, in terms of the matrices and ,\n\nwhere denotes the Jacobian matrix of the coordinate change.\n\nAssociated to any metric tensor is the quadratic form defined in each tangent space by\n\nIf is positive for all non-zero , then the metric is positive-definite at . If the metric is positive-definite at every , then is called a Riemannian metric. More generally, if the quadratic forms have constant signature independent of , then the signature of is this signature, and is called a pseudo-Riemannian metric. If is connected, then the signature of does not depend on .\n\nBy Sylvester's law of inertia, a basis of tangent vectors can be chosen locally so that the quadratic form diagonalizes in the following manner\n\nfor some between 1 and . Any two such expressions of (at the same point of ) will have the same number of positive signs. The signature of is the pair of integers , signifying that there are positive signs and negative signs in any such expression. Equivalently, the metric has signature if the matrix of the metric has positive and negative eigenvalues.\n\nCertain metric signatures which arise frequently in applications are:\n\nLet be a basis of vector fields, and as above let be the matrix of coefficients\nOne can consider the inverse matrix , which is identified with the inverse metric (or \"conjugate\" or \"dual metric\"). The inverse metric satisfies a transformation law when the frame is changed by a matrix via\n\nThe inverse metric transforms \"contravariantly\", or with respect to the inverse of the change of basis matrix . Whereas the metric itself provides a way to measure the length of (or angle between) vector fields, the inverse metric supplies a means of measuring the length of (or angle between) covector fields; that is, fields of linear functionals.\n\nTo see this, suppose that is a covector field. To wit, for each point , determines a function defined on tangent vectors at so that the following linearity condition holds for all tangent vectors and , and all real numbers and :\n\nAs varies, is assumed to be a smooth function in the sense that\n\nis a smooth function of for any smooth vector field .\n\nAny covector field has components in the basis of vector fields . These are determined by\n\nDenote the row vector of these components by\n\nUnder a change of by a matrix , changes by the rule\n\nThat is, the row vector of components transforms as a \"covariant\" vector.\n\nFor a pair and of covector fields, define the inverse metric applied to these two covectors by\n\nThe resulting definition, although it involves the choice of basis , does not actually depend on in an essential way. Indeed, changing basis to gives\n\nSo that the right-hand side of equation () is unaffected by changing the basis to any other basis whatsoever. Consequently, the equation may be assigned a meaning independently of the choice of basis. The entries of the matrix are denoted by , where the indices and have been raised to indicate the transformation law ().\n\nIn a basis of vector fields , any smooth tangent vector field can be written in the form\n\nfor some uniquely determined smooth functions . Upon changing the basis by a nonsingular matrix , the coefficients change in such a way that equation () remains true. That is,\n\nConsequently, . In other words, the components of a vector transform \"contravariantly\" (with respect to the inverse) under a change of basis by the nonsingular matrix . The contravariance of the components of is notationally designated by placing the indices of in the upper position.\n\nA frame also allows covectors to be expressed in terms of their components. For the basis of vector fields define the dual basis to be the linear functionals such that\n\nThat is, , the Kronecker delta. Let\n\nUnder a change of basis for a nonsingular matrix , transforms via\n\nAny linear functional on tangent vectors can be expanded in terms of the dual basis \n\nwhere denotes the row vector . The components transform when the basis is replaced by in such a way that equation () continues to hold. That is,\n\nwhence, because , it follows that . That is, the components transform \"covariantly\" (by the matrix rather than its inverse). The covariance of the components of is notationally designated by placing the indices of in the lower position.\n\nNow, the metric tensor gives a means to identify vectors and covectors as follows. Holding fixed, the function\n\nof tangent vector defines a linear functional on the tangent space at . This operation takes a vector at a point and produces a covector . In a basis of vector fields , if a vector field has components , then the components of the covector field in the dual basis are given by the entries of the row vector\n\nUnder a change of basis , the right-hand side of this equation transforms via\n\nso that : transforms covariantly. The operation of associating to the (contravariant) components of a vector field the (covariant) components of the covector field , where\n\nis called lowering the index.\n\nTo \"raise the index\", one applies the same construction but with the inverse metric instead of the metric. If are the components of a covector in the dual basis , then the column vector\n\nhas components which transform contravariantly:\n\nConsequently, the quantity does not depend on the choice of basis in an essential way, and thus defines a vector field on . The operation () associating to the (covariant) components of a covector the (contravariant) components of a vector given is called raising the index. In components, () is\n\nLet be an open set in , and let be a continuously differentiable function from into the Euclidean space , where . The mapping is called an immersion if its differential is injective at every point of . The image of is called an immersed submanifold.\n\nSuppose that is an immersion onto the submanifold . The usual Euclidean dot product in is a metric which, when restricted to vectors tangent to , gives a means for taking the dot product of these tangent vectors. This is called the induced metric.\n\nSuppose that is a tangent vector at a point of , say\n\nwhere are the standard coordinate vectors in . When is applied to , the vector goes over to the vector tangent to given by\n\n(This is called the pushforward of along .) Given two such vectors, and , the induced metric is defined by\n\nIt follows from a straightforward calculation that the matrix of the induced metric in the basis of coordinate vector fields is given by\n\nwhere is the Jacobian matrix:\n\nThe notion of a metric can be defined intrinsically using the language of fiber bundles and vector bundles. In these terms, a metric tensor is a function\n\nfrom the fiber product of the tangent bundle of with itself to such that the restriction of to each fiber is a nondegenerate bilinear mapping\n\nThe mapping () is required to be continuous, and often continuously differentiable, smooth, or real analytic, depending on the case of interest, and whether can support such a structure.\n\nBy the universal property of the tensor product, any bilinear mapping () gives rise naturally to a section of the dual of the tensor product bundle of with itself\n\nThe section is defined on simple elements of by\n\nand is defined on arbitrary elements of by extending linearly to linear combinations of simple elements. The original bilinear form is symmetric if and only if\nwhere\nis the braiding map.\n\nSince is finite-dimensional, there is a natural isomorphism\n\nso that is regarded also as a section of the bundle of the cotangent bundle with itself. Since is symmetric as a bilinear mapping, it follows that is a symmetric tensor.\n\nMore generally, one may speak of a metric in a vector bundle. If is a vector bundle over a manifold , then a metric is a mapping\n\nfrom the fiber product of to which is bilinear in each fiber:\n\nUsing duality as above, a metric is often identified with a section of the tensor product bundle . (See metric (vector bundle).)\n\nThe metric tensor gives a natural isomorphism from the tangent bundle to the cotangent bundle, sometimes called the musical isomorphism. This isomorphism is obtained by setting, for each tangent vector ,\n\nthe linear functional on which sends a tangent vector at to . That is, in terms of the pairing between and its dual space ,\n\nfor all tangent vectors and . The mapping is a linear transformation from to . It follows from the definition of non-degeneracy that the kernel of is reduced to zero, and so by the rank–nullity theorem, is a linear isomorphism. Furthermore, is a symmetric linear transformation in the sense that\n\nfor all tangent vectors and .\n\nConversely, any linear isomorphism defines a non-degenerate bilinear form on by means of\n\nThis bilinear form is symmetric if and only if is symmetric. There is thus a natural one-to-one correspondence between symmetric bilinear forms on and symmetric linear isomorphisms of to the dual .\n\nAs varies over , defines a section of the bundle of vector bundle isomorphisms of the tangent bundle to the cotangent bundle. This section has the same smoothness as : it is continuous, differentiable, smooth, or real-analytic according as . The mapping , which associates to every vector field on a covector field on gives an abstract formulation of \"lowering the index\" on a vector field. The inverse of is a mapping which, analogously, gives an abstract formulation of \"raising the index\" on a covector field.\n\nThe inverse defines a linear mapping\n\nwhich is nonsingular and symmetric in the sense that\n\nfor all covectors , . Such a nonsingular symmetric mapping gives rise (by the tensor-hom adjunction) to a map\n\nor by the double dual isomorphism to a section of the tensor product\n\nSuppose that is a Riemannian metric on . In a local coordinate system , , the metric tensor appears as a matrix, denoted here by , whose entries are the components of the metric tensor relative to the coordinate vector fields.\n\nLet be a piecewise-differentiable parametric curve in , for . The arclength of the curve is defined by\n\nIn connection with this geometrical application, the quadratic differential form\n\nis called the first fundamental form associated to the metric, while is the line element. When is pulled back to the image of a curve in , it represents the square of the differential with respect to arclength.\n\nFor a pseudo-Riemannian metric, the length formula above is not always defined, because the term under the square root may become negative. We generally only define the length of a curve when the quantity under the square root is always of one sign or the other. In this case, define\n\nNote that, while these formulas use coordinate expressions, they are in fact independent of the coordinates chosen; they depend only on the metric, and the curve along which the formula is integrated.\n\nGiven a segment of a curve, another frequently defined quantity is the (kinetic) energy of the curve:\n\nThis usage comes from physics, specifically, classical mechanics, where the integral can be seen to directly correspond to the kinetic energy of a point particle moving on the surface of a manifold. Thus, for example, in Jacobi's formulation of Maupertuis' principle, the metric tensor can be seen to correspond to the mass tensor of a moving particle.\n\nIn many cases, whenever a calculation calls for the length to be used, a similar calculation using the energy may be done as well. This often leads to simpler formulas by avoiding the need for the square-root. Thus, for example, the geodesic equations may be obtained by applying variational principles to either the length or the energy. In the latter case, the geodesic equations are seen to arise from the principle of least action: they describe the motion of a \"free particle\" (a particle feeling no forces) that is confined to move on the manifold, but otherwise moves freely, with constant momentum, within the manifold.\n\nIn analogy with the case of surfaces, a metric tensor on an -dimensional paracompact manifold gives rise to a natural way to measure the -dimensional volume of subsets of the manifold. The resulting natural positive Borel measure allows one to develop a theory of integrating functions on the manifold by means of the associated Lebesgue integral.\n\nA measure can be defined, by the Riesz representation theorem, by giving a positive linear functional on the space of compactly supported continuous functions on . More precisely, if is a manifold with a (pseudo-)Riemannian metric tensor , then there is a unique positive Borel measure such that for any coordinate chart ,\nfor all supported in . Here is the determinant of the matrix formed by the components of the metric tensor in the coordinate chart. That is well-defined on functions supported in coordinate neighborhoods is justified by Jacobian change of variables. It extends to a unique positive linear functional on by means of a partition of unity.\n\nIf is in addition oriented, then it is possible to define a natural volume form from the metric tensor. In a positively oriented coordinate system the volume form is represented as\nwhere the are the coordinate differentials and denotes the exterior product in the algebra of differential forms. The volume form also gives a way to integrate functions on the manifold, and this geometric integral agrees with the integral obtained by the canonical Borel measure.\n\nThe most familiar example is that of elementary Euclidean geometry: the two-dimensional Euclidean metric tensor. In the usual coordinates, we can write\n\nThe length of a curve reduces to the formula:\n\nThe Euclidean metric in some other common coordinate systems can be written as follows.\n\nPolar coordinates :\n\nSo\nby trigonometric identities.\n\nIn general, in a Cartesian coordinate system on a Euclidean space, the partial derivatives are orthonormal with respect to the Euclidean metric. Thus the metric tensor is the Kronecker delta δ in this coordinate system. The metric tensor with respect to arbitrary (possibly curvilinear) coordinates is given by\n\nThe unit sphere in comes equipped with a natural metric induced from the ambient Euclidean metric. In standard spherical coordinates , with the colatitude, the angle measured from the -axis, and the angle from the -axis in the -plane, the metric takes the form\n\nThis is usually written in the form\n\nIn flat Minkowski space (special relativity), with coordinates\n\nthe metric is, depending on choice of metric signature,\n\nFor a curve with—for example—constant time coordinate, the length formula with this metric reduces to the usual length formula. For a timelike curve, the length formula gives the proper time along the curve.\n\nIn this case, the spacetime interval is written as\n\nThe Schwarzschild metric describes the spacetime around a spherically symmetric body, such as a planet, or a black hole. With coordinates\n\nwe can write the metric as\n\nwhere (inside the matrix) is the gravitational constant and represents the total mass-energy content of the central object.\n\n\n"}
{"id": "43356944", "url": "https://en.wikipedia.org/wiki?curid=43356944", "title": "Milutin Dostanić", "text": "Milutin Dostanić\n\nMilutin R. Dostanić (; February 3, 1958 – January 14, 2014) was a Serbian mathematician. He focused his scientific interest on mathematical analysis, namely functional analysis and operator theory.\n\nHe was born in the village of Turica, near Guča, on February 3, 1958.\n\nHe graduated at the University of Belgrade Faculty of Science and Mathematics in\n1980. He received his PhD with Branislav Mirković in 1984, defending PhD\nthesis he had prepared at Lomonosov Moscow State University Faculty of Mechanics and Mathematics, under the\nadvisement of Anatolii Gordeevich Kostyuchenko.\n\nHe became assistant professor at University of Belgrade Faculty of Mathematics in 1994, associate professor in 1999 and obtained full professorship in 2003.\n\nHe left behind voluminous scientific work. He published over 70 papers,\nmany of them in the most cited scientific periodicals.\n\nHe died on January 14, 2014 in Belgrade.\n\n"}
{"id": "15667957", "url": "https://en.wikipedia.org/wiki?curid=15667957", "title": "Minkowski content", "text": "Minkowski content\n\nThe Minkowski content (named after Hermann Minkowski), or the boundary measure, of a set is a basic concept that uses concepts from geometry and measure theory to generalize the notions of length of a smooth curve in the plane, and area of a smooth surface in space, to arbitrary measurable sets. \n\nIt is typically applied to fractal boundaries of domains in the Euclidean space, but it can also be used in the context of general metric measure spaces.\n\nIt is related to, although different from, the Hausdorff measure.\nFor formula_1, and each integer \"m\" with formula_2, the \"m\"-dimensional upper Minkowski content is\n\nand the \"m\"-dimensional lower Minkowski content is defined as\n\nwhere formula_5 is the volume of the (\"n\"−\"m\")-ball of radius r and formula_6 is an formula_7-dimensional Lebesgue measure. \n\nIf the upper and lower \"m\"-dimensional Minkowski content of \"A\" are equal, then their common value is called the Minkowski content \"M\"(\"A\").\n\n\n"}
{"id": "58115588", "url": "https://en.wikipedia.org/wiki?curid=58115588", "title": "Nelli Neumann", "text": "Nelli Neumann\n\nNelli Neumann (January 3, 1886 – 1942) was a German mathematician who worked in synthetic geometry. She was one of the first women to obtain a doctorate in mathematics at a German university.\n\nNelli Neumann was born in Breslau, Prussia, the only child of Jewish parents Max Neumann, a judicial officer, and Sophie Neumann, who died when Nelli was two years old. After ten years in the private \"Höhere Töchterschule\" in Breslau, Neumann attended girls' grammar courses and graduated at a boys' school (\"König-Wilhelm-Gymnasium\") in 1905. Her father promoted her mathematical talent by arranging private mathematics lessons given by Richard Courant. The two went on to study together at the University of Breslau and University of Zürich. Neumann would return to Breslau for her doctorate, for which she completed her thesis in 1909 under the supervision of Rudolf Sturm. After Courant received his post-doctoral degree at Göttingen University, they married in the summer of 1912.\n\nTurning down a post-doctoral position at the University of Breslau, Neumann then took courses that qualified her to become a secondary school teacher. On February 16, 1916, she and Courant divorced. After the First World War she taught at a girls' school in Essen, but lost her position when the Nazis took power in 1933. On 10 November 1941 she was deported to Minsk, where she was executed in 1942.\n"}
{"id": "30871810", "url": "https://en.wikipedia.org/wiki?curid=30871810", "title": "North Magnetic Pole", "text": "North Magnetic Pole\n\nThe North Magnetic Pole is the wandering point on the surface of Earth's Northern Hemisphere at which the planet's magnetic field points vertically downwards (in other words, if a magnetic compass needle is allowed to rotate about a horizontal axis, it will point straight down). There is only one location where this occurs, near (but distinct from) the Geographic North Pole and the Geomagnetic North Pole.\n\nThe North Magnetic Pole moves over time due to magnetic changes in the Earth's core. In 2001, it was determined by the Geological Survey of Canada to lie west of Ellesmere Island in northern Canada at . It was situated at in 2005. In 2009, while still situated within the Canadian Arctic territorial claim at , it was moving toward Russia at between per year. As of 2017, the pole is projected to have moved beyond the Canadian Arctic territorial claim to .\n\nIts southern hemisphere counterpart is the South Magnetic Pole. Since the Earth's magnetic field is not exactly symmetrical, the North and South Magnetic Poles are not antipodal, meaning that a straight line drawn from one to the other does not pass through the geometric centre of the Earth.\n\nThe Earth's North and South Magnetic Poles are also known as Magnetic Dip Poles, with reference to the vertical \"dip\" of the magnetic field lines at those points.\n\nAll magnets have two poles, where the lines of magnetic flux enter and emerge. By analogy with the Earth's magnetic field, these are called the magnet's \"north\" and \"south\" poles. The convention in early compasses was to call the end of the needle pointing to the Earth's North Magnetic Pole the \"north pole\" (or \"north-seeking pole\") and the other end the \"south pole\" (the names are often abbreviated to \"N\" and \"S\"). Because opposite poles attract, this definition means that the Earth's North Magnetic Pole is actually a magnetic \"south\" pole and the Earth's South Magnetic Pole is a magnetic \"north\" pole.\n\nThe direction of magnetic field lines is defined such that the lines emerge from the magnet's north pole and enter into the magnet's south pole.\n\nEarly European navigators believed that compass needles were attracted to a \"magnetic island\" somewhere in the far north (see Rupes Nigra), or to the Pole Star. The idea that the Earth itself acts as a giant magnet was first proposed in 1600 by the English physician and natural philosopher William Gilbert. He was also the first to define the North Magnetic Pole as the point where the Earth's magnetic field points vertically downwards. This is the definition used nowadays, though it would be a few hundred years before the nature of the Earth's magnetic field was understood properly.\n\nThe first expedition to reach the North Magnetic Pole was led by James Clark Ross, who found it at Cape Adelaide on the Boothia Peninsula on June 1, 1831. Roald Amundsen found the North Magnetic Pole in a slightly different location in 1903. The third observation was by Canadian government scientists Paul Serson and Jack Clark, of the Dominion Astrophysical Observatory, who found the pole at Allen Lake on Prince of Wales Island in 1947.\n\nAt the start of the Cold War, the United States Department of War recognized a need for a comprehensive survey of the North American Arctic and asked the United States Army to undertake the task. An assignment was made in 1946 for the newly formed Army’s Air Corps Strategic Air Command to explore the entire Arctic Ocean area. The exploration was conducted by the 46th (later re-designated the 72nd) Photo Reconnaissance Squadron and reported on as a classified \"Top Secret\" mission named Project Nanook. This project in turn was divided into many separate, but identically classified, projects, one of which was Project Polaris, which was a radar, photographic (trimetrogon, or three-angle, cameras) and visual study of the entire Canadian Archipelago. A Canadian officer observer was assigned to accompany each flight.\n\nDirecting Project Polaris was its navigation leader, 1st Lieutenant Frank O. Klein, a World War II combat veteran. Incidental to the project and taken up at his own initiative was a study of northern terrestrial magnetism. The study was prompted by the surprise that the fluxgate compass did not behave erratically as expected. It oscillated no more than 1 to 2 degrees over much of the region. With the cooperation of many of his squadron teammates in obtaining many hundreds of statistical readings, startling results were revealed:\n\nThe centre of the north magnetic dip pole was on Prince of Wales Island some NNW of the positions determined by Amundsen and Ross, and the dip pole occupied a larger elliptical area, with foci about apart on Boothia Peninsula and Bathurst Island.\n\nKlein called the two foci local poles, for their importance to navigation in emergencies when using a \"homing\" procedure. About 3 months after Klein's findings were officially reported, a Canadian ground expedition was sent into the Archipelago to locate the position of the magnetic pole. R. Glenn Madill, Chief of Terrestrial Magnetism, Department of Mines and Resources, Canada, wrote to Lt. Klein on 21 July 1948:\n\nThe Canadian government has made several measurements since, which show that the North Magnetic Pole is moving continually northwestward. In 2001, an expedition located the pole at .\nIn 2007, the latest survey found the pole at .\nDuring the 20th century it moved 1100 km, and since 1970 its rate of motion has accelerated from 9 km/year to approximately 52 km/year (2001–2007 average; see also Polar drift). Members of the 2007 expedition to locate the magnetic north pole wrote that such expeditions have\nbecome logistically difficult, as the pole moves farther away from inhabited locations. They expect that in the future, the magnetic pole position will be obtained from satellite data instead of ground surveys.\n\nThis general movement is in addition to a daily or \"diurnal\" variation in which the North Magnetic Pole describes a rough ellipse, with a maximum deviation of 80 km from its mean position. This effect is due to disturbances of the geomagnetic field by charged particles from the Sun.\nThe first team of novices to reach the Magnetic North Pole did so in 1996, led by David Hempleman-Adams. It included the first British woman Sue Stockdale and first Swedish woman to reach the Pole. The team also successfully tracked the location of the Magnetic North Pole on behalf of the University of Ottawa, and certified its location by magnetometer and theodolite at .\n\nThe biennial Polar Race takes place between Resolute Bay in northern Canada and the 1996-certified location of the North Magnetic Pole at . On 25 July 2007, the \"Top Gear \" was broadcast on BBC Two in the United Kingdom, in which Jeremy Clarkson and James May (and their support and camera team) became the first people in history to reach this location in a car.\n\nHistorically, the magnetic compass was an important tool for navigation. While it has been widely replaced by global positioning systems, many airplanes and ships still carry them, as do casual boaters and hikers.\n\nThe direction in which a compass needle points is known as magnetic north. In general, this is not exactly the direction of the North Magnetic Pole (or of any other consistent location). Instead, the compass aligns itself to the local geomagnetic field, which varies in a complex manner over the Earth's surface, as well as over time. The local angular difference between magnetic north and true north is called the magnetic declination. Most map coordinate systems are based on true north, and magnetic declination is often shown on map legends so that the direction of true north can be determined from north as indicated by a compass.\n\nIn North America the line of zero declination (the \"agonic line\") runs from the North Magnetic Pole down through Lake Superior and southward into the Gulf of Mexico (see figure). Along this line, true north is the same as magnetic north. West of the agonic line a compass will give a reading that is east of true north and by convention the magnetic declination is positive. Conversely, east of the agonic line a compass will point west of true north and the declination is negative.\n\nAs a first-order approximation, the Earth's magnetic field can be modelled as a simple dipole (like a bar magnet), tilted about 10° with respect to the Earth's rotation axis (which defines the Geographic North and Geographic South Poles) and centred at the Earth's centre. The North and South Geomagnetic Poles are the antipodal points where the axis of this theoretical dipole intersects the Earth's surface. If the Earth's magnetic field were a perfect dipole then the field lines would be vertical at the Geomagnetic Poles, and they would coincide with the Magnetic Poles. However, the approximation is imperfect, and so the Magnetic and Geomagnetic Poles lie some distance apart.\n\nLike the North Magnetic Pole, the North Geomagnetic Pole attracts the north pole of a bar magnet and so is in a physical sense actually a magnetic \"south\" pole. It is the centre of the region of the magnetosphere in which the Aurora Borealis can be seen. As of 2015 it was located at approximately , over Ellesmere Island, Canada but it is now drifting away from North America and toward Siberia.\n\nOver the life of the Earth, the orientation of Earth's magnetic field has reversed many times, with magnetic north becoming magnetic south and vice versa – an event known as a geomagnetic reversal. Evidence of geomagnetic reversals can be seen at mid-ocean ridges where tectonic plates move apart and the seabed is filled in with magma. As the magma seeps out of the mantle the magnetic particles contained within it are oriented in the direction of the magnetic field at the time the magma cools and solidifies.\n\n\n"}
{"id": "54184232", "url": "https://en.wikipedia.org/wiki?curid=54184232", "title": "Out in Science, Technology, Engineering, and Mathematics", "text": "Out in Science, Technology, Engineering, and Mathematics\n\nOut in Science, Technology, Engineering, and Mathematics, Inc., abbreviated oSTEM, is a 501(c)(3) non-profit professional society dedicated to LGBTQ+ individuals within the science, technology, engineering, and mathematics (STEM) community.\n\nIn October 2005, IBM sponsored a focus group where students from across the United States convened at the Human Rights Campaign headquarters in Washington D.C. These students discussed topics relevant to LGBTQA communities at their own colleges and universities, and they debated how to structure an organization that serves students in science, technology, engineering, and mathematics.\n\nFounded in 2009 and achieving 501(c)(3) status in 2010, oSTEM, Inc. currently consists of more than 50 chapters across the United States and the United Kingdom. In 2017, oSTEM, Inc. expanded its mission to be inclusive of professionals, serving all LGBTQ people in the STEM community.\n\nAs an organization dedicated to community, oSTEM, Inc. strives to stay engaged to identify, address, and advocate for the needs of LGBTQA+ students and professionals within the STEM fields. oSTEM, Inc. fulfills these needs in many ways, including networking opportunities, mentorship connections, strategic collaborations and professional/leadership development, as well as an annual global conference.\n\noSTEM hosts annual conferences that discuss LGBT+ topics in STEM as well as intelligence fields. Topics discussed include inclusion, outreach, and diversity within the workplace. Workshops, presentations, and networking events for LGBT+ individuals aim to facilitate integration and advancement in their respective fields. The 4 annual conference was hosted jointly with NOGLSTP's Out to Innovate in Atlanta in 2014.\n\nConferences have been held in the following cities:\nOn July 5, 2018 oSTEM along with Pride in STEM, House of STEM, and InterEngineering created international awareness for LGBTQ+ people in Science, Technology, Engineering, and Math.\n\noSTEM presents a variety of awards annually to individuals and organizations that demonstrate a strong dedication to advancing and empowering LGBT+ in STEM fields.\n\nThe oSTEM Global STEM Service Award is given to present and past oSTEM members who show strong dedication to inclusion, diversity, and equality for LGBT+ and other marginalized individuals in STEM fields.\n\nAwardees are: \n\nThe oSTEM Strategic Alliance Award is presented to a current sponsoring organization, community partner, or grant provider of oSTEM who demonstrates strong dedication, engagement, and support to oSTEM and its values.\n\nAwardees are:\n\nThe oSTEM Partner Excellence Award is presented to individuals associated with oSTEM accomplished in their academic or professional lives who regularly advocate for the full inclusion of people of all marginalized identities.\n\nAwardees are: \n\nThe Overall Student Chapter of the Year is given to oSTEM chapters that educate, empower, and engage a diverse community. These chapters contribute greatly to identifying, addressing, and advocating for LGBTQ students in the STEM community\n\nAwardees are: \n\nThe Rookie Student Chapter of the Year celebrates achievements by oSTEM chapters that have been founded within two years of application submission.\n\nAwardees are:\n\noSTEM has over 90 chapters as of September, 2018. Chapters are organized into 6 geographic regions (A-F) and two types (student and professional).\nThe six regions are:\n\nThe first professional chapter is currently being tested in the Boston metropolitan area. Further cities will be announced at a later date.\n\noSTEM is sponsored by industries involved in STEM fields as well as government entities and academic STEM programs.\n\n\n\n\n\n\n"}
{"id": "11492969", "url": "https://en.wikipedia.org/wiki?curid=11492969", "title": "Polar homology", "text": "Polar homology\n\nIn complex geometry, a polar homology is a group which captures holomorphic invariants of a complex manifold in a similar way to usual homology of a manifold in differential topology. Polar homology was defined by B. Khesin and A. Rosly in 1999.\n\nLet \"M\" be a complex projective manifold. The space formula_1 of polar \"k\"-chains is a vector space over formula_2 defined as a quotient formula_3, with formula_4 and formula_5 vector spaces defined below.\n\nThe space formula_4 is freely generated by the triples formula_8, where \"X\" is a smooth, \"k\"-dimensional complex manifold, formula_9 a holomorphic map, and formula_10 is a rational \"k\"-form on \"X\", with first order poles on a divisor with normal crossing.\n\nThe space formula_5 is generated by the following relations.\n\n\nThe boundary operator formula_22 is defined by\n\nwhere formula_24 are components of the polar divisor of formula_10, \"res\" is the Poincaré residue, and formula_26 are restrictions of the map \"f\" to each component of the divisor.\n\nKhesin and Rosly proved that this boundary operator is well defined, and satisfies formula_27. They defined the polar cohomology as the quotient formula_28.\n\n"}
{"id": "58006785", "url": "https://en.wikipedia.org/wiki?curid=58006785", "title": "Polynomial solutions of P-recursive equations", "text": "Polynomial solutions of P-recursive equations\n\nIn mathematics a P-recursive equation can be solved for polynomial solutions. Sergei A. Abramov in 1989 and Marko Petkovšek in 1992 described an algorithm which finds all polynomial solutions of those recurrence equations with polynomial coefficients. The algorithm computes a \"degree bound\" for the solution in a first step. In a second step an ansatz for a polynomial of this degree is used and the unknown coefficients are computed by a system of linear equations. This article describes this algorithm.\n\nIn 1995 Abramov, Bronstein and Petkovšek showed that the polynomial case can be solved more efficiently by considering power series solution of the recurrence equation in a specific power basis (i.e. not the ordinary basis formula_1).\n\nOther algorithms which compute rational or hypergeometric solutions of a linear recurrence equation with polynomial coefficients also use algorithms which compute polynomial solutions.\n\nLet formula_2 be a field of characteristic zero and formula_3 a recurrence equation of order formula_4 with polynomial coefficients formula_5, polynomial right-hand side formula_6 and unknown polynomial sequence formula_7. Furthermore formula_8 denotes the degree of a polynomial formula_9 (with formula_10 for the zero polynomial) and formula_11 denotes the leading coefficient of the polynomial. Moreover letformula_12for formula_13 where formula_14 denotes the falling factorial and formula_15 the set of nonegative integers. Then formula_16. This is called a degree bound for the polynomial solution formula_17. This bound was shown by Abramov and Petkovšek.\n\nThe algorithm consists of two steps. In a first step the \"degree bound\" is computed. In a second step an \"ansatz\" with a polynomial formula_17 of that degree with arbitrary coefficients in formula_2 is made and plugged into the recurrence equation. Then the different powers are compared and a system of linear equations for the coefficients of formula_17 is set up and solved. This is called the \"method undetermined coefficients\". The algorithm returns the general polynomial solution of a recurrence equation.\n\nApplying the formula for the degree bound on the recurrence equationformula_37over formula_38 yields formula_39. Hence one can use an ansatz with a quadratic polynomial formula_40 with formula_41. Plugging this ansatz into the original recurrence equation leads toformula_42This is equivalent to the following system of linear equationsformula_43with the solution formula_44. Therefore the only polynomial solution is formula_45.\n"}
{"id": "13092241", "url": "https://en.wikipedia.org/wiki?curid=13092241", "title": "R. P. Paranjpe", "text": "R. P. Paranjpe\n\nSir Raghunath Purushottam Paranjpye (16 February 1876 – 6 May 1966) was the first Indian to achieve the coveted title of Senior Wrangler at the University of Cambridge, and became a university administrator and Indian ambassador.\n\nPreviously, at the Cambridge University of England, a student who gains first-class honors in the third year of the University’s undergraduate exam was honored by the title of ‘Wrangler’. The highest scoring student was called ‘Senior Wrangler’. R. P. Paranjape became a Senior Wrangler in the year 1899 by excelling in these exams. In those days, the exams were conducted only orally. Later in time they switched to exams in written format. The students appearing for exams would sit on a three legged stool; hence, the exams were named ‘Tripos’. The examiners would sit on a chair facing the student and intimidate them with the most difficult questions to test their true knowledge of the subject. The student, who would become senior wrangler, would further receive many awards and liberties. A senior wrangler would get many facilities for his further education; including a fellowship, a good position in the university and an invitation to write a book.\n\nRaghunath Paranjpye was born at Murdi near Dapoli in the coastal Ratnagiri district of Maharashtra. He was educated at Maratha high school, Bombay, Fergusson College, Pune and Bombay University before entering St John's College, Cambridge in 1896. He graduated B.A. as senior wrangler in 1899. Paranjpye was elected a Fellow of St John's College in November 1901 and stayed as such until 1907, but returned to India to become a professor of mathematics at Fergusson College in 1902. One of the earliest Indian documentary film makers, H. S. Bhatavdekar, made silent documentary films, \"Return of Wrangler Paranjpye\" (1902) and \"Delhi Durbar of Lord Curzon\" (1903), featuring R. P.\nIn 1907, R. P. became the first librarian of the Indian Mathematical Society at Fergusson College. He became the college's principal, and stayed in that position for two decades, until 1926. Subsequently, he consecutively became the Vice-Chancellor of Bombay University and Lucknow University. In 1921, the University of Calcutta awarded him an honorary Doctor of Science degree.\n\nSir Raghunath was elected to the Bombay Legislative Council in 1912 representing the University of Bombay constituency. He was again elected to the enlarged Council as per the Government of India Act 1919. As part of Diarchy in Bombay Presidency, Paranjpye was appointed as the first Minister for Education and he served in the position till 1923. He was unable to get elected in the 1923 elections losing to M. R. Jayakar of the Swaraj Party.\n\nParanjpye received a knighthood from the colonial government in 1942. In the three years (1944–1947) preceding India's independence from the British Raj, the British government appointed him India's High Commissioner to Australia. In the days of the British Raj, there was some criticism that R. P. had often appeared on the side of British authorities at a time of nationalist ferment in India.\n\nHe was the founder of the Indian Rationalist Association in Chennai (then Madras) in 1949, and remained its President for many years. His autobiography, \"84 Not Out\", appeared in 1961.\nAcharya Atre has devoted one full chapter in his autobiography for Wrangler Paranjpye and has written about his fame all over the country and how because of him students from outside Maharashtra came to study at Ferguson College.\nHis younger brother, Hari Purushottam Paranjpye was a well known agriculturist of his time. In 1991, the Government of India awarded R. P.'s daughter Shakuntala Paranjpye a Padma Bhushan title in recognition of her work in the field of family planning. She was also a nominated member of the Rajya Sabha in the 1960s In 2006, the Government of India awarded R. P.'s granddaughter Sai Paranjpye a Padma Bhushan title in recognition of her artistic talents. She is a film director and a scriptwriter.\n\n\n\n"}
{"id": "358477", "url": "https://en.wikipedia.org/wiki?curid=358477", "title": "Random graph", "text": "Random graph\n\nIn mathematics, random graph is the general term to refer to probability distributions over graphs. Random graphs may be described simply by a probability distribution, or by a random process which generates them. The theory of random graphs lies at the intersection between graph theory and probability theory. From a mathematical perspective, random graphs are used to answer questions about the properties of \"typical\" graphs. Its practical applications are found in all areas in which complex networks need to be modeled – a large number of random graph models are thus known, mirroring the diverse types of complex networks encountered in different areas. In a mathematical context, \"random graph\" refers almost exclusively to the Erdős–Rényi random graph model. In other contexts, any graph model may be referred to as a \"random graph\".\n\nA random graph is obtained by starting with a set of \"n\" isolated vertices and adding successive edges between them at random. The aim of the study in this field is to determine at what stage a particular property of the graph is likely to arise. Different random graph models produce different probability distributions on graphs. Most commonly studied is the one proposed by Edgar Gilbert, denoted \"G\"(\"n\",\"p\"), in which every possible edge occurs independently with probability 0 < \"p\" < 1. The probability of obtaining \"any one particular\" random graph with \"m\" edges is formula_1 with the notation formula_2.\n\nA closely related model, the Erdős–Rényi model denoted \"G\"(\"n\",\"M\"), assigns equal probability to all graphs with exactly \"M\" edges. With 0 ≤ \"M\" ≤ \"N\", \"G\"(\"n\",\"M\") has formula_3 elements and every element occurs with probability formula_4. The latter model can be viewed as a snapshot at a particular time (\"M\") of the random graph process formula_5, which is a stochastic process that starts with \"n\" vertices and no edges, and at each step adds one new edge chosen uniformly from the set of missing edges.\n\nIf instead we start with an infinite set of vertices, and again let every possible edge occur independently with probability 0 < \"p\" < 1, then we get an object \"G\" called an infinite random graph. Except in the trivial cases when \"p\" is 0 or 1, such a \"G\" almost surely has the following property:\n\nGiven any \"n\" + \"m\" elements formula_6, there is a vertex \"c\" in \"V\" that is adjacent to each of formula_7 and is not adjacent to any of formula_8.\n\nIt turns out that if the vertex set is countable then there is, up to isomorphism, only a single graph with this property, namely the Rado graph. Thus any countably infinite random graph is almost surely the Rado graph, which for this reason is sometimes called simply the random graph. However, the analogous result is not true for uncountable graphs, of which there are many (nonisomorphic) graphs satisfying the above property.\n\nAnother model, which generalizes Gilbert's random graph model, is the random dot-product model. A random dot-product graph associates with each vertex a real vector. The probability of an edge \"uv\" between any vertices \"u\" and \"v\" is some function of the dot product u • v of their respective vectors.\n\nThe network probability matrix models random graphs through edge probabilities, which represent the probability formula_9 that a given edge formula_10 exists for a specified time period. This model is extensible to directed and undirected; weighted and unweighted; and static or dynamic graphs structure.\n\nFor \"M\" ≃ \"pN\", where \"N\" is the maximal number of edges possible, the two most widely used models, \"G\"(\"n\",\"M\") and \"G\"(\"n\",\"p\"), are almost interchangeable.\n\nRandom regular graphs form a special case, with properties that may differ from random graphs in general.\n\nOnce we have a model of random graphs, every function on graphs, becomes a random variable. The study of this model is to determine if, or at least estimate the probability that, a property may occur.\n\nThe term 'almost every' in the context of random graphs refers to a sequence of spaces and probabilities, such that the \"error probabilities\" tend to zero.\n\nThe theory of random graphs studies typical properties of random graphs, those that hold with high probability for graphs drawn from a particular distribution. For example, we might ask for a given value of formula_11 and formula_12 what the probability is that formula_13 is connected. In studying such questions, researchers often concentrate on the asymptotic behavior of random graphs—the values that various probabilities converge to as formula_11 grows very large. Percolation theory characterizes the connectedness of random graphs, especially infinitely large ones.\n\nPercolation is related to the robustness of the graph (called also network). Given a random graph of formula_11 nodes and an average degree formula_16. Next we remove randomly a fraction formula_17 of nodes and leave only a fraction formula_12. There exists a critical percolation threshold formula_19 below which the network becomes fragmented while above formula_20 a giant connected component exists.\nLocalized percolation refers to removing a node its neighbors, next nearest neighbors etc. until a fraction of formula_17 of nodes from the network is removed. It was shown that for random graph with Poisson distribution of degrees formula_19 exactly as for random removal. For other types of degree distributions formula_20 for localized attack is different from random attack\n\"(threshold functions, evolution of formula_24)\"\n\nRandom graphs are widely used in the probabilistic method, where one tries to prove the existence of graphs with certain properties. The existence of a property on a random graph can often imply, via the Szemerédi regularity lemma, the existence of that property on almost all graphs.\n\nIn random regular graphs, formula_25 are the set of formula_26-regular graphs with formula_27 such that formula_11 and formula_29 are the natural numbers, formula_30, and formula_31 is even.\n\nThe degree sequence of a graph formula_32 in formula_33 depends only on the number of edges in the sets\n\nIf edges, formula_35 in a random graph, formula_36 is large enough to ensure that almost every formula_36 has minimum degree at least 1, then almost every formula_36 is connected and, if formula_11 is even, almost every formula_36 has a perfect matching. In particular, the moment the last isolated vertex vanishes in almost every random graph, the graph becomes connected.\n\nAlmost every graph process on an even number of vertices with the edge raising the minimum degree to 1 or a random graph with slightly more than formula_41 edges and with probability close to 1 ensures that the graph has a complete matching, with exception of at most one vertex.\n\nFor some constant formula_42, almost every labeled graph with formula_11 vertices and at least formula_44 edges is Hamiltonian. With the probability tending to 1, the particular edge that increases the minimum degree to 2 makes the graph Hamiltonian.\n\nProperties of random graph may change or remain invariant under graph transformations. Mashaghi A. et al., for example, demonstrated that a transformation which converts random graphs to their edge-dual graphs (or line graphs) produces an ensemble of graphs with nearly the same degree distribution, but with degree correlations and a significantly higher clustering coefficient.\n\nGiven a random graph \"G\" of order \"n\" with the vertex \"V\"(\"G\") = {1, ..., \"n\"}, by the greedy algorithm on the number of colors, the vertices can be colored with colors 1, 2, ... (vertex 1 is colored 1, vertex 2 is colored 1 if it is not adjacent to vertex 1, otherwise it is colored 2, etc.).\nThe number of proper colorings of random graphs given a number of \"q\" colors, called its chromatic polynomial, remains unknown so far. The scaling of zeros of the chromatic polynomial of random graphs with parameters \"n\" and the number of edges \"m\" or the connection probability \"p\" has been studied empirically using an algorithm based on symbolic pattern matching.\n\nA random tree is a tree or arborescence that is formed by a stochastic process. In a large range of random graphs of order \"n\" and size \"M\"(\"n\") the distribution of the number of tree components of order \"k\" is asymptotically Poisson. Types of random trees include uniform spanning tree, random minimal spanning tree, random binary tree, treap, rapidly exploring random tree, Brownian tree, and random forest.\n\nConsider a given random graph model defined on the probability space formula_45 and let formula_46 be a real valued function which assigns to each graph in formula_47 a vector of \"m\" properties. \nFor a fixed formula_48, \"conditional random graphs\" are models in which the probability measure formula_49 assigns zero probability to all graphs such that 'formula_50.\n\nSpecial cases are \"conditionally uniform random graphs\", where formula_49 assigns equal probability to all the graphs having specified properties. They can be seen as a generalization of the Erdős–Rényi model \"G\"(\"n\",\"M\"), when the conditioning information is not necessarily the number of edges \"M\", but whatever other arbitrary graph property formula_52. In this case very few analytical results are available and simulation is required to obtain empirical distributions of average properties. Recently, a general and exact methodology for random graph simulation has been proposed\n\nOther recently studied \"conditional random graphs\" are the \"conditionally exponential random graphs models\", where formula_49 has an ERGM functional form for all graphs verifying formula_54. This class of models have been introduced by Nasini et al. in the context of Scientific collaboration network\n\nIn interdependent graphs nodes in one network (graph) depend on other networks to function. So failures in one or several graphs induce cascading failures between the graphs which may lead to abrupt collapse.\n\nRandom graphs were first defined by Paul Erdős and Alfréd Rényi in their 1959 paper \"On Random Graphs\" and independently by Gilbert in his paper \"Random graphs\".\n\n"}
{"id": "25723", "url": "https://en.wikipedia.org/wiki?curid=25723", "title": "Regular language", "text": "Regular language\n\nIn theoretical computer science and formal language theory, a regular language (also called a rational language) is a formal language that can be expressed using a regular expression, in the strict sense of the latter notion used in theoretical computer science (as opposed to many regular expressions engines provided by modern programming languages, which are augmented with features that allow recognition of languages that cannot be expressed by a classic regular expression).\n\nAlternatively, a regular language can be defined as a language recognized by a finite automaton. The equivalence of regular expressions and finite automata is known as Kleene's theorem (after American mathematician Stephen Cole Kleene). In the Chomsky hierarchy, regular languages are defined to be the languages that are generated by Type-3 grammars (regular grammars).\n\nRegular languages are very useful in input parsing and programming language design.\n\nThe collection of regular languages over an alphabet Σ is defined recursively as follows:\n\nSee regular expression for its syntax and semantics. Note that the above cases are in effect the defining rules of regular expression.\n\nAll finite languages are regular; in particular the empty string language {ε} = Ø* is regular. Other typical examples include the language consisting of all strings over the alphabet {\"a\", \"b\"} which contain an even number of \"a\"s, or the language consisting of all strings of the form: several \"a\"s followed by several \"b\"s.\n\nA simple example of a language that is not regular is the set of strings { \"a\"\"b\" | \"n\" ≥ 0 }. Intuitively, it cannot be recognized with a finite automaton, since a finite automaton has finite memory and it cannot remember the exact number of a's. Techniques to prove this fact rigorously are given below.\n\nA regular language satisfies the following equivalent properties:\n\nProperties 9. and 10. are purely algebraic approaches to define regular languages; a similar set of statements can be formulated for a monoid \"M\"⊂Σ. In this case, equivalence over \"M\" leads to the concept of a recognizable language.\n\nSome authors use one of the above properties different from \"1.\" as alternative definition of regular languages.\n\nSome of the equivalences above, particularly those among the first four formalisms, are called \"Kleene's theorem\" in textbooks. Precisely which one (or which subset) is called such varies between authors. One textbook calls the equivalence of regular expressions and NFAs (\"1.\" and \"2.\" above) \"Kleene's theorem\". Another textbook calls the equivalence of regular expressions and DFAs (\"1.\" and \"3.\" above) \"Kleene's theorem\". Two other textbooks first prove the expressive equivalence of NFAs and DFAs (\"2.\" and \"3.\") and then state \"Kleene's theorem\" as the equivalence between regular expressions and finite automata (the latter said to describe \"recognizable languages\"). A linguistically oriented text first equates regular grammars (\"4.\" above) with DFAs and NFAs, calls the languages generated by (any of) these \"regular\", after which it introduces regular expressions which it terms to describe \"rational languages\", and finally states \"Kleene's theorem\" as the coincidence of regular and rational languages. Other authors simply \"define\" \"rational expression\" and \"regular expressions\" as synonymous and do the same with \"rational languages\" and \"regular languages\".\n\nThe regular languages are closed under the various operations, that is, if the languages \"K\" and \"L\" are regular, so is the result of the following operations:\n\n\nGiven two deterministic finite automata \"A\" and \"B\", it is decidable whether they accept the same language.\nAs a consequence, using the above closure properties, the following problems are also decidable for arbitrarily given deterministic finite automata \"A\" and \"B\", with accepted languages \"L\" and \"L\", respectively:\nFor regular expressions, the universality problem is NP-complete already for a singleton alphabet.\nFor larger alphabets, that problem is PSPACE-complete. If regular expressions are extended to allow also a \"squaring operator\", with \"\"A\"\" denoting the same as \"AA\", still just regular languages can be described, but the universality problem has an exponential space lower bound, and is in fact complete for exponential space with respect to polynomial-time reduction.\n\nIn computational complexity theory, the complexity class of all regular languages is sometimes referred to as REGULAR or REG and equals DSPACE(O(1)), the decision problems that can be solved in constant space (the space used is independent of the input size). REGULAR ≠ AC, since it (trivially) contains the parity problem of determining whether the number of 1 bits in the input is even or odd and this problem is not in AC. On the other hand, REGULAR does not contain AC, because the nonregular language of palindromes, or the nonregular language formula_1 can both be recognized in AC.\n\nIf a language is \"not\" regular, it requires a machine with at least Ω(log log \"n\") space to recognize (where \"n\" is the input size). In other words, DSPACE(o(log log \"n\")) equals the class of regular languages. In practice, most nonregular problems are solved by machines taking at least logarithmic space.\n\nTo locate the regular languages in the Chomsky hierarchy, one notices that every regular language is context-free. The converse is not true: for example the language consisting of all strings having the same number of \"a\"<nowiki>'</nowiki>s as \"b\"<nowiki>'</nowiki>s is context-free but not regular. To prove that a language such as this is not regular, one often uses the Myhill–Nerode theorem or the pumping lemma among other methods.\n\nImportant subclasses of regular languages include\n\nLet formula_2 denote the number of words of length formula_3 in formula_4. The ordinary generating function for \"L\" is the formal power series\n\nThe generating function of a language \"L\" is a rational function if \"L\" is regular. Hence for any regular language formula_4 there exist an integer constant formula_7, complex constants formula_8 and complex polynomials formula_9\nsuch that for every formula_10 the number formula_2 of words of length formula_3 in formula_4 is\nformula_14.\n\nThus, non-regularity of certain languages formula_15 can be proved by counting the words of a given length in\nformula_15. Consider, for example, the Dyck language of strings of balanced parentheses. The number of words of length formula_17\nin the Dyck language is equal to the Catalan number formula_18, which is not of the form formula_19,\nwitnessing the non-regularity of the Dyck language. Care must be taken since some of the eigenvalues formula_20 could have the same magnitude. For example, the number of words of length formula_3 in the language of all even binary words is not of the form formula_19, but the number of words of even or odd length are of this form; the corresponding eigenvalues are formula_23. In general, for every regular language there exists a constant formula_24 such that for all formula_25, the number of words of length formula_26 is asymptotically formula_27.\n\nThe \"zeta function\" of a language \"L\" is\n\nThe zeta function of a regular language is not in general rational, but that of an arbitrary cyclic language is.\n\nThe notion of a regular language has been generalized to infinite words (see ω-automata) and to trees (see tree automaton).\n\nRational set generalizes the notion (of regular/rational language) to monoids that are not necessarily free. Likewise, the notion of a recognizable language (by a finite automaton) has namesake as recognizable set over a monoid that is not necessarily free. Howard Straubing notes in relation to these facts that “The term \"regular language\" is a bit unfortunate. Papers influenced by Eilenberg's monograph often use either the term \"recognizable language\", which refers to the behavior of automata, or \"rational language\", which refers to important analogies between regular expressions and rational power series. (In fact, Eilenberg defines rational and recognizable subsets of arbitrary monoids; the two notions do not, in general, coincide.) This terminology, while better motivated, never really caught on, and \"regular language\" is used almost universally.”\n\nRational series is another generalization, this time in the context of a formal power series over a semiring. This approach gives rise to weighted rational expressions and weighted automata. In this algebraic context, the regular languages (corresponding to Boolean-weighted rational expressions) are usually called \"rational languages\". Also in this context, Kleene's theorem finds a generalization called the Kleene-Schützenberger theorem.\n\n\n"}
{"id": "40159314", "url": "https://en.wikipedia.org/wiki?curid=40159314", "title": "Relativistic chaos", "text": "Relativistic chaos\n\nIn physics, relativistic chaos is the application of chaos theory to dynamical systems described primarily by general relativity, and also special relativity.\n\nOne of the earlier references on the topic is (Barrow 1982) and a particularly relevant result is that relativistic chaos is coordinate invariant (Motter 2003).\n\n\n"}
{"id": "17590530", "url": "https://en.wikipedia.org/wiki?curid=17590530", "title": "Sequential dynamical system", "text": "Sequential dynamical system\n\nSequential dynamical systems (SDSs) are a class of graph dynamical systems. They are discrete dynamical systems which generalize many aspects of for example classical cellular automata, and they provide a framework for studying asynchronous processes over graphs. The analysis of SDSs uses techniques from combinatorics, abstract algebra, graph theory, dynamical systems and probability theory.\n\nAn SDS is constructed from the following components:\nIt is convenient to introduce the \"Y\"-local maps \"F\" constructed from the vertex functions by\n\nThe word \"w\" specifies the sequence in which the \"Y\"-local maps are composed to derive the sequential dynamical system map \"F\": \"K → K\" as\n\nIf the update sequence is a permutation one frequently speaks of a \"permutation SDS\" to emphasize this point. \nThe \"phase space\" associated to a sequential dynamical system with map \"F\": \"K → K\" is the finite directed graph with vertex set \"K\" and directed edges (\"x\", \"F\"(\"x\")). The structure of the phase space is governed by the properties of the graph \"Y\", the vertex functions (\"f\")\"\", and the update sequence \"w\". A large part of SDS research seeks to infer phase space properties based on the structure of the system constituents.\n\nConsider the case where \"Y\" is the graph with vertex set {1,2,3} and undirected edges {1,2}, {1,3} and {2,3} (a triangle or 3-circle) with vertex states from \"K\" = {0,1}. For vertex functions use the symmetric, boolean function nor : \"K → K\" defined by nor(\"x\",\"y\",\"z\") = (1+\"x\")(1+\"y\")(1+\"z\") with boolean arithmetic. Thus, the only case in which the function nor returns the value 1 is when all the arguments are 0. Pick \"w\" = (1,2,3) as update sequence. Starting from the initial system state (0,0,0) at time \"t\" = 0 one computes the state of vertex 1 at time \"t\"=1 as nor(0,0,0) = 1. The state of vertex 2 at time \"t\"=1 is nor(1,0,0) = 0. Note that the state of vertex 1 at time \"t\"=1 is used immediately. Next one obtains the state of vertex 3 at time \"t\"=1 as nor(1,0,0) = 0. This completes the update sequence, and one concludes that the Nor-SDS map sends the system state (0,0,0) to (1,0,0). The system state (1,0,0) is in turned mapped to (0,1,0) by an application of the SDS map.\n\n\n"}
{"id": "1890594", "url": "https://en.wikipedia.org/wiki?curid=1890594", "title": "Simple function", "text": "Simple function\n\nIn the mathematical field of real analysis, a simple function is a real-valued function over a subset of the real line, similar to a step function. Simple functions are sufficiently \"nice\" that using them makes mathematical reasoning, theory, and proof easier. For example, simple functions attain only a finite number of values. Some authors also require simple functions to be measurable; as used in practice, they invariably are.\n\nA basic example of a simple function is the floor function over the half-open interval [1, 9), whose only values are {1, 2, 3, 4, 5, 6, 7, 8}. A more advanced example is the Dirichlet function over the real line, which takes the value 1 if \"x\" is rational and 0 otherwise. (Thus the \"simple\" of \"simple function\" has a technical meaning somewhat at odds with common language.) Note also that all step functions are simple.\n\nSimple functions are used as a first stage in the development of theories of integration, such as the Lebesgue integral, because it is easy to define integration for a simple function and also it is straightforward to approximate more general functions by sequences of simple functions.\n\nFormally, a simple function is a finite linear combination of indicator functions of measurable sets. More precisely, let (\"X\", Σ) be a measurable space. Let \"A\", ..., \"A\" ∈ Σ be a sequence of disjoint measurable sets, and let \"a\", ..., \"a\" be a sequence of real or complex numbers. A \"simple function\" is a function formula_1 of the form\n\nwhere formula_3 is the indicator function of the set \"A\".\n\nThe sum, difference, and product of two simple functions are again simple functions, and multiplication by constant keeps a simple function simple; hence it follows that the collection of all simple functions on a given measurable space forms a commutative algebra over formula_4.\n\nIf a measure μ is defined on the space (\"X\",Σ), the integral of \"f\" with respect to μ is\n\nif all summands are finite.\n\nAny non-negative measurable function formula_6 is the pointwise limit of a monotonic increasing sequence of non-negative simple functions. Indeed, let formula_7 be a non-negative measurable function defined over the measure space formula_8 as before. For each formula_9, subdivide the range of formula_7 into formula_11 intervals, formula_12 of which have length formula_13. For each formula_14, set \n\nNow define the measurable sets \n\nThen the increasing sequence of simple functions \n\nconverges pointwise to formula_7 as formula_24. Note that, when formula_7 is bounded, the convergence is uniform. This approximation of formula_7 by simple functions (which are easily integrable) allows us to define an integral formula_7 itself; see the article on Lebesgue integration for more details.\n\n"}
{"id": "48211685", "url": "https://en.wikipedia.org/wiki?curid=48211685", "title": "Stacks Project", "text": "Stacks Project\n\nThe Stacks Project is an open source collaborative mathematics textbook writing project with the aim to cover \"algebraic stacks and the algebraic geometry needed to define them\". , the book consists of 109 chapters spreading over 6000 pages. The maintainer of the project, who reviews and accepts the changes, is Aise Johan de Jong.\n\n"}
{"id": "30701021", "url": "https://en.wikipedia.org/wiki?curid=30701021", "title": "Statistics in Medicine (journal)", "text": "Statistics in Medicine (journal)\n\nEstablished in 1982, the journal publishes articles on medical statistics.\nThe journal is indexed by \"Mathematical Reviews\" and SCOPUS.\nIts 2009 MCQ was 0.02. According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 1.861.\n"}
{"id": "38445971", "url": "https://en.wikipedia.org/wiki?curid=38445971", "title": "Subordinator (mathematics)", "text": "Subordinator (mathematics)\n\nIn the mathematics of probability, a subordinator is a concept related to stochastic processes. A subordinator is itself a stochastic process of the evolution of time within another stochastic process, the subordinated stochastic process. In other words, a subordinator will determine the random number of \"time steps\" that occur within the subordinated process for a given unit of chronological time.\n\nIn order to be a subordinator a process must be a Lévy process. It also must be increasing, almost surely.\n\nA subordinator is an increasing (a.s.) Lévy process.\n\nThe variance gamma process can be described as a Brownian motion subject to a gamma subordinator. If a Brownian motion, formula_1, with drift formula_2 is subjected to a random time change which follows a gamma process, formula_3, the variance gamma process will follow:\n\nThe Cauchy process can be described as a Brownian motion subject to a Lévy subordinator.\n"}
{"id": "12745577", "url": "https://en.wikipedia.org/wiki?curid=12745577", "title": "The Quadrature of the Parabola", "text": "The Quadrature of the Parabola\n\nThe Quadrature of the Parabola () is a treatise on geometry, written by Archimedes in the 3rd century BC. Written as a letter to his friend Dositheus, the work presents 24 propositions regarding parabolas, culminating in a proof that the area of a parabolic segment (the region enclosed by a parabola and a line) is 4/3 that of a certain inscribed triangle.\n\nThe statement of the problem used the method of exhaustion. Archimedes may have dissected the area into infinitely many triangles whose areas form a geometric progression. He computes the sum of the resulting geometric series, and proves that this is the area of the parabolic segment. This represents the most sophisticated use of the method of exhaustion in ancient mathematics, and remained unsurpassed until the development of integral calculus in the 17th century, being succeeded by Cavalieri's quadrature formula.\n\nA parabolic segment is the region bounded by a parabola and line. To find the area of a parabolic segment, Archimedes considers a certain inscribed triangle. The base of this triangle is the given chord of the parabola, and the third vertex is the point on the parabola such that the tangent to the parabola at that point is parallel to the chord. By Proposition 1 (Quadrature of the Parabola), a line from the third vertex drawn parallel to the axis divides the chord into equal segments. The main theorem claims that the area of the parabolic segment is 4/3 that of the inscribed triangle.\nArchimedes gives two proofs of the main theorem. The first uses abstract mechanics, with Archimedes arguing that the weight of the segment will balance the weight of the triangle when placed on an appropriate lever. The second, more famous proof uses pure geometry, specifically the method of exhaustion.\n\nOf the twenty-four propositions, the first three are quoted without proof from Euclid's \"Elements of Conics\" (a lost work by Euclid on conic sections). Propositions four and five establish elementary properties of the parabola; propositions six through seventeen give the mechanical proof of the main theorem; and propositions eighteen through twenty-four present the geometric proof.\n\nThe main idea of the proof is the dissection of the parabolic segment into infinitely many triangles, as shown in the figure to the right. Each of these triangles is inscribed in its own parabolic segment in the same way that the blue triangle is inscribed in the large segment.\n\nIn propositions eighteen through twenty-one, Archimedes proves that the area of each green triangle is one eighth of the area of the blue triangle. From a modern point of view, this is because the green triangle has half the width and a fourth of the height:\n\nBy extension, each of the yellow triangles has one eighth the area of a green triangle, each of the red triangles has one eighth the area of a yellow triangle, and so on. Using the method of exhaustion, it follows that the total area of the parabolic segment is given by\n\nHere \"T\" represents the area of the large blue triangle, the second term represents the total area of the two green triangles, the third term represents the total area of the four yellow triangles, and so forth. This simplifies to give\n\nTo complete the proof, Archimedes shows that\n\nThe formula above is a geometric series—each successive term is one fourth of the previous term. In modern mathematics, that formula is a special case of the sum formula for a geometric series.\n\nArchimedes evaluates the sum using an entirely geometric method, illustrated in the adjacent picture. This picture shows a unit square which has been dissected into an infinity of smaller squares. Each successive purple square has one fourth the area of the previous square, with the total purple area being the sum\n\nHowever, the purple squares are congruent to either set of yellow squares, and so cover 1/3 of the area of the unit square. It follows that the series above sums to 4/3.\n\n\n\n"}
{"id": "26436686", "url": "https://en.wikipedia.org/wiki?curid=26436686", "title": "Time-domain harmonic scaling", "text": "Time-domain harmonic scaling\n\nTime-domain harmonic scaling (TDHS) is a method for time-scale modification of speech (or other audio signals), allowing the apparent rate of speech articulation to be changed without affecting the pitch-contour and the time-evolution of the formant structure. TDHS differs from other time-scale modification algorithms in that time-scaling operations are performed in the time domain (not the frequency domain).\n\nProposed by D. Malah in 1979\n\n"}
{"id": "47321570", "url": "https://en.wikipedia.org/wiki?curid=47321570", "title": "Valeria de Paiva", "text": "Valeria de Paiva\n\nValeria Correa Vaz de Paiva is a Brazilian mathematician, logician, and computer scientist associated with Nuance Communications.\nHer work includes research on logical approaches to computation, especially using category theory, \nknowledge representation and natural language semantics, and functional programming with a focus on foundations and type theories.\n\nDe Paiva earned a bachelor's degree in mathematics in 1982, a master's degree in 1984 (on pure Algebra) and completed a doctorate at the University of Cambridge in 1988, under the supervision of Martin Hyland. Her thesis introduced Dialectica spaces, a categorical way of constructing models of linear logic.\n\nShe worked for nine years at PARC in Palo Alto, California, and also worked at Rearden Commerce and Cuill before joining Nuance. She is an honorary research fellow in computer science at the University of Birmingham.\n\n"}
{"id": "22081008", "url": "https://en.wikipedia.org/wiki?curid=22081008", "title": "Yvonne Choquet-Bruhat", "text": "Yvonne Choquet-Bruhat\n\nYvonne Choquet-Bruhat (; born 29 December 1923 in Lille) is a French mathematician and physicist. Her work lies in the intersection of mathematics and physics, notably in Einstein's theory of General Relativity. She is one of the pioneer in the study of General relativity, and she is particularly known to be the first to prove the well-posedness of the Einstein equations. Her works were applied in the detection of the gravitational waves. \n\nShe was the first woman to be elected to the \"Académie des Sciences Française\" (\"French Academy of Sciences\") and is a Grand Officier of the Légion d'honneur.\n\nYvonne was born in Lille in 1923. Her mother was the philosophy professor Berthe Hubert, her father was the physicist (1887 - 1945) (who died in the concentration camp Oranienburg-Sachsenhausen) and her brother was the mathematician François Bruhat. Yvonne Choquet-Bruhat undertook her secondary school education in Paris. In 1941 she entered the Concours General, a competition to determine the best pupils in the whole of France, and won the silver medal for physics. From 1943 to 1946 she studied at the \"École Normale Supérieure\" (\"ENS\") in Paris and from 1946 was a teaching assistant there and undertook research advised by André Lichnerowicz. From 1949 to 1951 she was a research assistant at the French National Centre for Scientific Research (\"CNRS\"), as a result of which she received her doctorate.\n\nYvonne Choquet-Bruhat has worked in a range of areas in mathematical physics, applying results from the analysis of partial differential equations and differential geometry to provide a firm basis for solutions in physics. From 1951-1952 she worked at the Institute for Advanced Study in Princeton, under the supervision of Albert Einstein, where she proved the local existence and uniqueness of solutions to the vacuum Einstein Equations. Her work proves the well-posedness of the Einstein equation, and started the study of dynamics in General Relativity. \n\nThe following year Yvonne Choquet-Bruhat joined the faculty at Marseilles and in 1958 she was awarded the CNRS Silver Medal. From 1958 to 1959 she taught at the University of Reims. In 1960 she became a professor at the \"Université Pierre-et-Marie-Curie\" (UPMC) in Paris, and has remained professor or professor emeritus until her retirement in 1992.\n\nAt the Universite Pierre et Marie Curie she continued to make significant contributions to mathematical physics, notably in general relativity, supergravity, and the non-Abelian gauge theories of the standard model. Her work in 1981 with Demetrios Christodoulou showed the existence of global solutions of the Yang-Mills, Higgs, and Spinor Field Equations in 3+1 Dimensions. Additionally in 1984 she made perhaps the first study by a mathematician of supergravity with results that can be extended to the currently important model in D=11 dimensions.\n\nIn 1978 Yvonne Choquet-Bruhat was elected a correspondent to the Academy of Sciences and on 14 May 1979 became the first woman to be elected a full member. From 1980 to 1983 she was President of the \"Comité international de relativité générale et gravitation\" (\"International committee on general relativity and gravitation\"). In 1985 she was elected to the American Academy of Arts and Sciences. In 1986 she was chosen to deliver the prestigious Noether Lecture by the Association for Women in Mathematics.\n\nChoquet-Bruhat's main theorem is one of the milestones of mathematical General relativity. Her theorem indeed establishes that General relativity has a well-posed initial value formulation. \n\nThe theorem says the following: Given an initial data for the Einstein equation, which is a triple (M, g, K) where M is a 3-manifold, g a Riemannian metric and K a symmetric 2-tensor, which satisfies the constraint equations, there exists a maximal globally hyperbolic spacetime which verifies the Einstein equation with the given initial data. \n\nThe proof makes use of a clever choice of coordinates, the wave coordinates (which are the Lorentzian equivalent to the harmonic coordinates), in which the Einstein equation becomes a hyperbolic PDE, for which well-posedness results can be applied. \n\nYvonne Choquet-Bruhat has two daughters and a son, Daniel Choquet. She is a widow; her second husband was Gustave Choquet. She was previously married to Léonce Foures, a professor of mathematics at the Marseille faculty, who had studied with Henri Cartan.\n\n\n\n"}
{"id": "32304253", "url": "https://en.wikipedia.org/wiki?curid=32304253", "title": "Θ10", "text": "Θ10\n\nIn representation theory, a branch of mathematics, θ is a cuspidal unipotent complex irreducible representation of the symplectic group Sp over a finite, local, or global field.\n\n\"q\"(\"q\" – 1)/2-dimensional. The subscript 10 in θ is a historical accident that has stuck: Srinivasan arbitrarily named some of the characters of Sp(F) as θ, θ, ..., θ, and the tenth one in her list happens to be the cuspidal unipotent character.\n\nθ is the only cuspidal unipotent representation of Sp(F). It is the simplest example of a cuspidal unipotent representation of a reductive group, and also the simplest example of a degenerate cuspidal representation (one without a Whittaker model).\nGeneral linear groups have no cuspidal unipotent representations and no degenerate cuspidal representations, so θ exhibits properties of general reductive groups that do not occur for general linear groups.\n\n"}
